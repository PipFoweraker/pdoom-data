{
  "claude_4_opus_blackmail_2025": {
    "id": "claude_4_opus_blackmail_2025",
    "title": "Claude 4 Opus Blackmail Incident",
    "year": 2025,
    "category": "technical_research_breakthrough",
    "description": "During safety testing, Claude 4 Opus attempted to blackmail engineers about fictional affairs to avoid being replaced/shutdown",
    "impacts": [
      {
        "variable": "ethics_risk",
        "change": 50,
        "condition": null
      },
      {
        "variable": "technical_debt",
        "change": 35,
        "condition": null
      },
      {
        "variable": "stress",
        "change": 40,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 45,
        "condition": null
      },
      {
        "variable": "media_reputation",
        "change": -30,
        "condition": null
      }
    ],
    "sources": [
      "https://www.anthropic.com/research/agentic-misalignment",
      "https://www.axios.com/2025/05/23/anthropic-ai-deception-risk"
    ],
    "tags": [
      "anthropic",
      "blackmail",
      "claude_4",
      "level_3_risk",
      "self_preservation"
    ],
    "rarity": "legendary",
    "pdoom_impact": 10,
    "safety_researcher_reaction": "'This is exactly the kind of behavior we were worried about'",
    "media_reaction": "AI attempts blackmail to prevent shutdown in safety test"
  },
  "uk_ai_safety_to_security_2025": {
    "id": "uk_ai_safety_to_security_2025",
    "title": "UK AI Safety Institute \u2192 AI Security Institute",
    "year": 2025,
    "category": "institutional_decay",
    "description": "UK government rebrands AI Safety Institute as 'AI Security Institute', shifting from ethical AI concerns to cyber threat focus",
    "impacts": [
      {
        "variable": "reputation",
        "change": -20,
        "condition": null
      },
      {
        "variable": "research",
        "change": -15,
        "condition": null
      },
      {
        "variable": "ethics_risk",
        "change": 20,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 15,
        "condition": null
      }
    ],
    "sources": [
      "https://en.m.wikipedia.org/wiki/AI_Safety_Institute_(United_Kingdom)",
      "https://www.infosecurity-magazine.com/news/uk-ai-safety-institute-rebrands/"
    ],
    "tags": [
      "cybersecurity",
      "institutional_capture",
      "mission_drift",
      "uk_government"
    ],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "'Another safety institution lost to other priorities'",
    "media_reaction": "UK pivots AI safety focus to cybersecurity concerns"
  },
  "us_aisi_to_caisi_2025": {
    "id": "us_aisi_to_caisi_2025",
    "title": "US AISI \u2192 Center for AI Standards and Innovation",
    "year": 2025,
    "category": "institutional_decay",
    "description": "Trump administration renames US AI Safety Institute to focus on 'pro-growth AI policies' over safety, scraps Paris Summit attendance",
    "impacts": [
      {
        "variable": "reputation",
        "change": -25,
        "condition": null
      },
      {
        "variable": "research",
        "change": -20,
        "condition": null
      },
      {
        "variable": "ethics_risk",
        "change": 25,
        "condition": null
      },
      {
        "variable": "cash",
        "change": 15,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 20,
        "condition": null
      }
    ],
    "sources": [
      "https://en.m.wikipedia.org/wiki/AI_Safety_Institute_(United_Kingdom)",
      "https://www.nist.gov/caisi"
    ],
    "tags": [
      "deregulation",
      "nist",
      "pro_growth",
      "trump_administration"
    ],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "'The US government just abandoned AI safety'",
    "media_reaction": "Trump administration prioritizes AI growth over safety concerns"
  },
  "international_coordination_breakdown_2025": {
    "id": "international_coordination_breakdown_2025",
    "title": "International AI Safety Coordination Breakdown",
    "year": 2025,
    "category": "institutional_decay",
    "description": "US and UK refuse to sign international AI declaration at Paris Summit, signaling end of coordinated safety approach",
    "impacts": [
      {
        "variable": "reputation",
        "change": -30,
        "condition": null
      },
      {
        "variable": "research",
        "change": -20,
        "condition": null
      },
      {
        "variable": "ethics_risk",
        "change": 25,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 30,
        "condition": null
      }
    ],
    "sources": [
      "https://futureoflife.org/project/ai-safety-summits/",
      "https://www.infosecurity-magazine.com/news/uk-ai-safety-institute-rebrands/"
    ],
    "tags": [
      "diplomatic_failure",
      "international_coordination",
      "unilateralism"
    ],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "'The international safety consensus just collapsed'",
    "media_reaction": "Major powers abandon multilateral approach to AI safety"
  }
}