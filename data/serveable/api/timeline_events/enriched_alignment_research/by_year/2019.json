[
  {
    "id": "arxiv_30d197f2abc4241f",
    "title": "Theoretically Principled Trade-off between Robustness and Accuracy",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1901.08573"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "30d197f2abc4241ff2e83d3701c25509"
  },
  {
    "id": "arxiv_b63f209cc6a759ef",
    "title": "Forecasting Transformative AI: An Expert Survey",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "Forecasting Transformative AI: An Expert Survey  Ross Gruetzemacher, David Paradice, Kang Bok Lee Auburn University, Harbert College of Business, Department of Systems and Technology   Abstract Transformative AI technologies have the potential to reshape critical aspects of society in the near future. In order to properly prepare policy initiatives for the arrival of such technologies accurate forecasts and timelines are necessary. A survey was administered to attendees of three AI conferences in 2018 (ICML, IJCAI and the HLAI conference). The survey included calibration questions, questions for estimating AI capabilities over the next decade, questions for forecasting five scenarios of transformative AI and questions concerning the impact of computational resources in AI research. Respondents indicated a median of 21.5% of human tasks (i.e., all tasks that humans are currently paid to do) can be feasibly automated now, and that this figure would rise to 40% in 5 years and 60% in 10...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1901.08579"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "b63f209cc6a759ef2e075137c82a818d"
  },
  {
    "id": "arxiv_f950f006f5efb012",
    "title": "Lyapunov-based Safe Policy Optimization for Continuous Control",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1901.10031"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "f950f006f5efb0120eb9dee0cce6e6c4"
  },
  {
    "id": "arxiv_50eceef4c4b20c6e",
    "title": "Human-Centered Artificial Intelligence and Machine Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1901.11184"
    ],
    "tags": [],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "50eceef4c4b20c6eb868b1193d898439"
  },
  {
    "id": "arxiv_90b5d7af9f5da8bf",
    "title": "Hybrid Models with Deep and Invertible Features",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1902.02767"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "90b5d7af9f5da8bf23e5e5b257801a3f"
  },
  {
    "id": "arxiv_7a25f9dac2f07281",
    "title": "Certified Adversarial Robustness via Randomized Smoothing",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1902.02918"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "7a25f9dac2f07281da16f94325ffa083"
  },
  {
    "id": "arxiv_e10bd434793cbcb9",
    "title": "Preferences Implicit in the State of the World",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1902.04198"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "e10bd434793cbcb959da40a40b8ebe69"
  },
  {
    "id": "arxiv_fd1a8691241568fd",
    "title": "Deep Reinforcement Learning from Policy-Dependent Human Feedback",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1902.04257"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "fd1a8691241568fdea23389e94e6d488"
  },
  {
    "id": "arxiv_42b5c7670cdc45c0",
    "title": "Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1902.06162"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "42b5c7670cdc45c040d2a40caa773e27"
  },
  {
    "id": "arxiv_919161b4469fbbd2",
    "title": "Parenting: Safe Reinforcement Learning from Human Input",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1902.06766"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "919161b4469fbbd27a582c674cfb5ec9"
  },
  {
    "id": "arxiv_c47368892bef3139",
    "title": "Regularizing Black-box Models for Improved Interpretability",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1902.06787"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "c47368892bef3139e5e80a2c8c846521"
  },
  {
    "id": "arxiv_96cde62c4dd6e7be",
    "title": "Meta-Weight-Net: Learning an Explicit Mapping For Sample Weighting",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1902.07379"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "96cde62c4dd6e7be161f0df82b1b1e83"
  },
  {
    "id": "arxiv_4b97d1dac7514262",
    "title": "World Discovery Models",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1902.07685"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "4b97d1dac7514262eae5edd5cb42782b"
  },
  {
    "id": "arxiv_0ab857cd2ee86671",
    "title": "Embedded Agency",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1902.09469"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "0ab857cd2ee86671502df2e380403f1d"
  },
  {
    "id": "arxiv_f5844f3a6e4347ca",
    "title": "Using Causal Analysis to Learn Specifications from Task Demonstrations",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1903.01267"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "f5844f3a6e4347ca877dc243cded9814"
  },
  {
    "id": "arxiv_9ab3cecfa4c1951e",
    "title": "Learning Exploration Policies for Navigation",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1903.01959"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "9ab3cecfa4c1951e55b7e2a5d128856b"
  },
  {
    "id": "arxiv_2fe8faa00c606c51",
    "title": "Learning Latent Plans from Play",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "\\thesection Introduction\n-------------------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1903.01973"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "2fe8faa00c606c51a8a2c3b46ab2fd84"
  },
  {
    "id": "arxiv_1bb63b4bece57ce3",
    "title": "Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1903.03096"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "1bb63b4bece57ce3ad8319c63c479e7e"
  },
  {
    "id": "arxiv_83849de1b9cb57cf",
    "title": "Deep Reinforcement Learning with Feedback-based Exploration",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1903.06151"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "83849de1b9cb57cf72aef0469b6c9dc6"
  },
  {
    "id": "arxiv_e0cdee14a523d8d2",
    "title": "Gradient Descent with Early Stopping is Provably Robust to Label Noise for Overparameterized Neural Networks",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1903.11680"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "e0cdee14a523d8d2dad74cb1d271241a"
  },
  {
    "id": "arxiv_047b16216740d354",
    "title": "Predicting human decisions with behavioral theories and machine learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 \n \n  \nPredicting human decisions with behavioral theories and machine learning   \nPlonsky,  Ori1a; Apel, Reuta; Ert, Eyalb; Tennenholtz, Moshea; Bourgin, Davidc; Peterson , Joshua , \nC.c; Reichman, Danielc; Griffiths , Thomas L.c; Russell , Stuart , J.d; Carter, Evan,  C.e; Cavanagh , \nJames , F.f; Erev, Idoa \na Technion - Israel Institute of Technology ; b The Hebrew  University of Jerusalem ; c Princeton  \nUniversity ; d University  of California, Berkeley ; e United  States Army Research Laboratory ; f \nThe University of New Mexico .  \n \nAbstract  \nBehavioral decision theories aim to explain human behavior. Can they help predict it? An open \ntournament for prediction of human choices in fundamental economic decision tasks is \npresented. The results suggest that integration of certain behavioral theorie s as features in \nmachine learning systems provides the best predictions. Surprisingly, the most useful theories for \nprediction build on basic properties of human and animal lea...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1904.06866"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "047b16216740d354a2ee5d8d7e21144d"
  },
  {
    "id": "arxiv_4ba32345a0367d2b",
    "title": "Optimization and Abstraction: A Synergistic Approach for Analyzing Neural Network Robustness",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1904.09959"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "4ba32345a0367d2bd3b18a59598528c6"
  },
  {
    "id": "arxiv_e551f77f4bbceddc",
    "title": "Transfer of Adversarial Robustness Between Perturbation Types",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1905.01034"
    ],
    "tags": [],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "e551f77f4bbceddcfccc7e010d960faa"
  },
  {
    "id": "arxiv_6353ef31023a168c",
    "title": "Adversarial Examples Are Not Bugs, They Are Features",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1905.02175"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "6353ef31023a168ceea35bc577748baf"
  },
  {
    "id": "arxiv_2ff079707f380773",
    "title": "Cognitive Model Priors for Predicting Human Decisions",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1905.09397"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Published in academic venue",
    "source_id": "2ff079707f38077331526ea3ee5ce378"
  },
  {
    "id": "arxiv_aa9a7266e2a3f6e8",
    "title": "Asymptotically Unambitious Artificial General Intelligence",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1905.12186"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "aa9a7266e2a3f6e8f34d60effc31a650"
  },
  {
    "id": "arxiv_5d45e51f2ea6d22b",
    "title": "Adversarial Robustness as a Prior for Learned Representations",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1906.00945"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "5d45e51f2ea6d22bdcb9d30310c79a00"
  },
  {
    "id": "arxiv_7775b0d3b8cbad17",
    "title": "Can You Trust Your Model's Uncertainty? Evaluating Predictive Uncertainty Under Dataset Shift",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1906.02530"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "7775b0d3b8cbad1703c53161c4e12115"
  },
  {
    "id": "arxiv_8e8ab37d7a89166c",
    "title": "An Extensible Interactive Interface for Agent Design",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1906.02641"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "8e8ab37d7a89166c80aa3ca36539e811"
  },
  {
    "id": "arxiv_0b830fb1671c291a",
    "title": "Likelihood Ratios for Out-of-Distribution Detection",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1906.02845"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "0b830fb1671c291a00adc2516fc8fd9b"
  },
  {
    "id": "arxiv_0a1c13b3bb93cd64",
    "title": "Weight Agnostic Neural Networks",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1906.04358"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "0a1c13b3bb93cd641700d3f269e30a86"
  },
  {
    "id": "arxiv_30334862e967a234",
    "title": "Categorizing Wireheading in Partially Embedded Agents",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1906.09136"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "30334862e967a2341fef9742c2e699b0"
  },
  {
    "id": "arxiv_060a27387c4518c0",
    "title": "Image Synthesis with a Single (Robust) Classifier",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1906.09453"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "060a27387c4518c01b642d1e5bb387d2"
  },
  {
    "id": "arxiv_6d55735612b0d645",
    "title": "Reinforcement Learning with Competitive Ensembles of Information-Constrained Primitives",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1906.10667"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "6d55735612b0d6459ba51dc5f6d07b5c"
  },
  {
    "id": "arxiv_8921c4e2df86ea16",
    "title": "Generalizing from a few environments in safety-critical reinforcement learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1907.01475"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "8921c4e2df86ea1656794ff5682c1f63"
  },
  {
    "id": "arxiv_a2fa77ab4077cf22",
    "title": "The Role of Cooperation in Responsible AI Development",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "Introduction\n------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1907.04534"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "a2fa77ab4077cf22ca4255482ea069af"
  },
  {
    "id": "arxiv_3514608b30257527",
    "title": "An Inductive Synthesis Framework for Verifiable Reinforcement Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1907.07273"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "3514608b30257527e6af3fcc3acf59ed"
  },
  {
    "id": "arxiv_fadbd429d0fa7b3f",
    "title": "Reducing malicious use of synthetic media research: Considerations and potential release practices for machine learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1907.11274"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "fadbd429d0fa7b3ff2fc4e373dd95b00"
  },
  {
    "id": "arxiv_82972a89dab65e8f",
    "title": "Reward Tampering Problems and Solutions in Reinforcement Learning: A Causal Influence Diagram Perspective",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1908.04734"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Academic research release",
    "source_id": "82972a89dab65e8fae8f8521ae4a290f"
  },
  {
    "id": "arxiv_669a2a89fe0b6b86",
    "title": "Implications of Quantum Computing for Artificial Intelligence alignment research",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "IMPLICATIONS OF QUANTUM COMPUTING FOR\n?\nARTIFICIAL INTELLIGENCE ALIGNMENT RESEARCH\n?\nby Jaime Sevilla\n and Pablo Moreno\n?\n1\n2\nABSTRACT:\nWe\nexplain\nthe\nkey\nfeatures\nof\nquantum\ncomputing\nvia\nthree\nheuristics\nand\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\napply\nthem\nto\nargue\nthat\na\ndeep\nunderstanding\nof\nquantum\ncomputing\nis\nunlikely\nto\nbe\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\nhelpful to address current bottlenecks in Artificial Intelligence Alignment.\n?\n?\nOur\nargument\nrelies\non\nthe\nclaims\nthat\nQuantum\nComputing\nleads\nto\ncompute\noverhang\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\ninstead\nof\nalgorithmic\noverhang,\nand\nthat\nthe\ndifficulties\nassociated\nwith\nthe\nmeasurement\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\nof\nquantum\nstates\ndo\nnot\ninvalidate\nany\nmajor\nassumptions\nof\ncurrent\nArtificial\nIntelligence\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\nAlignment research agendas.\n?\n?\nWe\nalso\ndiscuss\ntripwiring,\nadversarial\nblinding,\ninformed\noversight\nand\nside\neffects\nas\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\npossible exceptions.\n?\nKEYWORDS:\nQuantum\nComputing,\nArtificial\nIntelligence\nA...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1908.07613"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "669a2a89fe0b6b8658602a2d069bba39"
  },
  {
    "id": "arxiv_3d733b9f6a6b6091",
    "title": "Testing Robustness Against Unforeseen Adversaries",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1908.08016"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "3d733b9f6a6b6091cb45b2bea11e5c93"
  },
  {
    "id": "arxiv_f48be4c3fb9d9ad0",
    "title": "Release Strategies and the Social Impacts of Language Models",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "OpenAI ReportNovember,2019Release Strategies and theSocialImpacts of Language ModelsIreneSolaiman?OpenAIB`2M2!QT2M\u001cBX+QKMilesBrundageOpenAIKBH2b!QT2M\u001cBX+QKJackClarkOpenAID\u001c+F!QT2M\u001cBX+QKAmandaAskellOpenAI\u001cK\u001cM/\u001c!QT2M\u001cBX+QKArielHerbert-VossHarvardUniversity\u001c`B2Hn?2`#2`ipQbb!;X?\u001c`p\u001c`/X2/mJeffWuOpenAID277rm!QT2M\u001cBX+QKAlecRadfordOpenAI\u001cH2+!QT2M\u001cBX+QKGretchenKruegerOpenAI;`2i+?2M!QT2M\u001cBX+QKJong WookKimOpenAIDQM;rQQF!QT2M\u001cBX+QKSarahKrepsCornellUniversityb\u001c`\u001c?XF`2Tb!+Q`M2HHX2/mMiles McCainPolitiwatchKBH2b!`K`KXBQAlex NewhouseCTEC\u001cM2r?Qmb2!KB//H2#m`vX2/mJasonBlazakisCTECD#H\u001cx\u001cFBb!KB//H2#m`vX2/mKris McGuffieCTECEK+;m77B2!KB//H2#m`vX2/mJasmine WangOpenAID\u001cbKBM2!QT2M\u001cBX+QK\n?Listedindescendingorderofcontribution.\nContentsOverview..............................................11 Staged Release.........................................22 Partnerships..........................................33 Engagement..........................................44 Social Impacts of Large Language Models.................",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1908.09203"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "f48be4c3fb9d9ad0592fb15af644c0fb"
  },
  {
    "id": "arxiv_855de84aa73b3e51",
    "title": "Achieving Verified Robustness to Symbol Substitutions via Interval Bound Propagation",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1909.01492"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "855de84aa73b3e514946a208515b7694"
  },
  {
    "id": "arxiv_4f0c4f943196c1b6",
    "title": "Meta-Inverse Reinforcement Learning with Probabilistic Context Variables",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1909.09314"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Published in academic venue",
    "source_id": "4f0c4f943196c1b6b7b663a661ba7c0f"
  },
  {
    "id": "arxiv_59f6f938d8b690b2",
    "title": "Formal Language Constraints for Markov Decision Processes",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1910.01074"
    ],
    "tags": [],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "59f6f938d8b690b2c9ee1a0aa314e35a"
  },
  {
    "id": "arxiv_73478b418cc33143",
    "title": "Scaled Autonomy: Enabling Human Operators to Control Robot Fleets",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1910.02910"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "73478b418cc331431af728c2ee6d56db"
  },
  {
    "id": "arxiv_9bb1056693c6746e",
    "title": "On the Utility of Learning about Humans for Human-AI Coordination",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1910.05789"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "9bb1056693c6746e757975141d1574ca"
  },
  {
    "id": "arxiv_5c831da76432b236",
    "title": "An Alternative Surrogate Loss for PGD-based Adversarial Testing",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1910.09338"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "5c831da76432b236a058fa254d49b1c4"
  },
  {
    "id": "arxiv_6026676ef70b61b3",
    "title": "Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1910.10897"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "6026676ef70b61b371b5a8945a90540c"
  },
  {
    "id": "arxiv_d2f51e0350d35221",
    "title": "A Hamilton-Jacobi Reachability-Based Framework for Predicting and Analyzing Human Motion for Safe Planning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1910.13369"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "d2f51e0350d3522167886b4f5b8d42e2"
  },
  {
    "id": "arxiv_6c033586fd63cd2e",
    "title": "On the Measure of Intelligence",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "I Context and history\n----------------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1911.01547"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "6c033586fd63cd2eef2c414f74b9d305"
  },
  {
    "id": "arxiv_5223826fba8bc976",
    "title": "Nonverbal Robot Feedback for Human Teachers",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1911.02320"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "5223826fba8bc976904ad4b739288025"
  },
  {
    "id": "arxiv_135efea1cd78b777",
    "title": "(When) Is Truth-telling Favored in AI Debate?",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1911.04266"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "135efea1cd78b777ce408b28bc082fee"
  },
  {
    "id": "arxiv_623d2a613c808d33",
    "title": "Scaling Out-of-Distribution Detection for Real-World Settings",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1911.11132"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "623d2a613c808d33657d2068cf143f40"
  },
  {
    "id": "arxiv_cdb5c302cf99a7be",
    "title": "SafeLife 1.0: Exploring Side Effects in Complex Environments",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1912.01217"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "cdb5c302cf99a7be2bc503ca5fa99588"
  },
  {
    "id": "arxiv_352fdb904551171a",
    "title": "Optimal Policies Tend to Seek Power",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1912.01683"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "352fdb904551171a1a3031f5b2c0e608"
  },
  {
    "id": "arxiv_fae8082a3663346b",
    "title": "Learning Efficient Representation for Intrinsic Motivation",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1912.02624"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "fae8082a3663346be5c37dae351c0c1f"
  },
  {
    "id": "arxiv_bedbb9cfa9a577eb",
    "title": "Deep Ensembles: A Loss Landscape Perspective",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1912.02757"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "bedbb9cfa9a577ebe9376c55927c4d9f"
  },
  {
    "id": "arxiv_e05f8c3e7a81ae95",
    "title": "Learning Human Objectives by Evaluating Hypothetical Behavior",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1912.05652"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "e05f8c3e7a81ae955fe7f37b1972e757"
  },
  {
    "id": "arxiv_ecfece2c5b40a7df",
    "title": "Dota 2 with Large Scale Deep Reinforcement Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "Research publication: Dota 2 with Large Scale Deep Reinforcement Learning",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1912.06680"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "ecfece2c5b40a7df6a174d6db46cc72e"
  },
  {
    "id": "arxiv_f69600bf4fb8749b",
    "title": "Generative Teaching Networks: Accelerating Neural Architecture Search by Learning to Generate Synthetic Training Data",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction and Related Work\n--------------------------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1912.07768"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "f69600bf4fb8749b09909298aeb68f8a"
  },
  {
    "id": "arxiv_b09f079287d7fbd3",
    "title": "Mastering Complex Control in MOBA Games with Deep Reinforcement Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "Introduction\n------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1912.09729"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "b09f079287d7fbd3f53897adf2ac57ca"
  },
  {
    "id": "arxiv_fa408ad6b951e2be",
    "title": "Asking the Right Questions: Learning Interpretable Action Models Through Query Answering",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1912.12613"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "fa408ad6b951e2be15de9bf172f8df04"
  },
  {
    "id": "arxiv_b4656685cd55f878",
    "title": "Making AI meaningful again",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 The current paradigm of AI: Agnostic Deep Neural Networks (dNNs)\n-------------------------------------------------------------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1901.02918"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "b4656685cd55f878c25512c54fce5843"
  },
  {
    "id": "arxiv_61517cf54fe17bd5",
    "title": "A New Tensioning Method using Deep Reinforcement Learning for Surgical Pattern Cutting",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1901.03327"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "61517cf54fe17bd587b28e6d2c6bd513"
  },
  {
    "id": "arxiv_1ae584b18d1d3cb2",
    "title": "PUTWorkbench: Analysing Privacy in AI-intensive Systems",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1902.01580"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "1ae584b18d1d3cb27b8f7da4f90e6af2"
  },
  {
    "id": "arxiv_f568f9a05f383d1d",
    "title": "Ask Not What AI Can Do, But What AI Should Do: Towards a Framework of Task Delegability",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1902.03245"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "f568f9a05f383d1d188dbed83de33efb"
  },
  {
    "id": "arxiv_8dfe174756251e0d",
    "title": "Hacking Google reCAPTCHA v3 using Reinforcement Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1903.01003"
    ],
    "tags": [],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "8dfe174756251e0dc34b08231bdd7920"
  },
  {
    "id": "arxiv_266a1fefecfd5b20",
    "title": "Challenges for an Ontology of Artificial Intelligence",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Challenges for an Ontology of Artificial Intelligence Scott H. Hawley Department of Chemistry & Physics, Belmont University, Nashville TN USA   Abstract: Of primary importance in formulating a response to the increasing prevalence and power of artificial intelligence (AI) applications in society are questions of ontology. Questions such as: What ?are? these systems?  How are they to be regarded?  How does an algorithm come to be regarded as an agent?  We discuss three factors which hinder discussion and obscure attempts to form a clear ontology of AI: (1) the various and evolving definitions of AI, (2) the tendency for pre-existing technologies to be assimilated and regarded as ?normal,? and (3) the tendency of human beings to anthropomorphize.  This list is not intended as exhaustive, nor is it seen to preclude entirely a clear ontology, however, these challenges are a necessary set of topics for consideration.  Each of these factors is seen to present a 'moving target' for discu...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1903.03171"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "266a1fefecfd5b204686ddce2ff10447"
  },
  {
    "id": "arxiv_6d9c643dc346070e",
    "title": "The Ethics of AI Ethics -- An Evaluation of Guidelines",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 \n  \nThe Ethics of AI Ethics  \nAn Evaluation  of Guidelines  \n \n \nDr. Thilo Hagendorff  \nUniversity of Tuebingen  \nInternational Center for Ethics in the Sciences and Humanities  \nthilo.hagendorff@uni -tuebingen.de  \n \n \n \nAbstract  - Current advances in research, development \nand application of  artificial intelligence (AI) systems \nhave yielded  a far -reaching discourse on AI ethics. In \nconsequence , a number of  ethics guidelines h ave been \nreleased  in recent years. These guidelines comprise  \nnormative principles and recommendations aimed to \nharness  the ?disruptive? potential s of new  AI \ntechnolog ies. Designed as  a comprehensive evaluation , \nthis paper analy zes and compares these guidelines \nhighlighting overlaps but also omissions. As a result , I \ngive a detailed  overview of the field of AI ethics. Finally, \nI also examine  to what extent the respective ethical \nprinciples and values are implemented in the practice \nof research, development and application of AI ...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1903.03425"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "6d9c643dc346070e111e011b89b0227d"
  },
  {
    "id": "arxiv_4e6e866ec66e13ee",
    "title": "Improving Safety in Reinforcement Learning Using Model-Based Architectures and Human Intervention",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "Introduction\n------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1903.09328"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Academic research release",
    "source_id": "4e6e866ec66e13ee6a0eb816ebf7bff4"
  },
  {
    "id": "arxiv_2c321a00435b902b",
    "title": "Designing Normative Theories for Ethical and Legal Reasoning: LogiKEy Framework, Methodology, and Tool Support",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1903.10187"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "2c321a00435b902b01d250e9d3350687"
  },
  {
    "id": "arxiv_7260b5451ca708a2",
    "title": "Informed Machine Learning -- A Taxonomy and Survey of Integrating Knowledge into Learning Systems",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1903.12394"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "7260b5451ca708a208e5c3b0819d2a8f"
  },
  {
    "id": "arxiv_486e51b6eca9e021",
    "title": "Extending planning knowledge using ontologies for goal opportunities",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "Extending planning knowledge using ontologies for goal opportunities  \n \nMohannad Babli, Universitat Polit?cnica de Val?ncia, Department of Computer Systems and \nComputation, Valencia, Spain, mobab@dsic.upv.es  \nEva Onaindia, Universitat Polit?cnica de Val?ncia, Department of Computer Systems and \nComputation, Valencia, Spain, onaindia@dsic.upv.es  \nEliseo Marzal, Universitat Polit?cnica de Val?ncia, Department of Computer Syst ems and \nComputation, Valencia, Spain, emarzal@dsic.upv.es  \n \nAbstract.  Approaches to goal -directed behaviour  including online planning and opportunistic \nplanning tackle a change in the environment by generating alternative goals to avoid failures or seize \nopportunities. However, current approaches only address unanticipated changes related to objects or \nobject t ypes already defined in the planning task that is being solved. This article describes a domain -\nindependent approach that advances the state of the art by extending the knowledge of a planni...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1904.03606"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "486e51b6eca9e0218cb92722a407efc5"
  },
  {
    "id": "arxiv_ec9006a24eeee38c",
    "title": "Counterfactual Visual Explanations",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1904.07451"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "ec9006a24eeee38c1528c90760ba4e47"
  },
  {
    "id": "arxiv_45fa4bad8ce1fd79",
    "title": "Risk Structures: Towards Engineering Risk-aware Autonomous Systems",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "arXiv:1904.10386v1  [cs.SE]  23 Apr 2019RISKSTRUCTURES : TOWARDS ENGINEERING RISK-AWARE\nAUTONOMOUS SYSTEMS\nA P REPRINT\nMario Gleirscher\nComputer Science Department, University of York, York, UK?\nApril 24, 2019\nABSTRACT\nInspired by widely-used techniques of causal modelling in r isk, failure, and accident analysis, this\nwork discusses a com positional framework for risk modellin g. Risk models capture fragments of\nthe space of risky events likely to occur when operating a mac hine in a given environment. More-\nover, one can build such models into machines such as autonom ous robots, to equip them with the\nability of risk-aware perception, monitoring, decision ma king, and control. With the notion of a\nrisk factor as the modelling primitive, the framework provi des several means to construct and shape\nrisk models. Relational and algebraic properties are inves tigated and proofs support the validity and\nconsistency of these properties over the corresponding mod els. Several examples th...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1904.10386"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "45fa4bad8ce1fd796f7b3835c1b8711d"
  },
  {
    "id": "arxiv_cbf09e13232824de",
    "title": "Knowing When to Stop: Evaluation and Verification of Conformity to Output-size Specifications",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1904.12004"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "cbf09e13232824de9b9b3fbeaae7fdb6"
  },
  {
    "id": "arxiv_f3f72edbee43cb38",
    "title": "The relationship between Biological and Artificial Intelligence",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 From Symbolic AI to Machine Learning\n---------------------------------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1905.00547"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "f3f72edbee43cb389d03527008deceac"
  },
  {
    "id": "arxiv_f2b465bed533cd9f",
    "title": "Lie on the Fly: Strategic Voting in an Iterative Preference Elicitation Process",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1905.04933"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "f2b465bed533cd9fbfab2e631f50f26f"
  },
  {
    "id": "arxiv_1d8c98b2b9f9dbab",
    "title": "From What to How: An Initial Review of Publicly Available AI Ethics Tools, Methods and Research to Translate Principles into Practices",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "From What to How: An Initial Review of Publicly Available AI Ethics Tools, Methods and Research to Translate Principles into Practices   Jessica Morley1, Luciano Floridi1,2, Libby Kinsey3, Anat Elhalal3  1 Oxford Internet Institute, University of Oxford, 1 St Giles?, Oxford, OX1 3JS 2 Alan Turing Institute, British Library, 96 Euston Rd, London NW1 2DB 3 Digital Catapult, 101 Euston Road, Kings Cross, London, NW1 2RA  Abstract  The debate about the ethical implications of Artificial Intelligence dates from the 1960s (Samuel, 1960; Wiener, 1961). However, in recent years symbolic AI has been complemented and sometimes replaced by (Deep) Neural Networks and Machine Learning (ML) techniques. This has vastly increased its potential utility and impact on society, with the consequence that the ethical debate has gone mainstream. Such a debate has primarily focused on principles?the ?what? of AI ethics (beneficence, non-maleficence, autonomy, justice and explicability)?rather than on pract...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1905.06876"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "1d8c98b2b9f9dbab05957e92aa8c598f"
  },
  {
    "id": "arxiv_a9df46959c30e10d",
    "title": "On modelling the emergence of logical thinking",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "Introduction\n------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1905.09730"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "a9df46959c30e10d9aba7e5e093629b6"
  },
  {
    "id": "arxiv_9b07c785b4cee566",
    "title": "Better Future through AI: Avoiding Pitfalls and Guiding AI Towards its Full Potential",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1905.13178"
    ],
    "tags": [],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "9b07c785b4cee566bb90f482705f0831"
  },
  {
    "id": "arxiv_f39e06c0ba936138",
    "title": "Learner-aware Teaching: Inverse Reinforcement Learning with Preferences and Constraints",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1906.00429"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "f39e06c0ba93613877b99ea3f9030997"
  },
  {
    "id": "arxiv_18def41ad9ebddf1",
    "title": "An AGI with Time-Inconsistent Preferences",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "An AGI with Time -Inconsistent  Preferences  \n \nMay 28, 2019  \n \nJames D. Miller and Roman Yampolskiy  \n \nJdmiller@Smith.edu , roman.yampolskiy@louisville. edu   \n \n \nIntroduction  \n \n \nThis paper reveals  a trap for artificial  general intelligence (AGI) theorists who use  economists? standard \nmethod of discounting.   This trap is implicitly and falsely assuming that a rational AGI would  have time -\nconsistent preferences.  An agent with time -inconsistent preferences knows that its future self will \ndisagree with its current se lf concerning intertemporal decision making .  Such an agent cannot \nautomatically trust its future self to carry out plans that its current  self considers optimal.  \n \nEconomists have long used utility functions to model how rational agents behave  (see Mas -Colell  et al. , \n1995) .  AGI theorists often rely on these utility function s because they assume that an AGI would  either \nstart out as  rational or modify itself to become rational  (see Omohun...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1906.10536"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "18def41ad9ebddf14f29e506e7df9d1b"
  },
  {
    "id": "arxiv_acb8ec6d2eca4a07",
    "title": "Integration of Imitation Learning using GAIL and Reinforcement Learning using Task-achievement Rewards via Probabilistic Graphical Model",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1907.02140"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "acb8ec6d2eca4a070ddd9844ffd23626"
  },
  {
    "id": "arxiv_5de2b48b2c1f89fb",
    "title": "Artificial Intelligence Governance and Ethics: Global Perspectives",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "Artificial Intelligence \nGovernance and Ethics: \nGlobal Perspectives  \n \nReport  \n28 June 2019  \n \n \nAuthors:  \nAngela Daly, Thilo Hagendorf f, Li Hui, Monique Mann, Vidushi \nMarda, Ben Wagner, Wei Wang and Saskia Witteborn  \n \n \n \nThis report is supported by Angela Daly?s Chinese University of Hong Kong 2018 -2019 Direct Grant \nfor Research 2018 -2019 ?Governing the Future: How are Major Jurisdictions Tackling the Issue of \nArtificial Intelligence, Law and Ethics??  \n \n \n \nReleased under a Creative Commons CC BY -ND Attributio n-NoDerivs licence.  \n \n \n \nThe authors acknowledge the research assistance of Ms Jing Bei and Mr Sunny Ka Long Chan, and \nthe comments and observations from participants in the CUHK Law Global Governance of AI and \nEthics workshop, 20 -21 June 2019.  \n  \nARTIFICIAL INTELLIGENCE GOVERNANCE AND ETHICS: GLOBAL PERSPECTIVES  \n \nTable of C ontents  \nTable of Contents  2 \nAuthor biographies  3 \n1. Introduction  5 \nWhat is AI?  5 \nAI and Ethics  5 \nWhat does ?ethic...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1907.03848"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "5de2b48b2c1f89fb21bb09c8b0d58030"
  },
  {
    "id": "arxiv_3f342b07edb81627",
    "title": "Grounding Value Alignment with Ethical Principles",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1907.05447"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Academic research release",
    "source_id": "3f342b07edb81627f49fa61b3db643a4"
  },
  {
    "id": "arxiv_8c5a3cc4714aba1a",
    "title": "A system of different layers of abstraction for artificial intelligence",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "A system of different layers of abstraction for artificial \nintelligence  \nAlexander Serb, Themistoklis Prodromakis  \nUniveristy of Southampton, UK  \n \nThe field of artificial intelligence (AI) represents an enormous endeavour of humankind that is \ncurrently  transform ing our societies down to their very foundations. Its task,  building truly \nintelligent systems , is underpinned by a vast array of subfields ranging from the development of \nnew electronic components to mathematical formulations of highly abstract and complex reasoning. \nThis breadth of subfields renders it often difficul t to understand how they all fit  together into a \nbigger picture and hides the multi -faceted, multi -layered conceptual structure that in a sense can \nbe said to be what AI truly is . In this perspective we propose a system  of five levels /layers  of \nabstraction that underpin many AI implementations . We further posit that each layer is subject to \na complexity -performance trade -off whilst  d...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1907.10508"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "8c5a3cc4714aba1a63218bf0c79cc805"
  },
  {
    "id": "arxiv_bcfb223ceb5af178",
    "title": "Towards a Theory of Intentions for Human-Robot Collaboration",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1907.13275"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "bcfb223ceb5af178f44cf065cdee9397"
  },
  {
    "id": "arxiv_a7ee381d857e98a8",
    "title": "Neural Simplex Architecture",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1908.00528"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "a7ee381d857e98a8e9c68be066943f70"
  },
  {
    "id": "arxiv_423dcda046865535",
    "title": "Better AI through Logical Scaffolding",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1909.06965"
    ],
    "tags": [],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "423dcda046865535a079901768f2ebba"
  },
  {
    "id": "arxiv_eb20cd0d24a7d685",
    "title": "Emergent Tool Use From Multi-Agent Autocurricula",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "Research publication: Emergent Tool Use From Multi-Agent Autocurricula",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1909.07528"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "eb20cd0d24a7d6850d36c21a96aab7ee"
  },
  {
    "id": "arxiv_1dc156388ea7c94a",
    "title": "From the Internet of Information to the Internet of Intelligence",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1909.08068"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "1dc156388ea7c94a7c61a1352ee40af4"
  },
  {
    "id": "arxiv_4a42a1e94a9df88b",
    "title": "Towards Deployment of Robust AI Agents for Human-Machine Partnerships",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1910.02330"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "4a42a1e94a9df88b4eae9a33bc1df6e3"
  },
  {
    "id": "arxiv_ad8f9548298ee546",
    "title": "Can We Distinguish Machine Learning from Human Learning?",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1910.03466"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "ad8f9548298ee5468a1ba59b120ac242"
  },
  {
    "id": "arxiv_18135125de8f50d6",
    "title": "Improving Generalization in Meta Reinforcement Learning using Learned Objectives",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1910.04098"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "18135125de8f50d6919b5fe9d7a86e5b"
  },
  {
    "id": "arxiv_3507b1dfd2ca4512",
    "title": "Asking Easy Questions: A User-Friendly Approach to Active Reward Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1910.04365"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Academic research release",
    "source_id": "3507b1dfd2ca4512a7cc8812569ce409"
  },
  {
    "id": "arxiv_0ea949bb15660a63",
    "title": "The Quest for Interpretable and Responsible Artificial Intelligence",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1910.04527"
    ],
    "tags": [],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "0ea949bb15660a63ac8a9da71860db9a"
  },
  {
    "id": "arxiv_a5e4ac92c362434f",
    "title": "Using AI/ML to gain situational understanding from passive network observations",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1910.06266"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "a5e4ac92c362434f205fc758473236b6"
  },
  {
    "id": "arxiv_1e39f0a284624af1",
    "title": "How can AI Automate End-to-End Data Science?",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction and Motivation\n------------------------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1910.14436"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "1e39f0a284624af12b314836b846b149"
  },
  {
    "id": "arxiv_0e7d9ea18dd95c60",
    "title": "Generating Justifications for Norm-Related Agent Decisions",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1911.00226"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "0e7d9ea18dd95c60fb274334a5aaf66e"
  },
  {
    "id": "arxiv_b7e2676767766152",
    "title": "The relationship between trust in AI and trustworthy machine learning technologies",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1912.00782"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "b7e2676767766152882c5bda31a9d97d"
  },
  {
    "id": "arxiv_8ac12fda3d813829",
    "title": "Adaptive Online Planning for Continual Lifelong Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1912.01188"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "8ac12fda3d81382980f33ad55338ce49"
  },
  {
    "id": "arxiv_dcd0a0556ebfc56a",
    "title": "Interactive AI with a Theory of Mind",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1912.05284"
    ],
    "tags": [],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "dcd0a0556ebfc56ad048df9140c995f3"
  },
  {
    "id": "arxiv_285e08b9eeca3f26",
    "title": "Anti-Alignments -- Measuring The Precision of Process Models and Event Logs",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1912.05907"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "285e08b9eeca3f268751d175ee7145dd"
  },
  {
    "id": "arxiv_f1558dd5b768a522",
    "title": "Why we need an AI-resilient society",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1912.08786"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "f1558dd5b768a5226ec3044cc2f4aced"
  },
  {
    "id": "arxiv_8284c45318e073dc",
    "title": "Questions to Guide the Future of Artificial Intelligence Research",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "Key Points\n----------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1912.10305"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Published in academic venue",
    "source_id": "8284c45318e073dcda8af159093bc838"
  },
  {
    "id": "arxiv_6963078acea43dba",
    "title": "Defining AI in Policy versus Practice",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1912.11095"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "6963078acea43dbac5071b09cf57cb9e"
  },
  {
    "id": "arxiv_b9a647ad554c990a",
    "title": "Uncertainty-Based Out-of-Distribution Classification in Deep Reinforcement Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 INTRODUCTION\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2001.00496"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "b9a647ad554c990a5507d0f57de0a513"
  },
  {
    "id": "arxiv_a444c76549f57bb1",
    "title": "Paired Open-Ended Trailblazer (POET): Endlessly Generating Increasingly Complex and Diverse Learning Environments and Their Solutions",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1901.01753"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Academic research release",
    "source_id": "a444c76549f57bb1172c5b8c9a1dae55"
  },
  {
    "id": "arxiv_5089b9ff46e9fa8a",
    "title": "Risk-Aware Active Inverse Reinforcement Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "Risk-Aware Active Inverse Reinforcement Learning\nDaniel S. Brown\u0003, Yuchen Cui\u0003, and Scott Niekum\nDepartment of Computer Science\nUniversity of Texas at Austin, United States\ndsbrown@cs.utexas.edu, yuchencui@utexas.edu, sniekum@cs.utexas.edu\nAbstract: Active learning from demonstration allows a robot to query a human for\nspeci?c types of input to achieve ef?cient learning. Existing work has explored a\nvariety of active query strategies; however, to our knowledge, none of these strate-\ngies directly minimize the performance risk of the policy the robot is learning.\nUtilizing recent advances in performance bounds for inverse reinforcement learn-\ning, we propose a risk-aware active inverse reinforcement learning algorithm that\nfocuses active queries on areas of the state space with the potential for large gen-\neralization error. We show that risk-aware active learning outperforms standard\nactive IRL approaches on gridworld, simulated driving, and table setting tasks,\nwhile also providing...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1901.02161"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "5089b9ff46e9fa8a38f1e3a690398b44"
  },
  {
    "id": "arxiv_f95f04b04ff7a4b1",
    "title": "The Hanabi Challenge: A New Frontier for AI Research",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1902.00506"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "f95f04b04ff7a4b140b3d8687ce52165"
  },
  {
    "id": "arxiv_1f18fc5bb4cfac98",
    "title": "From Language to Goals: Inverse Reinforcement Learning for Vision-Based Instruction Following",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1902.07742"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "1f18fc5bb4cfac9854827d17db56b89b"
  },
  {
    "id": "arxiv_7aa7add91c4d9bde",
    "title": "Diagnosing Bottlenecks in Deep Q-learning Algorithms",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1902.10250"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "7aa7add91c4d9bde714f10971f2937c3"
  },
  {
    "id": "arxiv_fc1f4ca4b9f0f52f",
    "title": "SLIDE : In Defense of Smart Algorithms over Hardware Acceleration for Large-Scale Deep Learning Systems",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1903.03129"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "fc1f4ca4b9f0f52f0aa4ef8a5f020dda"
  },
  {
    "id": "arxiv_1971dfd835458fc8",
    "title": "A Survey of Reinforcement Learning Informed by Natural Language",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1906.03926"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "1971dfd835458fc825a2c897f3b04a74"
  },
  {
    "id": "arxiv_29912d5e770917b0",
    "title": "On Inductive Biases in Deep Reinforcement Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Background\n-------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1907.02908"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "29912d5e770917b0e0ab6c5a2649c725"
  },
  {
    "id": "arxiv_9588974df808d2b1",
    "title": "Improving Sample Efficiency in Model-Free Reinforcement Learning from Images",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1910.01741"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Academic research release",
    "source_id": "9588974df808d2b183e54b38430c5c51"
  },
  {
    "id": "arxiv_28785e694de9fb37",
    "title": "Integrating Behavior Cloning and Reinforcement Learning for Improved Performance in Dense and Sparse Reward Environments",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "Introduction\n------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1910.04281"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "28785e694de9fb37dbd4a8b9b0d92e0c"
  },
  {
    "id": "arxiv_c1201a83d177fa63",
    "title": "Stabilizing Transformers for Reinforcement Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1910.06764"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "c1201a83d177fa631e89a6d5fbc36d87"
  },
  {
    "id": "arxiv_77f8c55109ae4cb3",
    "title": "Planning with Goal-Conditioned Policies",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1911.08453"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "77f8c55109ae4cb3886681bac6dd6ac8"
  },
  {
    "id": "arxiv_aff90061d03fe488",
    "title": "Dream to Control: Learning Behaviors by Latent Imagination",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1912.01603"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "aff90061d03fe488dacd3c35f4c365c7"
  },
  {
    "id": "arxiv_50f785472f9f9817",
    "title": "Deep Bayesian Reward Learning from Preferences",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1912.04472"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "50f785472f9f981759bb03991e5b1643"
  },
  {
    "id": "arxiv_2d5fd096432bd8b9",
    "title": "What Can Learned Intrinsic Rewards Capture?",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1912.05500"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "2d5fd096432bd8b9f56ee0826f75f872"
  },
  {
    "id": "arxiv_0f2df22712848c03",
    "title": "Verification of Non-Linear Specifications for Neural Networks",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1902.09592"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "0f2df22712848c03edc4e6eed0d6ef3a"
  },
  {
    "id": "arxiv_f18e14f67088d23c",
    "title": "Adversarial Robustness through Local Linearization",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1907.02610"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "f18e14f67088d23c5a8275e213727bc3"
  },
  {
    "id": "arxiv_0e44e17c3879b667",
    "title": "Fine-Tuning Language Models from Human Preferences",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1909.08593"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "0e44e17c3879b66756afe3fa13309399"
  },
  {
    "id": "arxiv_1405aec1edf8be7e",
    "title": "Quantifying Hypothesis Space Misspecification in Learning from Human-Robot Demonstrations and Physical Corrections.",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2002.00941"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "1405aec1edf8be7e9d05c85a8fbb24fa"
  },
  {
    "id": "arxiv_117d259472867be5",
    "title": "Hierarchically Decoupled Imitation for Morphological Transfer.",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2003.01709"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "117d259472867be5546d128c227fecea"
  },
  {
    "id": "arxiv_d5d871f8c38b8423",
    "title": "Using Machine Learning to Guide Cognitive Modeling: A Case Study in Moral Reasoning.",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1902.06744"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "d5d871f8c38b842379b2abc4ca2280e5"
  },
  {
    "id": "arxiv_8606d4d1cec21bda",
    "title": "Implementing Mediators with Asynchronous Cheap Talk.",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1806.01214"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "8606d4d1cec21bda37ddc73d86aebc7f"
  },
  {
    "id": "arxiv_a5042b5aab956d77",
    "title": "Adversarial Training with Voronoi Constraints.",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1905.01019"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Published in academic venue",
    "source_id": "a5042b5aab956d77d2e18b28ac40b521"
  },
  {
    "id": "arxiv_0fdf5b2c39518e9d",
    "title": "Natural Adversarial Examples.",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1907.07174"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "0fdf5b2c39518e9d4970baa99364266e"
  },
  {
    "id": "arxiv_1381c91c59063974",
    "title": "Bayesian Robustness: A Nonasymptotic Viewpoint.",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1907.11826"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "1381c91c590639748c5f5f1a9aae4e24"
  },
  {
    "id": "arxiv_f84b0a1d30cf89ae",
    "title": "A Risk-Sensitive Finite-Time Reachability Approach for Safety of Stochastic Dynamic Systems.",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1902.11277"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "f84b0a1d30cf89ae9236ce82a3e24551"
  },
  {
    "id": "arxiv_1c1b01ae4d1233f4",
    "title": "Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty.",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1906.12340"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "1c1b01ae4d1233f4b49ea050c8fbc0fc"
  },
  {
    "id": "arxiv_3d6bfae31f2f8bec",
    "title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations.",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1903.12261"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "3d6bfae31f2f8beca77dacf06817bc2e"
  },
  {
    "id": "arxiv_3f4254f317701007",
    "title": "Deep Anomaly Detection with Outlier Exposure.",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1812.04606"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Published in academic venue",
    "source_id": "3f4254f317701007b2a5e1c3253ca325"
  },
  {
    "id": "arxiv_a8f634af414f0b09",
    "title": "Legible Normativity for AI Alignment: The Value of Silly Rules.",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "Introduction\n------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1811.01267"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "a8f634af414f0b09e1531308ef324d1f"
  },
  {
    "id": "arxiv_44744bf31057f3d2",
    "title": "Reward-rational (implicit) choice: A unifying formalism for reward learning.",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2002.04833"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "44744bf31057f3d2299f555a35ca0463"
  },
  {
    "id": "arxiv_961c51700a43ebc0",
    "title": "Literal or Pedagogic Human? Analyzing Human Model Misspecification in Objective Learning.",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1903.03877"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "961c51700a43ebc088587388657302ab"
  },
  {
    "id": "arxiv_1e1f88201aaae570",
    "title": "On the Utility of Model Learning in HRI.",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1901.01291"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "1e1f88201aaae570f63f28606e6cea25"
  },
  {
    "id": "arxiv_980dbd86b111912d",
    "title": "Hard Choices in Artificial Intelligence: Addressing Normative Uncertainty through Sociotechnical Commitments.",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "Introduction\n------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1911.09005"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "980dbd86b111912d8d645238b9eaa92f"
  },
  {
    "id": "arxiv_e8d31791732b0a20",
    "title": "Algorithms for Verifying Deep Neural Networks",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "Algorithms for Verifying Deep Neural Networks\nChangliu Liu\nCarnegie Mellon University\ncliu6@andrew.cmu.eduTomer Arnon\nStanford University\ntarnon@stanford.eduChristopher Lazarus\nStanford University\nclazarus@stanford.edu\nChristopher Strong\nStanford University\ncastrong@stanford.eduClark Barrett\nStanford University\nbarrett@cs.stanford.eduMykel J. Kochenderfer\nStanford University\nmykel@stanford.edu\nOctober 11, 2020\nAbstract\nDeep neural networks are widely used for nonlinear function approximation, with\napplications ranging from computer vision to control. Although these networks involve\nthe composition of simple arithmetic operations, it can be very challenging to verify\nwhether a particular network satisfies certain input-output properties. This article\nsurveys methods that have emerged recently for soundly verifying such properties.\nThese methods borrow insights from reachability analysis, optimization, and search.\nWe discuss fundamental differences and connections between existing alg...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1903.06758"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "e8d31791732b0a204e6fc89330d57350"
  },
  {
    "id": "arxiv_4fa22ceddc8532fa",
    "title": "Towards Characterizing Divergence in Deep Q-Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1903.08894"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "4fa22ceddc8532fa986de05cd7e53fd9"
  },
  {
    "id": "arxiv_693565496a05778f",
    "title": "The LogBarrier adversarial attack: making effective use of decision boundary information",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1903.10396"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "693565496a05778fc7eee68217da5e25"
  },
  {
    "id": "arxiv_499a4638a0e2f313",
    "title": "Finding and Visualizing Weaknesses of Deep Reinforcement Learning Agents",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1904.01318"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Published in academic venue",
    "source_id": "499a4638a0e2f313929527a759d887dc"
  },
  {
    "id": "arxiv_3f7138172c933108",
    "title": "Extrapolating Beyond Suboptimal Demonstrations via Inverse Reinforcement Learning from Observations",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1904.06387"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "3f7138172c9331083d2e33da97787e14"
  },
  {
    "id": "arxiv_f08658e9cc2aba17",
    "title": "HARK Side of Deep Learning -- From Grad Student Descent to Automated Machine Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1904.07633"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "f08658e9cc2aba173b0270450a412cee"
  },
  {
    "id": "arxiv_153bcb3b49c0c598",
    "title": "Challenges of Real-World Reinforcement Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1904.12901"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "153bcb3b49c0c5980991b5ddc2228ded"
  },
  {
    "id": "arxiv_e662dd63bdddd44f",
    "title": "PRECOG: PREdiction Conditioned On Goals in Visual Multi-Agent Settings",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1905.01296"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "e662dd63bdddd44f33a2e99b3f9ac3be"
  },
  {
    "id": "arxiv_0dbfdba362459a9e",
    "title": "Meta-learners' learning dynamics are unlike learners'",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1905.01320"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "0dbfdba362459a9ed82f9ef4f3ec650e"
  },
  {
    "id": "arxiv_a8e7867b6a274601",
    "title": "Meta-learning of Sequential Strategies",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1905.03030"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "a8e7867b6a2746011b0ba8fe04b56bed"
  },
  {
    "id": "arxiv_21e5965ab022e732",
    "title": "On Variational Bounds of Mutual Information",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1905.06922"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "21e5965ab022e732472e0cc3deda877b"
  },
  {
    "id": "arxiv_30993e4d225c1820",
    "title": "Cold Case: The Lost MNIST Digits",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1905.10498"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "30993e4d225c18200c1c4a6cef00e665"
  },
  {
    "id": "arxiv_c4f47b8ec83a65c4",
    "title": "AI-GAs: AI-generating algorithms, an alternate paradigm for producing general artificial intelligence",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Two approaches to producing general AI: the manual approach vs.?AI-generating algorithms\n-------------------------------------------------------------------------------------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1905.10985"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Published in academic venue",
    "source_id": "c4f47b8ec83a65c43d0e159eb7227f2f"
  },
  {
    "id": "arxiv_598d0f8ff5beacac",
    "title": "Causal Confusion in Imitation Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1905.11979"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "598d0f8ff5beacac441b919e5328e493"
  },
  {
    "id": "arxiv_79624763ad62f160",
    "title": "Learning Representations by Humans, for Humans",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1905.12686"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "79624763ad62f1602a878554c229b3d0"
  },
  {
    "id": "arxiv_89cd3ef79c4ea526",
    "title": "Imitation Learning as $f$-Divergence Minimization",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1905.12888"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "89cd3ef79c4ea526deb2899513439fbb"
  },
  {
    "id": "arxiv_21e9aed4c6db2398",
    "title": "E-LPIPS: Robust Perceptual Image Similarity via Random Transformation Ensembles",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1906.03973"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "21e9aed4c6db2398ff3168a1b7f49d46"
  },
  {
    "id": "arxiv_9037f853d10c9ac1",
    "title": "Modeling AGI Safety Frameworks with Causal Influence Diagrams",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1906.08663"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "9037f853d10c9ac10bbc0d6b4c7a747a"
  },
  {
    "id": "arxiv_42153d4c6fb5d1f9",
    "title": "Towards Empathic Deep Q-Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1906.10918"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "42153d4c6fb5d1f9e9190ddf4b1f74ad"
  },
  {
    "id": "arxiv_0242bd9afee7aace",
    "title": "Norms for Beneficial A.I.: A Computational Analysis of the Societal Value Alignment Problem",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1907.03843"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "0242bd9afee7aace1c8365b0891a40c9"
  },
  {
    "id": "arxiv_f86f78b8dda14fde",
    "title": "Better-than-Demonstrator Imitation Learning via Automatically-Ranked Demonstrations",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1907.03976"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "f86f78b8dda14fded82720f80c05d016"
  },
  {
    "id": "arxiv_782a1b8a0e048fa7",
    "title": "Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1907.11932"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Academic research release",
    "source_id": "782a1b8a0e048fa7a0557ce27c6d3660"
  },
  {
    "id": "arxiv_793b9faea6d52daf",
    "title": "Improving Deep Reinforcement Learning in Minecraft with Action Advice",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "Introduction\n------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1908.01007"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "793b9faea6d52dafd594c76a795aecf8"
  },
  {
    "id": "arxiv_64e368da441409b5",
    "title": "Finding Generalizable Evidence by Learning to Convince Q&A Models",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1909.05863"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "64e368da441409b50a472889d5c1323c"
  },
  {
    "id": "arxiv_7ffcd3b363df9e5b",
    "title": "Scaling data-driven robotics with reward sketching and batch reinforcement learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1909.12200"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Academic research release",
    "source_id": "7ffcd3b363df9e5be6093fbaa0220f3e"
  },
  {
    "id": "arxiv_cc87f82087030182",
    "title": "A Constructive Prediction of the Generalization Error Across Scales",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "Published as a conference paper at ICLR 2020\nA C ONSTRUCTIVE PREDICTION OF THE\nGENERALIZATION ERROR ACROSS SCALES\nJonathan S. Rosenfeld1Amir Rosenfeld2Yonatan Belinkov13Nir Shavit145\nfjonsr,belinkov,shanir g@csail.mit.edu amir@cse.yorku.ca\n1Massachusetts Institute of Technology2York University3Harvard University\n4Neural Magic Inc5Tel Aviv University\nABSTRACT\nThe dependency of the generalization error of neural networks on model and\ndataset size is of critical importance both in practice and for understanding the\ntheory of neural networks. Nevertheless, the functional form of this dependency\nremains elusive. In this work, we present a functional form which approximates\nwell the generalization error in practice. Capitalizing on the successful concept of\nmodel scaling (e.g., width, depth), we are able to simultaneously construct such\na form and specify the exact models which can attain it across model/data scales.\nOur construction follows insights obtained from observations conducted o...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1909.12673"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "cc87f8208703018219498e01b060e785"
  },
  {
    "id": "arxiv_5b89337caf817fe3",
    "title": "Positive-Unlabeled Reward Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1911.00459"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Published in academic venue",
    "source_id": "5b89337caf817fe3bf2498d4cbc62b49"
  },
  {
    "id": "arxiv_a338ff49276e0aa0",
    "title": "Self-training with Noisy Student improves ImageNet classification",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1911.04252"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "a338ff49276e0aa0c71004d1d1ff15a5"
  },
  {
    "id": "arxiv_9cce57483fe0df92",
    "title": "The Transformative Potential of Artificial Intelligence",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "The Transformative Potential of Artificial Intelligence  Ross Gruetzemacher? and Jess Whittlestone? ? Wichita State University, W. Frank Barton School of Business, ross.gruetzemacher@wichita.edu  ? University of Cambridge, Leverhulme Centre for the Future of Intelligence, jlw84@cam.ac.uk    Abstract  The terms ?human-level artificial intelligence? and ?artificial general intelligence? are widely used to refer to the possibility of advanced artificial intelligence (AI) with potentially extreme impacts on society. These terms are poorly defined and do not necessarily indicate what is most important with respect to future societal impacts. We suggest that the term ?transformative AI? is a helpful alternative, reflecting the possibility that advanced AI systems could have very large impacts on society without reaching human-level cognitive abilities. To be most useful, however, more analysis of what it means for AI to be ?transformative? is needed. In this paper, we propose three differ...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1912.00747"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "9cce57483fe0df92ae65dfe5c3193948"
  },
  {
    "id": "arxiv_584641e15cc07415",
    "title": "Exploratory Not Explanatory: Counterfactual Analysis of Saliency Maps for Deep Reinforcement Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1912.05743"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "584641e15cc07415351b5314971d36e0"
  },
  {
    "id": "arxiv_1eda22f5f61402fa",
    "title": "Regulatory Markets for AI Safety",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2001.00078"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "1eda22f5f61402faf20c6879ecd0ba35"
  },
  {
    "id": "arxiv_dfe1a69ce0a50944",
    "title": "The Offense-Defense Balance of Scientific Knowledge: Does Publishing AI Research Reduce Misuse?",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2001.00463"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "dfe1a69ce0a509449e51cd9ffb176807"
  },
  {
    "id": "arxiv_a7a43764ffb482b6",
    "title": "Robust Change Captioning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1  Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1901.02527"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "a7a43764ffb482b60a4176ef6520054d"
  },
  {
    "id": "arxiv_0701f434e0267fd4",
    "title": "Improving Robustness of Machine Translation with Synthetic Noise",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1902.09508"
    ],
    "tags": [],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Academic research release",
    "source_id": "0701f434e0267fd460a2eb6a766c5710"
  },
  {
    "id": "arxiv_1d30ff2c0b8a1b22",
    "title": "Toybox: A Suite of Environments for Experimental Evaluation of Deep Reinforcement Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1905.02825"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "1d30ff2c0b8a1b22074752038d18399e"
  },
  {
    "id": "arxiv_80f6a648f25568e2",
    "title": "The Principle of Unchanged Optimality in Reinforcement Learning Generalization",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1906.00336"
    ],
    "tags": [],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "80f6a648f25568e26d778a80296ddeca"
  },
  {
    "id": "arxiv_eae2467f1f42e114",
    "title": "Goal-conditioned Imitation Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1906.05838"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "eae2467f1f42e1149c7c35b8cde33bfd"
  },
  {
    "id": "arxiv_d6d4f93f29f8c1e5",
    "title": "Behaviour Suite for Reinforcement Learning",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "Published as a conference paper at ICLR 2020\nBehaviour Suite for Reinforcement Learning\nIan Osband?, Yotam Doron, Matteo Hessel, John Aslanides\nEren Sezener, Andre Saraiva, Katrina McKinney, Tor Lattimore, Csaba Szepesvari\nSatinder Singh, Benjamin Van Roy, Richard Sutton, David Silver, Hado Van Hasselt\nDeepMind\nAbstract\nThis paper introduces the Behaviour Suite for Reinforcement Learning , or\nbsuite for short. bsuite is a collection of carefully-designed experiments\nthat investigate core capabilities of reinforcement learning (RL) agents with\ntwo objectives. First, to collect clear, informative and scalable problems\nthat capture key issues in the design of general and e?cient learning al-\ngorithms. Second, to study agent behaviour through their performance\non these shared benchmarks. To complement this e?ort, we open source\ngithub.com/deepmind/bsuite , which automates evaluation and analysis\nof any agent on bsuite . This library facilitates reproducible and accessible\nresearch on th...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1908.03568"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "d6d4f93f29f8c1e55edf7becc7ff8a53"
  },
  {
    "id": "arxiv_b941110f24a934df",
    "title": "LCA: Loss Change Allocation for Neural Network Training",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1909.01440"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "b941110f24a934df99263071691453ad"
  },
  {
    "id": "arxiv_0cf68bfe04a22e30",
    "title": "ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1911.09785"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "0cf68bfe04a22e301801931fd6a76b99"
  },
  {
    "id": "arxiv_3625591de24ea616",
    "title": "Risks from Learned Optimization  in Advanced Machine Learning Systems",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1906.01820"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "3625591de24ea61694a0bfd620623349"
  },
  {
    "id": "arxiv_dfe4f6e3d2c81f5f",
    "title": "Using Pre-Training Can Improve Model Robustness and Uncertainty",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1901.09960"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "dfe4f6e3d2c81f5f75ee666f07400054"
  },
  {
    "id": "arxiv_d17f296dd337d166",
    "title": "Adversarial NLI: A New Benchmark \nfor Natural Language Understanding",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1910.14599"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "d17f296dd337d166eef3b39f38b283af"
  },
  {
    "id": "arxiv_ec61370a4d0d45f7",
    "title": "Detecting AI Trojans Using Meta Neural Analysis",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1910.03137"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "ec61370a4d0d45f75e622218893ae746"
  },
  {
    "id": "arxiv_4891c64c19a1494c",
    "title": "STRIP: A Defence Against Trojan Attacks on Deep Neural Networks",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1902.06531"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "4891c64c19a1494cb57fb7c38a4914bd"
  },
  {
    "id": "arxiv_17ef6ec21f8407a5",
    "title": "Universal Adversarial Triggers for Attacking and Analyzing NLP  WARNING: This paper contains model outputs which are offensive in nature.",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/1908.07125"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "17ef6ec21f8407a5ff3f77b505baa10f"
  },
  {
    "id": "distill_8ef6f034b4508a82",
    "title": "Computing Receptive Fields of Convolutional Neural Networks",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "While deep neural networks have overwhelmingly established state-of-the-art\n results in many artificial intelligence problems, they can still be\n difficult to develop and debug.\n Recent research on deep learning understanding has focused on\n feature visualization ,\n theoretical guarantees ,\n model interpretability ,\n and generalization .",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 5,
        "condition": null
      }
    ],
    "sources": [
      "https://distill.pub/2019/computing-receptive-fields"
    ],
    "tags": [],
    "rarity": "legendary",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Visual machine learning research",
    "source_id": "8ef6f034b4508a82d3da36f052345ec6"
  },
  {
    "id": "distill_4dab2fb3c6b0867c",
    "title": "A Discussion of 'Adversarial Examples Are Not Bugs, They Are Features'",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "On May 6th, Andrew Ilyas and colleagues [published a paper](http://gradientscience.org/adv/)\n outlining two sets of experiments.\n Firstly, they showed that models trained on adversarial examples can transfer to real data,\n and secondly that models trained on a dataset derived from the representations of robust neural networks\n seem to inherit non-trivial robustness.\n They proposed an intriguing interpretation for their results:\n adversarial examples are due to ?non-robust features? which are highly predictive but imperceptible to\n humans.",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 5,
        "condition": null
      }
    ],
    "sources": [
      "https://distill.pub/2019/advex-bugs-discussion"
    ],
    "tags": [],
    "rarity": "legendary",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Interactive research publication",
    "source_id": "4dab2fb3c6b0867cd11d51b1de9f1ecf"
  },
  {
    "id": "distill_9af84a92d724245f",
    "title": "A Discussion of 'Adversarial Examples Are Not Bugs, They Are Features': Adversarial Example Researchers Need to Expand What is Meant by 'Robustness'",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "#rebuttal,\n .comment-info {\n background-color: hsl(54, 78%, 96%);\n border-left: solid hsl(54, 33%, 67%) 1px;\n padding: 1em;\n color: hsla(0, 0%, 0%, 0.67);\n }",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 5,
        "condition": null
      }
    ],
    "sources": [
      "https://distill.pub/2019/advex-bugs-discussion/response-1"
    ],
    "tags": [],
    "rarity": "legendary",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Visual machine learning research",
    "source_id": "9af84a92d724245f276f38cfe61d7b12"
  },
  {
    "id": "distill_109a9ad019ae9b2c",
    "title": "A Discussion of 'Adversarial Examples Are Not Bugs, They Are Features': Robust Feature Leakage",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "#rebuttal,\n .comment-info {\n background-color: hsl(54, 78%, 96%);\n border-left: solid hsl(54, 33%, 67%) 1px;\n padding: 1em;\n color: hsla(0, 0%, 0%, 0.67);\n }",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 5,
        "condition": null
      }
    ],
    "sources": [
      "https://distill.pub/2019/advex-bugs-discussion/response-2"
    ],
    "tags": [],
    "rarity": "legendary",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Featured in Distill",
    "source_id": "109a9ad019ae9b2c07d878ac8650f88e"
  },
  {
    "id": "distill_90edb4745db80192",
    "title": "A Discussion of 'Adversarial Examples Are Not Bugs, They Are Features': Two Examples of Useful, Non-Robust Features",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "#rebuttal,\n .comment-info {\n background-color: hsl(54, 78%, 96%);\n border-left: solid hsl(54, 33%, 67%) 1px;\n padding: 1em;\n color: hsla(0, 0%, 0%, 0.67);\n }",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 5,
        "condition": null
      }
    ],
    "sources": [
      "https://distill.pub/2019/advex-bugs-discussion/response-3"
    ],
    "tags": [],
    "rarity": "legendary",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Featured in Distill",
    "source_id": "90edb4745db80192530bcfcdb853ebb3"
  },
  {
    "id": "distill_929bb52cf50e0b8d",
    "title": "A Discussion of 'Adversarial Examples Are Not Bugs, They Are Features': Adversarially Robust Neural Style Transfer",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "#rebuttal,\n .comment-info {\n background-color: hsl(54, 78%, 96%);\n border-left: solid hsl(54, 33%, 67%) 1px;\n padding: 1em;\n color: hsla(0, 0%, 0%, 0.67);\n }",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 5,
        "condition": null
      }
    ],
    "sources": [
      "https://distill.pub/2019/advex-bugs-discussion/response-4"
    ],
    "tags": [],
    "rarity": "legendary",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Featured in Distill",
    "source_id": "929bb52cf50e0b8d42c3547eb0bb34e0"
  },
  {
    "id": "distill_6e90076e03f74714",
    "title": "A Discussion of 'Adversarial Examples Are Not Bugs, They Are Features': Adversarial Examples are Just Bugs, Too",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": ".comment-info {\n background-color: hsl(54, 78%, 96%);\n border-left: solid hsl(54, 33%, 67%) 1px;\n padding: 1em;\n color: hsla(0, 0%, 0%, 0.67);\n }",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 5,
        "condition": null
      }
    ],
    "sources": [
      "https://distill.pub/2019/advex-bugs-discussion/response-5"
    ],
    "tags": [],
    "rarity": "legendary",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Interactive research publication",
    "source_id": "6e90076e03f74714d63d7b09c7ad8e59"
  },
  {
    "id": "distill_bda18cad07b62a0d",
    "title": "A Discussion of 'Adversarial Examples Are Not Bugs, They Are Features': Discussion and Author Responses",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "#rebuttal,\n .comment-info {\n background-color: hsl(54, 78%, 96%);\n border-left: solid hsl(54, 33%, 67%) 1px;\n padding: 1em;\n color: hsla(0, 0%, 0%, 0.67);\n }",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 5,
        "condition": null
      }
    ],
    "sources": [
      "https://distill.pub/2019/advex-bugs-discussion/original-authors"
    ],
    "tags": [],
    "rarity": "legendary",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Visual machine learning research",
    "source_id": "bda18cad07b62a0dff8e37b69a396da0"
  },
  {
    "id": "distill_a9e837be3cded3d2",
    "title": "Open Questions about Generative Adversarial Networks",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "By some metrics, research on Generative Adversarial Networks (GANs) has progressed substantially in the past 2 years.\n Practical improvements to image synthesis models are being made  almost too quickly to keep up with:",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 5,
        "condition": null
      }
    ],
    "sources": [
      "https://distill.pub/2019/gan-open-problems"
    ],
    "tags": [],
    "rarity": "legendary",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Interactive research publication",
    "source_id": "a9e837be3cded3d2c70b5d5864747eb6"
  },
  {
    "id": "distill_3a645443102ffa1e",
    "title": "Activation Atlas",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "Introduction\n------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 5,
        "condition": null
      }
    ],
    "sources": [
      "https://distill.pub/2019/activation-atlas"
    ],
    "tags": [],
    "rarity": "legendary",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Featured in Distill",
    "source_id": "3a645443102ffa1eb6428f582ff73b62"
  },
  {
    "id": "distill_eb5c12bc89464f38",
    "title": "AI Safety Needs Social Scientists",
    "year": 2019,
    "category": "technical_research_breakthrough",
    "description": "The goal of long-term artificial intelligence (AI) safety is to ensure that advanced AI systems are reliably aligned with human values???that they reliably do things that people want them to do.Roughly by human values we mean whatever it is that causes people to choose one option over another in each case, suitably corrected by reflection, with differences between groups of people taken into account. There are a lot of subtleties in this notion, some of which we will discuss in later sections and others of which are beyond the scope of this paper. Since it is difficult to write down precise rules describing human values, one approach is to treat aligning with human values as another learning problem. We ask humans a large number of questions about what they want, train an ML model of their values, and optimize the AI system to do well according to the learned values.",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 5,
        "condition": null
      }
    ],
    "sources": [
      "https://distill.pub/2019/safety-needs-social-scientists"
    ],
    "tags": [],
    "rarity": "legendary",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Visual machine learning research",
    "source_id": "eb5c12bc89464f38db9f304e78f2c702"
  }
]