[
  {
    "id": "arxiv_26323c8f3a2e6509",
    "title": "Evaluating the Robustness of Collaborative Agents",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2101.05507"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "26323c8f3a2e65098b8b69701e99db23"
  },
  {
    "id": "arxiv_3c7ec65d65c78749",
    "title": "Shielding Atari Games with Bounded Prescience",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2101.08153"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "3c7ec65d65c787492d9f80fc6540154c"
  },
  {
    "id": "arxiv_218ce086ce67d573",
    "title": "Accumulating Risk Capital Through Investing in Cooperation",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2101.10305"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "218ce086ce67d5739ddde8794db7f87c"
  },
  {
    "id": "arxiv_cbd42f5f1fdb1a3b",
    "title": "Agent Incentives: A Causal Perspective",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Introduction\n------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2102.01685"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "cbd42f5f1fdb1a3bd6edaad51406e535"
  },
  {
    "id": "arxiv_dadd385d71c754d2",
    "title": "Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Introduction\n------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2102.02503"
    ],
    "tags": [],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "dadd385d71c754d216ffda1325140d24"
  },
  {
    "id": "arxiv_62ef0e364eab5971",
    "title": "Consequences of Misaligned AI",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2102.03896"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Academic research release",
    "source_id": "62ef0e364eab59718630edc0016f83ee"
  },
  {
    "id": "arxiv_c171694c2a004f27",
    "title": "AI Development for the Public Interest: From Abstraction Traps to Sociotechnical Risks",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2102.04255"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "c171694c2a004f27a32a583c0ed8db7b"
  },
  {
    "id": "arxiv_b521f441eb2544a1",
    "title": "Zero-Shot Text-to-Image Generation",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2102.12092"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "b521f441eb2544a1c71ef1683ce417a1"
  },
  {
    "id": "arxiv_2693c7142eae6286",
    "title": "Causal Analysis of Agent Behavior for AI Safety",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.03938"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Academic research release",
    "source_id": "2693c7142eae6286c2f17d17b5435a70"
  },
  {
    "id": "arxiv_7f8331f6c517ac35",
    "title": "Pretrained Transformers as Universal Computation Engines",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.05247"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Published in academic venue",
    "source_id": "7f8331f6c517ac35ef8f069317e4374a"
  },
  {
    "id": "arxiv_3f1c98bc443cac76",
    "title": "The AI Index 2021 Annual Report",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Artificial  \nIntelligence\nIndex Report 2021\nArtificial Intelligence\nIndex Report 20212INTRODUCTION TO THE  \n2021 AI INDEX REPORT\nWelcome to the fourth edition of the AI Index Report! \nThis year we significantly expanded the amount of data \navailable in the report, worked with a broader set of \nexternal organizations to calibrate our data, and deepened \nour connections with Stanford?s Institute for Human-\nCentered Artificial Intelligence (HAI). \nThe AI Index Report tracks, collates, distills, and visualizes \ndata related to artificial intelligence. Its mission is to \nprovide unbiased, rigorously vetted, and globally sourced \ndata for policymakers, researchers, executives, journalists, \nand the general public to develop intuitions about the \ncomplex field of AI. The report aims to be the world?s most \ncredible and authoritative source for data and insights \nabout AI.\nCOVID AND AI  \nThe 2021 report shows the effects of COVID-19 on AI \ndevelopment from multiple perspectives. The Technic...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.06312"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "3f1c98bc443cac76d1c2dadc2d1dc290"
  },
  {
    "id": "arxiv_da2deeeadbeab086",
    "title": "Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.12656"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "da2deeeadbeab0866eb3a993f88f48db"
  },
  {
    "id": "arxiv_53c3414e76f6b1bc",
    "title": "Alignment of Language Agents",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.14659"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "53c3414e76f6b1bcc506da879e7d50e4"
  },
  {
    "id": "arxiv_441024d88860cc55",
    "title": "Detection of Dataset Shifts in Learning-Enabled Cyber-Physical Systems using Variational Autoencoder for Regression",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Detection of Dataset Shifts in Learning-Enabled\nCyber-Physical Systems using Variational\nAutoencoder for Regression\nFeiyang Cai\nVanderbilt University\nNashville, TN\nfeiyang.cai@vanderbilt.eduAli I. Ozdagli\nVanderbilt University\nNashville, TN\nali.i.ozdagli@vanderbilt.eduXenofon Koutsoukos\nVanderbilt University\nNashville, TN\nxenofon.koutsoukos@vanderbilt.edu\nAbstract ?Cyber-physical systems (CPSs) use learning-enabled\ncomponents (LECs) extensively to cope with various complex\ntasks under high-uncertainty environments. However, the dataset\nshifts between the training and testing phase may lead the LECs\nto become ineffective to make large-error predictions, and fur-\nther, compromise the safety of the overall system. In our paper, we\n?rst provide the formal de?nitions for different types of dataset\nshifts in learning-enabled CPS. Then, we propose an approach\nto detect the dataset shifts effectively for regression problems.\nOur approach is based on the inductive conformal anomaly\ndetection...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2104.06613"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "441024d88860cc5552cc12869e401a7c"
  },
  {
    "id": "arxiv_31a5fe3f499ab05b",
    "title": "Gradient-based Adversarial Attacks against Text Transformers",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2104.13733"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "31a5fe3f499ab05b2cf59866600148b2"
  },
  {
    "id": "arxiv_a57f6329c975e596",
    "title": "Ethics and Governance of Artificial Intelligence: Evidence from a Survey of Machine Learning Researchers",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2105.02117"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "a57f6329c975e596dd8713ab7ff5f72f"
  },
  {
    "id": "arxiv_0a11a1aed371713f",
    "title": "Leveraging Sparse Linear Layers for Debuggable Deep Networks",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2105.04857"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Published in academic venue",
    "source_id": "0a11a1aed371713f1c6e9cd580feecaa"
  },
  {
    "id": "arxiv_50e653fce3d60282",
    "title": "Axes for Sociotechnical Inquiry in AI Research",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2105.06551"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "50e653fce3d60282155679ae4629da1e"
  },
  {
    "id": "arxiv_aa2a65a3e15dd26d",
    "title": "Agree to Disagree: When Deep Learning Models With Identical Architectures Produce Distinct Explanations",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2105.06791"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "aa2a65a3e15dd26da0af907a5ca3f7c8"
  },
  {
    "id": "arxiv_cc4d70762dab69e1",
    "title": "AI and Shared Prosperity",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2105.08475"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "cc4d70762dab69e18daf8c5ec854430b"
  },
  {
    "id": "arxiv_b6f519be57b453ca",
    "title": "Goal Misgeneralization in Deep Reinforcement Learning",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2105.14111"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "b6f519be57b453ca6a68621ae7b0b805"
  },
  {
    "id": "arxiv_05f9af1daa2926cf",
    "title": "Provably Robust Detection of Out-of-distribution Data (almost) for free",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2106.04260"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "05f9af1daa2926cf92fee0f088a6f5ca"
  },
  {
    "id": "arxiv_4d86e7039be72db7",
    "title": "Engines of Power: Electricity, AI, and General-Purpose Military Transformations",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Engines of Power: Electricity, AI, and General-Purpose Military Transformations  Jeffrey Ding and Allan Dafoe* Abstract Major theories of military innovation focus on relatively narrow technological developments, such as nuclear weapons or aircraft carriers. Arguably the most profound military implications of technological change, however, come from more fundamental advances arising from ?general purpose technologies? (GPTs), such as the steam engine, electricity, and the computer. With few exceptions, political scientists have not theorized about GPTs. Drawing from the economics literature on GPTs, we distill several propositions on how and when GPTs affect military affairs. We call these effects ?general-purpose military transformations? (GMTs). In particular, we argue that the impacts of GMTs on military effectiveness are broad, delayed, and shaped by indirect productivity spillovers. Additionally, GMTs differentially advantage those militaries that can draw from a robust indus...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2106.04338"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "4d86e7039be72db776dd12d767e5f1e3"
  },
  {
    "id": "arxiv_022a0b73d5f487fa",
    "title": "There Is No Turning Back: A Self-Supervised Approach for Reversibility-Aware Reinforcement Learning",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2106.04480"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "022a0b73d5f487fae44178bcee6a8703"
  },
  {
    "id": "arxiv_ea0d3cf025dcd154",
    "title": "PEBBLE: Feedback-Efficient Interactive Reinforcement Learning via Relabeling Experience and Unsupervised Pre-training",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2106.05091"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "ea0d3cf025dcd15408fd7876f15bc655"
  },
  {
    "id": "arxiv_ac7c2b65f2dc94f9",
    "title": "Revisiting the Calibration of Modern Neural Networks",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2106.07998"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "ac7c2b65f2dc94f98f15b5809da2edbe"
  },
  {
    "id": "arxiv_6473bf92d37686f5",
    "title": "How Well do Feature Visualizations Support Causal Understanding of CNN Activations?",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2106.12447"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "6473bf92d37686f5ee1b1c1b8d9fbfed"
  },
  {
    "id": "arxiv_6e0f2c882ed2ded9",
    "title": "The MineRL BASALT Competition on Learning from Human Feedback",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Competition description\n--------------------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.01969"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "6e0f2c882ed2ded9333f20cc47412966"
  },
  {
    "id": "arxiv_ca9b96625c777525",
    "title": "What are you optimizing for? Aligning Recommender Systems with Human Values",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.10939"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Academic research release",
    "source_id": "ca9b96625c777525c419959f2af82f3d"
  },
  {
    "id": "arxiv_e413f8bb0dea4865",
    "title": "Standardized Max Logits: A Simple yet Effective Approach for Identifying Unexpected Road Obstacles in Urban-Scene Segmentation",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.11264"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "e413f8bb0dea4865235e8a2dc0f34bbf"
  },
  {
    "id": "arxiv_62048503a42e7698",
    "title": "Open-Ended Learning Leads to Generally Capable Agents",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.12808"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "62048503a42e769816742a6e31cf93e5"
  },
  {
    "id": "arxiv_4c1601e7b988fad5",
    "title": "Soft Calibration Objectives for Neural Networks",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2108.00106"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "4c1601e7b988fad5844599c6678524ce"
  },
  {
    "id": "arxiv_f9ade5d3a5d60077",
    "title": "Triggering Failures: Out-Of-Distribution detection by learning from local adversarial attacks in Semantic Segmentation",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2108.01634"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "f9ade5d3a5d6007790c5f35affa0d28f"
  },
  {
    "id": "arxiv_0b1f4debe314fa2e",
    "title": "Asleep at the Keyboard? Assessing the Security of GitHub Copilot's Code Contributions",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Asleep at the Keyboard? Assessing the\nSecurity of GitHub Copilot?s Code Contributions\nHammond Pearce\nDepartment of ECE\nNew York University\nBrooklyn, NY , USA\nhammond.pearce@nyu.eduBaleegh Ahmad\nDepartment of ECE\nNew York University\nBrooklyn, NY , USA\nba1283@nyu.eduBenjamin Tan\nDepartment of ESE\nUniversity of Calgary\nCalgary, Alberta, CA\nbenjamin.tan1@ucalgary.caBrendan Dolan-Gavitt\nDepartment of CSE\nNew York University\nBrooklyn, NY , USA\nbrendandg@nyu.eduRamesh Karri\nDepartment of ECE\nNew York University\nBrooklyn, NY , USA\nrkarri@nyu.edu\nAbstract ?There is burgeoning interest in designing AI-based\nsystems to assist humans in designing computing systems,\nincluding tools that automatically generate computer code. The\nmost notable of these comes in the form of the ?rst self-described\n?AI pair programmer?, GitHub Copilot, which is a language\nmodel trained over open-source GitHub code. However, code\noften contains bugs?and so, given the vast quantity of unvetted\ncode that Copilot has pro...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2108.09293"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Academic research release",
    "source_id": "0b1f4debe314fa2ea7476d73425a6120"
  },
  {
    "id": "arxiv_80458dc82661aceb",
    "title": "Robust fine-tuning of zero-shot models",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2109.01903"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Published in academic venue",
    "source_id": "80458dc82661aceb9b67ed0e0c31ca1c"
  },
  {
    "id": "arxiv_40199422e213e467",
    "title": "Augmenting Decision Making via Interactive What-If Analysis",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2109.06160"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "40199422e213e4674f2b87653ce8663e"
  },
  {
    "id": "arxiv_43da39bb4352078c",
    "title": "Challenges in Detoxifying Language Models",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2109.07445"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "43da39bb4352078c85659806a2a487fc"
  },
  {
    "id": "arxiv_70b81709b37af2f6",
    "title": "Recursively Summarizing Books with Human Feedback",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Research publication: Recursively Summarizing Books with Human Feedback",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2109.10862"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "70b81709b37af2f60fb175073d836d0e"
  },
  {
    "id": "arxiv_380bb59b80887c6e",
    "title": "Cartesian Frames",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Background and Motivation\n----------------------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2109.10996"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "380bb59b80887c6e766c66477d82370f"
  },
  {
    "id": "arxiv_c328090bc4305415",
    "title": "RAFT: A Real-World Few-Shot Text Classification Benchmark",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2109.14076"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "c328090bc430541575f05eb6ea8418f8"
  },
  {
    "id": "arxiv_03b945a38102e081",
    "title": "Can Machines Learn Morality? The Delphi Experiment",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction and Motivation\n------------------------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.07574"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "03b945a38102e0816f37dd67b7e975a4"
  },
  {
    "id": "arxiv_27c6059e550e8ff6",
    "title": "Certified Patch Robustness via Smoothed Vision Transformers",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.07719"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "27c6059e550e8ff65617559023400b1c"
  },
  {
    "id": "arxiv_8fad072693ba66f9",
    "title": "Quantifying Local Specialization in Deep Neural Networks",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.08058"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "8fad072693ba66f91ea02e912436c655"
  },
  {
    "id": "arxiv_e66bebdb252a6220",
    "title": "Analyzing Dynamic Adversarial Training Data in the Limit",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.08514"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "e66bebdb252a6220eda22876d977a84c"
  },
  {
    "id": "arxiv_15eb203180cab2f1",
    "title": "MEMO: Test Time Robustness via Adaptation and Augmentation",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.09506"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "15eb203180cab2f1b3c05f723a37f90c"
  },
  {
    "id": "arxiv_df96fcd4101b5279",
    "title": "What Would Jiminy Cricket Do? Towards Agents That Behave Morally",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.13136"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "df96fcd4101b5279b55d051013e57a44"
  },
  {
    "id": "arxiv_6e27957f99ea08be",
    "title": "Toward a Theory of Justice for Artificial Intelligence",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "218\n? 2022 by the American Academy of Arts & Sciences  \nPublished under a Creative Commons Attribution- \nNonCommercial 4.0 International (CC BY -NC 4.0) license \nhttps://doi.org/10.1162/DAED_a_01911Toward a Theory of Justice for  \nArtificial Intelligence\nIason Gabriel\nThis essay explores the relationship between artificial intelligence and principles of \ndistributive justice. Drawing upon the political philosophy of John Rawls, it holds \nthat the basic structure of society should be understood as a composite of sociotech-\nnical systems, and that the operation of these systems is increasingly shaped and in-\nfluenced by AI. Consequently, egalitarian norms of justice apply to the technology \nwhen it is deployed in these contexts. These norms entail that the relevant AI systems \nmust meet a certain standard of public justification, support citizens? rights, and \npromote substantively f air outcomes, something that requires particular attention \nto the impact they have on the worst-of f ...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.14419"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "6e27957f99ea08be41b331e52e28515b"
  },
  {
    "id": "arxiv_32193b4c5013c697",
    "title": "AI Ethics Statements -- Analysis and lessons learnt from NeurIPS Broader Impact Statements",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.01705"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "32193b4c5013c697aaa495098f6121cf"
  },
  {
    "id": "arxiv_5249c85b08bb42ca",
    "title": "Adversarial GLUE: A Multi-Task Benchmark for Robustness Evaluation of Language Models",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.02840"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "5249c85b08bb42cad7baa16536c30594"
  },
  {
    "id": "arxiv_43f3d019e5a786f9",
    "title": "B-Pref: Benchmarking Preference-Based Reinforcement Learning",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.03026"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "43f3d019e5a786f9e13ad48165961649"
  },
  {
    "id": "arxiv_88857fbe01e7fa53",
    "title": "Linguistic Cues of Deception in a Multilingual April Fools' Day Context",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.03913"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "88857fbe01e7fa536b3546526a91b7a7"
  },
  {
    "id": "arxiv_b990438c3d2f4172",
    "title": "Data Augmentation Can Improve Robustness",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.05328"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "b990438c3d2f4172f63ed3fb376fc7ac"
  },
  {
    "id": "arxiv_b344183bfa91e639",
    "title": "Solving Probability and Statistics Problems by Program Synthesis",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Solving Probability and Statistics Problems by Program Synthesis\nLeonard Tang\nHarvard University\nMathematicsElizabeth Ke\nMIT\nMathematicsNikhil Singh\nMIT\nMedia Lab\nNakul Verma\nColumbia University\nComputer Science DepartmentIddo Drori\nMIT\nEECS\nAbstract\nWe solve university level probability and statis-\ntics questions by program synthesis using\nOpenAI?s Codex, a Transformer trained on\ntext and ?ne-tuned on code. We transform\ncourse problems from MIT?s 18.05 Introduc-\ntion to Probability and Statistics and Harvard?s\nSTAT110 Probability into programming tasks.\nWe then execute the generated code to get\na solution. Since these course questions are\ngrounded in probability, we often aim to have\nCodex generate probabilistic programs that\nsimulate a large number of probabilistic depen-\ndencies to compute its solution. Our approach\nrequires prompt engineering to transform the\nquestion from its original form to an explicit,\ntractable form that results in a correct program\nand solution. To estimat...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.08267"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "b344183bfa91e6390d52521000889e57"
  },
  {
    "id": "arxiv_20e257a61198f4b8",
    "title": "Discrete Representations Strengthen Vision Transformer Robustness",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.10493"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "20e257a61198f4b85412e3111d39b638"
  },
  {
    "id": "arxiv_f3ed9ac8b53110c3",
    "title": "ReAct: Out-of-distribution Detection With Rectified Activations",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.12797"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "f3ed9ac8b53110c3f6800e3db67e8dfb"
  },
  {
    "id": "arxiv_02cb990df1910ff1",
    "title": "Normative Disagreement as a Challenge for Cooperative AI",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.13872"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "02cb990df1910ff181c0ac70d969f3c2"
  },
  {
    "id": "arxiv_122063637b044550",
    "title": "Pyramid Adversarial Training Improves ViT Performance",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.15121"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "122063637b044550e340b44b05203408"
  },
  {
    "id": "arxiv_c07dc0e7916bb37d",
    "title": "Certified Adversarial Defenses Meet Out-of-Distribution Corruptions: Benchmarking Robustness and Simple Baselines",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2112.00659"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "c07dc0e7916bb37d8a25132e2685d02c"
  },
  {
    "id": "arxiv_26f49ad8f2b64b02",
    "title": "A General Language Assistant as a Laboratory for Alignment",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2112.00861"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "26f49ad8f2b64b02085bf9211104583b"
  },
  {
    "id": "arxiv_481bd6001ca24466",
    "title": "PixMix: Dreamlike Pictures Comprehensively Improve Safety Measures",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2112.05135"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "481bd6001ca2446636547dd0484ada51"
  },
  {
    "id": "arxiv_334413a1e3315407",
    "title": "Socially Responsible AI Algorithms: Issues, Purposes, and Challenges",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2101.02032"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "334413a1e3315407cc5d7ea040822e21"
  },
  {
    "id": "arxiv_6ccfec6178816685",
    "title": "Bridging In- and Out-of-distribution Samples for Their Better Discriminability",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2101.02500"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "6ccfec6178816685bb9aa5f5e8fc7e0e"
  },
  {
    "id": "arxiv_6c87991453243015",
    "title": "Teaming up with information agents",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Teaming up with information agents   \n \nDr. Jurriaan van Diggelen  \nDr. Wiard Jorritsma  \nDr. Bob van der Vecht  \njurriaan.vandiggelen@tno.nl , wiard.jorritsma@tno.nl , bob.vandervecht@tno.nl  \nTNO, the Netherlands  \n \nIntroduction  \nRecent developments in Artificial Intelligence (AI) have led to impressive results \nin machine learning and pattern recognition, but have also led to the insight that AI \nhardly ever  functions in isolation [1]. Most p ractical AI applications involve \nhumans , e.g. for providing instructions, for correcting the machine  if needed , for \ninterpreting the machine?s outcomes . A recent article [2] summarizes this as ? no AI \nis an island ?, and argues that AI agents should be endowed with teaming \nintelligence  that allows them to team up with humans.   \nWhereas teaming skills come naturally to humans, coding them into a computer \nhas proven difficult. It involves (among others) making the computer decide which \ninformation to share with its teammates, wh...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2101.06133"
    ],
    "tags": [],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "6c87991453243015ac3212ffff727cec"
  },
  {
    "id": "arxiv_8e0b3bede15d2844",
    "title": "Adversarial Interaction Attack: Fooling AI to Misinterpret Human Intentions",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2101.06704"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "8e0b3bede15d2844f624a09eb2f55d0c"
  },
  {
    "id": "arxiv_c7b84bc87ee9cfb7",
    "title": "Making Responsible AI the Norm rather than the Exception",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Montreal AI Ethics Institute\n \n \nAn international, non-profit research institute helping humanity define its place in a world\n \nincreasingly driven and characterized by algorithms\n \n \nWebsite\n?\n: \n?\nhttps://montrealethics.ai\n \n \nNewsletter\n?\n: \n?\nhttps://aiethics.substack.com\n \n \n \nMaking Responsible AI the Norm rather than the Exception\n \nA report prepared by the Montreal AI Ethics Institute\n \nfor the National Security Commission on Artificial Intelligence\n \n \nBased on insights, analysis, and original research by the Montreal AI Ethics Institute (MAIEI)\n \nstaff of the \n?\nNSCAI Key Considerations for Responsible Development and Fielding of\n \nArtificial Intelligence\n?\n and supplemented by \n?\nworkshop\n?\n contributions from the AI Ethics\n \ncommunity convened by MAIEI on September 23, 2020.\n \n \nSubmitted on January 13, 2021\n \n \nPrimary contact for the report:\n \n \nAbhishek Gupta (\n?\nabhishek@montrealethics.ai\n?\n)\n \nFounder and Principal Researcher, Montreal AI Ethics Institute\n \nMachine ...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2101.11832"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Published in academic venue",
    "source_id": "c7b84bc87ee9cfb76f442a2d17610af6"
  },
  {
    "id": "arxiv_3220cd2617965b93",
    "title": "Fairness through Social Welfare Optimization",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2102.00311"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "3220cd2617965b938e4126aae21b286a"
  },
  {
    "id": "arxiv_cf6d86c6187b6551",
    "title": "Counterfactual Planning in AGI Systems",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2102.00834"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "cf6d86c6187b65515c75270394302627"
  },
  {
    "id": "arxiv_e02500165c9882ce",
    "title": "Exploring Beyond-Demonstrator via Meta Learning-Based Reward Extrapolation",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2102.02454"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "e02500165c9882ce286184172d1ad1c0"
  },
  {
    "id": "arxiv_191e09b94ec233fd",
    "title": "A Decentralized Approach towards Responsible AI in Social Ecosystems",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "A Decentralized Approach towards Responsible AI in Social Ecosystems Wenjing Chu Futurewei Technologies, Inc. wchu@futurewei.com    Abstract For AI technology to fulfill its full promises, we must have effective means to ensure Responsible AI behavior and cur-tail potential irresponsible use, e.g., in areas of privacy pro-tection, human autonomy, robustness, and prevention of bi-ases and discrimination in automated decision making. Re-cent literature in the field has identified serious shortcomings of narrow technology focused and formalism-oriented re-search and has proposed an interdisciplinary approach that brings the social context into the scope of study.   In this paper, we take a sociotechnical approach to propose a more expansive framework of thinking about the Responsi-ble AI challenges in both technical and social context. Effec-tive solutions need to bridge the gap between a technical sys-tem with the social system that it will be deployed to. To this end, we propose comp...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2102.06362"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "191e09b94ec233fdbfb7aa23877a7f2d"
  },
  {
    "id": "arxiv_dff8aedeb662848f",
    "title": "Mitigating Negative Side Effects via Environment Shaping",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2102.07017"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "dff8aedeb662848f79bc90a27eaf8f5a"
  },
  {
    "id": "arxiv_913763e4d36b0f9e",
    "title": "On the Equilibrium Elicitation of Markov Games Through Information Design",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2102.07152"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "913763e4d36b0f9e4d7d12502362fa2e"
  },
  {
    "id": "arxiv_beb53e03ce611e66",
    "title": "Machine Learning Model Development from a Software Engineering Perspective: A Systematic Literature Review",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2102.07574"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "beb53e03ce611e669108a73fc0145a00"
  },
  {
    "id": "arxiv_2fa1b68cb500bcd1",
    "title": "How RL Agents Behave When Their Actions Are Modified",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2102.07716"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "2fa1b68cb500bcd1bf76eefa3a22b52f"
  },
  {
    "id": "arxiv_9312ad006aca35cb",
    "title": "Training a Resilient Q-Network against Observational Interference",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Introduction\n------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2102.09677"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Published in academic venue",
    "source_id": "9312ad006aca35cb95f60f5b08fb07f2"
  },
  {
    "id": "arxiv_f1a46dbfbe90205f",
    "title": "Software Architecture for Next-Generation AI Planning Systems",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2102.10985"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "f1a46dbfbe90205f6d7d41fe82900dab"
  },
  {
    "id": "arxiv_99cb587661c88b56",
    "title": "Beyond Fine-Tuning: Transferring Behavior in Reinforcement Learning",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2102.13515"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "99cb587661c88b56aa49ea81468c8f74"
  },
  {
    "id": "arxiv_4d29d4a065f90b60",
    "title": "Secure Evaluation of Knowledge Graph Merging Gain",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.00082"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "4d29d4a065f90b60d68fd63bd6e70d60"
  },
  {
    "id": "arxiv_9985528a03f79df7",
    "title": "Evaluating Robustness of Counterfactual Explanations",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.02354"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "9985528a03f79df7ab395d787a35ab92"
  },
  {
    "id": "arxiv_378d3427c0ffac74",
    "title": "Symbolic Reinforcement Learning for Safe RAN Control",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction and Motivation\n-------------------------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.06602"
    ],
    "tags": [],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "378d3427c0ffac7400092b06246f15cb"
  },
  {
    "id": "arxiv_b71c7e1c9618e211",
    "title": "Towards Risk Modeling for Collaborative AI",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.07460"
    ],
    "tags": [],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "b71c7e1c9618e211deb045c196821411"
  },
  {
    "id": "arxiv_7349535db7a4ab6a",
    "title": "Success Weighted by Completion Time: A Dynamics-Aware Evaluation Criteria for Embodied Navigation",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.08022"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "7349535db7a4ab6a9ec3cd0a369f4d4d"
  },
  {
    "id": "arxiv_3887e5490a7a9880",
    "title": "Lyapunov Barrier Policy Optimization",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.09230"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "3887e5490a7a9880f242d7505634adbc"
  },
  {
    "id": "arxiv_1717dd816d939c97",
    "title": "Systematic Mapping Study on the Machine Learning Lifecycle",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.10248"
    ],
    "tags": [],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "1717dd816d939c979042176b5a004557"
  },
  {
    "id": "arxiv_59f90d6e3944f784",
    "title": "Combining Reward Information from Multiple Sources",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.12142"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "59f90d6e3944f784abd2420111e95882"
  },
  {
    "id": "arxiv_715784c647249f72",
    "title": "Assured Learning-enabled Autonomy: A Metacognitive Reinforcement Learning Framework",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.12558"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "715784c647249f72190e8326440e99e0"
  },
  {
    "id": "arxiv_a359baed17693d64",
    "title": "Counterfactual Explanation with Multi-Agent Reinforcement Learning for Drug Target Prediction",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.12983"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "a359baed17693d647b41f3135eab958c"
  },
  {
    "id": "arxiv_fcc1ea7b94857d53",
    "title": "W2WNet: a two-module probabilistic Convolutional Neural Network with embedded data cleansing functionality",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.13107"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "fcc1ea7b94857d53fab935650a85f7b7"
  },
  {
    "id": "arxiv_7bec26c394380c20",
    "title": "A Bayesian Approach to Identifying Representational Errors",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.15171"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "7bec26c394380c20518e354080a16aba"
  },
  {
    "id": "arxiv_e1dbcfab2d880dae",
    "title": "Towards An Ethics-Audit Bot",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "TOWARDS AN ETHICS-AUDIT BOT \nSiani Pearson, Martin Lloyd \nJust Algorithms Action Group (JAAG), UK \nsiani.pearson; info@jaag.org.uk \n \n \nVivek Nallur \nSchool of Computer Science, University College Dublin, Ireland \nvivek.nallur@ucd.ie  \n \n \nABSTRACT \nIn this paper we focus on artificial intelligence (AI) for governance, not governance for AI, and on just one aspect of \ngovernance, namely ethics audit. Different kinds of ethical audit bots are possible, but who makes the choices and what \nare the implications? In this paper, we do not provide ethical/philosophical solutions, but rather focus on the technical \naspects of what an AI-based solution for validating the ethical soundness of a target system would be like. We propose a \nsystem that is able to conduct an ethical audit  of a target system, given certain socio-technical conditions. To be more \nspecific, we propose the creation of a bot that is able to support organisations in ensuring that their software development \nlifecycles ...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.15746"
    ],
    "tags": [],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "e1dbcfab2d880dae2e20d8eee2c4a15f"
  },
  {
    "id": "arxiv_0141cd563881ab4f",
    "title": "Voluntary safety commitments provide an escape from over-regulation in AI development",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Research publication: Voluntary safety commitments provide an escape from over-regulation in AI development",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2104.03741"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "0141cd563881ab4f5cc5498335ded12d"
  },
  {
    "id": "arxiv_cdeea8d88c36ce15",
    "title": "Artificial intelligence, human rights, democracy, and the rule of law: a primer",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "ARTIFICIAL\nINTELLIGENCE, \nHUMAN RIGHTS,\nDEMOCRACY, AND\nTHE RULE OF LAW\nDAVID LESLIE, CHRISTOPHER BURR,\nMHAIRI AITKEN, JOSH COWLS, \nMIKE KATELL, & MORGAN BRIGGS\nWith a foreword by\nLORD TIM CLEMENT-JONESPREPARED TO SUPPORT THE FEASIBILITY STUDY\nPUBLISHED BY THE COUNCIL OF EUROPE'S AD\nHOC COMMITTEE ON ARTIFICIAL INTELLIGENCEA PRIMER",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2104.04147"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "cdeea8d88c36ce156a4d0e9f8ca81701"
  },
  {
    "id": "arxiv_ea8c2d32c2566698",
    "title": "The Atari Data Scraper",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I.???Introduction\n-----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2104.04893"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "ea8c2d32c25666984e45793dae543f09"
  },
  {
    "id": "arxiv_5fd293522bc3b6b6",
    "title": "Action Advising with Advice Imitation in Deep Reinforcement Learning",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2104.08441"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "5fd293522bc3b6b6ce0a980ce21d644f"
  },
  {
    "id": "arxiv_f0c09aed3d03e527",
    "title": "Causal Learning for Socially Responsible AI",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2104.12278"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "f0c09aed3d03e5275006cb2565d8ea9f"
  },
  {
    "id": "arxiv_73643a60bb86bf2f",
    "title": "A Framework for Ethical AI at the United Nations",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Unite Paper 2021 <<number to be assigned>> A Framework for Ethical AI at the United Nations Prepared by:  Lambert Hogenhout Organization:  UN Office for Information and Communications Technology Contact:    hogenhout@un.org Date:     15-3-2021  Contents  EXECUTIVE SUMMARY 2 INTRODUCTION 3 1. PROBLEMS WITH AI 5 2. DEFINING ETHICAL AI 11 3. IMPLEMENTING ETHICAL AI 20 CONCLUSION 23        Unite Papers? ?Informing and Capturing UN Technological Innovation?  An occasional paper series to share ideas, insights and in-depth studies on technology and the United Nations. The series is sponsored by the Office of Information and Communications Technology (OICT) but does not necessarily represent the official views of OICT or of the United Nations.",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2104.12547"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "73643a60bb86bf2fd0995a74ce06f8b7"
  },
  {
    "id": "arxiv_bae10359a6547ffd",
    "title": "pyBKT: An Accessible Python Library of Bayesian Knowledge Tracing Models",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2105.00385"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "bae10359a6547ffdba5e45b9df0c3ee7"
  },
  {
    "id": "arxiv_7d73ab05546a6fcf",
    "title": "Hybrid Intelligence",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "CATCHWORD\nHybrid Intelligence\nDominik Dellermann M.Sc. ?Philipp Ebel ?Matthias So ?llner ?Jan Marco Leimeister\nReceived: 30 October 2017 / Accepted: 7 November 2018 / Published online: 28 March 2019\n/C211Springer Fachmedien Wiesbaden GmbH, ein Teil von Springer Nature 2019\nKeywords Hybrid intelligence /C1Arti?cial intelligence /C1\nMachine learning /C1Human-computer collaboration /C1\nMachines as teammates /C1Future of work\n1 Introduction\nResearch has a long history of discussing what is superior\nin predicting certain outcomes: statistical methods or the\nhuman brain. This debate has repeatedly been sparked off\nby the remarkable technological advances in the ?eld of\narti?cial intelligence (AI), such as solving tasks like object\nand speech recognition, achieving signi?cant improve-\nments in accuracy through deep-learning algorithms\n(Goodfellow et al. 2016 ), or combining various methods of\ncomputational intelligence, such as fuzzy logic, genetic\nalgorithms, and case-based reasoning (Med...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2105.00691"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "7d73ab05546a6fcfd82aa9713733128c"
  },
  {
    "id": "arxiv_41bc4ce3496b2fe9",
    "title": "RL-IoT: Reinforcement Learning to Interact with IoT Devices",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2105.00884"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "41bc4ce3496b2fe92fd57bb393b3edfd"
  },
  {
    "id": "arxiv_f02af23f63156be9",
    "title": "AI Risk Skepticism",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 \n AI Risk Skepticism  \n \n \nRoman V. Yampolskiy  \nComputer Science  and Engineering  \nUniversity of Louisville  \nroman.yampolskiy@louisville.edu  \n \n \nAbstract  \nIn this work, we  survey  skepticism regarding AI risk and show parallels with other types of \nscientific skepticism . We start by classifying  different types of AI Risk skepticism and analyze \ntheir root causes.  We conclude by  suggest ing some intervention approaches, which  may be \nsuccessful in reducing AI risk skepticism , at least amongst artificial intelligence researchers.  \n \nKeywords:  AI Risk, AI Risk Skeptic ism, AI Risk Denialism , AI Safety, Existential Risk . \n \n \n1. Introduction  to AI Risk Skepticism  \nIt has been predicted  that if recent advanceme nt in machine learning continue  uninterrupted , \nhuman -level or even superintelligent Artificially Intelligent  (AI) systems will be designed at some \npoint in the near future  [1]. Currently available (and near -term predicted) AI software  is subhuman \nin...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2105.02704"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "f02af23f63156be9f54dad25a690fffe"
  },
  {
    "id": "arxiv_b92f2e30b3f18ed7",
    "title": "Finding the unicorn: Predicting early stage startup success through a hybrid intelligence method",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Predicting Startup Success through Hybrid Intelligence \n Thirty Eighth International Conference on Information Systems, South Korea 2017 1 Finding the Unicorn: Predicting Early Stage Startup Success through a Hybrid Intelligence Method Short Paper  Dominik Dellermann  \nUniversity of Kassel/Information \nSystems   \nPfannkuchstr.1, 34121 Kassel, Germany  \nDellermann@uni -kassel.de  Nikolaus Lipusch  \nUnive rsity of Kassel/Information \nSystems   \nPfannkuchstr.1, 34121 Kassel, Germany  \nNikolaus.lipusch@uni -kassel.de  \n Philipp Ebel  \nUniversity of Kassel/Information \nSystems   \nPfannkuchstr.1, 34121 Kassel, Germany  \nPh.ebel@uni -kassel.de  Karl Michael Popp  \nSAP SE  \nDietmar -Hopp -Allee 16, 69190 \nWalldorf, Germany  \nkarl.michael.popp@sap.com   \nJan Marco Leimeister  \nUniversity of Kassel/University of St. Gallen  \nInformation Systems/Institute of Information Management  \nPfannkuchstr.1, 34121 Kassel, Germany/M?ller -Friedberg -Strasse 8, 9000 \nSt.Gallen, Switzerland  \nleimeister@un...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2105.03360"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "b92f2e30b3f18ed7058d7b8eba660c49"
  },
  {
    "id": "arxiv_7b0d451e83568289",
    "title": "Hard Choices and Hard Limits for Artificial Intelligence",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Hard Choices and Hard Limits for Artificial Intelligence              Bryce Goodman  Department of Philosophy  University of Oxford  United Kingdom  bwgoodman@gmail.com            ABSTRACT Artificial intelligence (AI) is supposed to help us make better choices [1]. Some of these choices are small, like what route to take to work [27], or what music to listen to [64]. Others are big, like what treatment to administer for a disease [74] or how long to sentence someone for a crime [2]. If AI can assist with these big decisions, we might think it can also help with hard choices, cases where alternatives are neither better, worse nor equal but on a par [15]. The aim of this paper, however, is to show that this view is mistaken: the fact of parity shows that there are hard limits on AI in decision making and choices that AI cannot, and should not, resolve. KEYWORDS Value alignment; fairness; hard choices; AI ethics 1 Introduction Artificial intelligence (AI) is supposed to help us make be...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2105.07852"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "7b0d451e8356828929085352e215f289"
  },
  {
    "id": "arxiv_a729a26f4f765bad",
    "title": "An Offline Risk-aware Policy Selection Method for Bayesian Markov Decision Processes",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "An O \u000fine Risk-aware Policy Selection Method for Bayesian\nMarkov Decision Processes\nGiorgio Angelottia,b,\u0003, Nicolas Drougarda,b, Caroline P. C. Chanela,b\naANITI - Arti?cial and Natural Intelligence Toulouse Institute, University of Toulouse, France\nbISAE-SUPAERO, University of Toulouse, France\nAbstract\nIn O\u000fine Model Learning for Planning and in O \u000fine Reinforcement Learning, the limited data\nset hinders the estimate of the Value function of the relative Markov Decision Process (MDP).\nConsequently, the performance of the obtained policy in the real world is bounded and possibly\nrisky, especially when the deployment of a wrong policy can lead to catastrophic consequences.\nFor this reason, several pathways are being followed with the scope of reducing the model error (or\nthe distributional shift between the learned model and the true one) and, more broadly, obtaining\nrisk-aware solutions with respect to model uncertainty. But when it comes to the ?nal application\nwhich baseline should...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2105.13431"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "a729a26f4f765bad65dc0151c3ecf8e7"
  },
  {
    "id": "arxiv_aa2397b1dcdda034",
    "title": "Towards a Mathematical Theory of Abstraction",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2106.01826"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "aa2397b1dcdda034045dbaf26525b126"
  },
  {
    "id": "arxiv_49d1e059b5b2252b",
    "title": "Definitions of intent suitable for algorithms",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2106.04235"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "49d1e059b5b2252b1792f7fb47553887"
  },
  {
    "id": "arxiv_96d146702316db21",
    "title": "Curriculum Design for Teaching via Demonstrations: Theory and Applications",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2106.04696"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "96d146702316db2130833097d65c5d6a"
  },
  {
    "id": "arxiv_357c9172db62c1a5",
    "title": "Synthesising Reinforcement Learning Policies through Set-Valued Inductive Rule Learning",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2106.06009"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "357c9172db62c1a56eeea59cf764267c"
  },
  {
    "id": "arxiv_f9ac5781faaed74d",
    "title": "Developing a Fidelity Evaluation Approach for Interpretable Machine Learning",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2106.08492"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "f9ac5781faaed74d3e26472bd1a7ed17"
  },
  {
    "id": "arxiv_feb742285ce9f746",
    "title": "Hard Choices in Artificial Intelligence",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2106.11022"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "feb742285ce9f746cedcd7f73b797083"
  },
  {
    "id": "arxiv_950357c48af62862",
    "title": "Institutionalising Ethics in AI through Broader Impact Requirements",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Introduction\n------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2106.11039"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "950357c48af628620ea7265ca9713fc6"
  },
  {
    "id": "arxiv_b49589e94ad75d34",
    "title": "Not all users are the same: Providing personalized explanations for sequential decision making problems",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Illustrative example\n--------------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2106.12207"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "b49589e94ad75d344a9c2a5305b8549f"
  },
  {
    "id": "arxiv_d196c5722d701595",
    "title": "The Threat of Offensive AI to Organizations",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2106.15764"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "d196c5722d7015956a5930d50bbc52ad"
  },
  {
    "id": "arxiv_942a97fcf69f4e99",
    "title": "ML-Quadrat & DriotData: A Model-Driven Engineering Tool and a Low-Code Platform for Smart IoT Services",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.02692"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "942a97fcf69f4e992d9690a156fc986b"
  },
  {
    "id": "arxiv_342c6984900004ff",
    "title": "Integrating Planning, Execution and Monitoring in the presence of Open World Novelties: Case Study of an Open World Monopoly Solver",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Introduction\n------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.04303"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Academic research release",
    "source_id": "342c6984900004ffe5467063dbc8ec6d"
  },
  {
    "id": "arxiv_93b71b609bfa6bfb",
    "title": "Aligning an optical interferometer with beam divergence control and continuous action space",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.04457"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "93b71b609bfa6bfb22fb3aa9b2634396"
  },
  {
    "id": "arxiv_a1647aa4fae04ddf",
    "title": "Not Quite 'Ask a Librarian': AI on the Nature, Value, and Future of LIS",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "This is an author preprint. Please refer to the final published\nversion:\nDinneen, J. D., Bubinger, H. (2021). Not Quite ?Ask a\nLibrarian?: AI on the nature, value, and future of LIS. In\nASIS&T ?21: Proceedings of the 84th Annual Meeting of the\nAssociation for Information Science & Technology, 58.\nASIS&T Annual Meeting 2021 1 Papers\nNot Quite ?Ask a Librarian? :\nAI on the Nature, Value, and Future of LIS\nJesse David Dinneen\nHumboldt-Universit?t zu Berlin, Germany\njesse.dinneen@hu-berlin.deHelen Bubinger\nHumboldt-Universi?t zu Berlin, Germany\nhelen.bubinger@student.hu-berlin.de\nABSTRACT\nAI language models trained on Web data generate prose that reflects human knowledge and public sentiments, but\ncan also contain novel insights and predictions. We asked the world?s best language model, GPT-3, fifteen difficult\nquestions about the nature, value, and future of library and information science (LIS), topics that receive perennial\nattention from LIS scholars. We present highlights from its ...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.05383"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Published in academic venue",
    "source_id": "a1647aa4fae04ddf206f1473ff6efda3"
  },
  {
    "id": "arxiv_a0c29a80d370bee9",
    "title": "aiSTROM -- A roadmap for developing a successful AI strategy",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.06071"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "a0c29a80d370bee9e8c3ce0041e224a6"
  },
  {
    "id": "arxiv_839c200889ebc513",
    "title": "Deep Adaptive Multi-Intention Inverse Reinforcement Learning",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.06692"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "839c200889ebc513bdd5cf615ccac273"
  },
  {
    "id": "arxiv_349b721fcb4e01ce",
    "title": "A Modulation Layer to Increase Neural Network Robustness Against Data Quality Issues",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.08574"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "349b721fcb4e01cea631d2b13ae9a0c6"
  },
  {
    "id": "arxiv_62e683d54a625bee",
    "title": "On the Veracity of Local, Model-agnostic Explanations in Audio Classification: Targeted Investigations with Adversarial Examples",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.09045"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "62e683d54a625beee14632594079b8dd"
  },
  {
    "id": "arxiv_ffcecabe153f9af6",
    "title": "Towards Industrial Private AI: A two-tier framework for data and model security",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.12806"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "ffcecabe153f9af6ee57bd3da9f4a991"
  },
  {
    "id": "arxiv_ef2214c5eb3122eb",
    "title": "A Reflection on Learning from Data: Epistemology Issues and Limitations",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "A Reflection on Learning from Data: Epistemology Issues and Limitations  \nAhmad Hammoudeh a1,SaraTedmori a,NadimObeid b \na Princess Sumaya University for Technology  \nb The University of Jordan   \n \n1 Corresponding author : E-mail: at.hammoudeh@gmail.com.  \n  \n \nHAMMOUDEH, LEARNING FROM DATA 2019        2  \nAbstract  \nAlthough learning f rom data is effective and has achieved significan t milestones, it has many \nchallenges and limitations. Learning from data starts from observations and then proceeds to \nbroader generalizations. This framework is controversial in science, yet it has achieved \nremarkable engineering successes. This paper reflects on some epistemological issues and \nsome of the limitations of the knowledge discovered in data. The document  discusses the \ncommon perception that getting more data is the key to achieving better machine learning \nmodels from theoretical and practical perspectives. The paper sheds some light on the \nshortcomings of using generic mathemati...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.13270"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "ef2214c5eb3122eb7c35d6a85bd07b78"
  },
  {
    "id": "arxiv_46ba239757968f3f",
    "title": "Discovering User-Interpretable Capabilities of Black-Box Planning Agents",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.13668"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "46ba239757968f3f4a8421e9a457b1db"
  },
  {
    "id": "arxiv_844cb18b7b1f087b",
    "title": "An Ethical Framework for Guiding the Development of Affectively-Aware Artificial Intelligence",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.13734"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "844cb18b7b1f087bfc6df9709bc4dca8"
  },
  {
    "id": "arxiv_56ff800292644bea",
    "title": "The Role of Social Movements, Coalitions, and Workers in Resisting Harmful Artificial Intelligence and Contributing to the Development of Responsible AI",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "The Role of Social Movements, Coalitions, and Workers in Resisting Harmful Artificial Intelligence\nand Contributing to the Development of Responsible AI\nWorking Paper\nSusan von Struensee, JD, MPH\nGlobal Research Initiative\nJune 2021\nIntroduction\nThe rapid spread of artificial intelligence (AI) systems has precipitated a rise in ethical and rights-based\nframeworks intended to guide the development and use of these technologies. Despite the proliferation of these\n\"AI principles, \"  there is  mounting public concern over the influence that the AI systems have in our society,\nand coalitions in all sectors are organizing to resist harmful applications of AI worldwide.\nThe globe has witnessed an exponential growth in the use of AI and other automated decision-making systems.\nGovernment institutions increasingly rely on automated decision-making technologies in many areas, such as\nmanaging traffic,1  conducting risk assessments,2  screening immigrants,3  allocating social services,4  and m...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.14052"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "56ff800292644bea1be30f18f97ff2f3"
  },
  {
    "id": "arxiv_e279806c12c8a668",
    "title": "A Decision Model for Decentralized Autonomous Organization Platform Selection: Three Industry Case Studies",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.14093"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "e279806c12c8a6682a05f0a33c5aacb0"
  },
  {
    "id": "arxiv_577ffc18173d346a",
    "title": "DySR: A Dynamic Representation Learning and Aligning based Model for Service Bundle Recommendation",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2108.03360"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "577ffc18173d346a11c90cd1a1f861d6"
  },
  {
    "id": "arxiv_f53e1e0c49789ad6",
    "title": "Beyond Fairness Metrics: Roadblocks and Challenges for Ethical AI in Practice",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2108.06217"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "f53e1e0c49789ad663c2d392f6f2470d"
  },
  {
    "id": "arxiv_95b381a292b906e9",
    "title": "A Framework for Understanding AI-Induced Field Change: How AI Technologies are Legitimized and Institutionalized",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "A Framework for Understanding AI -Induced Field Change: How \nAI Technologies are Legitimized and Institutionalized  \n \n  \n  \n  \n  Benjamin Cedric Larsen   \n Department  of Economics \nGovernment & Business   \n Copenhagen Business School  \n Copenhagen, Denmark  \n bcl.egb@cbs .dk  \n  \n  \n  \n  \n \nABSTRACT  \nArtificial intelligence (AI) systems operate in increasingly diverse \nareas, from healthcare to facial recognition, the stock market, \nautonomous vehicles, and so on. While the underlying digital \ninfrastructure of AI systems is developing rapidly, each area of \nimplemen tation is subject to different degrees and processes of \nlegitimization. By combining elements from institutional theory \nand information systems -theory, this paper presents a conceptual \nframework to analyze and unde rstand AI -induced field -change. \nThe introd uction of novel AI -agents into new or existing fields \ncreates a dynamic in which algorithms (re)shape organizations \nand institutions while existing inst...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2108.07804"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "95b381a292b906e9691057da8db17d1b"
  },
  {
    "id": "arxiv_ec9b13447a3e2519",
    "title": "Safe Transformative AI via a Windfall Clause",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2108.09404"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "ec9b13447a3e2519a1e3752b9e389386"
  },
  {
    "id": "arxiv_1a84b206594ab34b",
    "title": "Learning Causal Models of Autonomous Agents using Interventions",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2108.09586"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "1a84b206594ab34ba77a101bd54bdf80"
  },
  {
    "id": "arxiv_c085d2d1d8ede633",
    "title": "With One Voice: Composing a Travel Voice Assistant from Re-purposed Models",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2108.11463"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "c085d2d1d8ede63323f432acd928c2d8"
  },
  {
    "id": "arxiv_759a6e91ea8575e1",
    "title": "Why and How Governments Should Monitor AI Development",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Executive summary\n-----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2108.12427"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "759a6e91ea8575e1e5b79c948bf9f426"
  },
  {
    "id": "arxiv_4d68272ca50e9711",
    "title": "Problem Learning: Towards the Free Will of Machines",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2109.00177"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "4d68272ca50e9711e6f8c83ac804cc15"
  },
  {
    "id": "arxiv_714861efdafd1851",
    "title": "Towards Resilient Artificial Intelligence: Survey and Research Issues",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Towards Resilient Artificial Intelligence:\nSurvey and Research Issues\nOliver Eigner, Sebastian Eresheim, Peter Kieseberg, Lukas Daniel Klausner,\nMartin Pirker, Torsten Priebe, Simon Tjoa\nInstitute of IT Security Research\nSt. P?lten University of Applied Sciences\n{oliver.eigner, sebastian.eresheim, peter.kieseberg, lukas.daniel.klausner,\nmartin.pirker, torsten.priebe, simon.tjoa}@fhstp.ac.at\nFiammetta Marulli\nDepartment of Mathematics and Physics\nUniversity of Campania ?Luigi Vanvitelli?\nfiammetta.marulli@unicampania.itFrancesco Mercaldo\nDepartment of Medicine and\nHealth Sciences ?Vincenzo Tiberio?\nUniversity of Molise\nfrancesco.mercaldo@unimol.it\nAbstract ?Artificial intelligence (AI) systems are be-\ncoming critical components of today?s IT landscapes.\nTheir resilience against attacks and other environmental\ninfluences needs to be ensured just like for other IT\nassets. Considering the particular nature of AI, and\nmachine learning (ML) in particular, this paper provides\nan overview o...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2109.08904"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "714861efdafd1851c3f7f71989d97e6a"
  },
  {
    "id": "arxiv_b2ad8022e71fd93f",
    "title": "Learning to Assist Agents by Observing Them",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.01311"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "b2ad8022e71fd93f6a46722dd4a4cb3a"
  },
  {
    "id": "arxiv_6843e44989aaddcc",
    "title": "Procedure Planning in Instructional Videos via Contextual Modeling and Model-based Policy Learning",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.01770"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "6843e44989aaddcc3d44fe9d11c0b1b0"
  },
  {
    "id": "arxiv_c515598ed82b0e38",
    "title": "Thinking Fast and Slow in AI: the Role of Metacognition",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Overview\n-----------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.01834"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Academic research release",
    "source_id": "c515598ed82b0e38f43042f1abda5cfb"
  },
  {
    "id": "arxiv_3f5d47ddec0cbf30",
    "title": "Fingerprinting Multi-exit Deep Neural Network Models via Inference Time",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.03175"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "3f5d47ddec0cbf30f633913932b9d488"
  },
  {
    "id": "arxiv_bb5283252d7c5fdc",
    "title": "Robustness of different loss functions and their impact on networks learning capability",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Robustness of different loss functions and their impact \non network?s learning capability  \nVishal Rajput1,?  \n1Computer Science Department, KU Leuven, Belgium  \n?Corresponding author. Email: vishal.rajput@student.kuleuven.be  \n \nAbstract Recent developments in AI have made it ubiquitous, every industry is trying to adopt \nsome form of intelligent processing of their data. Despite so many adva nces in the field, AI?s full \ncapability is yet to be exploited by the industry. Industries that involve some risk factors still \nremain cautious about the usage of AI due to the lack of trust in such autonomous systems. Present -\nday AI might be very good in a lot of things but it is very bad in reasoning and this behavior of AI \ncan lead to catastrophic results. Autonomous cars crashing into a person or a drone getting stuck \nin a tree are a few examples where AI decisions lead to catastrophic results. To devel op insight \nand generate an explanation about the learning capability of AI, we w...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.08322"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "bb5283252d7c5fdc2b489cb390913447"
  },
  {
    "id": "arxiv_ae08d781c06efe3d",
    "title": "Evaluating the Faithfulness of Importance Measures in NLP by Recursively Masking Allegedly Important Tokens and Retraining",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.08412"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "ae08d781c06efe3de684d4e6e8f576ad"
  },
  {
    "id": "arxiv_e2b71b5b174e59cc",
    "title": "Improving End-To-End Modeling for Mispronunciation Detection with Effective Augmentation Mechanisms",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Impro ving End-To-End Modeling for \nMispronunciation Detection with Effective \nAugmentation Mechanisms  \nTien-Hong Lo, Yao -Ting Sung  and Berlin Chen  \nNational Taiwan Normal  University, Taipei  City, Taiwan  \n{teinhonglo,  sungtc, berlin} @ntnu.edu.tw  \n \n \n \nAbstract ? Recently, end -to-end (E2E) model s, which allow to \ntake spectral vector sequences of L2 (second -language) learners? \nutterances as input and produce  the corresponding phone -level \nsequences as output , have attracted much research attention in \ndeveloping mispronunciation detection (MD) system s. However, \ndue to the lack of sufficient labeled  speech  data of L2 speakers for \nmodel estimation , E2E MD model s are prone to overfitting  in \nrelation to conventional ones that are built on  DNN -HMM \nacoustic model s. To alleviate this critical issue , we in this paper \npropose two modeling strategies to enhance the discrimination \ncapability of E2E MD  model s, each of which can implicitly \nleverage the phoneti...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.08731"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "e2b71b5b174e59cc7bfaf121367dd320"
  },
  {
    "id": "arxiv_d9b74722526e4fcd",
    "title": "Value alignment: a formal approach",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.09240"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Published in academic venue",
    "source_id": "d9b74722526e4fcd13dbf56813df0311"
  },
  {
    "id": "arxiv_6ae1ff25b772be68",
    "title": "Risks of AI Foundation Models in Education",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Risks of educational technologies at scale\n---------------------------------------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.10024"
    ],
    "tags": [],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "6ae1ff25b772be686ef8c0fd75dfef94"
  },
  {
    "id": "arxiv_38262fb2240896fa",
    "title": "QuantifyML: How Good is my Machine Learning Model?",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.12588"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "38262fb2240896fac01b0db87dcb1b82"
  },
  {
    "id": "arxiv_ffb3cdbe1647ac78",
    "title": "Understanding Interlocking Dynamics of Cooperative Rationalization",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.13880"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "ffb3cdbe1647ac78495d6f64df006a37"
  },
  {
    "id": "arxiv_efc0cd3231bac3fe",
    "title": "Learning to Be Cautious",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.15907"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "efc0cd3231bac3feea8077db475167c3"
  },
  {
    "id": "arxiv_76fd04d6177fa7e4",
    "title": "A Word on Machine Ethics: A Response to Jiang et al. (2021)",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.04158"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "76fd04d6177fa7e4a6fbf85c305943c9"
  },
  {
    "id": "arxiv_2d0f8fbf5aa49155",
    "title": "Efficient estimates of optimal transport via low-dimensional embeddings",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.04838"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "2d0f8fbf5aa491553e23b73b106a6494"
  },
  {
    "id": "arxiv_6c313d37e8b148d6",
    "title": "Lymph Node Detection in T2 MRI with Transformers",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.04885"
    ],
    "tags": [],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "6c313d37e8b148d6c69057adb3280c5b"
  },
  {
    "id": "arxiv_542736ebb8aad1d0",
    "title": "Explainable AI (XAI): A Systematic Meta-Survey of Current Challenges and Future Opportunities",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.06420"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "542736ebb8aad1d00128b39f55844a50"
  },
  {
    "id": "arxiv_464de48531ae3c80",
    "title": "Improving Learning from Demonstrations by Learning from Experience",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.08156"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "464de48531ae3c80a92faabee44103bf"
  },
  {
    "id": "arxiv_315b5d43a0d58bb6",
    "title": "Software Engineering for Responsible AI: An Empirical Study and Operationalised Patterns",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.09478"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "315b5d43a0d58bb6e2f341beb803c650"
  },
  {
    "id": "arxiv_da0cfd50754b6180",
    "title": "Finding Useful Predictions by Meta-gradient Descent to Improve Decision-making",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Making Sense of The World Through Predictions\n------------------------------------------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.11212"
    ],
    "tags": [],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "da0cfd50754b61801a17af771fae27fd"
  },
  {
    "id": "arxiv_7e373da22bc9542a",
    "title": "Machines & Influence: An Information Systems Lens",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Machines & Influence: An Information Systems Lens  \nShashank Yadav1\nIITB\nAbstract\nPolicymakers face a broader challenge of how to view AI capabilities today and where does\nsociety stand in terms of those capabilities. This paper surveys AI capabilities and tackles this very\nissue, exploring it in context of political security in digitally networked societies. We extend the\nideas of Information Management to better understand contemporary AI systems as part of a larger\nand  more  complex  information  system.  Comprehensively  reviewing  AI  capabilities  and\ncontemporary man-machine interactions, we undertake conceptual development to suggest that\nbetter information management could allow states to more optimally offset the risks of AI enabled\ninfluence  and  better  utilise  the  emerging  capabilities  which  these  systems  have  to  offer  to\npolicymakers and political institutions across the world. Hopefully this long essay will actuate\nfurther debates and discussions over thes...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.13365"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Published in academic venue",
    "source_id": "7e373da22bc9542af1e24fca4f84aeee"
  },
  {
    "id": "arxiv_118b4f6716338f5b",
    "title": "Learning from learning machines: a new generation of AI technology to meet the needs of science",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.13786"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "118b4f6716338f5b7736a9034fb5cc63"
  },
  {
    "id": "arxiv_9f93c053bb136fda",
    "title": "Weighing the Milky Way and Andromeda with Artificial Intelligence",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.14874"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "9f93c053bb136fda9f6c788de50ac321"
  },
  {
    "id": "arxiv_9c44e9033875db80",
    "title": "AI and the Everything in the Whole Wide World Benchmark",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.15366"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "9c44e9033875db80d47817cbec8dba9c"
  },
  {
    "id": "arxiv_0a76ecf713853808",
    "title": "MESA: Offline Meta-RL for Safe Adaptation and Fault Tolerance",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2112.03575"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "0a76ecf713853808cf41547d4342fbad"
  },
  {
    "id": "arxiv_f9b16944b77e75a3",
    "title": "Filling gaps in trustworthy development of AI",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "This is the author's version of the work. It is posted here by permission of the AAAS for personal use. The definitive version was published in Science , (2021-12-10), doi: 10.1126/science.abi7176 https://www.science.org/doi/10.1126/science.abi7176  Filling gaps in trustworthy development of AI Incident sharing, auditing, and other concrete mechanisms  could help verify the trustworthiness of actors By Shahar Avin1*?, Haydn Belfield1,2, Miles Brundage3, Gretchen Krueger3, Jasmine Wang4, Adrian Weller2,6,7, Markus Anderljung8, Igor Krawczuk9, David Krueger5,6, Jonathan Lebensold4,5, Tegan Maharaj5,10, Noa Zilberman11 The\t range\t of\t application\t of\t artificial\tintelligence\t(AI)\tis\tvast,\tas\tis\tthe\tpotential\tfor\tharm.\tGrowing\tawareness\tof\tpotential\trisks\tfrom\t AI\t systems\thas\t spurred\t action\t to\taddress\t those\t risks,\t while\teroding\tconfidence\tin\tAI\tsystems\t and\t the\torganizations\tthat\t develop\t them.\t A\t 2019\tstudy\t (1)\t found\t over\t 80\torganizations\t that\tpublished\tand\tadopted\t\"AI\te...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2112.07773"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "f9b16944b77e75a3da916261754db651"
  },
  {
    "id": "arxiv_226dad31be434c16",
    "title": "Programmatic Reward Design by Example",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Introduction\n------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2112.08438"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "226dad31be434c16248ac394a0fce33c"
  },
  {
    "id": "arxiv_7c7c5101e999d894",
    "title": "WebGPT: Browser-assisted question-answering with human feedback",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2112.09332"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "7c7c5101e999d894cf598473be662dae"
  },
  {
    "id": "arxiv_aa42112787cbc414",
    "title": "Demanding and Designing Aligned Cognitive Architectures",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2112.10190"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "aa42112787cbc41499c090721f1c03b9"
  },
  {
    "id": "arxiv_4bcb6e5e5420699a",
    "title": "Skill Preferences: Learning to Extract and Execute Robotic Skills from Human Feedback.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2108.05382"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "4bcb6e5e5420699a0b0dc34ed6e69573"
  },
  {
    "id": "arxiv_92cde803b8cb2b1d",
    "title": "Optimal Cost Design for Model Predictive Control.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2104.11353"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Published in academic venue",
    "source_id": "92cde803b8cb2b1dc470ec723ca1c4f3"
  },
  {
    "id": "arxiv_7dd0fe90b65c5210",
    "title": "Pragmatic Image Compression for Human-in-the-Loop Decision-Making.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2108.04219"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "7dd0fe90b65c521004bbc3247712b37f"
  },
  {
    "id": "arxiv_b208fd79f647fe24",
    "title": "On complementing end-to-end human behavior predictors with planning.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.05661"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Published in academic venue",
    "source_id": "b208fd79f647fe24573decb2bc265c15"
  },
  {
    "id": "arxiv_e27044932d54ad26",
    "title": "Analyzing Human Models that Adapt Online.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.05746"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "e27044932d54ad260c56dfa4d367950d"
  },
  {
    "id": "arxiv_173c85a03b5009b4",
    "title": "Dynamically Switching Human Prediction Models for Efficient Planning.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.07815"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "173c85a03b5009b4ae8420e7e1b70c42"
  },
  {
    "id": "arxiv_c6e1d26604cebcd7",
    "title": "AMP: Adversarial Motion Priors for Stylized Physics-Based Character Control.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2104.02180"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "c6e1d26604cebcd7d181573dfee094ae"
  },
  {
    "id": "arxiv_21a3c572c5611388",
    "title": "Perceptual Adversarial Robustness: Defense Against Unseen Threat Models.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2006.12655"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "21a3c572c561138809f7c04e6d53652a"
  },
  {
    "id": "arxiv_1118b36d97a0748c",
    "title": "Measuring mathematical problem solving with the math dataset.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.03874"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "1118b36d97a0748c1ebc2e7d85f27ab1"
  },
  {
    "id": "arxiv_a262d9743e00d855",
    "title": "Behavior From the Void: Unsupervised Active Pre-Training.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.04551"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "a262d9743e00d85523b73e9284559b01"
  },
  {
    "id": "arxiv_641ff6dee15b77cf",
    "title": "State Entropy Maximization with Random Encoders for Efficient Exploration.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2102.09430"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "641ff6dee15b77cf2ed27c75d450a762"
  },
  {
    "id": "arxiv_13e9b257e46a7316",
    "title": "Unsupervised Learning of Visual 3D Keypoints for Control.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2106.07643"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "13e9b257e46a73161a608cbdc1b435c6"
  },
  {
    "id": "arxiv_eaf0dda90bdb58bc",
    "title": "Contrastive Code Representation Learning.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2007.04973"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "eaf0dda90bdb58bcf5427325b2de713c"
  },
  {
    "id": "arxiv_82d12f25322fcc11",
    "title": "Offline-to-Online Reinforcement Learning via Balanced Replay and Pessimistic Q-Ensemble.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.00591"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "82d12f25322fcc11c2fa9be90b2dcec4"
  },
  {
    "id": "arxiv_fe1c58202b218fa6",
    "title": "Improving Computational Efficiency in Visual Reinforcement Learning via Stored Embeddings.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.02886"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "fe1c58202b218fa622a3d106fc7f9b41"
  },
  {
    "id": "arxiv_40981833e4aac1ab",
    "title": "URLB: Unsupervised Reinforcement Learning Benchmark.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.15191"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "40981833e4aac1ab5d23165b64a6374f"
  },
  {
    "id": "arxiv_2ddfc52c8f61abd0",
    "title": "Learning State Representations from Random Deep Action-Conditional Predictions.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2102.04897"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "2ddfc52c8f61abd0d0abe51b2f1874bd"
  },
  {
    "id": "arxiv_686b8ae940e6d772",
    "title": "Agent-aware state estimation for autonomous vehicles.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2108.00366"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "686b8ae940e6d7723afd773f604f4057"
  },
  {
    "id": "arxiv_f60dc3ec42354be6",
    "title": "Reinforcement Learning of Implicit and Explicit Control Flow Instructions.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2102.13195"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "f60dc3ec42354be607c544ba174b952f"
  },
  {
    "id": "arxiv_568f000a038e4bfb",
    "title": "Passive Attention in Artificial Neural Networks Predicts Human Visual Selectivity.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.07013"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "568f000a038e4bfbbfcc6c15ab68b948"
  },
  {
    "id": "arxiv_ab8ad7fbfc76f44a",
    "title": "Policy Gradient Bayesian Robust Optimization for Imitation Learning.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2106.06499"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Academic research release",
    "source_id": "ab8ad7fbfc76f44a2912cd5d42a82283"
  },
  {
    "id": "arxiv_c356f4bb1fc1101d",
    "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2109.07958"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "c356f4bb1fc1101d2792f15a9195db94"
  },
  {
    "id": "arxiv_dc43714b96ecfc2b",
    "title": "Truthful AI: Developing and governing AI that does not lie",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Executive Summary & Overview\n----------------------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.06674"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "dc43714b96ecfc2beed9d3c86b31c971"
  },
  {
    "id": "arxiv_1a828311da6c652e",
    "title": "Unsolved Problems in ML Safety.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2109.13916"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "1a828311da6c652ee1982cd7216340d3"
  },
  {
    "id": "arxiv_ec060a99eb4e8e9a",
    "title": "Designing Recommender Systems to Depolarize.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "To appear in First Monday, September 2021   Designing Recommender Systems to Depolarize     Jonathan Stray Center for Human-Compatible AI University of California at Berkeley jstray@berkeley.edu   Abstract  Polarization is implicated in the erosion of democracy and the progression to violence, which makes the polarization properties of large algorithmic content selection systems (recommender systems) a matter of concern for peace and security. While algorithm-driven social media does not seem to be a primary driver of polarization at the country level, it could be a useful intervention point in polarized societies. This paper examines algorithmic depolarization interventions with the goal of conflict transformation: not suppressing or eliminating conflict but moving towards more constructive conflict. Algorithmic intervention is considered at three stages: which content is available (moderation), how content is selected and personalized (ranking), and content presentation and contro...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.04953"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "ec060a99eb4e8e9a15cab3718c650549"
  },
  {
    "id": "arxiv_d515617e558a6b73",
    "title": "Feature Expansive Reward Learning: Rethinking Human Input.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2006.13208"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "d515617e558a6b73441a6e275f8849c1"
  },
  {
    "id": "arxiv_4f277b537530f3d0",
    "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2106.01345"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "4f277b537530f3d03d70405eaddf0108"
  },
  {
    "id": "arxiv_915a21392784fa54",
    "title": "Measuring Coding Challenge Competence With APPS.",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2105.09938"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "915a21392784fa54b433d2c7c2e7c90a"
  },
  {
    "id": "arxiv_7b03a29a7f0a47cb",
    "title": "The Challenge of Value Alignment: from Fairer Algorithms to AI Safety",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Forthcoming in The Oxford Handbook of Digital Ethics   The Challenge of Value Alignment: from Fairer  Algorithms to AI Safety  Iason Gabriel and Vafa Ghazavi 1. Introduction   There has long been a view among observers of artificial intelligence (AI) research, often expressed in science fiction, that it poses a distinctive moral challenge. This idea has been articulated in a number of ways, ranging from the notion that AI might take a ?treacherous turn? and act in ways that are opposed to the interests of its human operators, to deeper questions about the impact of AI on our understanding of human identity, emotions and relationships. Yet over the past decade, with the growth of more powerful and socially embedded AI technologies, discussion of these questions has become increasingly mainstream. Among topics that have commanded the most serious attention, the challenge of ?value alignment? stands out. It centres upon the question of how to ensure that AI systems are properly aligned...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2101.06060"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "7b03a29a7f0a47cbf07d5714d494fd65"
  },
  {
    "id": "arxiv_54b50aa3fdacde8f",
    "title": "Challenges for Using Impact Regularizers to Avoid Negative Side Effects",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2101.12509"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "54b50aa3fdacde8fb31743e0f8abd9f4"
  },
  {
    "id": "arxiv_e4afc38afe231b0e",
    "title": "Scaling Laws for Transfer",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2102.01293"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "e4afc38afe231b0e95bde9ed0254c7c8"
  },
  {
    "id": "arxiv_2e8b186e1b754281",
    "title": "Rissanen Data Analysis: Examining Dataset Characteristics via Description Length",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2103.03872"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "2e8b186e1b754281d64b8ec6021b1b8e"
  },
  {
    "id": "arxiv_f12247aaa7c5a301",
    "title": "Formal Methods for the Informal Engineer: Workshop Recommendations",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Program Committee\n-----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2104.00739"
    ],
    "tags": [],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "f12247aaa7c5a30132472244cd7a26a6"
  },
  {
    "id": "arxiv_14e5b7d17976f400",
    "title": "Adapting Language Models for Zero-shot Learning by Meta-tuning on Dataset and Prompt Collections",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2104.04670"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Academic research release",
    "source_id": "14e5b7d17976f40024339770e01ada48"
  },
  {
    "id": "arxiv_b541b11c1418c27e",
    "title": "The Power of Scale for Parameter-Efficient Prompt Tuning",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2104.08691"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "b541b11c1418c27e97d4a0e8fc03a2e1"
  },
  {
    "id": "arxiv_7461e158ad377f9a",
    "title": "True Few-Shot Learning with Language Models",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2105.11447"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Academic research release",
    "source_id": "7461e158ad377f9a601ca14b858bb6c4"
  },
  {
    "id": "arxiv_88b89589d5046f88",
    "title": "Interactive Explanations: Diagnosis and Repair of Reinforcement Learning Based Agent Behaviors",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "I Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2105.12938"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Published in academic venue",
    "source_id": "88b89589d5046f885be5bd243a2aa2ca"
  },
  {
    "id": "arxiv_d4d01f8ca206d12f",
    "title": "IQ-Learn: Inverse soft-Q Learning for Imitation",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2106.12142"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "d4d01f8ca206d12f59ec2f66aa4de1f4"
  },
  {
    "id": "arxiv_7a97baccf2d0dfad",
    "title": "Evaluating Large Language Models Trained on Code",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.03374"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Academic research release",
    "source_id": "7a97baccf2d0dfad4798e86392a5fd2c"
  },
  {
    "id": "arxiv_63f483a077d61ed3",
    "title": "Scalable Evaluation of Multi-Agent Reinforcement Learning with Melting Pot",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Research publication: Scalable Evaluation of Multi-Agent Reinforcement Learning with Melting Pot",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.06857"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "63f483a077d61ed36a0d5d5e8a69dd10"
  },
  {
    "id": "arxiv_84ae7baf831ae7f9",
    "title": "The Benchmark Lottery",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.07002"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "84ae7baf831ae7f9b13289a17aecb996"
  },
  {
    "id": "arxiv_80b432979afaa876",
    "title": "Human-Level Reinforcement Learning through Theory-Based Modeling, Exploration, and Planning",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Acknowledgments\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2107.12544"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Published in academic venue",
    "source_id": "80b432979afaa87683ab82ff9fc6914c"
  },
  {
    "id": "arxiv_2e13a5b9014cb671",
    "title": "Evaluating CLIP: Towards Characterization of Broader Capabilities and Downstream Implications",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2108.02818"
    ],
    "tags": [],
    "rarity": "common",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "2e13a5b9014cb67119d45d2e9cca9ed3"
  },
  {
    "id": "arxiv_ea99c17bfb8dff90",
    "title": "What Matters in Learning from Offline Human Demonstrations for Robot Manipulation",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Research publication: What Matters in Learning from Offline Human Demonstrations for Robot Manipulation",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2108.03298"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "ea99c17bfb8dff90e61d3a535b430bb3"
  },
  {
    "id": "arxiv_2da411f3489c10cb",
    "title": "On the Opportunities and Risks of Foundation Models",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "On the Opportunities and Risks of\nFoundation Models\nRishi Bommasani* Drew A. Hudson Ehsan Adeli Russ Altman Simran Arora\nSydney von Arx Michael S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill\nErik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji\nAnnie Chen Kathleen Creel Jared Quincy Davis Dorottya Demszky Chris Donahue\nMoussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh\nLi Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman\nShelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt\nDaniel E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain\nDan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani\nOmar Khattab Pang Wei Koh Mark Krass Ranjay Krishna Rohith Kuditipudi\nAnanya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent\nXiang Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher D. Manning\nSuvir Mirchandani Eric Mitchell Zanele Munyikwa ...",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2108.07258"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "2da411f3489c10cb274d7ba7fac229c4"
  },
  {
    "id": "arxiv_3a5dfe29a457d0e7",
    "title": "Program Synthesis with Large Language Models",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2108.07732"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "3a5dfe29a457d0e7ce7e32b2ed6e6136"
  },
  {
    "id": "arxiv_837ba9a1554593f1",
    "title": "Finetuned Language Models Are Zero-Shot Learners",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2109.01652"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Published in academic venue",
    "source_id": "837ba9a1554593f146d6b076605d56d9"
  },
  {
    "id": "arxiv_afea29156eae44db",
    "title": "User Tampering in Reinforcement Learning Recommender Systems",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1. Introduction\n----------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2109.04083"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "afea29156eae44db59e5ffb24367772c"
  },
  {
    "id": "arxiv_7c0a2d679a7a5ca5",
    "title": "Collaborating with Humans without Human Data",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2110.08176"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "7c0a2d679a7a5ca50fa500ac44849906"
  },
  {
    "id": "arxiv_abfd963c7afe7589",
    "title": "Navigation Turing Test (NTT): Learning to Evaluate Human-Like Navigation",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2105.09637"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "abfd963c7afe75892dc401c0d1b26215"
  },
  {
    "id": "arxiv_6ffccb173ea283dc",
    "title": "An Interpretability Illusion for BERT",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2104.07143"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Published in academic venue",
    "source_id": "6ffccb173ea283dc97f2cdd3d66cbe44"
  },
  {
    "id": "arxiv_8030d671c8dc7618",
    "title": "Acquisition of Chess Knowledge in AlphaZero",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2111.09259"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Published in academic venue",
    "source_id": "8030d671c8dc7618b4843fd6a48492cb"
  },
  {
    "id": "arxiv_2e751e13428ed9ea",
    "title": "Poisoning and Backdooring Contrastive Learning",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "1 Introduction\n---------------",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2106.09667"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Peer-reviewed publication",
    "source_id": "2e751e13428ed9ea208eddd4192a138d"
  },
  {
    "id": "arxiv_028a9baaa9a77d42",
    "title": "A New Formalism, Method and Open Issues for Zero-Shot Coordination",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Research publication: A New Formalism, Method and Open Issues for Zero-Shot Coordination",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 3,
        "condition": null
      }
    ],
    "sources": [
      "https://arxiv.org/abs/2106.06613"
    ],
    "tags": [],
    "rarity": "rare",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Academic research release",
    "source_id": "028a9baaa9a77d42694d3a19d33a0321"
  },
  {
    "id": "distill_dd6a446845d57fed",
    "title": "A Gentle Introduction to Graph Neural Networks",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "*This article is one of two Distill publications about graph neural networks. Take a look at [Understanding Convolutions on Graphs](https://distill.pub/2021/understanding-gnns/) to understand how convolutions over images generalize naturally to convolutions over graphs.*",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 5,
        "condition": null
      }
    ],
    "sources": [
      "https://distill.pub/2021/gnn-intro"
    ],
    "tags": [],
    "rarity": "legendary",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Notable work on AI safety",
    "media_reaction": "Featured in Distill",
    "source_id": "dd6a446845d57fed72059ee8bdb37857"
  },
  {
    "id": "distill_a15bd5a2f0b26e20",
    "title": "Adversarial Reprogramming of Neural Cellular Automata",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Research publication: Adversarial Reprogramming of Neural Cellular Automata",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 5,
        "condition": null
      }
    ],
    "sources": [
      "https://distill.pub/selforg/2021/adversarial"
    ],
    "tags": [],
    "rarity": "legendary",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Featured in Distill",
    "source_id": "a15bd5a2f0b26e2015a03fdc5a2319a9"
  },
  {
    "id": "distill_46959ccf83a5e89d",
    "title": "Weight Banding",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "![](images/multiple-pages.svg)",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 5,
        "condition": null
      }
    ],
    "sources": [
      "https://distill.pub/2020/circuits/weight-banding"
    ],
    "tags": [],
    "rarity": "legendary",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Interactive research publication",
    "source_id": "46959ccf83a5e89dbf4fc4aee11b4af9"
  },
  {
    "id": "distill_d2af05099a4301be",
    "title": "Branch Specialization",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "![](images/multiple-pages.svg)",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 5,
        "condition": null
      }
    ],
    "sources": [
      "https://distill.pub/2020/circuits/branch-specialization"
    ],
    "tags": [],
    "rarity": "legendary",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Valuable research for alignment",
    "media_reaction": "Visual machine learning research",
    "source_id": "d2af05099a4301be3320f05c220b8489"
  },
  {
    "id": "distill_8ca56371f32f6a2e",
    "title": "Self-Organising Textures",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "Research publication: Self-Organising Textures",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 5,
        "condition": null
      }
    ],
    "sources": [
      "https://distill.pub/selforg/2021/textures"
    ],
    "tags": [],
    "rarity": "legendary",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Important contribution to the field",
    "media_reaction": "Interactive research publication",
    "source_id": "8ca56371f32f6a2e55c8306b5fe94e7d"
  },
  {
    "id": "distill_e0055470e63b5b83",
    "title": "Visualizing Weights",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "![](images/multiple-pages.svg)",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 5,
        "condition": null
      }
    ],
    "sources": [
      "https://distill.pub/2020/circuits/visualizing-weights"
    ],
    "tags": [],
    "rarity": "legendary",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Significant technical contribution",
    "media_reaction": "Featured in Distill",
    "source_id": "e0055470e63b5b83359c358c17b108f9"
  },
  {
    "id": "distill_63e78aeacd5b3144",
    "title": "High-Low Frequency Detectors",
    "year": 2021,
    "category": "technical_research_breakthrough",
    "description": "![](images/multiple-pages.svg)",
    "impacts": [
      {
        "variable": "research",
        "change": 15,
        "condition": null
      },
      {
        "variable": "papers",
        "change": 10,
        "condition": null
      },
      {
        "variable": "vibey_doom",
        "change": 5,
        "condition": null
      }
    ],
    "sources": [
      "https://distill.pub/2020/circuits/frequency-edges"
    ],
    "tags": [],
    "rarity": "legendary",
    "pdoom_impact": null,
    "safety_researcher_reaction": "Advances our understanding of AI safety",
    "media_reaction": "Featured in Distill",
    "source_id": "63e78aeacd5b314498232de7a27d4381"
  }
]