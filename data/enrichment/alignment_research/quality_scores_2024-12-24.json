{
  "_metadata": {
    "version": "1.0.0",
    "created": "2025-12-24T06:44:37.431612Z",
    "source_file": "data.jsonl",
    "source_dump": "2025-12-24_063313",
    "total_records": 6549,
    "scoring_config": {
      "source_arxiv": 3,
      "source_distill": 3,
      "has_authors": 1,
      "not_newsletter": 2,
      "text_length_5k": 1,
      "text_length_10k": 1,
      "year_pre_2020": 1,
      "has_tags": 0.5
    },
    "tier_thresholds": {
      "A": 7.0,
      "B": 4.0,
      "C": 2.0,
      "D": 0.0
    }
  },
  "records": {
    "4e3806e28ffb49e0cc745e576f7a01f9": {
      "source_id": "4e3806e28ffb49e0cc745e576f7a01f9",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40461,
        "year": "2016",
        "has_tags": true
      },
      "title_preview": "Speculations on information under logical uncertainty"
    },
    "c46b6bd0749db7395b3e2804f7eadb09": {
      "source_id": "c46b6bd0749db7395b3e2804f7eadb09",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10862,
        "year": "2016",
        "has_tags": true
      },
      "title_preview": "Modeling the capabilities of advanced AI systems as episodic reinforcement learn"
    },
    "e820151a0cff0880453c0f15daf00063": {
      "source_id": "e820151a0cff0880453c0f15daf00063",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25550,
        "year": "2016",
        "has_tags": true
      },
      "title_preview": "Predicting HCH using expert advice"
    },
    "f9b4817ebff89e8953c762c9982c878d": {
      "source_id": "f9b4817ebff89e8953c762c9982c878d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5765,
        "year": "2016",
        "has_tags": true
      },
      "title_preview": "Pursuing convergent instrumental subgoals on the user's behalf doesn't always re"
    },
    "dd4ccb97b904bc5cd1739a3459c931c3": {
      "source_id": "dd4ccb97b904bc5cd1739a3459c931c3",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10969,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "On motivations for MIRI's highly reliable agent design research"
    },
    "a840765e7ffe6ef8b665fdef4ca199c5": {
      "source_id": "a840765e7ffe6ef8b665fdef4ca199c5",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38331,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "My current take on the Paul-MIRI disagreement on alignability of messy AI"
    },
    "b8a98d48c82bf02ff46564eea16859bc": {
      "source_id": "b8a98d48c82bf02ff46564eea16859bc",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33239,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "Futarchy Fix"
    },
    "59d658f078fbcf34d11f29189b691138": {
      "source_id": "59d658f078fbcf34d11f29189b691138",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11333,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "Why I am not currently working on the AAMLS agenda"
    },
    "8b8b89d37ec2a6d1a77f6326f6191e54": {
      "source_id": "8b8b89d37ec2a6d1a77f6326f6191e54",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22956,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "Corrigibility thoughts I: caring about multiple things"
    },
    "1df672e18088c5533928608e094d786e": {
      "source_id": "1df672e18088c5533928608e094d786e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9712,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "Stable Pointers to Value: An Agent Embedded in Its Own Utility Function"
    },
    "10a6df80f3c144a0d42778422a5fce80": {
      "source_id": "10a6df80f3c144a0d42778422a5fce80",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42340,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "Delegative Reinforcement Learning with a Merely Sane Advisor"
    },
    "aeeb5609c9d9391b858efd9da0ad2b53": {
      "source_id": "aeeb5609c9d9391b858efd9da0ad2b53",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2177,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Beware of black boxes in AI alignment research"
    },
    "b53d9f1c6c6d8a4dca21f7aaa3a9a1fb": {
      "source_id": "b53d9f1c6c6d8a4dca21f7aaa3a9a1fb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6549,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Sources of intuitions and data on AGI"
    },
    "e31a0e591d68faf4d1e0add11286a577": {
      "source_id": "e31a0e591d68faf4d1e0add11286a577",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8021,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Stable Pointers to Value II: Environmental Goals"
    },
    "9bc1dc39a77262f97e353ad9a5446b24": {
      "source_id": "9bc1dc39a77262f97e353ad9a5446b24",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3157,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Robustness to Scale"
    },
    "d69b6434ab235540b761ab4cc426d265": {
      "source_id": "d69b6434ab235540b761ab4cc426d265",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3740,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Arguments about fast takeoff"
    },
    "4717fe96daf8d07e6223b261463b59cf": {
      "source_id": "4717fe96daf8d07e6223b261463b59cf",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2839,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Self-regulation of safety in AI research"
    },
    "266a06a3379461ae85947d8cb058faeb": {
      "source_id": "266a06a3379461ae85947d8cb058faeb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7456,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Prize for probable problems"
    },
    "b4299d04b5b899a7325714eb1dde2a47": {
      "source_id": "b4299d04b5b899a7325714eb1dde2a47",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3525,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "An Untrollable Mathematician Illustrated"
    },
    "cf5ebc4ffcbf5b924434b489238581a9": {
      "source_id": "cf5ebc4ffcbf5b924434b489238581a9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1599,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Idea: Open Access AI Safety Journal"
    },
    "0f61e6cf2be608d7aa1f7aeb9406166b": {
      "source_id": "0f61e6cf2be608d7aa1f7aeb9406166b",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11804,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Non-Adversarial Goodhart and AI Risks"
    },
    "193274ca086081944c6e5054e555d12a": {
      "source_id": "193274ca086081944c6e5054e555d12a",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11347,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Evaluating Existing Approaches to AGI Alignment"
    },
    "29094e5fe6840da3a44493e7d7231bb3": {
      "source_id": "29094e5fe6840da3a44493e7d7231bb3",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3101,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "My take on agent foundations: formalizing metaphilosophical competence"
    },
    "2a164efada35092620507524eabe401d": {
      "source_id": "2a164efada35092620507524eabe401d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7246,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Can corrigibility be learned safely?"
    },
    "1de1f9ce973a8428edb5b681f12c1848": {
      "source_id": "1de1f9ce973a8428edb5b681f12c1848",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1742,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Specification gaming examples in AI"
    },
    "347795d5882aec9e047ba6d9d078d66c": {
      "source_id": "347795d5882aec9e047ba6d9d078d66c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 10745,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The Alignment Newsletter #1: 04/09/18"
    },
    "ad45fcc8964a4ae17689a11eac697969": {
      "source_id": "ad45fcc8964a4ae17689a11eac697969",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 12872,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The Alignment Newsletter #2: 04/16/18"
    },
    "39d498ff718b7e6e776f0130e3e48f25": {
      "source_id": "39d498ff718b7e6e776f0130e3e48f25",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18144,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Understanding Iterated Distillation and Amplification: Claims and Oversight"
    },
    "da5c78dfaa54d78877a3f1ce1e384da6": {
      "source_id": "da5c78dfaa54d78877a3f1ce1e384da6",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 13633,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The Alignment Newsletter #3: 04/23/18"
    },
    "72b5216624d4ff4fbf28d022fbf1dcb7": {
      "source_id": "72b5216624d4ff4fbf28d022fbf1dcb7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 7367,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The Alignment Newsletter #4: 04/30/18"
    },
    "2201ab06940826177be7f4c8d66ee2b2": {
      "source_id": "2201ab06940826177be7f4c8d66ee2b2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 103,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "AI Safety via Debate"
    },
    "04bf20c2fc94e87572ecde168b0750d9": {
      "source_id": "04bf20c2fc94e87572ecde168b0750d9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4900,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Open question: are minimal circuits daemon-free?"
    },
    "6d17dc8233070f81b12f38ce375aa92a": {
      "source_id": "6d17dc8233070f81b12f38ce375aa92a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 15111,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The Alignment Newsletter #5: 05/07/18"
    },
    "5f96ec6bc566d3d86d949701f181f818": {
      "source_id": "5f96ec6bc566d3d86d949701f181f818",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10213,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Thoughts on \"AI safety via debate\""
    },
    "8924accfe7ff514524472339815c04b4": {
      "source_id": "8924accfe7ff514524472339815c04b4",
      "quality_score": 2.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 4394,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The Alignment Newsletter #6: 05/14/18"
    },
    "c442292a657b46840d9837aea755bf19": {
      "source_id": "c442292a657b46840d9837aea755bf19",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2763,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "RFC: Philosophical Conservatism in AI Alignment Research"
    },
    "f66b39af2035c6d4a0c36151afc583ae": {
      "source_id": "f66b39af2035c6d4a0c36151afc583ae",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 129301,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Challenges to Christiano\u2019s capability amplification proposal"
    },
    "0a622e0b50b9cffefd005177dcf8155b": {
      "source_id": "0a622e0b50b9cffefd005177dcf8155b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 10830,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The Alignment Newsletter #7: 05/21/18"
    },
    "ebb9fac98db3c61bd1387f9d649dffde": {
      "source_id": "ebb9fac98db3c61bd1387f9d649dffde",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 14095,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The Alignment Newsletter #8: 05/28/18"
    },
    "91abb3911eb8cbf25946a4ae4b3a7993": {
      "source_id": "91abb3911eb8cbf25946a4ae4b3a7993",
      "quality_score": 2.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 4726,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The Alignment Newsletter #9: 06/04/18"
    },
    "4de5d6ad4a4cdb57b6aedc38acaf00f9": {
      "source_id": "4de5d6ad4a4cdb57b6aedc38acaf00f9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7081,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Beyond Astronomical Waste"
    },
    "fc7132628641659309e0f0045a4f7176": {
      "source_id": "fc7132628641659309e0f0045a4f7176",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6724,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "RFC: Meta-ethical uncertainty in AGI alignment"
    },
    "0e2c6e74d921c8e809ceb4f7b516fff9": {
      "source_id": "0e2c6e74d921c8e809ceb4f7b516fff9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19073,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The Alignment Newsletter #10: 06/11/18"
    },
    "e2273ff25e0b3d1b4647228178da6905": {
      "source_id": "e2273ff25e0b3d1b4647228178da6905",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2019,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "A general model of safety-oriented AI development"
    },
    "a9ca3c2469e1e88a0e93b905f675769e": {
      "source_id": "a9ca3c2469e1e88a0e93b905f675769e",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41926,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Worrying about the Vase: Whitelisting"
    },
    "0adfaa1d6d6be95bcf266912b9e065f3": {
      "source_id": "0adfaa1d6d6be95bcf266912b9e065f3",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 21681,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The Alignment Newsletter #11: 06/18/18"
    },
    "7ee1118db4a26a994f64630449003478": {
      "source_id": "7ee1118db4a26a994f64630449003478",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 8003,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The Alignment Newsletter #12: 06/25/18"
    },
    "3dae5d74351e87e0a7ea904a8146276d": {
      "source_id": "3dae5d74351e87e0a7ea904a8146276d",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 570600,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Optimization Amplifies"
    },
    "89fc9ed3e99a2bf1aa5dde7a6b0a500b": {
      "source_id": "89fc9ed3e99a2bf1aa5dde7a6b0a500b",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34046,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Policy Alignment"
    },
    "516d61036389e76ed10406adaeeaf8ce": {
      "source_id": "516d61036389e76ed10406adaeeaf8ce",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32726,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Overcoming Clinginess in Impact Measures"
    },
    "27939bdf7b6b1503af82ea4479dad8db": {
      "source_id": "27939bdf7b6b1503af82ea4479dad8db",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25248,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Another take on agent foundations: formalizing zero-shot reasoning"
    },
    "3f5a2a24a6a4a365cc18c6ee523673c1": {
      "source_id": "3f5a2a24a6a4a365cc18c6ee523673c1",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40131,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Paul's research agenda FAQ"
    },
    "d335c9bec8d9676370f66494e98fa014": {
      "source_id": "d335c9bec8d9676370f66494e98fa014",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 18134,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #13: 07/02/18"
    },
    "ba49f6835f8e6af71ac0d6ac803f52d8": {
      "source_id": "ba49f6835f8e6af71ac0d6ac803f52d8",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 80587,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The Learning-Theoretic AI Alignment Research Agenda"
    },
    "8c372795646b78f3fc46858b2ddd316a": {
      "source_id": "8c372795646b78f3fc46858b2ddd316a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 18757,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #14"
    },
    "56e3ea92eaea123280500230a31b71c7": {
      "source_id": "56e3ea92eaea123280500230a31b71c7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3242,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Announcing AlignmentForum.org Beta"
    },
    "681730b4c556936bb00050263e58920e": {
      "source_id": "681730b4c556936bb00050263e58920e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7443,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Mechanistic Transparency for Machine Learning"
    },
    "9feb06a5193fe6221dd164965077dfa1": {
      "source_id": "9feb06a5193fe6221dd164965077dfa1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2753,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "A comment on the IDA-AlphaGoZero metaphor; capabilities versus alignment"
    },
    "b20b71d5fe54abeedd496b1732284de0": {
      "source_id": "b20b71d5fe54abeedd496b1732284de0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3055,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Conceptual problems with utility functions"
    },
    "a2aee08c8c45786f03b465a63308f927": {
      "source_id": "a2aee08c8c45786f03b465a63308f927",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3878,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "No, I won't go there, it feels like you're trying to Pascal-mug me"
    },
    "03606e4abe2165052fb5844bf1ec664c": {
      "source_id": "03606e4abe2165052fb5844bf1ec664c",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 160963,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "On the Role of Counterfactuals in Learning"
    },
    "c8ad4fdc0d6452c0c6a65b63e80cdf49": {
      "source_id": "c8ad4fdc0d6452c0c6a65b63e80cdf49",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5117,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Mathematical Mindset"
    },
    "040b3caec782fdd1bfd578e69ea3cb70": {
      "source_id": "040b3caec782fdd1bfd578e69ea3cb70",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2311,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Announcement: AI alignment prize round 3 winners and next round"
    },
    "71050c88772e0285eb5094c629b9147e": {
      "source_id": "71050c88772e0285eb5094c629b9147e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6656,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Compact vs. Wide Models"
    },
    "24d5e373efb8616ccd32a90da11c8487": {
      "source_id": "24d5e373efb8616ccd32a90da11c8487",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 33978,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #15: 07/16/18"
    },
    "55eaa3527bba87c680ab69f3c06e9078": {
      "source_id": "55eaa3527bba87c680ab69f3c06e9078",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7007,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Stable Pointers to Value III: Recursive Quantilization"
    },
    "eb755f1e6b9b6f6f3f8d54be800a7f6e": {
      "source_id": "eb755f1e6b9b6f6f3f8d54be800a7f6e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 25569,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #16: 07/23/18"
    },
    "225e4d80e0f7e2c82dbe1ece1265e705": {
      "source_id": "225e4d80e0f7e2c82dbe1ece1265e705",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6117,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "A Gym Gridworld Environment for the  Treacherous Turn"
    },
    "d95b19d0d2f1bc3334b93e9c5d471481": {
      "source_id": "d95b19d0d2f1bc3334b93e9c5d471481",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 25312,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #17"
    },
    "d811456343ad28857e5da3505bd61048": {
      "source_id": "d811456343ad28857e5da3505bd61048",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19025,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #18"
    },
    "23578464429c765782c9a30f246105ec": {
      "source_id": "23578464429c765782c9a30f246105ec",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 24575,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #19"
    },
    "cbda0a19711727a01177c71ddb66e2ca": {
      "source_id": "cbda0a19711727a01177c71ddb66e2ca",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 11870,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #20"
    },
    "68173c0ab29d0767939c7a3d250e9489": {
      "source_id": "68173c0ab29d0767939c7a3d250e9489",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 14100,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #21"
    },
    "f9144670a738ac26fbf6f258a85d61cd": {
      "source_id": "f9144670a738ac26fbf6f258a85d61cd",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2660,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Do what we mean vs. do what we say"
    },
    "b32f9a16d33669b2ff17e4c73423979c": {
      "source_id": "b32f9a16d33669b2ff17e4c73423979c",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46746,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Impact Measure Desiderata"
    },
    "77ed7c73107f7783fecbdf8ae63ee6ac": {
      "source_id": "77ed7c73107f7783fecbdf8ae63ee6ac",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 12906,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #22"
    },
    "0426717380a1fd51fed9cbd594e98f4b": {
      "source_id": "0426717380a1fd51fed9cbd594e98f4b",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26824,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Counterfactuals and reflective oracles"
    },
    "ad107f9653b979cf8de408178e9ec9d0": {
      "source_id": "ad107f9653b979cf8de408178e9ec9d0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4434,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Comment on decision theory"
    },
    "d2ef28cd9df2a545dafa626516fe93b9": {
      "source_id": "d2ef28cd9df2a545dafa626516fe93b9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2325,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Disagreement with Paul: alignment induction"
    },
    "b910f39d5c07c49c7fc66b1a00bf8f10": {
      "source_id": "b910f39d5c07c49c7fc66b1a00bf8f10",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 14475,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #23"
    },
    "aa34b25cc03f1f7e05f57e29a6260108": {
      "source_id": "aa34b25cc03f1f7e05f57e29a6260108",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8466,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Realism about rationality"
    },
    "fae72bc41db63871e7d1ac201c2ab1e3": {
      "source_id": "fae72bc41db63871e7d1ac201c2ab1e3",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 24313,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #24"
    },
    "10d15095f32f0caaa4d6fa2786d7e5fb": {
      "source_id": "10d15095f32f0caaa4d6fa2786d7e5fb",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 85170,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Towards a New Impact Measure"
    },
    "391c344daf594238fc0f2d1dcdb52227": {
      "source_id": "391c344daf594238fc0f2d1dcdb52227",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9632,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "In Logical Time, All Games are Iterated Games"
    },
    "04bf17d77300f89e4ad5ec10f7f29b34": {
      "source_id": "04bf17d77300f89e4ad5ec10f7f29b34",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19479,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #25"
    },
    "95189c573dfdbd7fb7ffb967495c9ad0": {
      "source_id": "95189c573dfdbd7fb7ffb967495c9ad0",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59588,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Asymptotic Decision Theory (Improved Writeup)"
    },
    "068fcf232e779a9b9862355b6eaa5f78": {
      "source_id": "068fcf232e779a9b9862355b6eaa5f78",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 708,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "New DeepMind AI Safety Research Blog"
    },
    "9d928b81487350d8c8fd9dacb4432470": {
      "source_id": "9d928b81487350d8c8fd9dacb4432470",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 16001,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #26"
    },
    "57c1f9bb831e1261ab62406570d889ac": {
      "source_id": "57c1f9bb831e1261ab62406570d889ac",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28197,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The Rocket Alignment Problem"
    },
    "b12cc12058e3bf5be5ac3201a85a950f": {
      "source_id": "b12cc12058e3bf5be5ac3201a85a950f",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18245,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "A Rationality Condition for CDT Is That It Equal EDT (Part 1)"
    },
    "b3162e791d36b5b3a64f6b4b4ef1571b": {
      "source_id": "b3162e791d36b5b3a64f6b4b4ef1571b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 20306,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #27"
    },
    "875dcc88a98d95e9e8c8feb39164b0a9": {
      "source_id": "875dcc88a98d95e9e8c8feb39164b0a9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 18463,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #28"
    },
    "95aa71d0f6e6fc4db2f36492f39ab3b5": {
      "source_id": "95aa71d0f6e6fc4db2f36492f39ab3b5",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29516,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Addressing three problems with counterfactual corrigibility: bad bets, defending"
    },
    "33b8775b3a3d1284981750308523f266": {
      "source_id": "33b8775b3a3d1284981750308523f266",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 18796,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #29"
    },
    "172f687fcde27e25db787d03b26cfcb2": {
      "source_id": "172f687fcde27e25db787d03b26cfcb2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 13904,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #30"
    },
    "d981e0a425069457ecfd18f7fe9f4710": {
      "source_id": "d981e0a425069457ecfd18f7fe9f4710",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12237,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Introducing the AI Alignment Forum (FAQ)"
    },
    "7fd0a920d0ad317515c008ebe1b3723b": {
      "source_id": "7fd0a920d0ad317515c008ebe1b3723b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5521,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Preface to the sequence on value learning"
    },
    "3512aeef198ee4f19b68bf2b19708ee5": {
      "source_id": "3512aeef198ee4f19b68bf2b19708ee5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5585,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "What is ambitious value learning?"
    },
    "e9e37449817445409c50dfd86cada4c5": {
      "source_id": "e9e37449817445409c50dfd86cada4c5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8469,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Discussion on the machine learning approach to AI safety"
    },
    "17e1c5e4b697be0a17a692cded6a62a7": {
      "source_id": "17e1c5e4b697be0a17a692cded6a62a7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9270,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Meta-execution"
    },
    "5c8a39b7047ea58ff116a0e58b84567a": {
      "source_id": "5c8a39b7047ea58ff116a0e58b84567a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7794,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The easy goal inference problem is still hard"
    },
    "cc99bdaf91be798b0e4fa701eeae6100": {
      "source_id": "cc99bdaf91be798b0e4fa701eeae6100",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24323,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Humans can be assigned any values whatsoever\u2026"
    },
    "b2be37ce5becd5d59a28298ac9c7ee5c": {
      "source_id": "b2be37ce5becd5d59a28298ac9c7ee5c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 26076,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #31"
    },
    "47c075259af2b6a10ca000f9de0c17c8": {
      "source_id": "47c075259af2b6a10ca000f9de0c17c8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8953,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Subsystem Alignment"
    },
    "497bc9474b96ef019d3f27592d0050b2": {
      "source_id": "497bc9474b96ef019d3f27592d0050b2",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36373,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Latent Variables and Model Mis-Specification"
    },
    "3dab5c7045e2e1aa9c41304328d96200": {
      "source_id": "3dab5c7045e2e1aa9c41304328d96200",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4492,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Embedded Curiosities"
    },
    "fb756136d303a5ff1042afd7b0ab93f9": {
      "source_id": "fb756136d303a5ff1042afd7b0ab93f9",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49919,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Model Mis-specification and Inverse Reinforcement Learning"
    },
    "b9748f2a7b6be1bf1394f80327377263": {
      "source_id": "b9748f2a7b6be1bf1394f80327377263",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5101,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Preface to the sequence on iterated amplification"
    },
    "9670468baa52836f1073ed04b7afb0c9": {
      "source_id": "9670468baa52836f1073ed04b7afb0c9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9662,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Future directions for ambitious value learning"
    },
    "32ac2e0da812f76d5f672aca7dac842e": {
      "source_id": "32ac2e0da812f76d5f672aca7dac842e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 26604,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #32"
    },
    "f18628945333c4de24e8520ff55ca022": {
      "source_id": "f18628945333c4de24e8520ff55ca022",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13568,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The Steering Problem"
    },
    "9b39c0d83b6a565b1813dc01dcf166ca": {
      "source_id": "9b39c0d83b6a565b1813dc01dcf166ca",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6206,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Clarifying \"AI Alignment\""
    },
    "77576bf130b9e5316e1d438128d2c3a5": {
      "source_id": "77576bf130b9e5316e1d438128d2c3a5",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 131124,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Embedded Agency (full-text version)"
    },
    "512ae065c3b7375b018dbf685d735756": {
      "source_id": "512ae065c3b7375b018dbf685d735756",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3017,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Fixed Point Exercises"
    },
    "787520278e64bd0094b6ca0c673a59a5": {
      "source_id": "787520278e64bd0094b6ca0c673a59a5",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18481,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "An unaligned benchmark"
    },
    "e6b94e711c694fc300309ba8b11e2e1f": {
      "source_id": "e6b94e711c694fc300309ba8b11e2e1f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 20675,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #33"
    },
    "151de2fa1f7aff409f83db395e166f0f": {
      "source_id": "151de2fa1f7aff409f83db395e166f0f",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15251,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Prosaic AI alignment"
    },
    "ad72cb7125f001a8985a21042183be8d": {
      "source_id": "ad72cb7125f001a8985a21042183be8d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3635,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "New safety research agenda: scalable agent alignment via reward modeling"
    },
    "d259e3450017f6f6e6151bb293c8fb47": {
      "source_id": "d259e3450017f6f6e6151bb293c8fb47",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22299,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Iteration Fixed Point Exercises"
    },
    "e1b30625588d7be4fb49378f441ce8fc": {
      "source_id": "e1b30625588d7be4fb49378f441ce8fc",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30177,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Approval-directed agents"
    },
    "b53c8f020c6c07be0a47713225226648": {
      "source_id": "b53c8f020c6c07be0a47713225226648",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62901,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Fixed Point Discussion"
    },
    "45a6dc6a23037c9c1701d7d85ebda6f0": {
      "source_id": "45a6dc6a23037c9c1701d7d85ebda6f0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2127,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Approval-directed bootstrapping"
    },
    "eff5b60ecd47973305d1ea1b8712d8ae": {
      "source_id": "eff5b60ecd47973305d1ea1b8712d8ae",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2973,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Humans Consulting HCH"
    },
    "4192f8ace794eabd14e2362f095f1037": {
      "source_id": "4192f8ace794eabd14e2362f095f1037",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 21190,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #34"
    },
    "6da081d10939e7b5db7ec37a3c3c2a89": {
      "source_id": "6da081d10939e7b5db7ec37a3c3c2a89",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13786,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Corrigibility"
    },
    "b846a937f304eb0264a779eeafc95d43": {
      "source_id": "b846a937f304eb0264a779eeafc95d43",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39806,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Bounded Oracle Induction"
    },
    "25bc3c16b2623ccbdf8662a0f818704a": {
      "source_id": "25bc3c16b2623ccbdf8662a0f818704a",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27643,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Hyperreal Brouwer"
    },
    "d515905ddcf817f2ecb3de97ed22ac25": {
      "source_id": "d515905ddcf817f2ecb3de97ed22ac25",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22017,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The Ubiquitous Converse Lawvere Problem"
    },
    "25493f3893d73cf823e36806f549f905": {
      "source_id": "25493f3893d73cf823e36806f549f905",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32658,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Reflective oracles as a solution to the converse Lawvere problem"
    },
    "5e8120d700f75aeb7bc0d8ef1b30a966": {
      "source_id": "5e8120d700f75aeb7bc0d8ef1b30a966",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24905,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Formal Open Problem in Decision Theory"
    },
    "495a1936deccebf9aca83da2589f52de": {
      "source_id": "495a1936deccebf9aca83da2589f52de",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12546,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Iterated Distillation and Amplification"
    },
    "7abcb73716a9589663d704fc5e30fd5e": {
      "source_id": "7abcb73716a9589663d704fc5e30fd5e",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11962,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Intuitions about goal-directed behavior"
    },
    "fe4ff32694559b7ed8149a3c73433405": {
      "source_id": "fe4ff32694559b7ed8149a3c73433405",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15991,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Benign model-free RL"
    },
    "0ae170159869333eabaa30133f95b8c6": {
      "source_id": "0ae170159869333eabaa30133f95b8c6",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14460,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Coherence arguments do not entail goal-directed behavior"
    },
    "dd153a6a6492c343ce6041578c7ee709": {
      "source_id": "dd153a6a6492c343ce6041578c7ee709",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 14784,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #35"
    },
    "d54caa1d70db747eace15647b7bfd996": {
      "source_id": "d54caa1d70db747eace15647b7bfd996",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58432,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Factored Cognition"
    },
    "dffa5b7a8c88675392c08ec0a6ee8bb0": {
      "source_id": "dffa5b7a8c88675392c08ec0a6ee8bb0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9050,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Why we need a *theory* of human values"
    },
    "52a07bbe90f0b24af0361a48256a917d": {
      "source_id": "52a07bbe90f0b24af0361a48256a917d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4533,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Assuming we've solved X, could we do Y..."
    },
    "f0e8cd1b502500c55eb741b668d5d404": {
      "source_id": "f0e8cd1b502500c55eb741b668d5d404",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 22721,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #36"
    },
    "148af6c1531fbf2593ed11baf28a0a3c": {
      "source_id": "148af6c1531fbf2593ed11baf28a0a3c",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21149,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Multi-agent predictive minds and AI alignment"
    },
    "de923b6ba8312fd7e73ca3b9170d6ee6": {
      "source_id": "de923b6ba8312fd7e73ca3b9170d6ee6",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3234,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Three AI Safety Related Ideas"
    },
    "f3e1335db06427bff3ad3f5ba08a65ab": {
      "source_id": "f3e1335db06427bff3ad3f5ba08a65ab",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3351,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Two Neglected Problems in Human-AI Safety"
    },
    "7da9b1000e8d593eab46614c004be756": {
      "source_id": "7da9b1000e8d593eab46614c004be756",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 21345,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #37"
    },
    "0c6724190128e75972d955ee9128fb68": {
      "source_id": "0c6724190128e75972d955ee9128fb68",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 142584,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "2018 AI Alignment Literature Review and Charity Comparison"
    },
    "facae8ef9ee035c14ea730fe56e86f1f": {
      "source_id": "facae8ef9ee035c14ea730fe56e86f1f",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17363,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Reasons compute may not drive AI capabilities growth"
    },
    "803f526dc8f9725eed01ca2977b09de3": {
      "source_id": "803f526dc8f9725eed01ca2977b09de3",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 16221,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #38"
    },
    "886aa0b80252cf2e7b03abd0b3f062cc": {
      "source_id": "886aa0b80252cf2e7b03abd0b3f062cc",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 11519,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #39"
    },
    "cb91b3805a08936f93eaa64916d271a2": {
      "source_id": "cb91b3805a08936f93eaa64916d271a2",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40977,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Optimization Regularization through Time Penalty"
    },
    "893bc4ac5e373205217961eb7e72abb8": {
      "source_id": "893bc4ac5e373205217961eb7e72abb8",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10492,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Will humans build goal-directed agents?"
    },
    "9c566ffb511b6df71203978912a035a3": {
      "source_id": "9c566ffb511b6df71203978912a035a3",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1154,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Supervising strong learners by amplifying weak experts"
    },
    "d10ff3c41f9ba8c01f133626dc3c21a7": {
      "source_id": "d10ff3c41f9ba8c01f133626dc3c21a7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6681,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "AI safety without goal-directed behavior"
    },
    "25bf0d14950b3ebd45e166c17a2b14f3": {
      "source_id": "25bf0d14950b3ebd45e166c17a2b14f3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9404,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Reframing Superintelligence: Comprehensive AI Services as General Intelligence"
    },
    "71c03425c23a51d2a7fde92537f913e3": {
      "source_id": "71c03425c23a51d2a7fde92537f913e3",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 10940,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #40"
    },
    "2a7afa6d493be9278aaf052ac7439621": {
      "source_id": "2a7afa6d493be9278aaf052ac7439621",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4383,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "AlphaGo Zero and capability amplification"
    },
    "42ef268f3d8bd6d445bfb3bb545bd9d0": {
      "source_id": "42ef268f3d8bd6d445bfb3bb545bd9d0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3546,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "What is narrow value learning?"
    },
    "df622a7c4fdec9e41b12792882713984": {
      "source_id": "df622a7c4fdec9e41b12792882713984",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13302,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Non-Consequentialist Cooperation?"
    },
    "8f9b399dbdf3e35c8f8b570900d6ab29": {
      "source_id": "8f9b399dbdf3e35c8f8b570900d6ab29",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8029,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Ambitious vs. narrow value learning"
    },
    "b95a2e7a65cda7b05879955f90263f37": {
      "source_id": "b95a2e7a65cda7b05879955f90263f37",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13195,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Comments on CAIS"
    },
    "96ebf5d991c20723af239af04a4dbe83": {
      "source_id": "96ebf5d991c20723af239af04a4dbe83",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3981,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Dutch-Booking CDT"
    },
    "3b2caa6e9c64f5ecc58c77350b4bc649": {
      "source_id": "3b2caa6e9c64f5ecc58c77350b4bc649",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28509,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Directions and desiderata for AI alignment"
    },
    "183bab5ff480624cc1e465addce8a3c5": {
      "source_id": "183bab5ff480624cc1e465addce8a3c5",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 454,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "When is CDT Dutch-Bookable?"
    },
    "7492d0f9a031ae1d0c2033fcc60ec4db": {
      "source_id": "7492d0f9a031ae1d0c2033fcc60ec4db",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35726,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Towards formalizing universality"
    },
    "a05655a741e26929aa29241c25a371ac": {
      "source_id": "a05655a741e26929aa29241c25a371ac",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43109,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "CDT=EDT=UDT"
    },
    "dbf6006d14d53c360528957e7a1aa420": {
      "source_id": "dbf6006d14d53c360528957e7a1aa420",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8436,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Human-AI Interaction"
    },
    "152302f1c38acd9100de8bb5953f7f51": {
      "source_id": "152302f1c38acd9100de8bb5953f7f51",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14494,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "The reward engineering problem"
    },
    "65a65f3c29b42ad8803e06dcd017c21d": {
      "source_id": "65a65f3c29b42ad8803e06dcd017c21d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 21924,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #41"
    },
    "eeb59a4b04032211254d396d5910e866": {
      "source_id": "eeb59a4b04032211254d396d5910e866",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33448,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Anthropics is pretty normal"
    },
    "d62c8449d606076e6bdf07798b508e72": {
      "source_id": "d62c8449d606076e6bdf07798b508e72",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9569,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Reward uncertainty"
    },
    "68cfc490acf9c686483501783e1971ff": {
      "source_id": "68cfc490acf9c686483501783e1971ff",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 606,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Why not tool AI?"
    },
    "45b6a98876e7105977a27ecd793fe7cf": {
      "source_id": "45b6a98876e7105977a27ecd793fe7cf",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25705,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Capability amplification"
    },
    "b61c5a5d4d5d1c2eb0cca0a5e14b421e": {
      "source_id": "b61c5a5d4d5d1c2eb0cca0a5e14b421e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1842,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Announcement: AI alignment prize round 4 winners"
    },
    "e127bd23580dfa3eb9710d1dd4545ec9": {
      "source_id": "e127bd23580dfa3eb9710d1dd4545ec9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9201,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Following human norms"
    },
    "d02ecf69661d8fd8e235a0325512b070": {
      "source_id": "d02ecf69661d8fd8e235a0325512b070",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15775,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Disentangling arguments for the importance of AI safety"
    },
    "7e04ddccb4a1311e5c71f71c83504fd7": {
      "source_id": "7e04ddccb4a1311e5c71f71c83504fd7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 21469,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #42"
    },
    "8569b2453a38bb18a10571219ae46d91": {
      "source_id": "8569b2453a38bb18a10571219ae46d91",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7048,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Learning with catastrophes"
    },
    "b897eb77b6a6a87a31d71d17010a0a4f": {
      "source_id": "b897eb77b6a6a87a31d71d17010a0a4f",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21362,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Thoughts on reward engineering"
    },
    "8d16728a0204ce3170c0e2d7f75916ed": {
      "source_id": "8d16728a0204ce3170c0e2d7f75916ed",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8662,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Future directions for narrow value learning"
    },
    "d695c4f5cd58abc99385e50288ee4f6e": {
      "source_id": "d695c4f5cd58abc99385e50288ee4f6e",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16567,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Techniques for optimizing worst-case performance"
    },
    "777efb8914a737be4f9da2bf9475b2a2": {
      "source_id": "777efb8914a737be4f9da2bf9475b2a2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 28184,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #43"
    },
    "4235a772f1d31bde945d0b3c9663b03a": {
      "source_id": "4235a772f1d31bde945d0b3c9663b03a",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14334,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Reliability amplification"
    },
    "2eab18d3fe5301db3987cc8816727a76": {
      "source_id": "2eab18d3fe5301db3987cc8816727a76",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24078,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "How does Gradient Descent Interact with Goodhart?"
    },
    "b6d1100e5402acf603d049cd2aacb96d": {
      "source_id": "b6d1100e5402acf603d049cd2aacb96d",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11887,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Conclusion to the sequence on value learning"
    },
    "d3b86a17f2b3c4cf81954825834693ba": {
      "source_id": "d3b86a17f2b3c4cf81954825834693ba",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26488,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "When to use quantilization"
    },
    "05b2390b643dcbf4e27b3f02058e0a5f": {
      "source_id": "05b2390b643dcbf4e27b3f02058e0a5f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19656,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #44"
    },
    "dfdcf34a831c8a51175a726678e38ad7": {
      "source_id": "dfdcf34a831c8a51175a726678e38ad7",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25644,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Security amplification"
    },
    "2a9fdfca18e11e6c8d82344f400c53c0": {
      "source_id": "2a9fdfca18e11e6c8d82344f400c53c0",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24281,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Test Cases for Impact Regularisation Methods"
    },
    "8a413427c2fd2a6ae98e60d2ed92bee5": {
      "source_id": "8a413427c2fd2a6ae98e60d2ed92bee5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5414,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "HCH is not just Mechanical Turk"
    },
    "a5a3388500722f88f059286ecd35d440": {
      "source_id": "a5a3388500722f88f059286ecd35d440",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24507,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Reinforcement Learning in the Iterated Amplification Framework"
    },
    "f1a74a09c7ba0165a3cc30a6b7cdcffa": {
      "source_id": "f1a74a09c7ba0165a3cc30a6b7cdcffa",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2858,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "The Argument from Philosophical Difficulty"
    },
    "ccbca925d8aa3a0a3889de982fc0b277": {
      "source_id": "ccbca925d8aa3a0a3889de982fc0b277",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9702,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Some Thoughts on Metaphilosophy"
    },
    "22edf3f0301cb6807f3be0ab4e3779cb": {
      "source_id": "22edf3f0301cb6807f3be0ab4e3779cb",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17843,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Coherent behaviour in the real world is an incoherent concept"
    },
    "3c8239da1527ea6eb196c1ebb1b15eca": {
      "source_id": "3c8239da1527ea6eb196c1ebb1b15eca",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1649,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Would I think for ten thousand years?"
    },
    "292b9d20306ebfecbdcf432c3678b0a0": {
      "source_id": "292b9d20306ebfecbdcf432c3678b0a0",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30603,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Learning preferences by looking at the world"
    },
    "5f0dd031af77866866bc812ed1392ffe": {
      "source_id": "5f0dd031af77866866bc812ed1392ffe",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4155,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Nuances with ascription universality"
    },
    "68ad8512d86e011a46baef319022cf04": {
      "source_id": "68ad8512d86e011a46baef319022cf04",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19948,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #45"
    },
    "a996e66d05d8de595162d4d61cf3a0fa": {
      "source_id": "a996e66d05d8de595162d4d61cf3a0fa",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10850,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "How the MtG Color Wheel Explains AI Safety"
    },
    "b431d703c5f8120106506d331285a4cf": {
      "source_id": "b431d703c5f8120106506d331285a4cf",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15075,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Pavlov Generalizes"
    },
    "5d39bd9d6c7adf3d74840d5149a30edd": {
      "source_id": "5d39bd9d6c7adf3d74840d5149a30edd",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19321,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Thoughts on Human Models"
    },
    "00730a44dbe49021dd2b9c8dbebba8e3": {
      "source_id": "00730a44dbe49021dd2b9c8dbebba8e3",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 21056,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #46"
    },
    "5ffbf973194e48ade483cdc872a65894": {
      "source_id": "5ffbf973194e48ade483cdc872a65894",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5987,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Can HCH epistemically dominate Ramanujan?"
    },
    "20e995e3a9d34089df234386338ebcdf": {
      "source_id": "20e995e3a9d34089df234386338ebcdf",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 18135,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #47"
    },
    "7e7af0d6b8ebd1c09f37d833ae39836d": {
      "source_id": "7e7af0d6b8ebd1c09f37d833ae39836d",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23307,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Simplified preferences needed; simplified preferences sufficient"
    },
    "c3ba716dd7c13897cea472dfc29cb1ef": {
      "source_id": "c3ba716dd7c13897cea472dfc29cb1ef",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5886,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Three ways that \"Sufficiently optimized agents appear coherent\" can be false"
    },
    "e2be2a191d70b25cc88492a4dd9561fc": {
      "source_id": "e2be2a191d70b25cc88492a4dd9561fc",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19635,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Smoothmin and personal identity"
    },
    "6a4ade4c540b7126195064a4916da15a": {
      "source_id": "6a4ade4c540b7126195064a4916da15a",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30649,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Alignment Research Field Guide"
    },
    "54a4baf449784724c2235263abf9e022": {
      "source_id": "54a4baf449784724c2235263abf9e022",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5599,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Designing agent incentives to avoid side effects"
    },
    "c9436cabccb79962a4510e8445fab237": {
      "source_id": "c9436cabccb79962a4510e8445fab237",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 20805,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #48"
    },
    "85bb8982b997d3ebdc06af836076caaf": {
      "source_id": "85bb8982b997d3ebdc06af836076caaf",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16479,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "What failure looks like"
    },
    "aebd4d4ba481af341db4612544db9cb7": {
      "source_id": "aebd4d4ba481af341db4612544db9cb7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 23814,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #49"
    },
    "9d65c8f58b21d706dcd0b7b210f259f4": {
      "source_id": "9d65c8f58b21d706dcd0b7b210f259f4",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2346,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "What's wrong with these analogies for understanding Informed Oversight and IDA?"
    },
    "902c866b1eaea14ee1c1d815a13ab192": {
      "source_id": "902c866b1eaea14ee1c1d815a13ab192",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8168,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "The Main Sources of AI Risk?"
    },
    "33f1fb6896b8face378c7b12e3233658": {
      "source_id": "33f1fb6896b8face378c7b12e3233658",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27616,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "A Concrete Proposal for Adversarial IDA"
    },
    "fdd61eac989e5691918d1d3486d484bb": {
      "source_id": "fdd61eac989e5691918d1d3486d484bb",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 20275,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #50"
    },
    "1f961a02f0785a132978306d93b591f8": {
      "source_id": "1f961a02f0785a132978306d93b591f8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 29284,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #51"
    },
    "3b08869102a4ecbce528dd1ed80c8f54": {
      "source_id": "3b08869102a4ecbce528dd1ed80c8f54",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29510,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Defeating Goodhart and the \"closest unblocked strategy\" problem"
    },
    "e7fa1e0bd529c503541926feb4c8728d": {
      "source_id": "e7fa1e0bd529c503541926feb4c8728d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 17112,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #52"
    },
    "af41c3ddce47545588f3f4d576400ff0": {
      "source_id": "af41c3ddce47545588f3f4d576400ff0",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 89932,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Reinforcement learning with imperceptible rewards"
    },
    "1b421946a626a4c3e745970f38be2da7": {
      "source_id": "1b421946a626a4c3e745970f38be2da7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 39440,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter One Year Retrospective"
    },
    "57c6061fed9130ccf52269132e67c892": {
      "source_id": "57c6061fed9130ccf52269132e67c892",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23568,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Best reasons for pessimism about impact of impact measures?"
    },
    "5b28e5803b9b5091e1e5dc1882b92dbb": {
      "source_id": "5b28e5803b9b5091e1e5dc1882b92dbb",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43886,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Corrigibility as Constrained Optimisation"
    },
    "4e3776251f54bb67cfc2f4a487f28b0d": {
      "source_id": "4e3776251f54bb67cfc2f4a487f28b0d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 17278,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter #53"
    },
    "ede8e6ba4698b1d3c923c03d6d2b8878": {
      "source_id": "ede8e6ba4698b1d3c923c03d6d2b8878",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3006,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Strategic implications of AIs' ability to coordinate at low cost, for example by"
    },
    "e444a17b1afe4292c7d49511a3fb959c": {
      "source_id": "e444a17b1afe4292c7d49511a3fb959c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 18846,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #54] Boxing a finite-horizon AI system to keep it unambitious"
    },
    "e2d2fe36c5c53004e34c2ae855d4effc": {
      "source_id": "e2d2fe36c5c53004e34c2ae855d4effc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9540,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Self-confirming predictions can be arbitrarily bad"
    },
    "49a4a56003299a13467bde37524db3b7": {
      "source_id": "49a4a56003299a13467bde37524db3b7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19023,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #55] Regulatory markets and international standards as a means of ensuring b"
    },
    "3cd531d0e0136874c4c636584df57922": {
      "source_id": "3cd531d0e0136874c4c636584df57922",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12891,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "\"UDT2\" and \"against UD+ASSA\""
    },
    "9ee3f77c6f8c6caaa08bf11bf7991b8b": {
      "source_id": "9ee3f77c6f8c6caaa08bf11bf7991b8b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19645,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #56] Should ML researchers stop running experiments before making hypotheses"
    },
    "b970ac1752748415b2452bf1c22da601": {
      "source_id": "b970ac1752748415b2452bf1c22da601",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3060,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "And the AI would have got away with it too, if..."
    },
    "72ddddac25970441b2fe6a5045bad042": {
      "source_id": "72ddddac25970441b2fe6a5045bad042",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2769,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "A shift in arguments for AI risk"
    },
    "b15e2fb8d96ccfb871568f5fe456f68b": {
      "source_id": "b15e2fb8d96ccfb871568f5fe456f68b",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42662,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Risks from Learned Optimization: Introduction"
    },
    "52c4dc480d794757d0689b5799ffdad0": {
      "source_id": "52c4dc480d794757d0689b5799ffdad0",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41830,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Conditions for Mesa-Optimization"
    },
    "9bf7a20e1a14c9be9a05b6f9a66d72c8": {
      "source_id": "9bf7a20e1a14c9be9a05b6f9a66d72c8",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22992,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Selection vs Control"
    },
    "3444ef41ea8c602e57a67e2b8e0f76a1": {
      "source_id": "3444ef41ea8c602e57a67e2b8e0f76a1",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33662,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Does Bayes Beat Goodhart?"
    },
    "aa449168bd129b8ce2e98702d8ef08bc": {
      "source_id": "aa449168bd129b8ce2e98702d8ef08bc",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43961,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "The Inner Alignment Problem"
    },
    "ffd94a1b0fc538f00612a0bf19d10876": {
      "source_id": "ffd94a1b0fc538f00612a0bf19d10876",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52542,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Deceptive Alignment"
    },
    "0e5911e0496549d75f55e3ca29ff3bef": {
      "source_id": "0e5911e0496549d75f55e3ca29ff3bef",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 15679,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #57]\u00a0Why we should focus on robustness in AI safety, and the analogous probl"
    },
    "3d0b1602b08ce47ffb6aa4e071ec972a": {
      "source_id": "3d0b1602b08ce47ffb6aa4e071ec972a",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30758,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Risks from Learned Optimization: Conclusion and Related Work"
    },
    "5460d8d6d2635c8b54ed9b5881a81542": {
      "source_id": "5460d8d6d2635c8b54ed9b5881a81542",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3137,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "AGI will drastically increase economies of scale"
    },
    "24c4e012395a7fe869da1b7337b20685": {
      "source_id": "24c4e012395a7fe869da1b7337b20685",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12577,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Let's talk about \"Convergent Rationality\""
    },
    "ccb8dc2745b99ac9f2fc930aa7bc8daa": {
      "source_id": "ccb8dc2745b99ac9f2fc930aa7bc8daa",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 93110,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Research Agenda v0.9: Synthesising a human's preferences into a utility function"
    },
    "a493ff100190048cdb5c364378f93647": {
      "source_id": "a493ff100190048cdb5c364378f93647",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48865,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "1hr talk: Intro to AGI safety"
    },
    "180bb6b3186ee0b134eb0ef8925bd167": {
      "source_id": "180bb6b3186ee0b134eb0ef8925bd167",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1068,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Modeling AGI Safety Frameworks with Causal Influence Diagrams"
    },
    "0f596b795cd00d7ce369d63f2faf399c": {
      "source_id": "0f596b795cd00d7ce369d63f2faf399c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 16344,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #58] Mesa optimization: what it is, and why we should care"
    },
    "5f418db2f508155f1828402f02d52b6f": {
      "source_id": "5f418db2f508155f1828402f02d52b6f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5032,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Machine Learning Projects on IDA"
    },
    "81bef4c44f1828ba4300974ad3845150": {
      "source_id": "81bef4c44f1828ba4300974ad3845150",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2090,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Research Agenda in reverse: what *would* a solution look like?"
    },
    "fb4959952f68d872bcbc6b04c7a350d7": {
      "source_id": "fb4959952f68d872bcbc6b04c7a350d7",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23141,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Aligning a toy model of optimization"
    },
    "dbc736f6151079aefae9bbe613302101": {
      "source_id": "dbc736f6151079aefae9bbe613302101",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35978,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Conceptual Problems with UDT and Policy Selection"
    },
    "41dd8855c3f9afd8881d625023b83a59": {
      "source_id": "41dd8855c3f9afd8881d625023b83a59",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45616,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "An Increasingly Manipulative Newsfeed"
    },
    "77a79166481ec5e58d3c765de0a0e823": {
      "source_id": "77a79166481ec5e58d3c765de0a0e823",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7571,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Re-introducing Selection vs Control for Optimization (Optimizing and Goodhart Ef"
    },
    "8b4c8db1dc037a1e4a19c560b0f54833": {
      "source_id": "8b4c8db1dc037a1e4a19c560b0f54833",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7402,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Learning biases and rewards simultaneously"
    },
    "6fe1e12b890d7fc1fff131342bc01779": {
      "source_id": "6fe1e12b890d7fc1fff131342bc01779",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15382,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Musings on Cumulative Cultural Evolution and AI"
    },
    "b23ffbc31a3de977a73b0951f732cce5": {
      "source_id": "b23ffbc31a3de977a73b0951f732cce5",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 17098,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #59] How arguments for AI risk have changed over time"
    },
    "4da2f52633dbf0403401f5fc2f33c021": {
      "source_id": "4da2f52633dbf0403401f5fc2f33c021",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8119,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Some Comments on Stuart Armstrong's \"Research Agenda v0.9\""
    },
    "e7b207efa0106b0a8fcbd6ee33e8f7f7": {
      "source_id": "e7b207efa0106b0a8fcbd6ee33e8f7f7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 18811,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #60]\u00a0A new AI challenge: Minecraft agents that assist human players in creat"
    },
    "97a9987fc4d35c27564523f675670602": {
      "source_id": "97a9987fc4d35c27564523f675670602",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42865,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "AI Safety Debate and Its Applications"
    },
    "4f5e9658141f868b4552e820e6a610a7": {
      "source_id": "4f5e9658141f868b4552e820e6a610a7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3897,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "On the purposes of decision theory research"
    },
    "fc8f5b0f7f21b4986313ec0cb49df2e8": {
      "source_id": "fc8f5b0f7f21b4986313ec0cb49df2e8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9604,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Ought: why it matters and ways to help"
    },
    "b890b03d205df0f65ff2bb75f28ab99a": {
      "source_id": "b890b03d205df0f65ff2bb75f28ab99a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6569,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "The Artificial Intentional Stance"
    },
    "0bc45796cbc9a5d00ec7553919319516": {
      "source_id": "0bc45796cbc9a5d00ec7553919319516",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26340,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "What does Optimization Mean, Again?  (Optimizing and Goodhart Effects - Clarifyi"
    },
    "d9bf6111a0a402a0e29b1d9c06d679ce": {
      "source_id": "d9bf6111a0a402a0e29b1d9c06d679ce",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5508,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Applying Overoptimization to Selection vs. Control (Optimizing and Goodhart Effe"
    },
    "b687ad25fd547156e6093179d7b357ef": {
      "source_id": "b687ad25fd547156e6093179d7b357ef",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6360,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Contest: $1,000 for good questions to ask to an Oracle AI"
    },
    "3db2fea639ade952169137d150b7174a": {
      "source_id": "3db2fea639ade952169137d150b7174a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6067,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Practical consequences of impossibility of value learning"
    },
    "2ba533c0e632c1ee02c3f585222b7291": {
      "source_id": "2ba533c0e632c1ee02c3f585222b7291",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 249,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "AI Alignment Open Thread August 2019"
    },
    "33d452836e422f13898aaa214ac0452a": {
      "source_id": "33d452836e422f13898aaa214ac0452a",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33068,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "A Survey of Early Impact Measures"
    },
    "a289d0e9e2a7d6edb038ea979f28a116": {
      "source_id": "a289d0e9e2a7d6edb038ea979f28a116",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2898,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "New paper: Corrigibility with Utility Preservation"
    },
    "36c6ef08d2e515efeb059cb894189989": {
      "source_id": "36c6ef08d2e515efeb059cb894189989",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2868,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Project Proposal: Considerations for trading off capabilities and safety impacts"
    },
    "b717732c78df10089864e1ccd41d2f36": {
      "source_id": "b717732c78df10089864e1ccd41d2f36",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31664,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Understanding Recent Impact Measures"
    },
    "91749e92698f4c78f2c3ea6b09f9ae41": {
      "source_id": "91749e92698f4c78f2c3ea6b09f9ae41",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24723,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Self-Supervised Learning and AGI Safety"
    },
    "634693f5f2e39af302c4acd6505f91c5": {
      "source_id": "634693f5f2e39af302c4acd6505f91c5",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34405,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Four Ways An Impact Measure Could Help Alignment"
    },
    "8a2234903166456861208af581bb9dd9": {
      "source_id": "8a2234903166456861208af581bb9dd9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3544,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Verification and Transparency"
    },
    "8f17ea2e15f0e2f41f4b0aecdc6baffe": {
      "source_id": "8f17ea2e15f0e2f41f4b0aecdc6baffe",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8904,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Mesa-Optimizers and Over-optimization Failure (Optimizing and Goodhart Effects, "
    },
    "32862c7209236641a11594c0c3296020": {
      "source_id": "32862c7209236641a11594c0c3296020",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28793,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Distance Functions are Hard"
    },
    "60879333d13131e368f4c890d2c5901f": {
      "source_id": "60879333d13131e368f4c890d2c5901f",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22312,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Clarifying some key hypotheses in AI alignment"
    },
    "a53c3ee3194149c2578c604dcec38b77": {
      "source_id": "a53c3ee3194149c2578c604dcec38b77",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2918,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Problems in AI Alignment that philosophers could potentially contribute to"
    },
    "a39c0a143a0424c5ed1c7b9be298c042": {
      "source_id": "a39c0a143a0424c5ed1c7b9be298c042",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18656,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Goodhart's Curse and Limitations on AI Alignment"
    },
    "65c52207e5733a00da786bf1b58e51f4": {
      "source_id": "65c52207e5733a00da786bf1b58e51f4",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 10871,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Classifying specification problems as variants of Goodhart's Law"
    },
    "c69fcd6278281ba0ab518fd326ddea46": {
      "source_id": "c69fcd6278281ba0ab518fd326ddea46",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6281,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Two senses of \u201coptimizer\u201d"
    },
    "8c33e459208a17f086102b5147d1ec78": {
      "source_id": "8c33e459208a17f086102b5147d1ec78",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 7374,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Call for contributors to the Alignment Newsletter"
    },
    "2055305fc589c83fb91e6cfe0c54817a": {
      "source_id": "2055305fc589c83fb91e6cfe0c54817a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 862,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Announcement: Writing Day Today (Thursday)"
    },
    "ce6e0b935eb40872c78cb110c8471e53": {
      "source_id": "ce6e0b935eb40872c78cb110c8471e53",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29481,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Implications of Quantum Computing for Artificial Intelligence Alignment Research"
    },
    "517844cec9102175d39e1ff89aa42d26": {
      "source_id": "517844cec9102175d39e1ff89aa42d26",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19702,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #62]\u00a0Are adversarial examples caused by real but imperceptible features?"
    },
    "dc3a43b34da36d971cd9c92eaeb0d13a": {
      "source_id": "dc3a43b34da36d971cd9c92eaeb0d13a",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11971,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Towards a mechanistic understanding of corrigibility"
    },
    "8bb97a8d1f33bb64f997a7f6ae123c2d": {
      "source_id": "8bb97a8d1f33bb64f997a7f6ae123c2d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8565,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Thoughts from a Two Boxer"
    },
    "54344eeeb281432b1e55f4dc2fe6dc7b": {
      "source_id": "54344eeeb281432b1e55f4dc2fe6dc7b",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11852,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "The Commitment Races problem"
    },
    "18e458d90852d129b26e3cc238bd30ee": {
      "source_id": "18e458d90852d129b26e3cc238bd30ee",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14119,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Vaniver's View on Factored Cognition"
    },
    "919b34d159153dd163408eb328ab9fcb": {
      "source_id": "919b34d159153dd163408eb328ab9fcb",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30128,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Tabooing 'Agent' for Prosaic Alignment"
    },
    "5eb4f7f326b25d88cd5a72fa33a3b31c": {
      "source_id": "5eb4f7f326b25d88cd5a72fa33a3b31c",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14163,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Creating Environments to Design and Test Embedded Agents"
    },
    "c934c89dfe5bb80644a0c97d320326a0": {
      "source_id": "c934c89dfe5bb80644a0c97d320326a0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4375,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Formalising decision theory is hard"
    },
    "ef20ef5af584b47a3e829ed924aec2b6": {
      "source_id": "ef20ef5af584b47a3e829ed924aec2b6",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14838,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Soft takeoff can still lead to decisive strategic advantage"
    },
    "4a8c8d5998c427752af09a0ac3839614": {
      "source_id": "4a8c8d5998c427752af09a0ac3839614",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30825,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "When do utility functions constrain?"
    },
    "98fb4df863be169db891cc2d6966f72e": {
      "source_id": "98fb4df863be169db891cc2d6966f72e",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39126,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Troll Bridge"
    },
    "6295e9e1969b7b0a775718b61f003557": {
      "source_id": "6295e9e1969b7b0a775718b61f003557",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9949,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Optimization Provenance"
    },
    "c4b43445e7f69b015f8913034644566f": {
      "source_id": "c4b43445e7f69b015f8913034644566f",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26709,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Problems with AI debate"
    },
    "79eb135b9fe0b09968e46466bc92797f": {
      "source_id": "79eb135b9fe0b09968e46466bc92797f",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21004,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Embedded Agency via Abstraction"
    },
    "e8ebe5a452d9c918f2be99adeaa46caf": {
      "source_id": "e8ebe5a452d9c918f2be99adeaa46caf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8054,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Six AI Risk/Strategy Ideas"
    },
    "49bf1e04c629a8d302c834032eb859c4": {
      "source_id": "49bf1e04c629a8d302c834032eb859c4",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2460,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "AI Alignment Writing Day Roundup #1"
    },
    "974967abda49ec82c5aff18e8abbcad8": {
      "source_id": "974967abda49ec82c5aff18e8abbcad8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3239,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "2-D Robustness"
    },
    "cc322938c9ac5cb87e7f740203cf8c88": {
      "source_id": "cc322938c9ac5cb87e7f740203cf8c88",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23790,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Utility \u2260 Reward"
    },
    "327a9134f208785ed7e0131c6cd92655": {
      "source_id": "327a9134f208785ed7e0131c6cd92655",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11073,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Concrete experiments in inner alignment"
    },
    "dd4fd42b723917de02349f9aad4a4238": {
      "source_id": "dd4fd42b723917de02349f9aad4a4238",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8188,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "AI Safety \"Success Stories\""
    },
    "633d02adbecbf7b6241e0fd9bc2bd068": {
      "source_id": "633d02adbecbf7b6241e0fd9bc2bd068",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32689,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Are minimal circuits deceptive?"
    },
    "0f4640215a771d4c196498e6f0177698": {
      "source_id": "0f4640215a771d4c196498e6f0177698",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6427,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Counterfactual Oracles = online supervised learning with random selection of tra"
    },
    "4ae7ad5a27939366f9f6cf4ea425115e": {
      "source_id": "4ae7ad5a27939366f9f6cf4ea425115e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 17478,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #63]\u00a0How architecture search, meta learning, and environment design could le"
    },
    "4367f38532435741076c5c037de6b01e": {
      "source_id": "4367f38532435741076c5c037de6b01e",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 69492,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Relaxed adversarial training for inner alignment"
    },
    "3245a808ca843713d4d9338850cf82a0": {
      "source_id": "3245a808ca843713d4d9338850cf82a0",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49241,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Conversation with Paul Christiano"
    },
    "06ad4531cfbd69db957940ff2c8b6b7b": {
      "source_id": "06ad4531cfbd69db957940ff2c8b6b7b",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22704,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "What You See Isn't Always What You Want"
    },
    "87bb64e6a77044c2a96a518e9f0610df": {
      "source_id": "87bb64e6a77044c2a96a518e9f0610df",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17305,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Do Sufficiently Advanced Agents Use Logic?"
    },
    "a4f5833b6c1b21a716165bb281a241b0": {
      "source_id": "a4f5833b6c1b21a716165bb281a241b0",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21795,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "The strategy-stealing assumption"
    },
    "5b22c476358fd67c13bf8854154962b0": {
      "source_id": "5b22c476358fd67c13bf8854154962b0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 17281,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #64]: Using Deep RL and Reward Uncertainty to Incentivize Preference Learnin"
    },
    "7ddd6cb083d53763c8caf16885e7e586": {
      "source_id": "7ddd6cb083d53763c8caf16885e7e586",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6755,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Reframing Impact"
    },
    "0139afa472ce5c42df43296eb626ec34": {
      "source_id": "0139afa472ce5c42df43296eb626ec34",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5201,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "What are the differences between all the iterative/recursive approaches to AI al"
    },
    "3791fcce734c3b80bebd331e054da082": {
      "source_id": "3791fcce734c3b80bebd331e054da082",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3520,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Value Impact"
    },
    "6fcee0ec6749616d0f32aa3c2c6c1b98": {
      "source_id": "6fcee0ec6749616d0f32aa3c2c6c1b98",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 18934,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #65]:\u00a0Learning useful skills by watching humans \u201cplay\u201d"
    },
    "d0015e2abd654f175011b30d09a8aaaa": {
      "source_id": "d0015e2abd654f175011b30d09a8aaaa",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29692,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Towards an empirical investigation of inner alignment"
    },
    "287eae9aa28d7683978334553965dc64": {
      "source_id": "287eae9aa28d7683978334553965dc64",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3750,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "A simple environment for showing mesa misalignment"
    },
    "14973c42ed647b57b04d889fb2d9c9b0": {
      "source_id": "14973c42ed647b57b04d889fb2d9c9b0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 103,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[Talk] Paul Christiano on his alignment taxonomy"
    },
    "6001052c6f5845c6c2fb9b9713595baf": {
      "source_id": "6001052c6f5845c6c2fb9b9713595baf",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34596,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Partial Agency"
    },
    "2edd36884f98a520d5906f355e28d883": {
      "source_id": "2edd36884f98a520d5906f355e28d883",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 17076,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #66]: Decomposing robustness into capability robustness and alignment robust"
    },
    "c2f6e5041dd41a14a3a44f81e4f2ee97": {
      "source_id": "c2f6e5041dd41a14a3a44f81e4f2ee97",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7037,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "List of resolved confusions about IDA"
    },
    "b1cd8d99db33424d8258976a41742751": {
      "source_id": "b1cd8d99db33424d8258976a41742751",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23223,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "World State is the Wrong Abstraction for Impact"
    },
    "91bd3378d94d42001cbe3f66523a78db": {
      "source_id": "91bd3378d94d42001cbe3f66523a78db",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22930,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Human instincts, symbol grounding, and the blank-slate neocortex"
    },
    "8680ba0c10766bc4de0b24effd12c278": {
      "source_id": "8680ba0c10766bc4de0b24effd12c278",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6487,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Can we make peace with moral indeterminacy?"
    },
    "c7739671f351b69b964b8e95f9a2e485": {
      "source_id": "c7739671f351b69b964b8e95f9a2e485",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 268,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "AI Alignment Open Thread October 2019"
    },
    "b83a7c9977c1d48d6f7609a611173f65": {
      "source_id": "b83a7c9977c1d48d6f7609a611173f65",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29169,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Debate on Instrumental Convergence between LeCun, Russell, Bengio, Zador, and Mo"
    },
    "1e95834d5b1b210d2bab7552ff0e77af": {
      "source_id": "1e95834d5b1b210d2bab7552ff0e77af",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 17695,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #67]:\u00a0Creating environments in which to study inner alignment failures"
    },
    "6d511f51d4dccfa16d93dc0f49b7c68f": {
      "source_id": "6d511f51d4dccfa16d93dc0f49b7c68f",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24365,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "AI Alignment Writing Day Roundup #2"
    },
    "fc09d948b4ab581b53df84fe6638205f": {
      "source_id": "fc09d948b4ab581b53df84fe6638205f",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13150,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "What's the dream for giving natural language commands to AI?"
    },
    "caa5894b46ab63c1d4dac7b9de3e94e9": {
      "source_id": "caa5894b46ab63c1d4dac7b9de3e94e9",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10753,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Characterizing Real-World Agents as a Research Meta-Strategy"
    },
    "0d06b669f4d82bd90edde05d0217d57e": {
      "source_id": "0d06b669f4d82bd90edde05d0217d57e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8887,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Misconceptions about continuous takeoff"
    },
    "15f9859871c42c6838a1584182105f2a": {
      "source_id": "15f9859871c42c6838a1584182105f2a",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10906,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Minimization of prediction error as a foundation for human values in AI alignmen"
    },
    "44cede0ca9eb93bbfec4a3dc8a81eec7": {
      "source_id": "44cede0ca9eb93bbfec4a3dc8a81eec7",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10166,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Thoughts on \"Human-Compatible\""
    },
    "6c038e7dadb5c24766a78a335808a0ee": {
      "source_id": "6c038e7dadb5c24766a78a335808a0ee",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 813,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "AI alignment landscape"
    },
    "d364b1860d78b156c1010eea52d836e5": {
      "source_id": "d364b1860d78b156c1010eea52d836e5",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 17662,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #68]: The attainable utility theory of impact"
    },
    "0590cb309303ed7a2dae03a824f8e1b8": {
      "source_id": "0590cb309303ed7a2dae03a824f8e1b8",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30641,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Impact measurement and value-neutrality verification"
    },
    "88b9b9570209e9e354b1ffb7701eb2d7": {
      "source_id": "88b9b9570209e9e354b1ffb7701eb2d7",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27649,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "The Parable of Predict-O-Matic"
    },
    "408e5e39c7a7bbb0172043831e8e1dda": {
      "source_id": "408e5e39c7a7bbb0172043831e8e1dda",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6252,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Gradient hacking"
    },
    "c9e652d17df8ec7246183904bccc6ffd": {
      "source_id": "c9e652d17df8ec7246183904bccc6ffd",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35853,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Random Thoughts on Predict-O-Matic"
    },
    "db09d3111bb277635b3ca78bb7b40b94": {
      "source_id": "db09d3111bb277635b3ca78bb7b40b94",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8121,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Technical AGI safety research outside AI"
    },
    "c41127c13b6f3c471ec5604f4c8950f8": {
      "source_id": "c41127c13b6f3c471ec5604f4c8950f8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 29851,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #69] Stuart Russell's new book on why we need to replace the standard model "
    },
    "6c82da8e3ecff05b039cdc1fa4992a90": {
      "source_id": "6c82da8e3ecff05b039cdc1fa4992a90",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33325,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Defining Myopia"
    },
    "f19921bbacad1308534d56e794fa2642": {
      "source_id": "f19921bbacad1308534d56e794fa2642",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4431,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Human-AI Collaboration"
    },
    "7ca99a9b24815725bceab431b4875029": {
      "source_id": "7ca99a9b24815725bceab431b4875029",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37347,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Deliberation as a method to find the \"actual preferences\" of humans"
    },
    "f08f156ab14088e131ec5180ad67b366": {
      "source_id": "f08f156ab14088e131ec5180ad67b366",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 20135,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #70]: Agents that help humans who are still learning about their own prefere"
    },
    "eeb96f7aa54094880bc17b03b2676551": {
      "source_id": "eeb96f7aa54094880bc17b03b2676551",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 16681,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #71]:\u00a0Avoiding reward tampering through current-RF optimization"
    },
    "8e7fa0f0159199f72ba1b068dad0d785": {
      "source_id": "8e7fa0f0159199f72ba1b068dad0d785",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1412,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Rohin Shah on reasons for AI optimism"
    },
    "0b149c616e43c62f9d3b4f179ead694e": {
      "source_id": "0b149c616e43c62f9d3b4f179ead694e",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24108,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Chris Olah\u2019s views on AGI safety"
    },
    "655bfbbda74a8e6dd308e12eb47bce8c": {
      "source_id": "655bfbbda74a8e6dd308e12eb47bce8c",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10113,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "\u201cembedded self-justification,\u201d or something like that"
    },
    "de295dc646e1979653d793f92cf4a0a4": {
      "source_id": "de295dc646e1979653d793f92cf4a0a4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5900,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "But exactly how complex and fragile?"
    },
    "784534a042fd1eac8a7f039464afa1f1": {
      "source_id": "784534a042fd1eac8a7f039464afa1f1",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31058,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Will transparency help catch deception? Perhaps not"
    },
    "4c65700117e86e22c17e6e10d7612d2f": {
      "source_id": "4c65700117e86e22c17e6e10d7612d2f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6501,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "More variations on pseudo-alignment"
    },
    "2c7efd08a11b462cba8f7b227291361d": {
      "source_id": "2c7efd08a11b462cba8f7b227291361d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 22442,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #72]: Alignment, robustness, methodology, and system building as research pr"
    },
    "01d20fad171a081bc483f414b2f9f35b": {
      "source_id": "01d20fad171a081bc483f414b2f9f35b",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30634,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "AI Alignment Research Overview (by Jacob Steinhardt)"
    },
    "cc4842a138517920391bd4699202ae82": {
      "source_id": "cc4842a138517920391bd4699202ae82",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33780,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "The Credit Assignment Problem"
    },
    "c27d59dfed5a27e851b9ff65e6bc3f13": {
      "source_id": "c27d59dfed5a27e851b9ff65e6bc3f13",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2286,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "What I\u2019ll be doing at MIRI"
    },
    "826f914082e66028219bcec3bd773e9b": {
      "source_id": "826f914082e66028219bcec3bd773e9b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 15282,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #73]: Detecting catastrophic failures by learning how agents tend to break"
    },
    "a0f70b3d556958c47eb16da941819605": {
      "source_id": "a0f70b3d556958c47eb16da941819605",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23401,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "The Value Definition Problem"
    },
    "4facef7d70c671db6cccde7530364104": {
      "source_id": "4facef7d70c671db6cccde7530364104",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8797,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "The Goodhart Game"
    },
    "69a7724b52c4d2d8ac16164df2b2b0ee": {
      "source_id": "69a7724b52c4d2d8ac16164df2b2b0ee",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 17380,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #74]:\u00a0Separating beneficial AI into competence, alignment, and coping with i"
    },
    "6715c5a123e8e08ffe5b16c9803a730a": {
      "source_id": "6715c5a123e8e08ffe5b16c9803a730a",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44225,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "A Brief Intro to Domain Theory"
    },
    "16cb1ad2ea290b0fff8f4fbc65935279": {
      "source_id": "16cb1ad2ea290b0fff8f4fbc65935279",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26899,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Defining AI wireheading"
    },
    "6f41cbc7dfde5814a75004eeb36e3395": {
      "source_id": "6f41cbc7dfde5814a75004eeb36e3395",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13210,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Thoughts on implementing corrigible robust alignment"
    },
    "a732b32d081c0c15c3c2635a6cdb75dd": {
      "source_id": "a732b32d081c0c15c3c2635a6cdb75dd",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 20924,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #75]: Solving Atari and Go with learned game models, and thoughts from a MIR"
    },
    "51fba6fabc26f406bc07d37b690f258e": {
      "source_id": "51fba6fabc26f406bc07d37b690f258e",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21406,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Useful Does Not Mean Secure"
    },
    "62454ec7f45689fba8f6de5f95f70414": {
      "source_id": "62454ec7f45689fba8f6de5f95f70414",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5066,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "What I talk about when I talk about AI x-risk: 3 core claims I want machine lear"
    },
    "77d788e611b53794b2c9c82349464b04": {
      "source_id": "77d788e611b53794b2c9c82349464b04",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4550,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "A list of good heuristics that the case for AI x-risk fails"
    },
    "1127e9f4f9199dc49ca6dc718c9c7675": {
      "source_id": "1127e9f4f9199dc49ca6dc718c9c7675",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 21343,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #76]:\u00a0How dataset size affects robustness, and benchmarking safe exploration"
    },
    "1f42157ceda996402db94bdacdd73c68": {
      "source_id": "1f42157ceda996402db94bdacdd73c68",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55008,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Recent Progress in the Theory of Neural Networks"
    },
    "74ab2e6f01f08445b98b789daf5aadc9": {
      "source_id": "74ab2e6f01f08445b98b789daf5aadc9",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21615,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "What are some non-purely-sampling ways to do deep RL?"
    },
    "3f34418742af968801b1203da8720b10": {
      "source_id": "3f34418742af968801b1203da8720b10",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54237,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Seeking Power is Often Convergently Instrumental in MDPs"
    },
    "dab9cb99ec48b42cd04896a22e629d6b": {
      "source_id": "dab9cb99ec48b42cd04896a22e629d6b",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33067,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Oracles: reject all deals - break superrationality, with superrationality"
    },
    "05fd0deca6e496222c8078a0b07d853c": {
      "source_id": "05fd0deca6e496222c8078a0b07d853c",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45533,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Values, Valence, and Alignment"
    },
    "22901c6f65fbac98b6c70c54ba3d51a7": {
      "source_id": "22901c6f65fbac98b6c70c54ba3d51a7",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11381,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Understanding \u201cDeep Double Descent\u201d"
    },
    "1f287c290bc5a2feb8e3d3d29cf9fb8f": {
      "source_id": "1f287c290bc5a2feb8e3d3d29cf9fb8f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9274,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Comment on Coherence arguments do not imply goal directed behavior"
    },
    "fd8cbad6b08de8f66df141e4ff1072a9": {
      "source_id": "fd8cbad6b08de8f66df141e4ff1072a9",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16136,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Predictive coding = RL + SL + Bayes + MPC"
    },
    "5df20e0f2fb0175ede83b453ab241c69": {
      "source_id": "5df20e0f2fb0175ede83b453ab241c69",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5579,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Preface to CLR's Research Agenda on Cooperation, Conflict, and TAI"
    },
    "4198dbe4a764bb6894c2ea0220a94bae": {
      "source_id": "4198dbe4a764bb6894c2ea0220a94bae",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33413,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Acknowledgements & References"
    },
    "30c3f8734d405cdd2d5c355ba31e2de2": {
      "source_id": "30c3f8734d405cdd2d5c355ba31e2de2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3075,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Is the term mesa optimizer too narrow?"
    },
    "a4974b3260ab0eb64e913a39a15eba6a": {
      "source_id": "a4974b3260ab0eb64e913a39a15eba6a",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46533,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Sections 1 & 2: Introduction, Strategy and Governance"
    },
    "8de94a52ce46d8321da14d6c1f464d5e": {
      "source_id": "8de94a52ce46d8321da14d6c1f464d5e",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42313,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Sections 3 & 4: Credibility, Peaceful Bargaining Mechanisms"
    },
    "12659bf477496bb32db8f31ba9cd9dc9": {
      "source_id": "12659bf477496bb32db8f31ba9cd9dc9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6463,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "A dilemma for prosaic AI alignment"
    },
    "169cb33ed4b77f6637c5a3baa10a1349": {
      "source_id": "169cb33ed4b77f6637c5a3baa10a1349",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5209,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Counterfactual Mugging: Why should you pay?"
    },
    "da9395cdad81c568f89230a0a2c54b42": {
      "source_id": "da9395cdad81c568f89230a0a2c54b42",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 27991,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #77]: Double descent: a unification of statistical theory and modern ML prac"
    },
    "410842c0d9da9247e72869f3c017922d": {
      "source_id": "410842c0d9da9247e72869f3c017922d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6325,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Inductive biases stick around"
    },
    "0a0f641febb4f6163fa5f170edb0dbec": {
      "source_id": "0a0f641febb4f6163fa5f170edb0dbec",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 147219,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "2019 AI Alignment Literature Review and Charity Comparison"
    },
    "8e71ff8cfd5ed47a74482df4dd73f1e7": {
      "source_id": "8e71ff8cfd5ed47a74482df4dd73f1e7",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39904,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Sections 5 & 6: Contemporary Architectures, Humans in the Loop"
    },
    "a79afe32e2beef00c147327257dbf58b": {
      "source_id": "a79afe32e2beef00c147327257dbf58b",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22631,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Clarifying Power-Seeking and Instrumental Convergence"
    },
    "bbd50e11bc8fd3871a0993945413b84e": {
      "source_id": "bbd50e11bc8fd3871a0993945413b84e",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35338,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Section 7: Foundations of Rational Agency"
    },
    "84ad1e6af471fa3fdfdddecb5ff4ef45": {
      "source_id": "84ad1e6af471fa3fdfdddecb5ff4ef45",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10101,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Humans Are Embedded Agents Too"
    },
    "7ea1ac4a37e031f0682e621dd822b83e": {
      "source_id": "7ea1ac4a37e031f0682e621dd822b83e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 21499,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #78]\u00a0Formalizing power and instrumental convergence, and the end-of-year AI "
    },
    "dec3c5d7eeb521fefff9a4acb727f2f7": {
      "source_id": "dec3c5d7eeb521fefff9a4acb727f2f7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8878,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "New paper: (When) is Truth-telling Favored in AI debate?"
    },
    "903bc04ae8f96ea50806f32a4477e74c": {
      "source_id": "903bc04ae8f96ea50806f32a4477e74c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6837,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Critiquing \"What failure looks like\""
    },
    "34dbd20dcc7a1ec58df1dcf90da0d4f5": {
      "source_id": "34dbd20dcc7a1ec58df1dcf90da0d4f5",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25885,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Safe exploration and corrigibility"
    },
    "555121ab60501803606a56ca07bd552e": {
      "source_id": "555121ab60501803606a56ca07bd552e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 25177,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #79]: Recursive reward modeling as an alignment technique integrated with de"
    },
    "fcbad849b33212ac3c517bb0f7859b8c": {
      "source_id": "fcbad849b33212ac3c517bb0f7859b8c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19686,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #80]: Why AI risk might be solved without additional intervention from longt"
    },
    "daea13bad1d31b1c033d9498ab2461e7": {
      "source_id": "daea13bad1d31b1c033d9498ab2461e7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7390,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Exploring safe exploration"
    },
    "2ade106204f7ec23f0d3274622ebde0f": {
      "source_id": "2ade106204f7ec23f0d3274622ebde0f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4469,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "(Double-)Inverse Embedded Agency Problem"
    },
    "303d09e63768206ddd97dd4c25b9336e": {
      "source_id": "303d09e63768206ddd97dd4c25b9336e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 22511,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #81]: Universality as a potential solution to conceptual difficulties in int"
    },
    "088f3d3eb0aa6beb183f7b52831c5d55": {
      "source_id": "088f3d3eb0aa6beb183f7b52831c5d55",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36429,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Outer alignment and imitative amplification"
    },
    "3dcc44b42816621c1d8013a8f0b1adf4": {
      "source_id": "3dcc44b42816621c1d8013a8f0b1adf4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10870,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Of arguments and wagers"
    },
    "3b943f80b0c1f994cc3a22432fce8940": {
      "source_id": "3b943f80b0c1f994cc3a22432fce8940",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24870,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Malign generalization without internal search"
    },
    "e62549b14685db3321871fe505fa8813": {
      "source_id": "e62549b14685db3321871fe505fa8813",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2165,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Update on Ought's experiments on factored evaluation of arguments"
    },
    "ae5c0c8af2c74f2abfcfda9cb2fc8b58": {
      "source_id": "ae5c0c8af2c74f2abfcfda9cb2fc8b58",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 16590,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #82]: How OpenAI Five distributed their training computation"
    },
    "af9e73f2774260efb862acb368e17582": {
      "source_id": "af9e73f2774260efb862acb368e17582",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26359,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Inner alignment requires making assumptions about human values"
    },
    "f29f96117ba41a267e070aaacfdec114": {
      "source_id": "f29f96117ba41a267e070aaacfdec114",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 23856,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #83]: Sample-efficient deep learning with ReMixMatch"
    },
    "95c18bf6745da9a2227bf21d24528cf5": {
      "source_id": "95c18bf6745da9a2227bf21d24528cf5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 539,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "New paper: The Incentives that Shape Behaviour"
    },
    "aff57fe8a743c3d7dbfd902b5bddbcfa": {
      "source_id": "aff57fe8a743c3d7dbfd902b5bddbcfa",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18952,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "The two-layer model of human values, and problems with synthesizing preferences"
    },
    "f7d37210ea313f847a4debca8f689234": {
      "source_id": "f7d37210ea313f847a4debca8f689234",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 102097,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AI Alignment 2018-19 Review"
    },
    "2ad928d2fdd15e1ec22ee5454ca88218": {
      "source_id": "2ad928d2fdd15e1ec22ee5454ca88218",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25329,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Using vector fields to visualise preferences and make them consistent"
    },
    "e012e1002b27139ba6259361e7541884": {
      "source_id": "e012e1002b27139ba6259361e7541884",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 13720,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #84] Reviewing AI alignment work in 2018-19"
    },
    "78b78f3de87f4edbdd98687ca3e9314a": {
      "source_id": "78b78f3de87f4edbdd98687ca3e9314a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16370,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Towards deconfusing values"
    },
    "c43c6fc8c96d7fc2edc734b416e206e5": {
      "source_id": "c43c6fc8c96d7fc2edc734b416e206e5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25958,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Pessimism About Unknown Unknowns Inspires Conservatism"
    },
    "62da1fe9fbe5e197fd429c7e35110951": {
      "source_id": "62da1fe9fbe5e197fd429c7e35110951",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 16448,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #85]: The normative questions we should be asking for AI alignment, and a su"
    },
    "1613a80307de005bc3898a11714a9c10": {
      "source_id": "1613a80307de005bc3898a11714a9c10",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 63245,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Writeup: Progress on AI Safety via Debate"
    },
    "ce725f008fd911200d79a7f6fc2ce340": {
      "source_id": "ce725f008fd911200d79a7f6fc2ce340",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25600,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Synthesizing amplification and debate"
    },
    "aed99420348891216560a4df432f6fe7": {
      "source_id": "aed99420348891216560a4df432f6fe7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23052,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Plausibly, almost every powerful algorithm would be manipulative"
    },
    "c00e9fa6708717e173aab70820f68469": {
      "source_id": "c00e9fa6708717e173aab70820f68469",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8133,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "On the falsifiability of hypercomputation"
    },
    "df18fa2670ce4bf133e8a738bf45d5cd": {
      "source_id": "df18fa2670ce4bf133e8a738bf45d5cd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34550,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What can the principal-agent literature tell us about AI risk?"
    },
    "0c8ec3f6ce6e68153c24105aaf6dfe5a": {
      "source_id": "0c8ec3f6ce6e68153c24105aaf6dfe5a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19464,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #86]: Improving debate and factored cognition through human experiments"
    },
    "7c0efd06f2d9680881fb078fb45787fc": {
      "source_id": "7c0efd06f2d9680881fb078fb45787fc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16062,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Distinguishing definitions of takeoff"
    },
    "5c28a52bdafb53e9ef56e0e1a3e7b94e": {
      "source_id": "5c28a52bdafb53e9ef56e0e1a3e7b94e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17583,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "The Reasonable Effectiveness of Mathematics or: AI vs sandwiches"
    },
    "1c1a206f970454a82738d6a9736bf643": {
      "source_id": "1c1a206f970454a82738d6a9736bf643",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37858,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "The Catastrophic Convergence Conjecture"
    },
    "c51f5ca5b1d9e7c9a393eeb5f0c816bf": {
      "source_id": "c51f5ca5b1d9e7c9a393eeb5f0c816bf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10493,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Bayesian Evolving-to-Extinction"
    },
    "e20e1fa5572ac7830313ea4beebdfe05": {
      "source_id": "e20e1fa5572ac7830313ea4beebdfe05",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 334,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Does iterated amplification tackle the inner alignment problem?"
    },
    "72acecc68cc06340b5250ed600f35250": {
      "source_id": "72acecc68cc06340b5250ed600f35250",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4264,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Reference Post: Trivial Decision Theory Problem"
    },
    "fa3ffe0f4ae0f4ee801980a4d1ebe431": {
      "source_id": "fa3ffe0f4ae0f4ee801980a4d1ebe431",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7987,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "On the falsifiability of hypercomputation, part 2: finite input streams"
    },
    "8f1f2796d06d9082b030ec84d8573653": {
      "source_id": "8f1f2796d06d9082b030ec84d8573653",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23349,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Wireheading and discontinuity"
    },
    "357f5cf4c652cbd0ae4b05060e93c280": {
      "source_id": "357f5cf4c652cbd0ae4b05060e93c280",
      "quality_score": 2.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 9985,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #87]:\u00a0What might happen as deep learning scales even further?"
    },
    "cf228da698105ab8a3c21a4687058488": {
      "source_id": "cf228da698105ab8a3c21a4687058488",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11394,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "On unfixably unsafe AGI architectures"
    },
    "5b2d7f9140de1627cac37fad1a0916be": {
      "source_id": "5b2d7f9140de1627cac37fad1a0916be",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21100,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Tessellating Hills: a toy model for demons in imperfect search"
    },
    "f35fcc7b111a920f909afb7ed6fc4f34": {
      "source_id": "f35fcc7b111a920f909afb7ed6fc4f34",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6096,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Goal-directed = Model-based RL?"
    },
    "8fdd0974c5f0ac8e9c8ddf70c44708eb": {
      "source_id": "8fdd0974c5f0ac8e9c8ddf70c44708eb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 60900,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Will AI undergo discontinuous progress?"
    },
    "1e6bf1ec08c06fe0f30b7cd8300beedd": {
      "source_id": "1e6bf1ec08c06fe0f30b7cd8300beedd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38606,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Attainable Utility Preservation: Empirical Results"
    },
    "c9329ce90c9551dae66f53fdfb9f2308": {
      "source_id": "c9329ce90c9551dae66f53fdfb9f2308",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 60876,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "How Low Should Fruit Hang Before We Pick It?"
    },
    "fe22308d33e2b05dfbb95081557f1810": {
      "source_id": "fe22308d33e2b05dfbb95081557f1810",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11614,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "If I were a well-intentioned AI... I: Image classifier"
    },
    "1dc23697da05da4a64b11a447a32f731": {
      "source_id": "1dc23697da05da4a64b11a447a32f731",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19857,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #88]: How the principal-agent literature relates to AI risk"
    },
    "6320bde3a6b60c7ea12a73a393ceabbf": {
      "source_id": "6320bde3a6b60c7ea12a73a393ceabbf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23120,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "If I were a well-intentioned AI... II: Acting in a world"
    },
    "3ed02eb5d609ffd970cf04eff457a6ea": {
      "source_id": "3ed02eb5d609ffd970cf04eff457a6ea",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27438,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Reasons for Excitement about Impact of Impact Measure Research"
    },
    "d32b2cc700b53f601a9d70bd7cca7c43": {
      "source_id": "d32b2cc700b53f601a9d70bd7cca7c43",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6452,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Conclusion to 'Reframing Impact'"
    },
    "0e12ffc390229a854e67cbe8746d86fd": {
      "source_id": "0e12ffc390229a854e67cbe8746d86fd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16287,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Trace: Goals and Principles"
    },
    "31792fa82be3420012df269233296583": {
      "source_id": "31792fa82be3420012df269233296583",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21588,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Cort\u00e9s, Pizarro, and Afonso as Precedents for Takeover"
    },
    "1d029130342841184905e9b9ff91b8d9": {
      "source_id": "1d029130342841184905e9b9ff91b8d9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13260,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "An Analytic Perspective on AI Alignment"
    },
    "19852a880661c825e69946ee2e0dd874": {
      "source_id": "19852a880661c825e69946ee2e0dd874",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28798,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "If I were a well-intentioned AI... IV: Mesa-optimising"
    },
    "6c8452562691e8a396bc45de9f4db7ba": {
      "source_id": "6c8452562691e8a396bc45de9f4db7ba",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19955,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Anthropics over-simplified: it's about priors, not updates"
    },
    "280794cc600aa563414a63e9fbb8313e": {
      "source_id": "280794cc600aa563414a63e9fbb8313e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 20307,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #89]: A unifying formalism for preference learning algorithms"
    },
    "964b28072f467b8420dd5b3a6c8994b0": {
      "source_id": "964b28072f467b8420dd5b3a6c8994b0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5062,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Zoom In: An Introduction to Circuits"
    },
    "42bc43e92c830b86f0fb52203047702a": {
      "source_id": "42bc43e92c830b86f0fb52203047702a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 16735,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #90]:\u00a0How search landscapes can contain self-reinforcing feedback loops"
    },
    "8175e731f73e0e6d91e23e3716410952": {
      "source_id": "8175e731f73e0e6d91e23e3716410952",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3160,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What are some exercises for building/generating intuitions about key disagreemen"
    },
    "11fe38781ba058c11631aab6f9effbe4": {
      "source_id": "11fe38781ba058c11631aab6f9effbe4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 84689,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AI Alignment Podcast: On Lethal Autonomous Weapons with Paul Scharre"
    },
    "feb0ab58247cedb8406dcb2cb52787b4": {
      "source_id": "feb0ab58247cedb8406dcb2cb52787b4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22858,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What is Interpretability?"
    },
    "5b1612aa19d40c732bb1be2525eb1748": {
      "source_id": "5b1612aa19d40c732bb1be2525eb1748",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 30217,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #91]:\u00a0Concepts, implementations, problems, and a benchmark for impact measur"
    },
    "fed24f043ccbd4d583bf13a99e64c8d9": {
      "source_id": "fed24f043ccbd4d583bf13a99e64c8d9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9374,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Alignment as Translation"
    },
    "f61bfa282f241f7deaaa2314f1aa5465": {
      "source_id": "f61bfa282f241f7deaaa2314f1aa5465",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45151,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Thinking About Filtered Evidence Is (Very!) Hard"
    },
    "00afed09943bf665600df641c409aa99": {
      "source_id": "00afed09943bf665600df641c409aa99",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1261,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[Meta] Do you want AIS Webinars?"
    },
    "28c9f38b43807c65faacb81d91c7af64": {
      "source_id": "28c9f38b43807c65faacb81d91c7af64",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7838,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Deconfusing Human Values Research Agenda v1"
    },
    "e695f16ba4a318059f6b28a079386c2d": {
      "source_id": "e695f16ba4a318059f6b28a079386c2d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 20287,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #92]:\u00a0Learning good representations with contrastive predictive coding"
    },
    "86e4991caf1e071a19d116701d99e706": {
      "source_id": "86e4991caf1e071a19d116701d99e706",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3215,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "How important are MDPs for AGI (Safety)?"
    },
    "9fbfa00d56e32f5f8177ca539b457e2b": {
      "source_id": "9fbfa00d56e32f5f8177ca539b457e2b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1159,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What are the most plausible \"AI Safety warning shot\" scenarios?"
    },
    "37c4653c6f89b70db20d6a5e4112aa31": {
      "source_id": "37c4653c6f89b70db20d6a5e4112aa31",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6338,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "My current framework for thinking about AGI timelines"
    },
    "9843ed3236fb5278a20910ae63e586c5": {
      "source_id": "9843ed3236fb5278a20910ae63e586c5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11029,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Three Kinds of Competitiveness"
    },
    "98bb204c7519335b04fc9289bfba191e": {
      "source_id": "98bb204c7519335b04fc9289bfba191e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15938,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "How special are human brains among animal brains?"
    },
    "80a73329506f56145c0f5a171e2e7a66": {
      "source_id": "80a73329506f56145c0f5a171e2e7a66",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 15090,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #93]:\u00a0The Precipice we\u2019re standing at, and how we can back away from it"
    },
    "f1aec2e3cc5a4b07321c2a45c735f5ff": {
      "source_id": "f1aec2e3cc5a4b07321c2a45c735f5ff",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19855,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Equilibrium and prior selection problems in multipolar deployment"
    },
    "488aa02e04bf12da25338c4c2309559e": {
      "source_id": "488aa02e04bf12da25338c4c2309559e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2125,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Announcing Web-TAISU, May 13-17"
    },
    "69f2bdac8e378f7331cff97f6421dd17": {
      "source_id": "69f2bdac8e378f7331cff97f6421dd17",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23634,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Resources for AI Alignment Cartography"
    },
    "611d65026a0d4b076083d092fa1c6746": {
      "source_id": "611d65026a0d4b076083d092fa1c6746",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34326,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "An Orthodox Case Against Utility Functions"
    },
    "2c39d75c7c6ecbd5e8582857b2ae772b": {
      "source_id": "2c39d75c7c6ecbd5e8582857b2ae772b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 15917,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #94]:\u00a0AI alignment as translation between humans and machines"
    },
    "874c8d89116387687b98104a4bf32305": {
      "source_id": "874c8d89116387687b98104a4bf32305",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20810,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Asymptotically Unambitious AGI"
    },
    "eb1ad3f15a8260a93b2330ea1f1d30f4": {
      "source_id": "eb1ad3f15a8260a93b2330ea1f1d30f4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22080,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "\"How conservative\" should the partial maximisers be?"
    },
    "1b0f1c1c51b7f0cdd9e0508840ec0f47": {
      "source_id": "1b0f1c1c51b7f0cdd9e0508840ec0f47",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 23244,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #95]: A framework for thinking about how to make AI go well"
    },
    "f470eb8b93f5a70cc394dc7aa1eca638": {
      "source_id": "f470eb8b93f5a70cc394dc7aa1eca638",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 155599,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AI Alignment Podcast: An Overview of Technical AI Alignment in 2018 and 2019 wit"
    },
    "20c7c73eb778b27e90cde12f4b6e9406": {
      "source_id": "20c7c73eb778b27e90cde12f4b6e9406",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7972,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AI Services as a Research Paradigm"
    },
    "1833daf1121085b5c132cf17946840ff": {
      "source_id": "1833daf1121085b5c132cf17946840ff",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32731,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Inner alignment in the brain"
    },
    "9fdb067a24041dc6f97335645bb148e1": {
      "source_id": "9fdb067a24041dc6f97335645bb148e1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 22200,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #96]: Buck and I discuss/argue about AI Alignment"
    },
    "222dfa0bcba6391e272ae3527a389e2d": {
      "source_id": "222dfa0bcba6391e272ae3527a389e2d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31560,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Problem relaxation as a tactic"
    },
    "b13455d69d0bb44243dc36b15b70499e": {
      "source_id": "b13455d69d0bb44243dc36b15b70499e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6260,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What makes counterfactuals comparable?"
    },
    "b11a47358c570e115e3ea1cd7fe52a32": {
      "source_id": "b11a47358c570e115e3ea1cd7fe52a32",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 21632,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #97]: Are there historical examples of large, robust discontinuities?"
    },
    "08cf4306f9a54736aa7a6e84da3e2442": {
      "source_id": "08cf4306f9a54736aa7a6e84da3e2442",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 516,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What is the alternative to intent alignment called?"
    },
    "7f4ecef8e113f9e47a9e1d7b9b7cbbbd": {
      "source_id": "7f4ecef8e113f9e47a9e1d7b9b7cbbbd",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7326,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Topological metaphysics: relating point-set topology and locale theory"
    },
    "b6dd472a6a05288540c51e8fa3663ae1": {
      "source_id": "b6dd472a6a05288540c51e8fa3663ae1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20748,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "How does iterated amplification exceed human abilities?"
    },
    "78004975cbfbb7e3011dc48a557a833c": {
      "source_id": "78004975cbfbb7e3011dc48a557a833c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25514,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "How uniform is the neocortex?"
    },
    "cef4b7a1811e1a9322c48c45b91bfaaa": {
      "source_id": "cef4b7a1811e1a9322c48c45b91bfaaa",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8544,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Competitive safety via gradated curricula"
    },
    "2a3545fc9f4358c0bb0d453bd73ac36a": {
      "source_id": "2a3545fc9f4358c0bb0d453bd73ac36a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19425,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #98]:\u00a0Understanding neural net training by seeing which gradients were helpf"
    },
    "054a2bfba124eaa8b99f725fe094e4e2": {
      "source_id": "054a2bfba124eaa8b99f725fe094e4e2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14194,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Specification gaming: the flip side of AI ingenuity"
    },
    "3d6e175d6dc8a3f548fc0bff06451c50": {
      "source_id": "3d6e175d6dc8a3f548fc0bff06451c50",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25109,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Corrigibility as outside view"
    },
    "17c2cd4f5354b5650609538b2cbbf91f": {
      "source_id": "17c2cd4f5354b5650609538b2cbbf91f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 21874,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #99]: Doubling times for the efficiency of AI algorithms"
    },
    "1e303dc03ac09398034d3b36c30b7ad1": {
      "source_id": "1e303dc03ac09398034d3b36c30b7ad1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10681,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Multi-agent safety"
    },
    "78d27b7ee103d2ce383cad67d6ba1593": {
      "source_id": "78d27b7ee103d2ce383cad67d6ba1593",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2453,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "The Mechanistic and Normative Structure of Agency"
    },
    "37442e305ca529131dd395332c6bd682": {
      "source_id": "37442e305ca529131dd395332c6bd682",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20729,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Probabilities, weights, sums: pretty much the same for reward functions"
    },
    "7fa4aa440cfda677dc8f2ea7e292181d": {
      "source_id": "7fa4aa440cfda677dc8f2ea7e292181d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 26638,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #100]:\u00a0What might go wrong if you learn a reward function while acting"
    },
    "5353b9246380daef8df2f10d6b5acc6b": {
      "source_id": "5353b9246380daef8df2f10d6b5acc6b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8377,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AGIs as collectives"
    },
    "b59381f21edb033c240e8dcdd53459cc": {
      "source_id": "b59381f21edb033c240e8dcdd53459cc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18323,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "How can Interpretability help Alignment?"
    },
    "65926377e9a903ef5f59488b3b048eba": {
      "source_id": "65926377e9a903ef5f59488b3b048eba",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4939,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AI Safety Discussion Days"
    },
    "ca77dbe5de5abefea271249213cc2468": {
      "source_id": "ca77dbe5de5abefea271249213cc2468",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 22044,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #101]: Why we should rigorously measure and forecast AI progress"
    },
    "38810ad3c8e80a6e1ce2d641de7025a2": {
      "source_id": "38810ad3c8e80a6e1ce2d641de7025a2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 102905,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "An overview of 11 proposals for building safe advanced AI"
    },
    "b0eaa3c757c8ad35d7fb51939d0a797a": {
      "source_id": "b0eaa3c757c8ad35d7fb51939d0a797a",
      "quality_score": 2.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 5972,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Possible takeaways from the coronavirus pandemic for slow AI takeoff"
    },
    "fdc33ef63f2ec976c779804c0eed1953": {
      "source_id": "fdc33ef63f2ec976c779804c0eed1953",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33501,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Sparsity and interpretability?"
    },
    "bd82c86a3ddc5d2c57f44c7ee1fb1fbb": {
      "source_id": "bd82c86a3ddc5d2c57f44c7ee1fb1fbb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15659,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Building brain-inspired AGI is infinitely easier than understanding the brain"
    },
    "bf8cec9afcdccae75e358cfdfad2a030": {
      "source_id": "bf8cec9afcdccae75e358cfdfad2a030",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26960,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Inaccessible information"
    },
    "377dc467f1f90736f71973dd7b4d7b7e": {
      "source_id": "377dc467f1f90736f71973dd7b4d7b7e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 21299,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #102]: Meta learning by GPT-3, and a list of full proposals for AI alignment"
    },
    "64f18b0e78cea4e5f0c65aca85b92b7b": {
      "source_id": "64f18b0e78cea4e5f0c65aca85b92b7b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23681,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Focus: you are allowed to be bad at accomplishing your goals"
    },
    "9a640eb49f1ce8b8d99bafb278daa3ae": {
      "source_id": "9a640eb49f1ce8b8d99bafb278daa3ae",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10229,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Reply to Paul Christiano on Inaccessible Information"
    },
    "82a566fcda3ff489af622f65830471a3": {
      "source_id": "82a566fcda3ff489af622f65830471a3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4899,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Goal-directedness is behavioral, not structural"
    },
    "539f0ed1ff9a51ea55d8c0707f51ae24": {
      "source_id": "539f0ed1ff9a51ea55d8c0707f51ae24",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5591,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "More on disambiguating \"discontinuity\""
    },
    "caa2320f0ecc635364ead0d1df8ac0a8": {
      "source_id": "caa2320f0ecc635364ead0d1df8ac0a8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 20566,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #103]: ARCHES: an agenda for existential safety, and combining natural langu"
    },
    "e0fd79d4a9a86f30b03cb276e79d1c8a": {
      "source_id": "e0fd79d4a9a86f30b03cb276e79d1c8a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5343,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Preparing for \"The Talk\" with AI projects"
    },
    "6d6258c34650b451a2ac0bde59cb5a28": {
      "source_id": "6d6258c34650b451a2ac0bde59cb5a28",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 666,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What are the high-level approaches to AI alignment?"
    },
    "b5f7947171ec8bb3c3b53d070837ca1b": {
      "source_id": "b5f7947171ec8bb3c3b53d070837ca1b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8863,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Relating HCH and Logical Induction"
    },
    "f86b8bcf435a7d0fa4be4bb882e9bf7e": {
      "source_id": "f86b8bcf435a7d0fa4be4bb882e9bf7e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 17226,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #104]: The perils of inaccessible information, and what we can learn about A"
    },
    "1fba8f9379efcd3a147c067c9f0b497a": {
      "source_id": "1fba8f9379efcd3a147c067c9f0b497a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 68081,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "The ground of optimization"
    },
    "bd1df714a76db50397e322bd22e254ac": {
      "source_id": "bd1df714a76db50397e322bd22e254ac",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43228,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Relevant pre-AGI possibilities"
    },
    "9596d03efbeb1ca974a577ebe55a5113": {
      "source_id": "9596d03efbeb1ca974a577ebe55a5113",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21263,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Plausible cases for HRAD work, and locating the crux in the \"realism about ratio"
    },
    "243c980b03ba06f0f2adfab0722c786d": {
      "source_id": "243c980b03ba06f0f2adfab0722c786d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10904,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Locality of goals"
    },
    "9401ac7353242872956034997e42d391": {
      "source_id": "9401ac7353242872956034997e42d391",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31328,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Modelling Continuous Progress"
    },
    "9ec0d4ce85f41c0d6ebb644d36da8552": {
      "source_id": "9ec0d4ce85f41c0d6ebb644d36da8552",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 23090,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #105]: The economic trajectory of humanity, and what we might mean by optimi"
    },
    "94b4f8e448015aa0815f7a9790d87371": {
      "source_id": "94b4f8e448015aa0815f7a9790d87371",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41151,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AI safety via market making"
    },
    "86f5dac406d33bfa6ddef2a92b12f6e7": {
      "source_id": "86f5dac406d33bfa6ddef2a92b12f6e7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5419,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AI Benefits Post 2: How AI Benefits Differs from AI Alignment & AI for Good"
    },
    "edbb18a4efb9aeccd82015496d86c45d": {
      "source_id": "edbb18a4efb9aeccd82015496d86c45d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4917,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Web AI discussion Groups"
    },
    "31136813627eb1d939efcc77051cdfd6": {
      "source_id": "31136813627eb1d939efcc77051cdfd6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17292,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Comparing AI Alignment Approaches to Minimize False Positive Risk"
    },
    "30f02f903c57567b1bde9bb89f769f2a": {
      "source_id": "30f02f903c57567b1bde9bb89f769f2a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 25004,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #106]: Evaluating generalization ability of learned reward models"
    },
    "7ec2e6e63be53f18a3902e96eff6e065": {
      "source_id": "7ec2e6e63be53f18a3902e96eff6e065",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 118507,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Evan Hubinger on Inner Alignment, Outer Alignment, and Proposals for Building Sa"
    },
    "b955993f8d4043d413f88a2f0c76c49d": {
      "source_id": "b955993f8d4043d413f88a2f0c76c49d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22129,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "The \"AI Debate\" Debate"
    },
    "ef5dc0ed98201db14360813aa72b90e2": {
      "source_id": "ef5dc0ed98201db14360813aa72b90e2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28414,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Goals and short descriptions"
    },
    "ebec4adfb87b9a342e7d859bc4c29664": {
      "source_id": "ebec4adfb87b9a342e7d859bc4c29664",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26428,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AI Unsafety via Non-Zero-Sum Debate"
    },
    "0a108e3716c05b10c1c8198a78cf0254": {
      "source_id": "0a108e3716c05b10c1c8198a78cf0254",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 26962,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Tradeoff between desirable properties for baseline choices in impact measures"
    },
    "1f311769994542a761294f964fee6296": {
      "source_id": "1f311769994542a761294f964fee6296",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14459,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Learning the prior"
    },
    "bb8470d58ae94012ae2cdcd60c73681b": {
      "source_id": "bb8470d58ae94012ae2cdcd60c73681b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10673,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Better priors as a safety problem"
    },
    "274cab22734060305c3bf2979fc58078": {
      "source_id": "274cab22734060305c3bf2979fc58078",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33803,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What does it mean to apply decision theory?"
    },
    "6e4ffaa1bfba7a4d0d7a0f1f22e70495": {
      "source_id": "6e4ffaa1bfba7a4d0d7a0f1f22e70495",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 352,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AI Research Considerations for Human Existential Safety (ARCHES)"
    },
    "73349bffd4c48a64bbec60a74268e288": {
      "source_id": "73349bffd4c48a64bbec60a74268e288",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40959,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Arguments against myopic training"
    },
    "d256e899047dd41c23a74011f2c4fcff": {
      "source_id": "d256e899047dd41c23a74011f2c4fcff",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16875,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Mesa-Optimizers vs \u201cSteered Optimizers\u201d"
    },
    "f0df039e92dca764927cf373498576b7": {
      "source_id": "f0df039e92dca764927cf373498576b7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7557,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "A space of proposals for building safe advanced AI"
    },
    "b1e1a87b35a3e91c225d45157af01c47": {
      "source_id": "b1e1a87b35a3e91c225d45157af01c47",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1722,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Talk: Key Issues In Near-Term AI Safety Research"
    },
    "cfc3c1348365437bfafbbb3c8a7fb598": {
      "source_id": "cfc3c1348365437bfafbbb3c8a7fb598",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30753,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "New paper: AGI Agent Safety by Iteratively Improving the Utility Function"
    },
    "4d40ca113ad949784c04131aa079916d": {
      "source_id": "4d40ca113ad949784c04131aa079916d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28243,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "How should AI debate be judged?"
    },
    "cab116a8a15ba8f5b9fac5a62cc05e0b": {
      "source_id": "cab116a8a15ba8f5b9fac5a62cc05e0b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41275,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Alignment proposals and complexity classes"
    },
    "00671cab97bcd7dc6d8d6388c6980cc7": {
      "source_id": "00671cab97bcd7dc6d8d6388c6980cc7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 25794,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #108]:\u00a0Why we should scrutinize arguments for AI risk"
    },
    "eda7d8f54688ad21b3adb39954310d11": {
      "source_id": "eda7d8f54688ad21b3adb39954310d11",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 16564,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #107]: The convergent instrumental subgoals of goal-directed agents"
    },
    "6ad942c687ee89f4707fb91a365dce6f": {
      "source_id": "6ad942c687ee89f4707fb91a365dce6f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11529,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Environments as a bottleneck in AGI development"
    },
    "a88f6548ef36b2642bc39698f935c8fd": {
      "source_id": "a88f6548ef36b2642bc39698f935c8fd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22637,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Why is pseudo-alignment \"worse\" than other ways ML can fail to generalize?"
    },
    "ea4ecdc23d987ddcf7ea813e6b3565ab": {
      "source_id": "ea4ecdc23d987ddcf7ea813e6b3565ab",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28008,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "To what extent is GPT-3 capable of reasoning?"
    },
    "243d1bb3a061ff6fc769f961578474a5": {
      "source_id": "243d1bb3a061ff6fc769f961578474a5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4142,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Parallels Between AI Safety by Debate and Evidence Law"
    },
    "5b14f2cbab716045587c60fab3fe7455": {
      "source_id": "5b14f2cbab716045587c60fab3fe7455",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3784,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "$1000 bounty for OpenAI to show whether GPT3 was \"deliberately\" pretending to be"
    },
    "998a27a2d7825463fa6ef4435adc737e": {
      "source_id": "998a27a2d7825463fa6ef4435adc737e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6759,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Alignment As A Bottleneck To Usefulness Of GPT-3"
    },
    "a95d38424b96a5757be2fc7ac9cde182": {
      "source_id": "a95d38424b96a5757be2fc7ac9cde182",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6582,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Competition: Amplify Rohin\u2019s Prediction on AGI researchers & Safety Concerns"
    },
    "6b1fabd1edc4debcce5b1661544be7a2": {
      "source_id": "6b1fabd1edc4debcce5b1661544be7a2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2577,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[Preprint] The Computational Limits of Deep Learning"
    },
    "14d03ad74b243aea101341c99112c3cc": {
      "source_id": "14d03ad74b243aea101341c99112c3cc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 18970,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #109]:\u00a0Teaching neural nets to generalize the way humans would"
    },
    "89430ad40b04f2d118685766aad396cf": {
      "source_id": "89430ad40b04f2d118685766aad396cf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24710,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Weak HCH accesses EXP"
    },
    "15744a6a4b64c91e38b81955ade5abe2": {
      "source_id": "15744a6a4b64c91e38b81955ade5abe2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24992,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Can you get AGI from a Transformer?"
    },
    "7399d1d32f2b81ac532ae64381abf69d": {
      "source_id": "7399d1d32f2b81ac532ae64381abf69d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20793,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Optimizing arbitrary expressions with a linear number of queries to a Logical In"
    },
    "75e2d1f5cfddf9f3451e3ebfed4ea845": {
      "source_id": "75e2d1f5cfddf9f3451e3ebfed4ea845",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13468,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Developmental Stages of GPTs"
    },
    "3039c46ab771d769ad4eff557849bdb0": {
      "source_id": "3039c46ab771d769ad4eff557849bdb0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2421,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What specific dangers arise when asking GPT-N to write an Alignment Forum post?"
    },
    "195572815c62bd1731c78118e4f841d9": {
      "source_id": "195572815c62bd1731c78118e4f841d9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 22574,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #110]: Learning features from human feedback to enable reward learning"
    },
    "d3a08f4d7c83da61b86ef41c900e2d3f": {
      "source_id": "d3a08f4d7c83da61b86ef41c900e2d3f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13998,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What Failure Looks Like: Distilling the Discussion"
    },
    "a2becb6f07357a2fdf135d0759074fb7": {
      "source_id": "a2becb6f07357a2fdf135d0759074fb7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27061,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Learning the prior and generalization"
    },
    "5ec205c8c57c5642e2b576c774b8f410": {
      "source_id": "5ec205c8c57c5642e2b576c774b8f410",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3433,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What if memes are common in highly capable minds?"
    },
    "ebe3f4e540c8faae7cbd0f405f6c91e4": {
      "source_id": "ebe3f4e540c8faae7cbd0f405f6c91e4",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6404,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "\"Go west, young man!\" - Preferences in (imperfect) maps"
    },
    "408c69497f6bcc998a96b915b3dde9a5": {
      "source_id": "408c69497f6bcc998a96b915b3dde9a5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12369,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Power as Easily Exploitable Opportunities"
    },
    "ab1714c054b6bcc12c66db1a676269bf": {
      "source_id": "ab1714c054b6bcc12c66db1a676269bf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42888,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Inner Alignment: Explain like I'm 12 Edition"
    },
    "9556c2cd2b8d608535b511a487dfb616": {
      "source_id": "9556c2cd2b8d608535b511a487dfb616",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25991,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Three mental images from thinking about AGI debate & corrigibility"
    },
    "911ea940d7222e4065a419356c5aaacb": {
      "source_id": "911ea940d7222e4065a419356c5aaacb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30178,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Interpretability in ML: A Broad Overview"
    },
    "d748b44740bf5984c5a55da97f4ddc13": {
      "source_id": "d748b44740bf5984c5a55da97f4ddc13",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2966,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Infinite Data/Compute Arguments in Alignment"
    },
    "1a6910f4f9def8bcb63b592e794f1205": {
      "source_id": "1a6910f4f9def8bcb63b592e794f1205",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 20502,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #111]:\u00a0The Circuits hypotheses for deep learning"
    },
    "aedea795b548c83e084441b9865d5585": {
      "source_id": "aedea795b548c83e084441b9865d5585",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5972,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "The Fusion Power Generator Scenario"
    },
    "d4ddf68fa8630c0680434c94f8284302": {
      "source_id": "d4ddf68fa8630c0680434c94f8284302",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3855,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Book review: Architects of Intelligence by Martin Ford (2018)"
    },
    "eded43cb436b92fea0be5f36a253ee10": {
      "source_id": "eded43cb436b92fea0be5f36a253ee10",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2063,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Will OpenAI's work unintentionally increase existential risks related to AI?"
    },
    "235c3f54728bcf889ea1956d237e5d81": {
      "source_id": "235c3f54728bcf889ea1956d237e5d81",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11106,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Matt Botvinick on the spontaneous emergence of learning algorithms"
    },
    "4b0cd1fcc2e00bac11f81569d8cb9536": {
      "source_id": "4b0cd1fcc2e00bac11f81569d8cb9536",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22907,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Alignment By Default"
    },
    "547ae7c5b784a3c76708d9efed151351": {
      "source_id": "547ae7c5b784a3c76708d9efed151351",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9954,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Blog post: A tale of two research communities"
    },
    "531b319d81d697c2336282e9e7d5ff34": {
      "source_id": "531b319d81d697c2336282e9e7d5ff34",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 23139,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #112]: Engineering a Safer World"
    },
    "73d81a2cfd48b26a8914a460f045e27a": {
      "source_id": "73d81a2cfd48b26a8914a460f045e27a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27060,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Mapping Out Alignment"
    },
    "3ea19d8d03e8fb9c2d00d9f2f66e1f2b": {
      "source_id": "3ea19d8d03e8fb9c2d00d9f2f66e1f2b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 79678,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "My Understanding of Paul Christiano's Iterated Amplification AI Safety Research "
    },
    "4df3f0b3f13dc5cf8372b640a1656e0d": {
      "source_id": "4df3f0b3f13dc5cf8372b640a1656e0d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 68973,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Search versus design"
    },
    "2e36f187f3768db3793cf6338a8eba66": {
      "source_id": "2e36f187f3768db3793cf6338a8eba66",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4320,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Goal-Directedness: What Success Looks Like"
    },
    "e71224864e3fa91958070604ac078d7b": {
      "source_id": "e71224864e3fa91958070604ac078d7b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14190,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Mesa-Search vs Mesa-Control"
    },
    "3e912ec166c473e1b1006dfebe51e167": {
      "source_id": "3e912ec166c473e1b1006dfebe51e167",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 89059,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Radical Probabilism"
    },
    "1b9f4e416a1fb1748738da9de33fcc6a": {
      "source_id": "1b9f4e416a1fb1748738da9de33fcc6a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2823,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Looking for adversarial collaborators to test our Debate protocol"
    },
    "e9bab64f635d60c2cf1f54870047fcd2": {
      "source_id": "e9bab64f635d60c2cf1f54870047fcd2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2177,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AI safety as featherless bipeds *with broad flat nails*"
    },
    "cc13c491df98d2f704c4da60346a3189": {
      "source_id": "cc13c491df98d2f704c4da60346a3189",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 20071,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #113]: Checking the ethical intuitions of large language models"
    },
    "bdf2997a9edf9a6e708d54497c6c5b45": {
      "source_id": "bdf2997a9edf9a6e708d54497c6c5b45",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53915,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Universality Unwrapped"
    },
    "e405b0b0b5a30bdca4dc0aee252108dc": {
      "source_id": "e405b0b0b5a30bdca4dc0aee252108dc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 958,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What's a Decomposable Alignment Topic?"
    },
    "0b1b2bbe014c110d815d3d5fc5defba7": {
      "source_id": "0b1b2bbe014c110d815d3d5fc5defba7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 18553,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #114]: Theory-inspired safety solutions for powerful Bayesian RL agents"
    },
    "fbc330c9e00692fee954bd0716f3d022": {
      "source_id": "fbc330c9e00692fee954bd0716f3d022",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45496,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Introduction To The Infra-Bayesianism Sequence"
    },
    "38bdc87ccf314b393325bbd664861485": {
      "source_id": "38bdc87ccf314b393325bbd664861485",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 90852,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Proofs Section 2.3 (Updates, Decision Theory)"
    },
    "c07536d81bf22e0269868b92c5b7c527": {
      "source_id": "c07536d81bf22e0269868b92c5b7c527",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 125789,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Proofs Section 2.2 (Isomorphism to Expectations)"
    },
    "1bbd93ee3efe91f6102e5b733a6131e5": {
      "source_id": "1bbd93ee3efe91f6102e5b733a6131e5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 99146,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Proofs Section 2.1 (Theorem 1, Lemmas)"
    },
    "0cd8e518ee1e021b3ad88495852750e5": {
      "source_id": "0cd8e518ee1e021b3ad88495852750e5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55520,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Proofs Section 1.2 (Mixtures, Updates, Pushforwards)"
    },
    "bbf116d56f31343af7f1cf4302cc2b31": {
      "source_id": "bbf116d56f31343af7f1cf4302cc2b31",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 67747,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Proofs Section 1.1 (Initial results to LF-duality)"
    },
    "1bd4645765b4f159cfab88fd7d937c18": {
      "source_id": "1bd4645765b4f159cfab88fd7d937c18",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 101740,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Belief Functions And Decision Theory"
    },
    "deb31b3e66f91751c6cc2aecf0e5e147": {
      "source_id": "deb31b3e66f91751c6cc2aecf0e5e147",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73223,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Basic Inframeasure Theory"
    },
    "61ecb19b4c26b6c11d71ca37828514f6": {
      "source_id": "61ecb19b4c26b6c11d71ca37828514f6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 90552,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Model splintering: moving from one imperfect model to another"
    },
    "12181b452dd5dda051c6f841d917133c": {
      "source_id": "12181b452dd5dda051c6f841d917133c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23740,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Updates and additions to \"Embedded Agency\""
    },
    "8d3e422a605509acccbf51018a004c05": {
      "source_id": "8d3e422a605509acccbf51018a004c05",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3013,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Safe Scrambling?"
    },
    "d4d490e8363e47eabea2188c3dfad3ce": {
      "source_id": "d4d490e8363e47eabea2188c3dfad3ce",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20566,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "interpreting GPT: the logit lens"
    },
    "ae9c97ec80809e1be38e17c39be8b397": {
      "source_id": "ae9c97ec80809e1be38e17c39be8b397",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 15713,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #115]:\u00a0AI safety research problems in the AI-GA framework"
    },
    "99c56a863b9ad14b02538ded7876da47": {
      "source_id": "99c56a863b9ad14b02538ded7876da47",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5078,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Using GPT-N to Solve Interpretability of Neural Networks: A Research Agenda"
    },
    "120607fb810a0bf6c4229b48e2ed3598": {
      "source_id": "120607fb810a0bf6c4229b48e2ed3598",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 21028,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #116]: How to make explanations of neurons compositional"
    },
    "33c52573ac6821eca8a901dc3dbfde1f": {
      "source_id": "33c52573ac6821eca8a901dc3dbfde1f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8394,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Safer sandboxing via collective separation"
    },
    "56c393054dfcec52d9aec5c7e5d5174a": {
      "source_id": "56c393054dfcec52d9aec5c7e5d5174a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10529,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Safety via selection for obedience"
    },
    "9c7af1fb8611ec2b5a70696bfd7f203e": {
      "source_id": "9c7af1fb8611ec2b5a70696bfd7f203e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 801,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Do mesa-optimizer risk arguments rely on the train-test paradigm?"
    },
    "eeedd8f780c03709c4adee52502f7866": {
      "source_id": "eeedd8f780c03709c4adee52502f7866",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33394,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Decision Theory is multifaceted"
    },
    "1621cb4e50ec4e73f7204a809cfc804f": {
      "source_id": "1621cb4e50ec4e73f7204a809cfc804f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29223,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "My computational framework for the brain"
    },
    "f585815cc42a9b4a7b5edcb301b85547": {
      "source_id": "f585815cc42a9b4a7b5edcb301b85547",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52086,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Comparing Utilities"
    },
    "0e82ad20b0f9151658fc12f7ce269d87": {
      "source_id": "0e82ad20b0f9151658fc12f7ce269d87",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 15493,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #117]:\u00a0How neural nets would fare under the TEVV framework"
    },
    "96fa84c21cf9e2283c79f3b352e06795": {
      "source_id": "96fa84c21cf9e2283c79f3b352e06795",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4612,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "The \"Backchaining to Local Search\" Technique in AI Alignment"
    },
    "816e3ccc4edb61759b2343556d4dd31d": {
      "source_id": "816e3ccc4edb61759b2343556d4dd31d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17557,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Why GPT wants to mesa-optimize & how we might change this"
    },
    "84a0970145fc4e9f968303a0944e8639": {
      "source_id": "84a0970145fc4e9f968303a0944e8639",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36588,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Clarifying \u201cWhat failure looks like\u201d"
    },
    "8754c8c4b0c4e0c939e72863c7945b46": {
      "source_id": "8754c8c4b0c4e0c939e72863c7945b46",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3375,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Needed: AI infohazard policy"
    },
    "e89387e438793c89e2d9573e6fa73df8": {
      "source_id": "e89387e438793c89e2d9573e6fa73df8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 22668,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #118]:\u00a0Risks, solutions, and prioritization in a world with many AI systems"
    },
    "3f04bdb019d6d47050f250f1d0118384": {
      "source_id": "3f04bdb019d6d47050f250f1d0118384",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1617,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What to do with imitation humans, other than asking them what the right thing to"
    },
    "4035e6cb5eae10b8ef4285dbab4ec35d": {
      "source_id": "4035e6cb5eae10b8ef4285dbab4ec35d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3952,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AGI safety from first principles: Introduction"
    },
    "c1e75b4916e38413baa380a4658a79c9": {
      "source_id": "c1e75b4916e38413baa380a4658a79c9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18546,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AGI safety from first principles: Superintelligence"
    },
    "586ad764714021217d2fd52286c16ae4": {
      "source_id": "586ad764714021217d2fd52286c16ae4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29657,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AGI safety from first principles: Goals and Agency"
    },
    "ad9b15522e32e47f7002343176feb549": {
      "source_id": "ad9b15522e32e47f7002343176feb549",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7290,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "\u201cUnsupervised\u201d translation as an (intent) alignment problem"
    },
    "8e603cbb72cfb5b1580e32ad59848436": {
      "source_id": "8e603cbb72cfb5b1580e32ad59848436",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 24268,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #119]:\u00a0AI safety when agents are shaped by environments, not rewards"
    },
    "94037099323462591961ea92e261a193": {
      "source_id": "94037099323462591961ea92e261a193",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25702,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AGI safety from first principles: Alignment"
    },
    "c1dc9d644bd3109c1815c3cf9a857a03": {
      "source_id": "c1dc9d644bd3109c1815c3cf9a857a03",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5623,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Hiring engineers and researchers to help align GPT-3"
    },
    "755992d5694791e0785a1ac4990b0f51": {
      "source_id": "755992d5694791e0785a1ac4990b0f51",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17621,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AGI safety from first principles: Control"
    },
    "1f1b838aec949ee45b56ba586fc8d781": {
      "source_id": "1f1b838aec949ee45b56ba586fc8d781",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5782,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AGI safety from first principles: Conclusion"
    },
    "68d43711c83b257276d5d3878846c676": {
      "source_id": "68d43711c83b257276d5d3878846c676",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 12197,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "The Alignment Problem: Machine Learning and Human Values"
    },
    "ef4eaa981e7a520128482c0519330acd": {
      "source_id": "ef4eaa981e7a520128482c0519330acd",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 21764,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #120]:\u00a0Tracing the intellectual roots of AI and AI alignment"
    },
    "1d5f3a2f13120789f94e08d13966ec0c": {
      "source_id": "1d5f3a2f13120789f94e08d13966ec0c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3925,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Toy Problem: Detective Story Alignment"
    },
    "da165e67a0885e279cbdffe0ec49e0f7": {
      "source_id": "da165e67a0885e279cbdffe0ec49e0f7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51838,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "The Solomonoff Prior is Malign"
    },
    "59fc00ba17bc6f7f0701096d1abba058": {
      "source_id": "59fc00ba17bc6f7f0701096d1abba058",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 27743,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #121]:\u00a0Forecasting transformative AI timelines using biological anchors"
    },
    "0e33754ca220361a23506be6a2760647": {
      "source_id": "0e33754ca220361a23506be6a2760647",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6458,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Box inversion hypothesis"
    },
    "1064f4c92924f57c1008c27be21b2994": {
      "source_id": "1064f4c92924f57c1008c27be21b2994",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 18121,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #122]:\u00a0Arguing for AGI-driven existential risk from first principles"
    },
    "f9ea65c11456eb5ca289e979f44ffb09": {
      "source_id": "f9ea65c11456eb5ca289e979f44ffb09",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4426,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "The date of AI Takeover is not the day the AI takes over"
    },
    "7cb2522efada9b895776c3e611464aa4": {
      "source_id": "7cb2522efada9b895776c3e611464aa4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61996,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Introduction to Cartesian Frames"
    },
    "1e94de601c5cf7f1d71cb7841e7609c9": {
      "source_id": "1e94de601c5cf7f1d71cb7841e7609c9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9773,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Reply to Jebari and Lundborg on Artificial Superintelligence"
    },
    "f62880c2461cb785f3b06fe908e4aefe": {
      "source_id": "f62880c2461cb785f3b06fe908e4aefe",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22114,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Supervised learning of outputs in the brain"
    },
    "fdde67d0d9ffcd07b96faf0208009546": {
      "source_id": "fdde67d0d9ffcd07b96faf0208009546",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37797,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "A Correspondence Theorem"
    },
    "92741a9531f7cfe05b61b18bec7236bd": {
      "source_id": "92741a9531f7cfe05b61b18bec7236bd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14830,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Security Mindset and Takeoff Speeds"
    },
    "79bad74b007f523f159dd07cc0bb62ee": {
      "source_id": "79bad74b007f523f159dd07cc0bb62ee",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48246,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Dutch-Booking CDT: Revised Argument"
    },
    "3eb10d91e041fbf6332bffaac9d2a164": {
      "source_id": "3eb10d91e041fbf6332bffaac9d2a164",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1815,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Draft papers for REALab and Decoupled Approval on tampering"
    },
    "2dad9d2285cd61ec8464550a3bff10d3": {
      "source_id": "2dad9d2285cd61ec8464550a3bff10d3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 17982,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #123]:\u00a0Inferring what is valuable in order to align recommender systems"
    },
    "6679bd407056f3c333d7e329937f04f9": {
      "source_id": "6679bd407056f3c333d7e329937f04f9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8258,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AI risk hub in Singapore?"
    },
    "19b1f4bc45b179a8091485150eba4334": {
      "source_id": "19b1f4bc45b179a8091485150eba4334",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27693,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "\"Inner Alignment Failures\" Which Are Actually Outer Alignment Failures"
    },
    "2ddc7951b87609eca1a167876b0e82f7": {
      "source_id": "2ddc7951b87609eca1a167876b0e82f7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11121,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Confucianism in AI Alignment"
    },
    "9cf8d4234b24dbf2abd3956a362846a8": {
      "source_id": "9cf8d4234b24dbf2abd3956a362846a8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34355,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Subagents of Cartesian Frames"
    },
    "5a81b7a59af37a5a5171e0260448c527": {
      "source_id": "5a81b7a59af37a5a5171e0260448c527",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 17808,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #124]:\u00a0Provably safe exploration through shielding"
    },
    "0f20e9f11eb7da650de673bbe285ba38": {
      "source_id": "0f20e9f11eb7da650de673bbe285ba38",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39483,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Defining capability and alignment in gradient descent"
    },
    "b28743e69f3e0612e51fe2ac615adc0e": {
      "source_id": "b28743e69f3e0612e51fe2ac615adc0e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49635,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Does SGD Produce Deceptive Alignment?"
    },
    "dea29a00b6e182dd351c387f57465ece": {
      "source_id": "dea29a00b6e182dd351c387f57465ece",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11796,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "When Hindsight Isn't 20/20: Incentive Design With Imperfect Credit Allocation"
    },
    "baed50b975b7c4edccaad47555f6d4d0": {
      "source_id": "baed50b975b7c4edccaad47555f6d4d0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22992,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Why You Should Care About Goal-Directedness"
    },
    "7d1073e9b49020590224870b11fc925b": {
      "source_id": "7d1073e9b49020590224870b11fc925b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26679,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Clarifying inner alignment terminology"
    },
    "7275dabc5f94cc813ae0c2af6016f5dd": {
      "source_id": "7275dabc5f94cc813ae0c2af6016f5dd",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 20472,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #125]:\u00a0Neural network scaling laws across multiple modalities"
    },
    "82ded0e6629c830915feceafe4f63b1e": {
      "source_id": "82ded0e6629c830915feceafe4f63b1e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55839,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Learning Normativity: A Research Agenda"
    },
    "b0dbef76453306389b9b618bd20c208b": {
      "source_id": "b0dbef76453306389b9b618bd20c208b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29242,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "A Correspondence Theorem in the Maximum Entropy Framework"
    },
    "aaba06c101037ea77610b88225844147": {
      "source_id": "aaba06c101037ea77610b88225844147",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29533,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Communication Prior as Alignment Strategy"
    },
    "4eca850265e6b7304a2361a0ae2eeb63": {
      "source_id": "4eca850265e6b7304a2361a0ae2eeb63",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2871,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Misalignment and misuse: whose values are manifest?"
    },
    "850089265cec10da9ae12e055efff74a": {
      "source_id": "850089265cec10da9ae12e055efff74a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9205,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Early Thoughts on Ontology/Grounding Problems"
    },
    "8e2c8ca81dbde692bab44b1cf646582d": {
      "source_id": "8e2c8ca81dbde692bab44b1cf646582d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48060,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "A guide to Iterated Amplification & Debate"
    },
    "3b805aa388400ce935e2ef8e027d4a95": {
      "source_id": "3b805aa388400ce935e2ef8e027d4a95",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52535,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Normativity"
    },
    "e499ff1de7aded97269b4aefcc7be92a": {
      "source_id": "e499ff1de7aded97269b4aefcc7be92a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37971,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "The Pointers Problem: Human Values Are A Function Of Humans' Latent Variables"
    },
    "4a829d76c2bb606cc440bef9cf72f8dd": {
      "source_id": "4a829d76c2bb606cc440bef9cf72f8dd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22897,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Inner Alignment in Salt-Starved Rats"
    },
    "a4cb5b1ce2fb3771d869769a03030bae": {
      "source_id": "a4cb5b1ce2fb3771d869769a03030bae",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 98059,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Some AI research areas and their relevance to existential safety"
    },
    "e437b7f1e56542b010bf45502b63b1fb": {
      "source_id": "e437b7f1e56542b010bf45502b63b1fb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23078,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Persuasion Tools: AI takeover without AGI or agency?"
    },
    "c0e8954d26e2abdf5e1e850a8f969f85": {
      "source_id": "c0e8954d26e2abdf5e1e850a8f969f85",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57475,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Non-Obstruction: A Simple Concept Motivating Corrigibility"
    },
    "0f5544f649dc97f897085efb6090bfc6": {
      "source_id": "0f5544f649dc97f897085efb6090bfc6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18671,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Continuing the takeoffs debate"
    },
    "dd8421e6a2c91eb4e5384f3bf177ef3a": {
      "source_id": "dd8421e6a2c91eb4e5384f3bf177ef3a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 119551,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Commentary on AGI Safety from First Principles"
    },
    "f267835a15e5ee0edb3a180967d23ae0": {
      "source_id": "f267835a15e5ee0edb3a180967d23ae0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 458,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Critiques of the Agent Foundations agenda?"
    },
    "82f462772ed16082fc79c3ef4ffec863": {
      "source_id": "82f462772ed16082fc79c3ef4ffec863",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 20272,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #126]: Avoiding wireheading by decoupling action feedback from action effect"
    },
    "73798d888d505aa9a36419f8994c267f": {
      "source_id": "73798d888d505aa9a36419f8994c267f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39263,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Idealized Factored Cognition"
    },
    "ff5b2df9e3d7ba91373cbf83ace968a3": {
      "source_id": "ff5b2df9e3d7ba91373cbf83ace968a3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 734,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "In a multipolar scenario, how do people expect systems to be trained to interact"
    },
    "3d8660b5c9a436152df9a944e93701a5": {
      "source_id": "3d8660b5c9a436152df9a944e93701a5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45136,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Recursive Quantilizers II"
    },
    "4f60b180b590254768c1efdc6fc7e115": {
      "source_id": "4f60b180b590254768c1efdc6fc7e115",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 24180,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #127]:\u00a0Rethinking agency: Cartesian frames as a formalization of ways to car"
    },
    "630b2d68a37907181741ee2f56ab8679": {
      "source_id": "630b2d68a37907181741ee2f56ab8679",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8015,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AI Problems Shared by Non-AI Systems"
    },
    "edc6171827b32cf67322d2d1e77f3c9c": {
      "source_id": "edc6171827b32cf67322d2d1e77f3c9c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15788,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Conservatism in neocortex-like AGIs"
    },
    "f56abd059a454b2128cede6a19a3c0a9": {
      "source_id": "f56abd059a454b2128cede6a19a3c0a9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 20929,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #128]:\u00a0Prioritizing research on AI existential safety based on its applicati"
    },
    "522cb2982c20ffb9641d9538d24ed8ab": {
      "source_id": "522cb2982c20ffb9641d9538d24ed8ab",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6466,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Avoiding Side Effects in Complex Environments"
    },
    "4efbd94663eff0d12e0c7f0e05a6a82b": {
      "source_id": "4efbd94663eff0d12e0c7f0e05a6a82b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24479,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Clarifying Factored Cognition"
    },
    "63bb8c02798d5c362f1af9301206662e": {
      "source_id": "63bb8c02798d5c362f1af9301206662e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14970,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Risk Map of AI Systems"
    },
    "afa9224051a4e00e3be6df71303e7007": {
      "source_id": "afa9224051a4e00e3be6df71303e7007",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7905,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Homogeneity vs. heterogeneity in AI takeoff scenarios"
    },
    "8099cfd43448ee1514784b04a045477d": {
      "source_id": "8099cfd43448ee1514784b04a045477d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 147756,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Less Basic Inframeasure Theory"
    },
    "1a468d34b2ceef34a2b203bcd65a24ed": {
      "source_id": "1a468d34b2ceef34a2b203bcd65a24ed",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 15900,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #129]:\u00a0Explaining double descent by measuring bias and variance"
    },
    "e93eef718fe8472c16b2589885c4a9a3": {
      "source_id": "e93eef718fe8472c16b2589885c4a9a3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 68133,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Extrapolating GPT-N performance"
    },
    "95dc03f91373f125dc486a9d67b11997": {
      "source_id": "95dc03f91373f125dc486a9d67b11997",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33757,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Hierarchical planning: context agents"
    },
    "f3515b42aa127138e43cf9b8e3b50472": {
      "source_id": "f3515b42aa127138e43cf9b8e3b50472",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 163839,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "2020 AI Alignment Literature Review and Charity Comparison"
    },
    "a433beae9c2760047372de1041bf5510": {
      "source_id": "a433beae9c2760047372de1041bf5510",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37426,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "TAI Safety Bibliographic Database"
    },
    "1d3becb495f00b9f280be717c8034a8e": {
      "source_id": "1d3becb495f00b9f280be717c8034a8e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32218,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Debate update: Obfuscated arguments problem"
    },
    "048616e5c600aaacc02a1190227b87ab": {
      "source_id": "048616e5c600aaacc02a1190227b87ab",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26395,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "2019 Review Rewrite: Seeking Power is Often Robustly Instrumental in MDPs"
    },
    "5cf6dbe41151b29ea60851b1bebc9379": {
      "source_id": "5cf6dbe41151b29ea60851b1bebc9379",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 652,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Announcing AXRP, the AI X-risk Research Podcast"
    },
    "0c1ff263b04b956749a6ca8746f1d2fe": {
      "source_id": "0c1ff263b04b956749a6ca8746f1d2fe",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 15129,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #130]: A new AI x-risk podcast, and reviews of the field"
    },
    "24c5d8b76ae96be87a7e727d423c1340": {
      "source_id": "24c5d8b76ae96be87a7e727d423c1340",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26316,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Operationalizing compatibility with strategy-stealing"
    },
    "9c543c7b51c910c2e4e89fa5ad731a0a": {
      "source_id": "9c543c7b51c910c2e4e89fa5ad731a0a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18531,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Defusing AGI Danger"
    },
    "6d26d59814ae3682a61fe8e272cdce4c": {
      "source_id": "6d26d59814ae3682a61fe8e272cdce4c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2765,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Why Neural Networks Generalise, and Why They Are (Kind of) Bayesian"
    },
    "3e78c1f93299be8c3466135b986bacf4": {
      "source_id": "3e78c1f93299be8c3466135b986bacf4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28085,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Against GDP as a metric for timelines and takeoff speeds"
    },
    "26d131087cd40fcb93d4f5e7ecbc1c08": {
      "source_id": "26d131087cd40fcb93d4f5e7ecbc1c08",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 60079,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 1 - Adversarial Policies with Adam Gleave"
    },
    "03aead3b05c0aec58462302c1b8f1b70": {
      "source_id": "03aead3b05c0aec58462302c1b8f1b70",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59222,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 2 - Learning Human Biases with Rohin Shah"
    },
    "0c3d18fc7091aa16161707fd417d9843": {
      "source_id": "0c3d18fc7091aa16161707fd417d9843",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48950,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 3 - Negotiable Reinforcement Learning with Andrew Critch"
    },
    "c2c316f306c154be3a5dde3fb3f329a3": {
      "source_id": "c2c316f306c154be3a5dde3fb3f329a3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39616,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Debate Minus Factored Cognition"
    },
    "8b200ee0c90ea41612a217fbda23eed9": {
      "source_id": "8b200ee0c90ea41612a217fbda23eed9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 20900,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[AN #131]: Formalizing the argument of ignored attributes in a utility function"
    },
    "dcff3a5a68bf10290072d2f64fb85f5d": {
      "source_id": "dcff3a5a68bf10290072d2f64fb85f5d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43363,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AI Alignment, Philosophical Pluralism, and the Relevance of Non-Western Philosop"
    },
    "898da267695e9d47e3bd567fc08d0894": {
      "source_id": "898da267695e9d47e3bd567fc08d0894",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11517,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Reflections on Larks\u2019 2020 AI alignment literature review"
    },
    "095c961a75cdab45670ffce10bd24bdc": {
      "source_id": "095c961a75cdab45670ffce10bd24bdc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20076,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Multi-dimensional rewards for AGI interpretability and control"
    },
    "9dcfdc08d29e5ae53672934a654e557a": {
      "source_id": "9dcfdc08d29e5ae53672934a654e557a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53979,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The Pointers Problem: Clarifications/Variations"
    },
    "4219581f5fa93723a2e71ca4eb41cb36": {
      "source_id": "4219581f5fa93723a2e71ca4eb41cb36",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 23503,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #132]:\u00a0Complex and subtly incorrect arguments as an obstacle to debate"
    },
    "e2c9b0267750077252a09ce5e29dcdd3": {
      "source_id": "e2c9b0267750077252a09ce5e29dcdd3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35487,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Review of 'But exactly how complex and fragile?'"
    },
    "3aaa1a501a97ed4c19a0019071b80d0d": {
      "source_id": "3aaa1a501a97ed4c19a0019071b80d0d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9849,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Eight claims about multi-agent AGI safety"
    },
    "77b71b9037cd56f09a527b4c34c8a9d5": {
      "source_id": "77b71b9037cd56f09a527b4c34c8a9d5",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8892,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The Case for a Journal of AI Alignment"
    },
    "de4c0455a1d7f7270e1df9cc72fe2f64": {
      "source_id": "de4c0455a1d7f7270e1df9cc72fe2f64",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39301,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Imitative Generalisation (AKA 'Learning the Prior')"
    },
    "d8cec8fbf59ec688eff4b88db134b076": {
      "source_id": "d8cec8fbf59ec688eff4b88db134b076",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10532,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Review of Soft Takeoff Can Still Lead to DSA"
    },
    "c04f8dfe06338ebb79d400a03edcc0da": {
      "source_id": "c04f8dfe06338ebb79d400a03edcc0da",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20742,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Prediction can be Outer Aligned at Optimum"
    },
    "8cf8b19f327c7debb4bf3beb1433efec": {
      "source_id": "8cf8b19f327c7debb4bf3beb1433efec",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59560,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Transparency and AGI safety"
    },
    "4f7d67ccb3b9b49238b9206e9c3b59fa": {
      "source_id": "4f7d67ccb3b9b49238b9206e9c3b59fa",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23047,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Review of 'Debate on Instrumental Convergence between LeCun, Russell, Bengio, Za"
    },
    "918349ea8f7c8dcbee86c9a75b163342": {
      "source_id": "918349ea8f7c8dcbee86c9a75b163342",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 20565,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #133]:\u00a0Building machines that can cooperate (with humans, institutions, or o"
    },
    "edfe4377ebf54d73d35e40ef6a680f16": {
      "source_id": "edfe4377ebf54d73d35e40ef6a680f16",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6194,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Some recent survey papers on (mostly near-term) AI safety, security, and assuran"
    },
    "fadeb3cc71fcc0adf4142654c4114758": {
      "source_id": "fadeb3cc71fcc0adf4142654c4114758",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6548,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Thoughts on Iason Gabriel\u2019s Artificial Intelligence, Values, and Alignment"
    },
    "aaa896cd597e2544f81f54487b487881": {
      "source_id": "aaa896cd597e2544f81f54487b487881",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13384,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Why I'm excited about Debate"
    },
    "b75e30a367f20454dff916ae16380d22": {
      "source_id": "b75e30a367f20454dff916ae16380d22",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 87165,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Literature Review on Goal-Directedness"
    },
    "773d5a27b20bb1babd88306c30ba1319": {
      "source_id": "773d5a27b20bb1babd88306c30ba1319",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27763,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Birds, Brains, Planes, and AI: Against Appeals to the Complexity/Mysteriousness/"
    },
    "7ad3af07b34991fe5db7bd349c375d4f": {
      "source_id": "7ad3af07b34991fe5db7bd349c375d4f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32192,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Some thoughts on risks from narrow, non-agentic AI"
    },
    "a08784881780a40e049c8b96a09ea156": {
      "source_id": "a08784881780a40e049c8b96a09ea156",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7700,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Against the Backward Approach to Goal-Directedness"
    },
    "3910ea66302bf20e38d254882719b6b8": {
      "source_id": "3910ea66302bf20e38d254882719b6b8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 71334,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Infra-Bayesianism Unwrapped"
    },
    "f0298abb1a865ccedc52412e61037f1d": {
      "source_id": "f0298abb1a865ccedc52412e61037f1d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 15397,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #134]:\u00a0Underspecification as a cause of fragility to distribution shift"
    },
    "3b88d36a7069cfcc2d40c206714d37c4": {
      "source_id": "3b88d36a7069cfcc2d40c206714d37c4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2157,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Poll: Which variables are most strategically relevant?"
    },
    "d9de55330127f58140c7b19f5f3d5144": {
      "source_id": "d9de55330127f58140c7b19f5f3d5144",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25522,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Optimal play in human-judged Debate usually won't answer your question"
    },
    "dd273c69684795909e0c06b056b95b99": {
      "source_id": "dd273c69684795909e0c06b056b95b99",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19237,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #135]:\u00a0Five properties of goal-directed systems"
    },
    "92b41738908e808ce010d031ff77388c": {
      "source_id": "92b41738908e808ce010d031ff77388c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20229,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Extracting Money from Causal Decision Theorists"
    },
    "52b1ce720a153bf6e38df4a94157ccc9": {
      "source_id": "52b1ce720a153bf6e38df4a94157ccc9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1689,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AMA on EA Forum: Ajeya Cotra, researcher at Open Phil"
    },
    "03a23a21e2f486fcc450387076b1e0d4": {
      "source_id": "03a23a21e2f486fcc450387076b1e0d4",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7895,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A Critique of Non-Obstruction"
    },
    "e71f390234a0c0880426405fe9ba716e": {
      "source_id": "e71f390234a0c0880426405fe9ba716e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16563,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Distinguishing claims about training vs deployment"
    },
    "10196edbeb76c1a8b9b01abf37ea6ec4": {
      "source_id": "10196edbeb76c1a8b9b01abf37ea6ec4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11845,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Counterfactual Planning in AGI Systems"
    },
    "3b7d0886fee5a8807e89156f42243d3e": {
      "source_id": "3b7d0886fee5a8807e89156f42243d3e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 21002,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #136]:\u00a0How well will GPT-N perform on downstream tasks?"
    },
    "951337533c534cb88d8862e6b08001c2": {
      "source_id": "951337533c534cb88d8862e6b08001c2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34823,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Creating AGI Safety Interlocks"
    },
    "68aa02077de9904f6aca09cba531404b": {
      "source_id": "68aa02077de9904f6aca09cba531404b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5580,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Timeline of AI safety"
    },
    "bba1de057ab5280d6522588ddfdbb0b3": {
      "source_id": "bba1de057ab5280d6522588ddfdbb0b3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21165,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Epistemology of HCH"
    },
    "258290fac8bbc041aaa0b8dc47ae1720": {
      "source_id": "258290fac8bbc041aaa0b8dc47ae1720",
      "quality_score": 3.0,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 18458,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "[AN #137]: Quantifying the benefits of pretraining on downstream task performanc"
    },
    "920ed48a2e6919d0302d27cfea7d4439": {
      "source_id": "920ed48a2e6919d0302d27cfea7d4439",
      "quality_score": 1.0,
      "quality_tier": "D",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 440,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Institute for Assured Autonomy (IAA) newsletter"
    },
    "e4e5428853e4741ddda270b91d1bcc2d": {
      "source_id": "e4e5428853e4741ddda270b91d1bcc2d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58748,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Mapping the Conceptual Territory in AI Existential Safety and Alignment"
    },
    "0c5cf17d3fbc78e26e7e0851133e6b30": {
      "source_id": "0c5cf17d3fbc78e26e7e0851133e6b30",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9123,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Tournesol, YouTube and AI Risk"
    },
    "111792882d00a45dffb3c9d4e5281323": {
      "source_id": "111792882d00a45dffb3c9d4e5281323",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2363,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Suggestions of posts on the AF to review"
    },
    "62bf952412bf08df4424ee400564fe20": {
      "source_id": "62bf952412bf08df4424ee400564fe20",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37942,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Disentangling Corrigibility: 2015-2021"
    },
    "7fb8e12312317cb2c7cf3aaf1ede4c7c": {
      "source_id": "7fb8e12312317cb2c7cf3aaf1ede4c7c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38836,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Graphical World Models, Counterfactuals, and Machine Learning Agents"
    },
    "a0592fdfc8b88536b86630b14d00113a": {
      "source_id": "a0592fdfc8b88536b86630b14d00113a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29946,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Safely controlling the AGI agent reward function"
    },
    "1f49ed0a6981faa12b6cb622787941d9": {
      "source_id": "1f49ed0a6981faa12b6cb622787941d9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19521,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #138]:\u00a0Why AI governance should find problems rather than just solving them"
    },
    "131fe90e3960212a7318561f076caedc": {
      "source_id": "131fe90e3960212a7318561f076caedc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 153417,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 4 - Risks from Learned Optimization with Evan Hubinger"
    },
    "a0e3291c8fd88f1e634f509ab21cab7b": {
      "source_id": "a0e3291c8fd88f1e634f509ab21cab7b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21865,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Formal Solution to the Inner Alignment Problem"
    },
    "1e7bd578296c30057836284b5acc2989": {
      "source_id": "1e7bd578296c30057836284b5acc2989",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29895,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Utility Maximization = Description Length Minimization"
    },
    "62d2534e6665ff3f7eaf2ae3c0569e12": {
      "source_id": "62d2534e6665ff3f7eaf2ae3c0569e12",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 25083,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #139]:\u00a0How the simplicity of reality explains the success of neural nets"
    },
    "19f8650f4f80be3d018e9a30c2275dd3": {
      "source_id": "19f8650f4f80be3d018e9a30c2275dd3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4331,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Bootstrapped Alignment"
    },
    "b89d416ccc7e1194f0b6072a1b864fda": {
      "source_id": "b89d416ccc7e1194f0b6072a1b864fda",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1398,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Full-time AGI Safety!"
    },
    "8327908b83017a0f3b9c62fee38eab1a": {
      "source_id": "8327908b83017a0f3b9c62fee38eab1a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28579,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Fun with +12 OOMs of Compute"
    },
    "f412b1d9fedb969894caa1c0131847e2": {
      "source_id": "f412b1d9fedb969894caa1c0131847e2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49932,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "How does bee learning compare with machine learning?"
    },
    "59c9838e4ea8cb1541531544dff5bb0c": {
      "source_id": "59c9838e4ea8cb1541531544dff5bb0c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55186,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Book review: \"A Thousand Brains\" by Jeff Hawkins"
    },
    "1b10ea9fa5fdb2cd255539019df61292": {
      "source_id": "1b10ea9fa5fdb2cd255539019df61292",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 21068,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #140]: Theoretical models that predict scaling laws"
    },
    "cbcf1c1ce382a061161c9862ad8f35a6": {
      "source_id": "cbcf1c1ce382a061161c9862ad8f35a6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 74974,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The case for aligning narrowly superhuman models"
    },
    "a3f8aade404e5b4063998a5dedb3f212": {
      "source_id": "a3f8aade404e5b4063998a5dedb3f212",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51338,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "MIRI comments on Cotra's \"Case for Aligning Narrowly Superhuman Models\""
    },
    "302e91321def0cc365b2bad7dd084f43": {
      "source_id": "302e91321def0cc365b2bad7dd084f43",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18104,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Epistemological Framing for AI Alignment Research"
    },
    "2608810fd28e1eb3c95a6389d0490b59": {
      "source_id": "2608810fd28e1eb3c95a6389d0490b59",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30102,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "CLR's recent work on multi-agent systems"
    },
    "ffcdfe927f0c36bd4fb12393d9867675": {
      "source_id": "ffcdfe927f0c36bd4fb12393d9867675",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10387,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Towards a Mechanistic Understanding of Goal-Directedness"
    },
    "3bd6328c190852078008fe6195ac875f": {
      "source_id": "3bd6328c190852078008fe6195ac875f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 64279,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 5 - Infra-Bayesianism with Vanessa Kosoy"
    },
    "4d4fa40bfcd32fdac8001ac8c98aba8d": {
      "source_id": "4d4fa40bfcd32fdac8001ac8c98aba8d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4178,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Extended Picture Theory or Models inside Models inside Models"
    },
    "fe3009a48eabd41b8fad1fd3c8fd73ef": {
      "source_id": "fe3009a48eabd41b8fad1fd3c8fd73ef",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19245,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #141]:\u00a0The case for practicing alignment work on GPT-3 and other large model"
    },
    "de2612a2b9c3f6f02cd5d1dcfe092399": {
      "source_id": "de2612a2b9c3f6f02cd5d1dcfe092399",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16704,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Open Problems with Myopia"
    },
    "285797e63a56ead099b8d30571d9a606": {
      "source_id": "285797e63a56ead099b8d30571d9a606",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2322,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "TASP Ep 3 - Optimal Policies Tend to Seek Power"
    },
    "447a3ceee355ae5fb8d98142eb2f6d09": {
      "source_id": "447a3ceee355ae5fb8d98142eb2f6d09",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35912,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Behavioral Sufficient Statistics for Goal-Directedness"
    },
    "be30ea7fcf6abc60258f656e36548a80": {
      "source_id": "be30ea7fcf6abc60258f656e36548a80",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9964,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Four Motivations for Learning Normativity"
    },
    "719de0af72a38816d3212a0df6054f42": {
      "source_id": "719de0af72a38816d3212a0df6054f42",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5056,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AI x-risk reduction: why I chose academia over industry"
    },
    "a2dcc2c90c41e2a607f1543f90fa95b6": {
      "source_id": "a2dcc2c90c41e2a607f1543f90fa95b6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33831,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Comments on \"The Singularity is Nowhere Near\""
    },
    "c67157d535548bfff89ce84bbb6b47f8": {
      "source_id": "c67157d535548bfff89ce84bbb6b47f8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 39102,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Intermittent Distillations #1"
    },
    "1eb97fca8419d495376c3510699e1891": {
      "source_id": "1eb97fca8419d495376c3510699e1891",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34655,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "HCH Speculation Post #2A"
    },
    "64237bed49ba067a71fecfc5908425c1": {
      "source_id": "64237bed49ba067a71fecfc5908425c1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 17033,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #142]:\u00a0The quest to understand a network well enough to reimplement it by ha"
    },
    "21c5d85faf4d21a92ed5ba46f14a9ad6": {
      "source_id": "21c5d85faf4d21a92ed5ba46f14a9ad6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30937,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Generalizing POWER to multi-agent games"
    },
    "a3fac625899e3e2917d0c2103be791c6": {
      "source_id": "a3fac625899e3e2917d0c2103be791c6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29743,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "My research methodology"
    },
    "b03e1414e703b567249d8892dff0f64b": {
      "source_id": "b03e1414e703b567249d8892dff0f64b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 68406,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Against evolution as an analogy for how humans will create AGI"
    },
    "cd5b297a034f448f2feac0d38c92f854": {
      "source_id": "cd5b297a034f448f2feac0d38c92f854",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 17709,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #143]:\u00a0How to make embedded agents that reason probabilistically about their"
    },
    "378e12e8266c53e3c43d25ffab762e77": {
      "source_id": "378e12e8266c53e3c43d25ffab762e77",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33733,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "My AGI Threat Model: Misaligned Model-Based RL Agent"
    },
    "7d72316b2ff1cc1e666ad2a7cbc11700": {
      "source_id": "7d72316b2ff1cc1e666ad2a7cbc11700",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 86999,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Inframeasures and Domain Theory"
    },
    "17f92a83396cdd65e514b8b074c4a3d9": {
      "source_id": "17f92a83396cdd65e514b8b074c4a3d9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15108,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Review of \"Fun with +12 OOMs of Compute\""
    },
    "bb7a4e53166611113c119529aa0c7394": {
      "source_id": "bb7a4e53166611113c119529aa0c7394",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16425,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Transparency Trichotomy"
    },
    "0cfbe881362f3882eb9c7ca11dd96a02": {
      "source_id": "0cfbe881362f3882eb9c7ca11dd96a02",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14084,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "How do we prepare for final crunch time?"
    },
    "70145e3dc699593863144bd01996d02c": {
      "source_id": "70145e3dc699593863144bd01996d02c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 63606,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What Multipolar Failure Looks Like, and Robust Agent-Agnostic Processes (RAAPs)"
    },
    "2669ff0cde3645b5b2f4fbdb136e0043": {
      "source_id": "2669ff0cde3645b5b2f4fbdb136e0043",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 15069,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #144]:\u00a0How language models can also be finetuned for non-language tasks"
    },
    "63ed746ba31f25a5dbfc17a54bd351e2": {
      "source_id": "63ed746ba31f25a5dbfc17a54bd351e2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14263,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "My take on Michael Littman on \"The HCI of HAI\""
    },
    "19273ff27b979f491768ead9cfdbdfc8": {
      "source_id": "19273ff27b979f491768ead9cfdbdfc8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 151458,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The Many Faces of Infra-Beliefs"
    },
    "2f58baff05742d1a5064844df70ad3cd": {
      "source_id": "2f58baff05742d1a5064844df70ad3cd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13917,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Testing The Natural Abstraction Hypothesis: Project Intro"
    },
    "a1523a7bf7a6b299f7d7520b3d68dc79": {
      "source_id": "a1523a7bf7a6b299f7d7520b3d68dc79",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 10688,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Alignment Newsletter Three Year Retrospective"
    },
    "cd0296d707ea9c44382fc3f7d7517c93": {
      "source_id": "cd0296d707ea9c44382fc3f7d7517c93",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32059,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Which counterfactuals should an AI follow?"
    },
    "d651603cae5fc034c12526fa268ccb30": {
      "source_id": "d651603cae5fc034c12526fa268ccb30",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20994,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Another (outer) alignment failure story"
    },
    "01b45b5d40a83c3ad675a59ff09fa43a": {
      "source_id": "01b45b5d40a83c3ad675a59ff09fa43a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52583,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Solving the whole AGI control problem, version 0.0001"
    },
    "037e009a9ffa4811b4a528b683ab65cd": {
      "source_id": "037e009a9ffa4811b4a528b683ab65cd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27781,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "If you don't design for extrapolation, you'll extrapolate poorly - possibly fata"
    },
    "c38225b47b19c4512dd9b5eda3a50b21": {
      "source_id": "c38225b47b19c4512dd9b5eda3a50b21",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 102108,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 6 - Debate and Imitative Generalization with Beth Barnes"
    },
    "12b0c58fb7d78405212e98bb5f63cc8b": {
      "source_id": "12b0c58fb7d78405212e98bb5f63cc8b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 16731,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #145]: Our three year anniversary!"
    },
    "ad6fa9b8bcc96bf5d5d68d71bc1032ee": {
      "source_id": "ad6fa9b8bcc96bf5d5d68d71bc1032ee",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 60636,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "My Current Take on Counterfactuals"
    },
    "8ffd1db048dfffd976385353c451df00": {
      "source_id": "8ffd1db048dfffd976385353c451df00",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 214505,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Opinions on Interpretable Machine Learning and 70 Summaries of Recent Papers"
    },
    "05c78390d701e28c0104a0f4d9a97da7": {
      "source_id": "05c78390d701e28c0104a0f4d9a97da7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19070,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Intermittent Distillations #2"
    },
    "5a74ff3b7db0e1b51703ddb753b8afe4": {
      "source_id": "5a74ff3b7db0e1b51703ddb753b8afe4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 17642,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #146]:\u00a0Plausible stories of how we might fail to avert an existential catast"
    },
    "cb8adee160ea31d4fbbda9282a0f93c9": {
      "source_id": "cb8adee160ea31d4fbbda9282a0f93c9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31109,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Computing Natural Abstractions: Linear Approximation"
    },
    "e3d979d3f6f27eb1ef3c020f2b136683": {
      "source_id": "e3d979d3f6f27eb1ef3c020f2b136683",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17842,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Gradations of Inner Alignment Obstacles"
    },
    "997a47b6b3516d3f2938d423d83de06d": {
      "source_id": "997a47b6b3516d3f2938d423d83de06d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 14448,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #147]: An overview of the interpretability landscape"
    },
    "a86d3a08178c9e4d6b0401f10b78b955": {
      "source_id": "a86d3a08178c9e4d6b0401f10b78b955",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11788,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Probability theory and logical induction as lenses"
    },
    "a3f748da0f4482271bc1370a64fe5866": {
      "source_id": "a3f748da0f4482271bc1370a64fe5866",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16436,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Naturalism and AI alignment"
    },
    "5d819f28ba7002678fbfd87f9b21303f": {
      "source_id": "5d819f28ba7002678fbfd87f9b21303f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1741,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "FAQ: Advice for AI Alignment Researchers"
    },
    "338edf175eb52d4c047bcd7c2a4cb489": {
      "source_id": "338edf175eb52d4c047bcd7c2a4cb489",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1257,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Announcing the Alignment Research Center"
    },
    "5f0a5b688c51f6256bf3e610ae341a0a": {
      "source_id": "5f0a5b688c51f6256bf3e610ae341a0a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 75898,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Agents Over Cartesian World Models"
    },
    "75f27ca66fd73e17cb9a8694ddc36f12": {
      "source_id": "75f27ca66fd73e17cb9a8694ddc36f12",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 23401,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #148]:\u00a0Analyzing generalization across more axes than just accuracy or loss"
    },
    "6910748a761d904a07b70508df86dd2f": {
      "source_id": "6910748a761d904a07b70508df86dd2f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 274,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AMA: Paul Christiano, alignment researcher"
    },
    "91fa65f19202e5c6308a105187297e74": {
      "source_id": "91fa65f19202e5c6308a105187297e74",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1137,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Draft report on existential risk from power-seeking AI"
    },
    "f827f0c2658b5ad8dded6458193d8e1e": {
      "source_id": "f827f0c2658b5ad8dded6458193d8e1e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12963,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Low-stakes alignment"
    },
    "e50220558ade0cb8c158713096b277f1": {
      "source_id": "e50220558ade0cb8c158713096b277f1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1398,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[Weekly Event] Alignment Researcher Coffee Time (in Walled Garden)"
    },
    "64835f7e77795dd804884429b2598533": {
      "source_id": "64835f7e77795dd804884429b2598533",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12934,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Parsing Abram on Gradations of Inner Alignment Obstacles"
    },
    "e533c5574b1c46a1d636b0b687f5b97e": {
      "source_id": "e533c5574b1c46a1d636b0b687f5b97e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9106,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Mundane solutions to exotic problems"
    },
    "ca624badb16a9112085f4d755a3bfd21": {
      "source_id": "ca624badb16a9112085f4d755a3bfd21",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 16458,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #149]: The newsletter's editorial policy"
    },
    "50acd1416eb21320c61d2e44d0658917": {
      "source_id": "50acd1416eb21320c61d2e44d0658917",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13220,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Parsing Chris Mingard on Neural Networks"
    },
    "67626b44cd21b4f210f5545832020cfc": {
      "source_id": "67626b44cd21b4f210f5545832020cfc",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8799,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Less Realistic Tales of Doom"
    },
    "49cb28f225610477aec7f75786dab29c": {
      "source_id": "49cb28f225610477aec7f75786dab29c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6357,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Pre-Training + Fine-Tuning Favors Deception"
    },
    "4aeabf0a7c1e5d401a4f351fa820fbd0": {
      "source_id": "4aeabf0a7c1e5d401a4f351fa820fbd0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1012,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[Event] Weekly Alignment Research Coffee Time (05/10)"
    },
    "8248c5d43a00dc7d86ee03859745c185": {
      "source_id": "8248c5d43a00dc7d86ee03859745c185",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 760,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Yampolskiy on AI Risk Skepticism"
    },
    "266a0756fe09b5ca123f35cb06aee50f": {
      "source_id": "266a0756fe09b5ca123f35cb06aee50f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 15247,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #150]:\u00a0The subtypes of Cooperative AI research"
    },
    "01ccfc4f6c67010b08eb3383ca14cba0": {
      "source_id": "01ccfc4f6c67010b08eb3383ca14cba0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50005,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Formal Inner Alignment, Prospectus"
    },
    "8a00a82fce89e2240409fbf230370db5": {
      "source_id": "8a00a82fce89e2240409fbf230370db5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34136,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Understanding the Lottery Ticket Hypothesis"
    },
    "b106920c069ddac96d8b698249a918e3": {
      "source_id": "b106920c069ddac96d8b698249a918e3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 75997,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 7 - Side Effects with Victoria Krakovna"
    },
    "bc99107b3afbf2e99eca4a8cb9719156": {
      "source_id": "bc99107b3afbf2e99eca4a8cb9719156",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39719,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Intermittent Distillations #3"
    },
    "9930ffc1998a31dc6bd298116f509645": {
      "source_id": "9930ffc1998a31dc6bd298116f509645",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 969,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[Event] Weekly Alignment Research Coffee Time (05/17)"
    },
    "c9fd1fee4ae3197bbdf1022c99487fa7": {
      "source_id": "c9fd1fee4ae3197bbdf1022c99487fa7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21585,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Knowledge Neurons in Pretrained Transformers"
    },
    "e5cddb9bd54f2a4c0f730856f0e3550e": {
      "source_id": "e5cddb9bd54f2a4c0f730856f0e3550e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 12567,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #151]:\u00a0How sparsity in the final layer makes a neural net debuggable"
    },
    "1e24b9f6f5106c07fd495bdbc8a9a163": {
      "source_id": "1e24b9f6f5106c07fd495bdbc8a9a163",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7815,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AI Safety Research Project Ideas"
    },
    "2fe3a6d4a79619717abb649600159c0d": {
      "source_id": "2fe3a6d4a79619717abb649600159c0d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 971,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[Event] Weekly Alignment Research Coffee Time (05/24)"
    },
    "5f6dd2d01a1576dcd2c65cd5e3de78a4": {
      "source_id": "5f6dd2d01a1576dcd2c65cd5e3de78a4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 64749,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Finite Factored Sets"
    },
    "eba03feafa513e2bb12fe863483125b7": {
      "source_id": "eba03feafa513e2bb12fe863483125b7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13094,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Problems facing a correspondence theory of knowledge"
    },
    "e4ac3117db9b3bd161a8fcd2433b5652": {
      "source_id": "e4ac3117db9b3bd161a8fcd2433b5652",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17522,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Decoupling deliberation from competition"
    },
    "cc128d58b3675fff926e2f18da7cdd0e": {
      "source_id": "cc128d58b3675fff926e2f18da7cdd0e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23354,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "MDP models are determined by the agent architecture and the environmental dynami"
    },
    "218909fa95bcc10df5f534442d63cfa4": {
      "source_id": "218909fa95bcc10df5f534442d63cfa4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2213,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "List of good AI safety project ideas?"
    },
    "e2ea474691a9f41365ddc4fd45aee142": {
      "source_id": "e2ea474691a9f41365ddc4fd45aee142",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 118100,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 7.5 - Forecasting Transformative AI from Biological Anchors with Aj"
    },
    "52c4926dd7df7b887717fc7767222c3c": {
      "source_id": "52c4926dd7df7b887717fc7767222c3c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29927,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Teaching ML to answer questions honestly instead of predicting human answers"
    },
    "cdc88eaf2b5b3f56b61335d04124a7a4": {
      "source_id": "cdc88eaf2b5b3f56b61335d04124a7a4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1008,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[Event] Weekly Alignment Research Coffee Time"
    },
    "3a4b57ffc4de8239679777f4a4a096ba": {
      "source_id": "3a4b57ffc4de8239679777f4a4a096ba",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37866,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "\"Existential risk from AI\" survey results"
    },
    "6fdded65b2c16fd3075904fb113d26cc": {
      "source_id": "6fdded65b2c16fd3075904fb113d26cc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51162,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Thoughts on the Alignment Implications of Scaling Language Models"
    },
    "07ece067b966ff73e2daea767c5bb0cb": {
      "source_id": "07ece067b966ff73e2daea767c5bb0cb",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6535,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Rogue AGI Embodies Valuable Intellectual Property"
    },
    "a78aa6d477b83b38763a017f41e9f058": {
      "source_id": "a78aa6d477b83b38763a017f41e9f058",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12946,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Review of \"Learning Normativity: A Research Agenda\""
    },
    "2665774613c80b6d1aa496006d43a51c": {
      "source_id": "2665774613c80b6d1aa496006d43a51c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4048,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Some AI Governance Research Ideas"
    },
    "a284274dcb72d0c5c9ea64ca52b612d9": {
      "source_id": "a284274dcb72d0c5c9ea64ca52b612d9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3554,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Speculations against GPT-n writing alignment papers"
    },
    "537cc19486d5a64fabea112f4626bea2": {
      "source_id": "537cc19486d5a64fabea112f4626bea2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35674,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Game-theoretic Alignment in terms of Attainable Utility"
    },
    "41f0d57f568dad73e9de70dd1af75629": {
      "source_id": "41f0d57f568dad73e9de70dd1af75629",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 76851,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Big picture of phasic dopamine"
    },
    "827fce9b938f21e728a30641146be90e": {
      "source_id": "827fce9b938f21e728a30641146be90e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18690,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Supplement to \"Big picture of phasic dopamine\""
    },
    "43105989664e6df3c885377924f962d1": {
      "source_id": "43105989664e6df3c885377924f962d1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17520,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Survey on AI existential risk scenarios"
    },
    "7a5f09a04b10d72aac90a867959529dd": {
      "source_id": "7a5f09a04b10d72aac90a867959529dd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 104111,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Evan Hubinger on Homogeneity in Takeoff Speeds, Learned Optimization and Interpr"
    },
    "8aa8c62ff4f837ba1a9e682feaa3cab8": {
      "source_id": "8aa8c62ff4f837ba1a9e682feaa3cab8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 129194,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 8 - Assistance Games with Dylan Hadfield-Menell"
    },
    "062b7782e10c89cd061da121faf638c5": {
      "source_id": "062b7782e10c89cd061da121faf638c5",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6533,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A naive alignment strategy and optimism about generalization"
    },
    "c09f4ed72470ae6499a0df714fed70b1": {
      "source_id": "c09f4ed72470ae6499a0df714fed70b1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30245,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Answering questions honestly given world-model mismatches"
    },
    "4a95f2597dbc790f375b5fcdbf883ff8": {
      "source_id": "4a95f2597dbc790f375b5fcdbf883ff8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3717,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Avoiding the instrumental policy by hiding information about humans"
    },
    "29e7ef59d181e810977b7cdd2ddc3813": {
      "source_id": "29e7ef59d181e810977b7cdd2ddc3813",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48008,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Looking Deeper at Deconfusion"
    },
    "3be33ac925d8661cec1bc8f2373bcac8": {
      "source_id": "3be33ac925d8661cec1bc8f2373bcac8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20622,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Open problem: how can we quantify player alignment in 2x2 normal-form games?"
    },
    "e3c4ed5bcc26db373d36304b05a280cf": {
      "source_id": "e3c4ed5bcc26db373d36304b05a280cf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20381,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Reward Is Not Enough"
    },
    "3236e524a3170acd5f80fecb13500b47": {
      "source_id": "3236e524a3170acd5f80fecb13500b47",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10828,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Insufficient Values"
    },
    "a6c5dc4af96ba2132a6c299bd12de6e4": {
      "source_id": "a6c5dc4af96ba2132a6c299bd12de6e4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 17563,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #152]:\u00a0How we\u2019ve overestimated few-shot learning capabilities"
    },
    "8b64ed70b950fddf995645036225736f": {
      "source_id": "8b64ed70b950fddf995645036225736f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5138,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Pros and cons of working on near-term technical AI safety and assurance"
    },
    "91cb9a8ca0a4b414e425fd2e2a749ad8": {
      "source_id": "91cb9a8ca0a4b414e425fd2e2a749ad8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12483,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Knowledge is not just precipitation of action"
    },
    "e2b3dca6c45dace985bcfeb3dc024481": {
      "source_id": "e2b3dca6c45dace985bcfeb3dc024481",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 109015,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Parameter counts in Machine Learning"
    },
    "3994bd514d834695d9d7d9c618940674": {
      "source_id": "3994bd514d834695d9d7d9c618940674",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53320,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Environmental Structure Can Cause Instrumental Convergence"
    },
    "ebd148bbe5b8f24f1aa8ec2479f9c00f": {
      "source_id": "ebd148bbe5b8f24f1aa8ec2479f9c00f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9175,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Frequent arguments about alignment"
    },
    "4584d4c3632b39e724cadffd80c8bc2e": {
      "source_id": "4584d4c3632b39e724cadffd80c8bc2e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6141,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Alex Turner's Research, Comprehensive Information Gathering"
    },
    "20bfe7f746257f5772bfbaeea45cb234": {
      "source_id": "20bfe7f746257f5772bfbaeea45cb234",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18780,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Empirical Observations of Objective Robustness Failures"
    },
    "b63c174e94f4db7f05260900c6de1d8c": {
      "source_id": "b63c174e94f4db7f05260900c6de1d8c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39510,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Discussion: Objective Robustness and Inner Alignment Terminology"
    },
    "5c17a1c86bb188f6aa2101c949cdc807": {
      "source_id": "5c17a1c86bb188f6aa2101c949cdc807",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 101457,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 9 - Finite Factored Sets with Scott Garrabrant"
    },
    "01b3267572e210aea84c1cc0567e2956": {
      "source_id": "01b3267572e210aea84c1cc0567e2956",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19465,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #153]:\u00a0Experiments that demonstrate failures of objective robustness"
    },
    "935b21ab38f5ea60ac34d6499375e87d": {
      "source_id": "935b21ab38f5ea60ac34d6499375e87d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 114217,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Finite Factored Sets: LW transcript with running commentary"
    },
    "800f9b0fc10ba702e4fdb7dce17886c4": {
      "source_id": "800f9b0fc10ba702e4fdb7dce17886c4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20793,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Brute force searching for alignment"
    },
    "396cd34f032b41ad0043408595ae76ec": {
      "source_id": "396cd34f032b41ad0043408595ae76ec",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21705,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Progress on Causal Influence Diagrams"
    },
    "0aa53ca5de496ee9f3e11cd94a2a6f98": {
      "source_id": "0aa53ca5de496ee9f3e11cd94a2a6f98",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19438,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #154]:\u00a0What economic growth theory has to say about transformative AI"
    },
    "9b0ad9b3fd662b394d764bca67e67805": {
      "source_id": "9b0ad9b3fd662b394d764bca67e67805",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5371,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Musings on general systems alignment"
    },
    "d636c1d844f686c8021e654cc49a32e6": {
      "source_id": "d636c1d844f686c8021e654cc49a32e6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41098,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Thoughts on safety in predictive learning"
    },
    "9ceabacf944861038e1390255eb6affd": {
      "source_id": "9ceabacf944861038e1390255eb6affd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17456,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Experimentally evaluating whether honesty generalizes"
    },
    "1a940b344c2b555c95462677277937ed": {
      "source_id": "1a940b344c2b555c95462677277937ed",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34724,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Confusions re: Higher-Level Game Theory"
    },
    "ab50d3b8a41820751a3519c7e3141da5": {
      "source_id": "ab50d3b8a41820751a3519c7e3141da5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26284,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A simple example of conditional orthogonality in finite factored sets"
    },
    "fdfba6e353ad4890bba35ca6e81955b1": {
      "source_id": "fdfba6e353ad4890bba35ca6e81955b1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21758,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A second example of conditional orthogonality in finite factored sets"
    },
    "8859993dd89ebf350f8e88114b475ecc": {
      "source_id": "8859993dd89ebf350f8e88114b475ecc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21525,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A world in which the alignment problem seems lower-stakes"
    },
    "783db9c442a30be1237329b828bab245": {
      "source_id": "783db9c442a30be1237329b828bab245",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 15131,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #155]:\u00a0A Minecraft benchmark for algorithms that learn without reward functi"
    },
    "c253c83142d5d354161808cc9081f7d4": {
      "source_id": "c253c83142d5d354161808cc9081f7d4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3139,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "BASALT: A Benchmark for Learning from Human Feedback"
    },
    "e27c4686b3e051bd1963fea7094471bb": {
      "source_id": "e27c4686b3e051bd1963fea7094471bb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38507,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Intermittent Distillations #4: Semiconductors, Economics, Intelligence, and Tech"
    },
    "07dfd5bb52faebf5ddec940f492afee2": {
      "source_id": "07dfd5bb52faebf5ddec940f492afee2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13451,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The accumulation of knowledge: literature review"
    },
    "938a86739b9d126f3019c687b8a96988": {
      "source_id": "938a86739b9d126f3019c687b8a96988",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31666,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The More Power At Stake, The Stronger Instrumental Convergence Gets For Optimal "
    },
    "c6f3d773626323961a87dd857e042eda": {
      "source_id": "c6f3d773626323961a87dd857e042eda",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 71809,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Answering questions honestly instead of predicting human answers: lots of proble"
    },
    "afafca6d2fd98a6204feb02e8a9613c1": {
      "source_id": "afafca6d2fd98a6204feb02e8a9613c1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28596,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Model-based RL, Desires, Brains, Wireheading"
    },
    "89ad27783eb0b3e9142eba009fbb1af8": {
      "source_id": "89ad27783eb0b3e9142eba009fbb1af8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33021,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Fractional progress estimates for AI timelines and implied resource requirements"
    },
    "8ce3a1eaefd78d8bec3e78bc68d94f63": {
      "source_id": "8ce3a1eaefd78d8bec3e78bc68d94f63",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 17135,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #156]:\u00a0The scaling hypothesis: a plan for building AGI"
    },
    "c6af21acc42e5aa605ceaba9e6850ed2": {
      "source_id": "c6af21acc42e5aa605ceaba9e6850ed2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29223,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Bayesianism versus conservatism versus Goodhart"
    },
    "37981ef8e5154a856f0e4bea5ba48a47": {
      "source_id": "37981ef8e5154a856f0e4bea5ba48a47",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5650,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A model of decision-making in the brain (the short version)"
    },
    "9f1508627eebe76d2305c57e0a07d640": {
      "source_id": "9f1508627eebe76d2305c57e0a07d640",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25721,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Re-Define Intent Alignment?"
    },
    "d8aca17ba2c71b1e6c381ae20878f0d2": {
      "source_id": "d8aca17ba2c71b1e6c381ae20878f0d2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 16746,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #157]: Measuring misalignment in the technology underlying Copilot"
    },
    "de684c73d6f2901b5e90ad801fbab466": {
      "source_id": "de684c73d6f2901b5e90ad801fbab466",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 132046,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 10 - AI\u2019s Future and Impacts with Katja Grace"
    },
    "795b758ec4f9185f378422c2aeb90f58": {
      "source_id": "795b758ec4f9185f378422c2aeb90f58",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34520,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Refactoring Alignment (attempt #2)"
    },
    "ee9f2ddda47cac12d92374da937ed195": {
      "source_id": "ee9f2ddda47cac12d92374da937ed195",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2138,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "How much compute was used to train DeepMind's generally capable agents?"
    },
    "18c56c6c148660e101fe30d7665bef91": {
      "source_id": "18c56c6c148660e101fe30d7665bef91",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 18404,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #158]: Should we be optimistic about generalization?"
    },
    "c37b15190bbd3ee92fe98c81780b3758": {
      "source_id": "c37b15190bbd3ee92fe98c81780b3758",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48580,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "LCDT, A Myopic Decision Theory"
    },
    "cf3f0ada240302524dfd60799a28f325": {
      "source_id": "cf3f0ada240302524dfd60799a28f325",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 84883,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Garrabrant and Shah on human modeling in AGI"
    },
    "e9e39c1b3c00e7880b389026768e4568": {
      "source_id": "e9e39c1b3c00e7880b389026768e4568",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 28720,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #159]:\u00a0Building agents that know how to experiment, by training on procedura"
    },
    "bf93c510fba6fa361d0d46a1eaab7d4c": {
      "source_id": "bf93c510fba6fa361d0d46a1eaab7d4c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17214,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Value loading in the human brain: a worked example"
    },
    "ddd30df957ebd43f69d0bcb80b0e6702": {
      "source_id": "ddd30df957ebd43f69d0bcb80b0e6702",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13125,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Traps of Formalization in Deconfusion"
    },
    "b99c70c3b63268042ef2888f2ea8ad55": {
      "source_id": "b99c70c3b63268042ef2888f2ea8ad55",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32879,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What 2026 looks like"
    },
    "0526ce96e90d96d713e2a3256a106591": {
      "source_id": "0526ce96e90d96d713e2a3256a106591",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15398,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Research agenda update"
    },
    "829a5b1fd0cf995af117011b2bdf3c07": {
      "source_id": "829a5b1fd0cf995af117011b2bdf3c07",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37258,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Seeking Power is Convergently Instrumental in a Broad Class of Environments"
    },
    "4e7ed11a11c2ac8521792ab019d2b8ad": {
      "source_id": "4e7ed11a11c2ac8521792ab019d2b8ad",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11128,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Applications for Deconfusing Goal-Directedness"
    },
    "662b064b1bbfafd6ea2e093322403730": {
      "source_id": "662b064b1bbfafd6ea2e093322403730",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4188,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Goal-Directedness and Behavior, Redux"
    },
    "7154aca101dbeb10a055757add26a1d3": {
      "source_id": "7154aca101dbeb10a055757add26a1d3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28350,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Automating Auditing: An ambitious concrete technical research proposal"
    },
    "da77213025a90beb1fcd9bfbf201749b": {
      "source_id": "da77213025a90beb1fcd9bfbf201749b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6982,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Some criteria for sandwiching projects"
    },
    "ce8cbd1d3e99b2fbe0c2bf12590b61df": {
      "source_id": "ce8cbd1d3e99b2fbe0c2bf12590b61df",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26243,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Power-seeking for successive choices"
    },
    "b0316162b299d0aee327fec6d8774bba": {
      "source_id": "b0316162b299d0aee327fec6d8774bba",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25395,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A review of \"Agents and Devices\""
    },
    "a59a81b1715930bfb862665c7e470a76": {
      "source_id": "a59a81b1715930bfb862665c7e470a76",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 20485,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #160]: Building AIs that learn and think like people"
    },
    "e8f312deeddd71e7cd024678913d9dc4": {
      "source_id": "e8f312deeddd71e7cd024678913d9dc4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14043,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Approaches to gradient hacking"
    },
    "87618eaab9f0d94c406dc93b343f2490": {
      "source_id": "87618eaab9f0d94c406dc93b343f2490",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20280,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Modelling Transformative AI Risks (MTAIR) Project: Introduction"
    },
    "212832d6f15056893b76a37646e8868b": {
      "source_id": "212832d6f15056893b76a37646e8868b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19149,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #161]:\u00a0Creating generalizable reward functions for multiple tasks by learnin"
    },
    "2ea165ca7f95b1053c29939bcafbc8c4": {
      "source_id": "2ea165ca7f95b1053c29939bcafbc8c4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1576,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Provide feedback on Open Philanthropy\u2019s AI alignment RFP"
    },
    "dd10a71460d110013721706f7f19056e": {
      "source_id": "dd10a71460d110013721706f7f19056e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36341,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Analogies and General Priors on Intelligence"
    },
    "7fec40c6f9d02f6fcad1550cc7bd7a38": {
      "source_id": "7fec40c6f9d02f6fcad1550cc7bd7a38",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5531,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AI Safety Papers: An App for the TAI Safety Database"
    },
    "9e014bca6c84d14258507326619ac17a": {
      "source_id": "9e014bca6c84d14258507326619ac17a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23374,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AI Risk for Epistemic Minimalists"
    },
    "440711917a12937056f8ffe9a01c4a3b": {
      "source_id": "440711917a12937056f8ffe9a01c4a3b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9782,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Extraction of human preferences  \ud83d\udc68\u2192\ud83e\udd16"
    },
    "7c03eb84466144617ce0c6f87ac8257a": {
      "source_id": "7c03eb84466144617ce0c6f87ac8257a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14020,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Welcome & FAQ!"
    },
    "455a70b8e1b18a9f04dad8ea9a8aaca0": {
      "source_id": "455a70b8e1b18a9f04dad8ea9a8aaca0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 269,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "(apologies for Alignment Forum server outage last night)"
    },
    "77a4447207f1cb9c3f9ce17bc968fa25": {
      "source_id": "77a4447207f1cb9c3f9ce17bc968fa25",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19449,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "MIRI/OP exchange about decision theory"
    },
    "96a64fdb46a4da0ea164aed2d642e74f": {
      "source_id": "96a64fdb46a4da0ea164aed2d642e74f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9410,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Introduction to Reducing Goodhart"
    },
    "f141fca899fb3e36d4f348fde9db4c84": {
      "source_id": "f141fca899fb3e36d4f348fde9db4c84",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 17330,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #162]: Foundation models: a paradigm shift within AI"
    },
    "3bac2fc72dbd34b17a256ce29da597cc": {
      "source_id": "3bac2fc72dbd34b17a256ce29da597cc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 86817,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Can you control the past?"
    },
    "fcacb4add6cd9c29bfbdd61dfa5f6387": {
      "source_id": "fcacb4add6cd9c29bfbdd61dfa5f6387",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 744,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What are good alignment conference papers?"
    },
    "f48f894127cc2d9ab4862fe49f8783b3": {
      "source_id": "f48f894127cc2d9ab4862fe49f8783b3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15690,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A short introduction to machine learning"
    },
    "269c9228c5550543edf16a5a4674d86a": {
      "source_id": "269c9228c5550543edf16a5a4674d86a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10175,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Alignment Research = Conceptual Alignment Research + Applied Alignment Research"
    },
    "c7dc9b4ffb67462715fdead79fea51d2": {
      "source_id": "c7dc9b4ffb67462715fdead79fea51d2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40689,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Grokking the Intentional Stance"
    },
    "ec0f51143946123c568121aa028b7afd": {
      "source_id": "ec0f51143946123c568121aa028b7afd",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 857,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Reward splintering as reverse of interpretability"
    },
    "514f722e8ce4e67867dadc575253cfc6": {
      "source_id": "514f722e8ce4e67867dadc575253cfc6",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8870,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Call for research on evaluating alignment (funding + advice available)"
    },
    "b4706f691040de3357e046cfcba4d716": {
      "source_id": "b4706f691040de3357e046cfcba4d716",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4385,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "NIST AI Risk Management Framework request for information (RFI)"
    },
    "93a73a4ba8df148f4874d0701050c2b9": {
      "source_id": "93a73a4ba8df148f4874d0701050c2b9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7382,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Thoughts on gradient hacking"
    },
    "6a4be448c457c9d72f6bc378c726a2ac": {
      "source_id": "6a4be448c457c9d72f6bc378c726a2ac",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2039,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Multi-Agent Inverse Reinforcement Learning: Suboptimal Demonstrations and  Alter"
    },
    "8ab2295334fef8e3ef82bf0abc12aae3": {
      "source_id": "8ab2295334fef8e3ef82bf0abc12aae3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33526,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Distinguishing AI takeover scenarios"
    },
    "e4095ce8389643e7af3eec439516a6c1": {
      "source_id": "e4095ce8389643e7af3eec439516a6c1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 18733,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #163]: Using finite factored sets for causal and temporal inference"
    },
    "0d20bb442d0cd7ec3be2a988179ed2f8": {
      "source_id": "0d20bb442d0cd7ec3be2a988179ed2f8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54492,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Countably Factored Spaces"
    },
    "49136bf679edffe4e15d207501790d4c": {
      "source_id": "49136bf679edffe4e15d207501790d4c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8707,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The alignment problem in different capability regimes"
    },
    "2d0bb65aeab75c462702595131abeeb4": {
      "source_id": "2d0bb65aeab75c462702595131abeeb4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36959,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The Blackwell order as a formalization of knowledge"
    },
    "9e3e9cded76242e39e036a937a30735b": {
      "source_id": "9e3e9cded76242e39e036a937a30735b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 74709,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Paths To High-Level Machine Intelligence"
    },
    "dc9b447881b009d1f3930429a09c53ff": {
      "source_id": "dc9b447881b009d1f3930429a09c53ff",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25378,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Measurement, Optimization, and Take-off Speed"
    },
    "5e5dfb41fb887955ad3ca12a60b01356": {
      "source_id": "5e5dfb41fb887955ad3ca12a60b01356",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19547,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #164]: How well can language models write code?"
    },
    "8b7dc6e9c81d18c96d6b5adc6a2bd4b7": {
      "source_id": "8b7dc6e9c81d18c96d6b5adc6a2bd4b7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13679,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "How truthful is GPT-3? A benchmark for language models"
    },
    "b8d55b1700020ca4e45eeb46b1920844": {
      "source_id": "b8d55b1700020ca4e45eeb46b1920844",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10130,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Economic AI Safety"
    },
    "3e03f255912fb117be0b3c10df516c54": {
      "source_id": "3e03f255912fb117be0b3c10df516c54",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4036,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Immobile AI makes a move: anti-wireheading, ontology change, and model splinteri"
    },
    "d609ad78d952d7756aba74f6fcba28fd": {
      "source_id": "d609ad78d952d7756aba74f6fcba28fd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29095,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Goodhart Ethology"
    },
    "d02edebb7e42468f8b5a5d715a1a2ad0": {
      "source_id": "d02edebb7e42468f8b5a5d715a1a2ad0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61474,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Investigating AI Takeover Scenarios"
    },
    "7f3bd53639e082345b48d42dfb9046ce": {
      "source_id": "7f3bd53639e082345b48d42dfb9046ce",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13421,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The theory-practice gap"
    },
    "8b2d2f34c58c53314fde1d0d093e4e82": {
      "source_id": "8b2d2f34c58c53314fde1d0d093e4e82",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30837,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[Book Review] \"The Alignment Problem\" by Brian Christian"
    },
    "f06ecceae1b570cbe0c143d128e39053": {
      "source_id": "f06ecceae1b570cbe0c143d128e39053",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5864,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AI, learn to be conservative, then learn to be less so: reducing side-effects, l"
    },
    "56f632a542a87ca1b85f58bc8bf7c098": {
      "source_id": "56f632a542a87ca1b85f58bc8bf7c098",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2690,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Announcing the Vitalik Buterin Fellowships in AI Existential Safety!"
    },
    "797ef53546284e42a9ce763840a92aba": {
      "source_id": "797ef53546284e42a9ce763840a92aba",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42315,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "David Wolpert on Knowledge"
    },
    "ea7f52cf74b05478d28258d503a2f8b1": {
      "source_id": "ea7f52cf74b05478d28258d503a2f8b1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26612,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Redwood Research\u2019s current project"
    },
    "22796d09bf2b33bded8f73bbc0bc7878": {
      "source_id": "22796d09bf2b33bded8f73bbc0bc7878",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 18479,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #165]:\u00a0When large models are more likely to lie"
    },
    "e345d0a78beb4f2d3d46f8a2ac28355f": {
      "source_id": "e345d0a78beb4f2d3d46f8a2ac28355f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3273,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Pathways: Google's AGI"
    },
    "f2018605130d3dfc40034b5966e7a6e1": {
      "source_id": "f2018605130d3dfc40034b5966e7a6e1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50752,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Cognitive Biases in Large Language Models"
    },
    "0c07fca6f12fba6cd56aa643771088f6": {
      "source_id": "0c07fca6f12fba6cd56aa643771088f6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 92886,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 11 - Attainable Utility and Power with Alex Turner"
    },
    "618f5df2808384479a3bd9f87fcb8192": {
      "source_id": "618f5df2808384479a3bd9f87fcb8192",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22126,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AI takeoff story: a continuation of progress by other means"
    },
    "8e42ba5d79f78afb435dc7e394e0be83": {
      "source_id": "8e42ba5d79f78afb435dc7e394e0be83",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13306,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Selection Theorems: A Program For Understanding Agents"
    },
    "37c472100e3cac8b6d2edd89ce4ed810": {
      "source_id": "37c472100e3cac8b6d2edd89ce4ed810",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1208,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Collection of arguments to expect (outer and inner) alignment failure?"
    },
    "db3aaed0b092657cdc029ed0904b539a": {
      "source_id": "db3aaed0b092657cdc029ed0904b539a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46657,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Brain-inspired AGI and the \"lifetime anchor\""
    },
    "0e12e5ee7bf7fe538214b396e2d2159e": {
      "source_id": "0e12e5ee7bf7fe538214b396e2d2159e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7135,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Unsolved ML Safety Problems"
    },
    "15aec086e51c4e6faecfe3ecf9b89710": {
      "source_id": "15aec086e51c4e6faecfe3ecf9b89710",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23489,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A brief review of the reasons multi-objective RL could be important in AI Safety"
    },
    "c7c03ddf9b59cc0c4bcf70642ba8e7b4": {
      "source_id": "c7c03ddf9b59cc0c4bcf70642ba8e7b4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4567,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AI learns betrayal and how to avoid it"
    },
    "6476b8d4ff6938a53b71b835e85bed14": {
      "source_id": "6476b8d4ff6938a53b71b835e85bed14",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 82609,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "My take on Vanessa Kosoy's take on AGI safety"
    },
    "cc094f5fbfd7eb70ebeb40fae67fef6b": {
      "source_id": "cc094f5fbfd7eb70ebeb40fae67fef6b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33450,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Takeoff Speeds and Discontinuities"
    },
    "ba386f05916eb8adfda487ab8fc17835": {
      "source_id": "ba386f05916eb8adfda487ab8fc17835",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33809,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What Selection Theorems Do We Expect/Want?"
    },
    "342892949984eda928e951cd7f0c6748": {
      "source_id": "342892949984eda928e951cd7f0c6748",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6765,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Meta learning to gradient hack"
    },
    "8e1b6e70824f39f91d1a5a88ceed1cb5": {
      "source_id": "8e1b6e70824f39f91d1a5a88ceed1cb5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33071,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The Simulation Hypothesis Undercuts the SIA/Great Filter Doomsday Argument"
    },
    "bec23481b02866192dffd860a2962cbe": {
      "source_id": "bec23481b02866192dffd860a2962cbe",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4811,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Force neural nets to use models, then detect these"
    },
    "cdd39a64b5c2c53e0e226dbf3d5c6704": {
      "source_id": "cdd39a64b5c2c53e0e226dbf3d5c6704",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4000,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "We're Redwood Research, we do applied alignment research, AMA"
    },
    "b20f32dd2543639b6bbfbe8d24d2e67c": {
      "source_id": "b20f32dd2543639b6bbfbe8d24d2e67c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5711,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Preferences from (real and hypothetical) psychology papers"
    },
    "c775394505157aacc615e05f5f3191d6": {
      "source_id": "c775394505157aacc615e05f5f3191d6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16615,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Automated Fact Checking: A Look at the Field"
    },
    "2a20bf637d2a95f155ab93a1bb47fb35": {
      "source_id": "2a20bf637d2a95f155ab93a1bb47fb35",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6691,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Safety-capabilities tradeoff dials are inevitable in AGI"
    },
    "796cd4d44fbdcf6f0d7c04dd1bda124c": {
      "source_id": "796cd4d44fbdcf6f0d7c04dd1bda124c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 18831,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #166]: Is it crazy to claim we're in the most important century?"
    },
    "88afce05a21769ec868738213aa6472e": {
      "source_id": "88afce05a21769ec868738213aa6472e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7015,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Intelligence or Evolution?"
    },
    "9479fe2caf053543f3f099ea50e4b933": {
      "source_id": "9479fe2caf053543f3f099ea50e4b933",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30018,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "On Solving Problems Before They Appear: The Weird Epistemologies of Alignment"
    },
    "e21d0dcc064835a7647ba5c19856a42d": {
      "source_id": "e21d0dcc064835a7647ba5c19856a42d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29449,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Modeling Risks From Learned Optimization"
    },
    "99b5d7440ed67d3b504e37cf4146a349": {
      "source_id": "99b5d7440ed67d3b504e37cf4146a349",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3496,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[Proposal] Method of locating useful subnets in large models"
    },
    "ea9b0f92b3ec82df1cd1c80fd63b4d1e": {
      "source_id": "ea9b0f92b3ec82df1cd1c80fd63b4d1e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 913,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Memetic hazards of AGI architecture posts"
    },
    "0afa069b05fdde19c0ce409e71259d69": {
      "source_id": "0afa069b05fdde19c0ce409e71259d69",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38118,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Optimization Concepts in the Game of Life"
    },
    "9b8bb7d1bc4a06e3d395a18020e33c48": {
      "source_id": "9b8bb7d1bc4a06e3d395a18020e33c48",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23361,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Epistemic Strategies of Selection Theorems"
    },
    "db2bea21e8c3df7db80d45ca07d08749": {
      "source_id": "db2bea21e8c3df7db80d45ca07d08749",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5789,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[MLSN #1]: ICLR Safety Paper Roundup"
    },
    "92bd30912c7ecf36a439a9c21f03c6cc": {
      "source_id": "92bd30912c7ecf36a439a9c21f03c6cc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20714,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Truthful AI: Developing and governing AI that does not lie"
    },
    "10b177507847c3866c6f1ff85080e10b": {
      "source_id": "10b177507847c3866c6f1ff85080e10b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7119,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "On The Risks of Emergent Behavior in Foundation Models"
    },
    "f9598242868ee1652f03bdd8f82cdba9": {
      "source_id": "f9598242868ee1652f03bdd8f82cdba9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7129,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Beyond the human training distribution: would the AI CEO create almost-illegal t"
    },
    "377144b6c908f057b5028a25e3c86029": {
      "source_id": "377144b6c908f057b5028a25e3c86029",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 18975,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #167]:\u00a0Concrete ML safety problems and their relevance to x-risk"
    },
    "1fc6c6af4b07f158eee6998b6c9a1354": {
      "source_id": "1fc6c6af4b07f158eee6998b6c9a1354",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18815,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AGI Safety Fundamentals curriculum and application"
    },
    "1005825f80a420920913e8c222fc6bc7": {
      "source_id": "1005825f80a420920913e8c222fc6bc7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6656,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Emergent modularity and safety"
    },
    "c692b2d5e0dcb73a6f5506b0a31fea61": {
      "source_id": "c692b2d5e0dcb73a6f5506b0a31fea61",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11907,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Epistemic Strategies of Safety-Capabilities Tradeoffs"
    },
    "ec47715d3ff61b7d6eb68048c7624170": {
      "source_id": "ec47715d3ff61b7d6eb68048c7624170",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6215,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "General alignment plus human values, or alignment via human values?"
    },
    "c6d24ec4564cc0761907c4fab9043cee": {
      "source_id": "c6d24ec4564cc0761907c4fab9043cee",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41463,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Towards Deconfusing Gradient Hacking"
    },
    "1e1e9d0f48ab01eaa1e7bde7da35ac98": {
      "source_id": "1e1e9d0f48ab01eaa1e7bde7da35ac98",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28812,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Selfishness, preference falsification, and AI alignment"
    },
    "adea8ad1da45b846a620cc684c21959f": {
      "source_id": "adea8ad1da45b846a620cc684c21959f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19945,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #168]: Four technical topics for which Open Phil is soliciting grant proposa"
    },
    "ca5317adfcf2a974611e745e6cf6c0cc": {
      "source_id": "ca5317adfcf2a974611e745e6cf6c0cc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11128,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Request for proposals for projects in AI alignment that work with deep learning "
    },
    "25a02867ad29d482370dcaaa45940c66": {
      "source_id": "25a02867ad29d482370dcaaa45940c66",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32400,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Measuring and forecasting risks"
    },
    "355d212a093ad987e8e84d85f21c6bee": {
      "source_id": "355d212a093ad987e8e84d85f21c6bee",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23371,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Interpretability"
    },
    "efbc21c7607e2580844867ba9675cbfc": {
      "source_id": "efbc21c7607e2580844867ba9675cbfc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32889,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Truthful and honest AI"
    },
    "329e98f1c1cbd69e2f9613f770c816c4": {
      "source_id": "329e98f1c1cbd69e2f9613f770c816c4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3916,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A very crude deception eval is already passed"
    },
    "f341a70b550117a00e90dc87d68c68a0": {
      "source_id": "f341a70b550117a00e90dc87d68c68a0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5980,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Stuart Russell and Melanie Mitchell on Munk Debates"
    },
    "befb7ec295714c5a039192e94ab4bcfb": {
      "source_id": "befb7ec295714c5a039192e94ab4bcfb",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3197,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Apply to the ML for Alignment Bootcamp (MLAB) in Berkeley [Jan 3 - Jan 22]"
    },
    "77466047310526fd451c471a9d0f259f": {
      "source_id": "77466047310526fd451c471a9d0f259f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24067,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Modeling the impact of safety agendas"
    },
    "d8a9190e5a773b48db05fa7d6ea5eeef": {
      "source_id": "d8a9190e5a773b48db05fa7d6ea5eeef",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32067,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Drug addicts and deceptively aligned agents - a comparative analysis"
    },
    "05960e5f9196393d3d1a800f0a462246": {
      "source_id": "05960e5f9196393d3d1a800f0a462246",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13679,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Comments on OpenPhil's Interpretability RFP"
    },
    "becd92f65215697d087df23c70888a8d": {
      "source_id": "becd92f65215697d087df23c70888a8d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27172,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What are red flags for Neural Network suffering?"
    },
    "c1ad46c2335d8cd53b3ac9c3bc59140e": {
      "source_id": "c1ad46c2335d8cd53b3ac9c3bc59140e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 84526,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "How do we become confident in the safety of a machine learning system?"
    },
    "198fe3304796041a6fd4330f099d9c12": {
      "source_id": "198fe3304796041a6fd4330f099d9c12",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21639,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Possible research directions to improve the mechanistic explanation of neural ne"
    },
    "b6adb5a87398306d186283bc032cf716": {
      "source_id": "b6adb5a87398306d186283bc032cf716",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2928,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What exactly is GPT-3's base objective?"
    },
    "7203d61a8d680a71ba6d1fc8911bece0": {
      "source_id": "7203d61a8d680a71ba6d1fc8911bece0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 63106,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Discussion with Eliezer Yudkowsky on AGI interventions"
    },
    "be3d11a3c37493faa301e705498749cb": {
      "source_id": "be3d11a3c37493faa301e705498749cb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12783,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Why I'm excited about Redwood Research's current project"
    },
    "80d5e3793fa001407f1e6c216b9cef15": {
      "source_id": "80d5e3793fa001407f1e6c216b9cef15",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73947,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Comments on Carlsmith's \u201cIs power-seeking AI an existential risk?\u201d"
    },
    "9544e210063eff81990ecc81c10f27ed": {
      "source_id": "9544e210063eff81990ecc81c10f27ed",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6391,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What would we do if alignment were futile?"
    },
    "8ca703776527939dc69225d635fd7a90": {
      "source_id": "8ca703776527939dc69225d635fd7a90",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28382,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Attempted Gears Analysis of AGI Intervention Discussion With Eliezer"
    },
    "d3566036e4035f008669dd4415fe1555": {
      "source_id": "d3566036e4035f008669dd4415fe1555",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5479,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "My understanding of the alignment problem"
    },
    "57f1e8aa142b2c4903f78254256ff117": {
      "source_id": "57f1e8aa142b2c4903f78254256ff117",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 176656,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Ngo and Yudkowsky on alignment difficulty"
    },
    "d9a1ab5d908b25438fad0f9535c50207": {
      "source_id": "d9a1ab5d908b25438fad0f9535c50207",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12610,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A positive case for how we might succeed at prosaic AI alignment"
    },
    "0fc341e460df88dda3c705e1fb320900": {
      "source_id": "0fc341e460df88dda3c705e1fb320900",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1494,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Applications for AI Safety Camp 2022 Now Open!"
    },
    "e21f2f8dd816f716cb6a4fda781328e8": {
      "source_id": "e21f2f8dd816f716cb6a4fda781328e8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52768,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Satisficers Tend To Seek Power: Instrumental Convergence Via Retargetability"
    },
    "81f2f03ae927da33c240f4f856c5f4a8": {
      "source_id": "81f2f03ae927da33c240f4f856c5f4a8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 72356,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Ngo and Yudkowsky on AI capability gains"
    },
    "0460d70bee5fc14626ff0195e601405d": {
      "source_id": "0460d70bee5fc14626ff0195e601405d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25245,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "How To Get Into Independent Research On Alignment/Agency"
    },
    "b945bcf834d18813f1191bc3715341b0": {
      "source_id": "b945bcf834d18813f1191bc3715341b0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16583,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Goodhart: Endgame"
    },
    "a32e7b60bedcf9279949806a540e3fcd": {
      "source_id": "a32e7b60bedcf9279949806a540e3fcd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15951,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "More detailed proposal for measuring alignment of current models"
    },
    "15afd6bda96c9efb593cc62c52282165": {
      "source_id": "15afd6bda96c9efb593cc62c52282165",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34966,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A Certain Formalization of Corrigibility Is VNM-Incoherent"
    },
    "9da9dad787f00f40295e1dc8b2dac2c2": {
      "source_id": "9da9dad787f00f40295e1dc8b2dac2c2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10794,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "From language to ethics by automated reasoning"
    },
    "3a415b7a1e3da1504d060984c04e5085": {
      "source_id": "3a415b7a1e3da1504d060984c04e5085",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5107,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Some real examples of gradient hacking"
    },
    "1a16faa07a1373139da12cc2b4df336d": {
      "source_id": "1a16faa07a1373139da12cc2b4df336d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22410,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Morally underdefined situations can be deadly"
    },
    "e6d4806bd5d886b06db4d3f0d93dbbcf": {
      "source_id": "e6d4806bd5d886b06db4d3f0d93dbbcf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 110311,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Yudkowsky and Christiano discuss \"Takeoff Speeds\""
    },
    "82e9c8eba641dc6b8e2d914cf742ace2": {
      "source_id": "82e9c8eba641dc6b8e2d914cf742ace2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22129,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Potential Alignment mental tool: Keeping track of the types"
    },
    "81ebfbe85f31075c7d2c61fc6fad07c9": {
      "source_id": "81ebfbe85f31075c7d2c61fc6fad07c9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 71054,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Integrating Three Models of (Human) Cognition"
    },
    "9ef84728ce9e131852e0327695b7f959": {
      "source_id": "9ef84728ce9e131852e0327695b7f959",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7130,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AI Safety Needs Great Engineers"
    },
    "2eabc76154d4dcd1fa265b604084a776": {
      "source_id": "2eabc76154d4dcd1fa265b604084a776",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6988,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AI Tracker: monitoring current and near-future risks from superscale models"
    },
    "acf1f304a8a10fde87ee1ede9963d9b0": {
      "source_id": "acf1f304a8a10fde87ee1ede9963d9b0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 18653,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #169]:\u00a0Collaborating with humans without human data"
    },
    "30956b8a3f0775f6f635f8b83c4cb90f": {
      "source_id": "30956b8a3f0775f6f635f8b83c4cb90f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 125133,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Christiano, Cotra, and Yudkowsky on AI progress"
    },
    "32d51265cbf03e5e3a75f6225d4d0f7c": {
      "source_id": "32d51265cbf03e5e3a75f6225d4d0f7c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73373,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "EfficientZero: How It Works"
    },
    "4e14ac485260223817e24a50129066d3": {
      "source_id": "4e14ac485260223817e24a50129066d3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58245,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "larger language models may disappoint you [or, an eternally unfinished draft]"
    },
    "2aa212eb12217a1306f855ff1256a979": {
      "source_id": "2aa212eb12217a1306f855ff1256a979",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2716,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Solve Corrigibility Week"
    },
    "61dd2a2cff141a0ec5e78c09a5996c16": {
      "source_id": "61dd2a2cff141a0ec5e78c09a5996c16",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14134,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Comments on Allan Dafoe on AI Governance"
    },
    "05cacbf2af48063e033f5a99452d2352": {
      "source_id": "05cacbf2af48063e033f5a99452d2352",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 74684,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Soares, Tallinn, and Yudkowsky discuss AGI cognition"
    },
    "1a40b320e2cd1dff9f0ffcdf9adea3e9": {
      "source_id": "1a40b320e2cd1dff9f0ffcdf9adea3e9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23422,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Visible Thoughts Project and Bounty Announcement"
    },
    "55edfb8dbf7a2393ee5f87db0934e348": {
      "source_id": "55edfb8dbf7a2393ee5f87db0934e348",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27500,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "My take on higher-order game theory"
    },
    "5c1c4c2061d2ada606ba536affab55c6": {
      "source_id": "5c1c4c2061d2ada606ba536affab55c6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 100937,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Infra-Bayesian physicalism: a formal theory of naturalized induction"
    },
    "ef34a2c0213a72f2a63167c98cbabce1": {
      "source_id": "ef34a2c0213a72f2a63167c98cbabce1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 64840,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Infra-Bayesian physicalism: proofs part I"
    },
    "572cb5340b036136f2a26b9a40633273": {
      "source_id": "572cb5340b036136f2a26b9a40633273",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 66555,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Infra-Bayesian physicalism: proofs part II"
    },
    "5910429cff09cd9e64d500f2483e774d": {
      "source_id": "5910429cff09cd9e64d500f2483e774d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 217571,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 12 - AI Existential Risk with Paul Christiano"
    },
    "933db021caf33abdd780f4a1ea4302ee": {
      "source_id": "933db021caf33abdd780f4a1ea4302ee",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7506,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Morality is Scary"
    },
    "8c8ecad500ce185aab7f49f70b31a368": {
      "source_id": "8c8ecad500ce185aab7f49f70b31a368",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3026,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Sydney AI Safety Fellowship"
    },
    "47a22fa911712a1a2a1b7c7f9707cf1a": {
      "source_id": "47a22fa911712a1a2a1b7c7f9707cf1a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1993,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "$100/$50 rewards for good references"
    },
    "dbbb1cc15f2ba41a7fe246214caa5a83": {
      "source_id": "dbbb1cc15f2ba41a7fe246214caa5a83",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 4003,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[Linkpost] A General Language Assistant as a Laboratory for Alignment"
    },
    "7e8d75ca634b5d9f6363e56d82ee7566": {
      "source_id": "7e8d75ca634b5d9f6363e56d82ee7566",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37592,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Shulman and Yudkowsky on AI progress"
    },
    "31728989c28401bd01c9ff6cd44b07b5": {
      "source_id": "31728989c28401bd01c9ff6cd44b07b5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3206,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Misc. questions about EfficientZero"
    },
    "7a69975ac358d6def38ca48334eac909": {
      "source_id": "7a69975ac358d6def38ca48334eac909",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6124,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Agency: What it is and why it matters"
    },
    "3b3270a5f8eebb7bbfd59c60a9eb5d4f": {
      "source_id": "3b3270a5f8eebb7bbfd59c60a9eb5d4f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24325,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Behavior Cloning is Miscalibrated"
    },
    "fd8c6444de11fb404982273be3a82369": {
      "source_id": "fd8c6444de11fb404982273be3a82369",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47165,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Interpreting Yudkowsky on Deep vs Shallow Knowledge"
    },
    "716cacc7558e742f8e84390ed970c5d1": {
      "source_id": "716cacc7558e742f8e84390ed970c5d1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2498,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Are limited-horizon agents a good heuristic for the off-switch problem?"
    },
    "bcb28e29f0752ada0a354361dd47a5c2": {
      "source_id": "bcb28e29f0752ada0a354361dd47a5c2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4265,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "ML Alignment Theory Program under Evan Hubinger"
    },
    "f5794e8b7bcfd27a285b561463aa9076": {
      "source_id": "f5794e8b7bcfd27a285b561463aa9076",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37237,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A Framework to Explain Bayesian Models"
    },
    "0d6e227fda9784f466f978d681b9bde1": {
      "source_id": "0d6e227fda9784f466f978d681b9bde1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28849,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Modeling Failure Modes of High-Level Machine Intelligence"
    },
    "d696fa5d6209bc854f3029fd26e0733f": {
      "source_id": "d696fa5d6209bc854f3029fd26e0733f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10065,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Are there alternative to solving value transfer and extrapolation?"
    },
    "483a513fbb763c54360a8b40a335f28c": {
      "source_id": "483a513fbb763c54360a8b40a335f28c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7787,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Considerations on interaction between AI and expected value of the future"
    },
    "0e931ec789fa9d6b38cf7c4238ae2990": {
      "source_id": "0e931ec789fa9d6b38cf7c4238ae2990",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54177,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Theoretical Neuroscience For Alignment Theory"
    },
    "cf60dc934588ea9fc2d3ff88ea092f22": {
      "source_id": "cf60dc934588ea9fc2d3ff88ea092f22",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4100,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Some thoughts on why adversarial training might be useful"
    },
    "2483be04da9f735d8eef3a4222535fff": {
      "source_id": "2483be04da9f735d8eef3a4222535fff",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 16154,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[AN #170]:\u00a0Analyzing the argument for risk from power-seeking AI"
    },
    "4e681425d8ec08f094e83b2f03b004d8": {
      "source_id": "4e681425d8ec08f094e83b2f03b004d8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4846,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Finding the multiple ground truths of CoinRun and image classification"
    },
    "e6892d68f153b886ed7e97d3d9f43520": {
      "source_id": "e6892d68f153b886ed7e97d3d9f43520",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20724,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Introduction to inaccessible information"
    },
    "2d833750b9457d595a82da02d68fafa0": {
      "source_id": "2d833750b9457d595a82da02d68fafa0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14701,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Supervised learning and self-modeling: What's \"superhuman?\""
    },
    "258dc14301bd7b1fdb8d192b0f87d76b": {
      "source_id": "258dc14301bd7b1fdb8d192b0f87d76b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8124,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[MLSN #2]: Adversarial Training"
    },
    "edcca076ef370bedf492c1134d72f269": {
      "source_id": "edcca076ef370bedf492c1134d72f269",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56871,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Conversation on technology forecasting and gradualism"
    },
    "667fcae760f32ff2573a32b2fdfdf942": {
      "source_id": "667fcae760f32ff2573a32b2fdfdf942",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29860,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The Promise and Peril of Finite Sets"
    },
    "dc5380225685c309e084641c5ca08777": {
      "source_id": "dc5380225685c309e084641c5ca08777",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6358,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "There is essentially one best-validated theory of cognition."
    },
    "9271d4fa53466ccab287a07267912911": {
      "source_id": "9271d4fa53466ccab287a07267912911",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 75338,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Understanding Gradient Hacking"
    },
    "4e266af91b9a601a63a2165e0c23cbb1": {
      "source_id": "4e266af91b9a601a63a2165e0c23cbb1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29154,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The Plan"
    },
    "0f5e944dc9cbdabbffe4ba68b32a888a": {
      "source_id": "0f5e944dc9cbdabbffe4ba68b32a888a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51174,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Moore's Law, AI, and the pace of progress"
    },
    "dbab4dfd016e9fce276b28c4dd7c3528": {
      "source_id": "dbab4dfd016e9fce276b28c4dd7c3528",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27457,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Transforming myopic optimization to ordinary optimization - Do we want to seek c"
    },
    "ea906b55b438ea9bcd4daccdd3e1dca9": {
      "source_id": "ea906b55b438ea9bcd4daccdd3e1dca9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12089,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Some abstract, non-technical reasons to be non-maximally-pessimistic about AI al"
    },
    "1ca705c2acff9552d1732f18212b93c8": {
      "source_id": "1ca705c2acff9552d1732f18212b93c8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13632,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Redwood's Technique-Focused Epistemic Strategy"
    },
    "ed83df6d87a662d85dc75be7ffd28825": {
      "source_id": "ed83df6d87a662d85dc75be7ffd28825",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57390,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Hard-Coding Neural Computation"
    },
    "e7a9c88cdadf52354066fffad364217a": {
      "source_id": "e7a9c88cdadf52354066fffad364217a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8793,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Summary of the Acausal Attack Issue for AIXI"
    },
    "d4b929360a7722a0687d297ce1e20197": {
      "source_id": "d4b929360a7722a0687d297ce1e20197",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48746,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Understanding and controlling auto-induced distributional shift"
    },
    "90c07c6e3ab2e50a4b5ed6bce644e28b": {
      "source_id": "90c07c6e3ab2e50a4b5ed6bce644e28b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2860,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Solving Interpretability Week"
    },
    "a33f85fbeebf1bba9387ca5b7123513f": {
      "source_id": "a33f85fbeebf1bba9387ca5b7123513f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1860,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Language Model Alignment Research Internships"
    },
    "dbdacb864176b93cb3faa079e4f6664f": {
      "source_id": "dbdacb864176b93cb3faa079e4f6664f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15005,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Consequentialism & corrigibility"
    },
    "046f1cbaaae13a0cad840c353b1b67f6": {
      "source_id": "046f1cbaaae13a0cad840c353b1b67f6",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9169,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Interlude: Agents as Automobiles"
    },
    "d081be6f16c9dcec9dc3d363bedc37b4": {
      "source_id": "d081be6f16c9dcec9dc3d363bedc37b4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3059,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "ARC is hiring!"
    },
    "2812f20a00bd120b46eafe7b216c6d1c": {
      "source_id": "2812f20a00bd120b46eafe7b216c6d1c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1948,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "ARC's first technical report: Eliciting Latent Knowledge"
    },
    "d76cb64c3406f0c2dce8f2375d88a0a4": {
      "source_id": "d76cb64c3406f0c2dce8f2375d88a0a4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10815,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Should we rely on the speed prior for safety?"
    },
    "dcd7d7cfdf9137877db00c79674384d5": {
      "source_id": "dcd7d7cfdf9137877db00c79674384d5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33847,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Ngo's view on alignment difficulty"
    },
    "329e36a9b878be1b043b8dc3132c1384": {
      "source_id": "329e36a9b878be1b043b8dc3132c1384",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57271,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The Natural Abstraction Hypothesis: Implications and Evidence"
    },
    "f7c9a137407fbfecf88388ff749380d9": {
      "source_id": "f7c9a137407fbfecf88388ff749380d9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29611,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "My Overview of the AI Alignment Landscape: A Bird's Eye View"
    },
    "61d23a26ed2019bc51f0998ba4d57646": {
      "source_id": "61d23a26ed2019bc51f0998ba4d57646",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39049,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Universality and the \u201cFilter\u201d"
    },
    "aa5c7992702a5cecbdad3aba8b0bd890": {
      "source_id": "aa5c7992702a5cecbdad3aba8b0bd890",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 118064,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Motivations, Natural Selection, and Curriculum Engineering"
    },
    "f6ca4b0d7b1157731dd8a59eac496199": {
      "source_id": "f6ca4b0d7b1157731dd8a59eac496199",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18380,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Elicitation for Modeling Transformative AI Risks"
    },
    "6b47c1aaf4432a6ee913bad0a7d59020": {
      "source_id": "6b47c1aaf4432a6ee913bad0a7d59020",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 75000,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Evidence Sets: Towards Inductive-Biases based Analysis of Prosaic AGI"
    },
    "3ff3c2c59f3ad1baadeeeeb72de8ebcc": {
      "source_id": "3ff3c2c59f3ad1baadeeeeb72de8ebcc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22026,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Introducing the Principles of Intelligent Behaviour in Biological and Social Sys"
    },
    "66819fa6e5892022eecc310cdd914583": {
      "source_id": "66819fa6e5892022eecc310cdd914583",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22569,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Disentangling Perspectives On Strategy-Stealing in AI Safety"
    },
    "a0505f642fcc51bb5953dfcab3e6151a": {
      "source_id": "a0505f642fcc51bb5953dfcab3e6151a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8789,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Exploring Decision Theories With Counterfactuals and Dynamic Agent Self-Pointers"
    },
    "b356a1b15f398dd05687f8bf86c05439": {
      "source_id": "b356a1b15f398dd05687f8bf86c05439",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37200,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Don't Influence the Influencers!"
    },
    "9aca335953cbe7c46847c6deb43fc728": {
      "source_id": "9aca335953cbe7c46847c6deb43fc728",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11020,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Demanding and Designing Aligned Cognitive Architectures"
    },
    "18cb73b261db7d44b4ddd7de35cf2f06": {
      "source_id": "18cb73b261db7d44b4ddd7de35cf2f06",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7019,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Transformer Circuits"
    },
    "06c9bcc89b7a248c694ae1e9108432e8": {
      "source_id": "06c9bcc89b7a248c694ae1e9108432e8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12305,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Worst-case thinking in AI alignment"
    },
    "aee50e85550d593f1e8cedf5e7c00b6c": {
      "source_id": "aee50e85550d593f1e8cedf5e7c00b6c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 178694,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "2021 AI Alignment Literature Review and Charity Comparison"
    },
    "ce6dcd5640e1cfece34e827d3d94b4ef": {
      "source_id": "ce6dcd5640e1cfece34e827d3d94b4ef",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31083,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Reply to Eliezer on Biological Anchors"
    },
    "56b9fe0d46e19d86c10481fbe668979d": {
      "source_id": "56b9fe0d46e19d86c10481fbe668979d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61360,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Risks from AI persuasion"
    },
    "ad7ef9ccdffaf1fdf0da944589fa02d2": {
      "source_id": "ad7ef9ccdffaf1fdf0da944589fa02d2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59314,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "My Overview of the AI Alignment Landscape: Threat Models"
    },
    "536aced9d622f8bc759f8d3769332164": {
      "source_id": "536aced9d622f8bc759f8d3769332164",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7421,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Gradient Hacking via Schelling Goals"
    },
    "21ab14346c2b728d8dc291371d3a4a4b": {
      "source_id": "21ab14346c2b728d8dc291371d3a4a4b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10144,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Reverse-engineering using interpretability"
    },
    "1e0acf18349ce60b0cb8d4dbe7607d04": {
      "source_id": "1e0acf18349ce60b0cb8d4dbe7607d04",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10751,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Eliciting Latent Knowledge Via Hypothetical Sensors"
    },
    "c8607fce7a636978fcea8f8bb486b39a": {
      "source_id": "c8607fce7a636978fcea8f8bb486b39a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14708,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Counterexamples to some ELK proposals"
    },
    "143490a8465619ca61007e8624fd9b71": {
      "source_id": "143490a8465619ca61007e8624fd9b71",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8728,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "$1000 USD prize - Circular Dependency of Counterfactuals"
    },
    "40e96310daaafff5a4c51454eb73940b": {
      "source_id": "40e96310daaafff5a4c51454eb73940b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10084,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How an alien theory of mind might be unlearnable"
    },
    "452d2efe6ce62654ac6542f28d38eb91": {
      "source_id": "452d2efe6ce62654ac6542f28d38eb91",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16885,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Prizes for ELK proposals"
    },
    "038288d015e3e6cddba723a8c50416c6": {
      "source_id": "038288d015e3e6cddba723a8c50416c6",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2953,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Apply for research internships at ARC!"
    },
    "fb34441353afe5f684f47ed030763979": {
      "source_id": "fb34441353afe5f684f47ed030763979",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4975,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Promising posts on AF that have fallen through the cracks"
    },
    "f4620b358a20ccb432a3eb180cdf69f2": {
      "source_id": "f4620b358a20ccb432a3eb180cdf69f2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6574,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "More Is Different for AI"
    },
    "ba9d44fa118f2468568afb9b10bbb384": {
      "source_id": "ba9d44fa118f2468568afb9b10bbb384",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20694,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Importance of foresight evaluations within ELK"
    },
    "0c440cf859e29ce006ada5bd85aa38bc": {
      "source_id": "0c440cf859e29ce006ada5bd85aa38bc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11426,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Future ML Systems Will Be Qualitatively Different"
    },
    "27ca82db681522f79688f034fa79a36a": {
      "source_id": "27ca82db681522f79688f034fa79a36a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34381,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Understanding the two-head strategy for teaching ML to answer questions honestly"
    },
    "2f28d6796bb74b7b7b4f8a0f8a7e8589": {
      "source_id": "2f28d6796bb74b7b7b4f8a0f8a7e8589",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30159,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "New year, new research agenda post"
    },
    "cb1dc86a7f0eac21f8c7ea21dcfc6c1b": {
      "source_id": "cb1dc86a7f0eac21f8c7ea21dcfc6c1b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47408,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Greedy Doctor Problem... turns out to be relevant to the ELK problem?"
    },
    "3b85cfd2624314faf50de5e4deffd8bd": {
      "source_id": "3b85cfd2624314faf50de5e4deffd8bd",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5621,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Challenges with Breaking into MIRI-Style Research"
    },
    "8a8b23acae6d90f2a8c740a5972f15cb": {
      "source_id": "8a8b23acae6d90f2a8c740a5972f15cb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27623,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Truthful LMs as a warm-up for aligned AGI"
    },
    "167820cdf9d602234dde0e62aa403caf": {
      "source_id": "167820cdf9d602234dde0e62aa403caf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22954,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Scalar reward is not enough for aligned AGI"
    },
    "d27e65673b7c4e1b39bfbf3b090de528": {
      "source_id": "d27e65673b7c4e1b39bfbf3b090de528",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7006,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What's Up With Confusingly Pervasive Goal Directedness?"
    },
    "e7814785ac8aeae31ecde9b491ba73b9": {
      "source_id": "e7814785ac8aeae31ecde9b491ba73b9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 16284,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[AN #171]: Disagreements between alignment \"optimists\" and \"pessimists\""
    },
    "28ecf8fe9effa6358c7cd1d5189c6107": {
      "source_id": "28ecf8fe9effa6358c7cd1d5189c6107",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39930,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Instrumental Convergence For Realistic Agent Objectives"
    },
    "fd6a4a14ac33c548960771486a217a1e": {
      "source_id": "fd6a4a14ac33c548960771486a217a1e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1332,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "ELK First Round Contest Winners"
    },
    "03533f0c68cafeedbb1350148158cb97": {
      "source_id": "03533f0c68cafeedbb1350148158cb97",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48211,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Intro to brain-like-AGI safety] 1. What's the problem & Why work on it now?"
    },
    "51ec01ffe57cc162ed5b4fc1ee33d13b": {
      "source_id": "51ec01ffe57cc162ed5b4fc1ee33d13b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1777,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Arguments about Highly Reliable Agent Designs as a Useful Path to Artificial Int"
    },
    "415193773038670791961d1995834aa0": {
      "source_id": "415193773038670791961d1995834aa0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15500,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Causality, Transformative AI and alignment - part I"
    },
    "1de3d68b0622cd0ca9b98f56fdd9a4de": {
      "source_id": "1de3d68b0622cd0ca9b98f56fdd9a4de",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56290,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Intro to brain-like-AGI safety] 2. \u201cLearning from scratch\u201d in the brain"
    },
    "64ca59ffdee4ea1b6f8391a4f39604c7": {
      "source_id": "64ca59ffdee4ea1b6f8391a4f39604c7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 63469,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Thoughts on AGI safety from the top"
    },
    "76b1ff95c97432fca8760b275fb2529e": {
      "source_id": "76b1ff95c97432fca8760b275fb2529e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26759,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "QNR prospects are important for AI alignment research"
    },
    "37fcf702b81b72535fe0077037ce9b0f": {
      "source_id": "37fcf702b81b72535fe0077037ce9b0f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42250,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Alignment versus AI Alignment"
    },
    "ce5edb27216aeef4ed67abaee267b204": {
      "source_id": "ce5edb27216aeef4ed67abaee267b204",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5124,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Paradigm-building: Introduction"
    },
    "83f5dd75f5e4311f2972543327ed866a": {
      "source_id": "83f5dd75f5e4311f2972543327ed866a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48955,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How complex are myopic imitators?"
    },
    "a44215fd8f7bdf56229ebef58ff1d9e0": {
      "source_id": "a44215fd8f7bdf56229ebef58ff1d9e0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42492,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Hypothesis: gradient descent prefers general circuits"
    },
    "e4b033875f25df2d8db96aa0498eec27": {
      "source_id": "e4b033875f25df2d8db96aa0498eec27",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54564,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Intro to brain-like-AGI safety] 3. Two subsystems: Learning & Steering"
    },
    "02b9df000745fb392dbf0eebd8719548": {
      "source_id": "02b9df000745fb392dbf0eebd8719548",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35627,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Inferring utility functions from locally non-transitive preferences"
    },
    "07736e961db61517f0d7c97bd0947160": {
      "source_id": "07736e961db61517f0d7c97bd0947160",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17350,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A summary of aligning narrowly superhuman models"
    },
    "d868fc0903598e62ce2d4e881d53280e": {
      "source_id": "d868fc0903598e62ce2d4e881d53280e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27236,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Some Hacky ELK Ideas"
    },
    "70350e2922fe0e788eac761944d508cd": {
      "source_id": "70350e2922fe0e788eac761944d508cd",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6732,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is ELK enough? Diamond, Matrix and Child AI"
    },
    "85e66f347a8352ab3c813f39dd7aaf4b": {
      "source_id": "85e66f347a8352ab3c813f39dd7aaf4b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28742,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Intro to brain-like-AGI safety] 4. The \u201cshort-term predictor\u201d"
    },
    "1faa081097385be7bf06a3994590e3fa": {
      "source_id": "1faa081097385be7bf06a3994590e3fa",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3993,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Compute Trends Across Three eras of Machine Learning"
    },
    "4db4f9ff307bd8f5ea5df3e6e8d45909": {
      "source_id": "4db4f9ff307bd8f5ea5df3e6e8d45909",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61829,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Implications of automated ontology identification"
    },
    "56296b0711612cc38dac2b28a7e00cd3": {
      "source_id": "56296b0711612cc38dac2b28a7e00cd3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2865,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Alignment researchers, how useful is extra compute for you?"
    },
    "7a0a8ad3a348feef216acc842112404c": {
      "source_id": "7a0a8ad3a348feef216acc842112404c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1269,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Big Picture Of Alignment (Talk Part 1)"
    },
    "b15af40d513cb2772ed9eaf876bf0d2e": {
      "source_id": "b15af40d513cb2772ed9eaf876bf0d2e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 236,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Favorite / most obscure research on understanding DNNs?"
    },
    "4df030f09db83b15078c1bacf2cead42": {
      "source_id": "4df030f09db83b15078c1bacf2cead42",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17430,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Alignment research exercises"
    },
    "7b7a22177c6b68439aa6a0272c007251": {
      "source_id": "7b7a22177c6b68439aa6a0272c007251",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 64358,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Ngo and Yudkowsky on scientific reasoning and pivotal acts"
    },
    "9268d3aa134f130679006c2da3868552": {
      "source_id": "9268d3aa134f130679006c2da3868552",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40469,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "ELK Proposal: Thinking Via A Human Imitator"
    },
    "9b6b2d018aa9ce782a2c82eed672a828": {
      "source_id": "9b6b2d018aa9ce782a2c82eed672a828",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48935,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Intro to brain-like-AGI safety] 5. The \u201clong-term predictor\u201d, and TD learning"
    },
    "2bf060b9b784c124a80c9b9e85142db7": {
      "source_id": "2bf060b9b784c124a80c9b9e85142db7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1895,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Transformer inductive biases & RASP"
    },
    "0244595a63f37c60029cfcd5af0300b3": {
      "source_id": "0244595a63f37c60029cfcd5af0300b3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2530,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Big Picture Of Alignment (Talk Part 2)"
    },
    "8e1919afa0d740b0fc74efe587335d97": {
      "source_id": "8e1919afa0d740b0fc74efe587335d97",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22833,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How I Formed My Own Views About AI Safety"
    },
    "cb15288e2438764ff1d23ef93d7f1d5d": {
      "source_id": "cb15288e2438764ff1d23ef93d7f1d5d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 168219,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Shah and Yudkowsky on alignment failures"
    },
    "cee6825497c3bc8619eed3d2543d1df9": {
      "source_id": "cee6825497c3bc8619eed3d2543d1df9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 799,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Late 2021 MIRI Conversations: AMA / Discussion"
    },
    "eb138a2057e47522867fb4a44e9a7672": {
      "source_id": "eb138a2057e47522867fb4a44e9a7672",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36935,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Musings on the Speed Prior"
    },
    "3ecb95080e1aad5d2551ba6c673cf7bd": {
      "source_id": "3ecb95080e1aad5d2551ba6c673cf7bd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35799,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Intro to brain-like-AGI safety] 6. Big picture of motivation, decision-making, "
    },
    "fbe4d4e683cba0a73767cd9fd841199e": {
      "source_id": "fbe4d4e683cba0a73767cd9fd841199e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30502,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Projecting compute trends in Machine Learning"
    },
    "e641343a3039cfe2c0584eb20959a8dd": {
      "source_id": "e641343a3039cfe2c0584eb20959a8dd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11073,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[MLSN #3]: NeurIPS Safety Paper Roundup"
    },
    "ac7c80db3284c0550a92289a0be34bce": {
      "source_id": "ac7c80db3284c0550a92289a0be34bce",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22079,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Value extrapolation, concept extrapolation, model splintering"
    },
    "b23978374b53f6dad7550bf00a5fef37": {
      "source_id": "b23978374b53f6dad7550bf00a5fef37",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43215,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "ELK prize results"
    },
    "75a22bf8d7940c363dc09929af1475b9": {
      "source_id": "75a22bf8d7940c363dc09929af1475b9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21988,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Intro to brain-like-AGI safety] 7. From hardcoded drives to foresighted plans: "
    },
    "e7e05580b55f85a2ea69166199791259": {
      "source_id": "e7e05580b55f85a2ea69166199791259",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1421,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "It Looks Like You're Trying To Take Over The World"
    },
    "dcb9a67af6d4e4897afcea47f54044df": {
      "source_id": "dcb9a67af6d4e4897afcea47f54044df",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9106,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Rephrasing Of and Footnote To An Embedded Agency Proposal"
    },
    "9ae79b9bed10b0915834e604af5c449a": {
      "source_id": "9ae79b9bed10b0915834e604af5c449a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9663,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Longlist of Theories of Impact for Interpretability"
    },
    "87832a74ed5cbbe8c6b6e22b2a8c769f": {
      "source_id": "87832a74ed5cbbe8c6b6e22b2a8c769f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33356,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Intro to brain-like-AGI safety] 8. Takeaways from neuro 1/2: On AGI development"
    },
    "d9de2a7b86a23c81ede6bd10ad4d3679": {
      "source_id": "d9de2a7b86a23c81ede6bd10ad4d3679",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54934,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Intro to brain-like-AGI safety] 9. Takeaways from neuro 2/2: On AGI motivation"
    },
    "5f1904bab40c1aa5c4b9066ea59113ac": {
      "source_id": "5f1904bab40c1aa5c4b9066ea59113ac",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3457,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A survey of tool use and workflows in alignment research"
    },
    "a386c6961dcaa57751c63fd58414b813": {
      "source_id": "a386c6961dcaa57751c63fd58414b813",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15800,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why Agent Foundations? An Overly Abstract Explanation"
    },
    "98dda839ee97715cb18d244d68ff5ca6": {
      "source_id": "98dda839ee97715cb18d244d68ff5ca6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18623,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Compute Governance: The Role of Commodity Hardware"
    },
    "4a5f891275734e5662e3801acd57a493": {
      "source_id": "4a5f891275734e5662e3801acd57a493",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3490,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[ASoT] Some ways ELK could still be solvable in practice"
    },
    "bcb06697a2b39301567dea87b8073d82": {
      "source_id": "bcb06697a2b39301567dea87b8073d82",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6836,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[ASoT] Searching for consequentialist structure"
    },
    "a910b3113c82c3c42546937a35bf6c7d": {
      "source_id": "a910b3113c82c3c42546937a35bf6c7d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12683,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[ASoT] Some thoughts about deceptive mesaoptimization"
    },
    "291700ab0ada97d765faf0ed5a575bcc": {
      "source_id": "291700ab0ada97d765faf0ed5a575bcc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13881,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Vaniver's ELK Submission"
    },
    "f7ee2e2ac2ba5fa2cc5f5a1a464d09f6": {
      "source_id": "f7ee2e2ac2ba5fa2cc5f5a1a464d09f6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47458,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Towards a better circuit prior: Improving on ELK state-of-the-art"
    },
    "4c6945df5983aa98298d125c33173769": {
      "source_id": "4c6945df5983aa98298d125c33173769",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30816,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Gears-Level Mental Models of Transformer Interpretability"
    },
    "0a5cd119ae93fff64462a28c0156b63d": {
      "source_id": "0a5cd119ae93fff64462a28c0156b63d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48583,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Intro to brain-like-AGI safety] 10. The alignment problem"
    },
    "a6e977e32df2fa4cf3ae6239030a4014": {
      "source_id": "a6e977e32df2fa4cf3ae6239030a4014",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3456,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[ASoT] Some thoughts about LM monologue limitations and ELK"
    },
    "96ba45b464357df659893fa2d25ef5d3": {
      "source_id": "96ba45b464357df659893fa2d25ef5d3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12407,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Procedurally evaluating factual accuracy: a request for research"
    },
    "96c7968a939062e355f3cbed94f1a9f9": {
      "source_id": "96c7968a939062e355f3cbed94f1a9f9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13353,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "ELK Computational Complexity: Three Levels of Difficulty"
    },
    "4f680eef68bcbcdd59534343d28b7574": {
      "source_id": "4f680eef68bcbcdd59534343d28b7574",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 85314,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 13 - First Principles of AGI Safety with Richard Ngo"
    },
    "dce5c58a691f5dfa04fce9c53d6f54bc": {
      "source_id": "dce5c58a691f5dfa04fce9c53d6f54bc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28457,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Optimality is the tiger, and agents are its teeth"
    },
    "90bc869be603f7e6d991ddc6e5e53a3a": {
      "source_id": "90bc869be603f7e6d991ddc6e5e53a3a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6114,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Governance across Slow/Fast Takeoff and Easy/Hard Alignment spectra"
    },
    "db9bae3c1e93e77188d568ff1e66548e": {
      "source_id": "db9bae3c1e93e77188d568ff1e66548e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33859,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "On Agent Incentives to Manipulate Human Feedback in Multi-Agent Reward Learning "
    },
    "fa2e8aab8b9144ca035e415c1b4c233c": {
      "source_id": "fa2e8aab8b9144ca035e415c1b4c233c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14521,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Theories of Modularity in the Biological Literature"
    },
    "661b0abb05e4879122db0436151ef791": {
      "source_id": "661b0abb05e4879122db0436151ef791",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31543,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Project Intro: Selection Theorems for Modularity"
    },
    "d27ed8bb825e58bbd92c6bdf91572ffa": {
      "source_id": "d27ed8bb825e58bbd92c6bdf91572ffa",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5803,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Call For Distillers"
    },
    "13f4e825d0292ef35d8570e9d960fd97": {
      "source_id": "13f4e825d0292ef35d8570e9d960fd97",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20851,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Supervise Process, not Outcomes"
    },
    "e94404eedd5bfad3cfd2aef012a66b83": {
      "source_id": "e94404eedd5bfad3cfd2aef012a66b83",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 96462,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 14 - Infra-Bayesian Physicalism with Vanessa Kosoy"
    },
    "cc440b9c70aa86c1b32b94fae710ada6": {
      "source_id": "cc440b9c70aa86c1b32b94fae710ada6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20856,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Intro to brain-like-AGI safety] 11. Safety \u2260 alignment (but they\u2019re close!)"
    },
    "07575b125e9f87f5cf6b7c450b0bdbb0": {
      "source_id": "07575b125e9f87f5cf6b7c450b0bdbb0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 322,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Link] Why I\u2019m excited about AI-assisted human feedback"
    },
    "a4c5bd77b317246670b4a729bd978be7": {
      "source_id": "a4c5bd77b317246670b4a729bd978be7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 384,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Link] A minimal viable product for alignment"
    },
    "13146b6d46152bca07e3915f4e6123c5": {
      "source_id": "13146b6d46152bca07e3915f4e6123c5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62449,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Truthfulness, standards and credibility"
    },
    "f4d4c222e7a274bc0f3e333186201c50": {
      "source_id": "f4d4c222e7a274bc0f3e333186201c50",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4145,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How  BoMAI Might fail"
    },
    "b02f0ca8f89ce7292aee27faa21842ed": {
      "source_id": "b02f0ca8f89ce7292aee27faa21842ed",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8094,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[ASoT] Some thoughts about imperfect world modeling"
    },
    "7e18090be931e29fc8241a26a4c148c4": {
      "source_id": "7e18090be931e29fc8241a26a4c148c4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12959,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Productive Mistakes, Not Perfect Answers"
    },
    "392847f52d00e3c1a2ca999a78ec300f": {
      "source_id": "392847f52d00e3c1a2ca999a78ec300f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29136,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Different perspectives on concept extrapolation"
    },
    "0daa454cbd11a885ac066b27a64d19e1": {
      "source_id": "0daa454cbd11a885ac066b27a64d19e1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7502,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "We Are Conjecture, A New Alignment Research Startup"
    },
    "5eaa29342322bfa148945bd0a71f31cf": {
      "source_id": "5eaa29342322bfa148945bd0a71f31cf",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1597,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AIs should learn human preferences, not biases"
    },
    "65749323dd1f32775a2cc5a7d600302f": {
      "source_id": "65749323dd1f32775a2cc5a7d600302f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3801,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Language Model Tools for Alignment Research"
    },
    "57694468b5a27ae7d9511df4578b67cf": {
      "source_id": "57694468b5a27ae7d9511df4578b67cf",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1093,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AMA Conjecture, A New Alignment Startup"
    },
    "5f63aa9bedd426bd73e0949a6698fe0d": {
      "source_id": "5f63aa9bedd426bd73e0949a6698fe0d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27569,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Elicit: Language Models as Research Assistants"
    },
    "9e211fe665c9947fbd7301a550553d09": {
      "source_id": "9e211fe665c9947fbd7301a550553d09",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4162,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A broad basin of attraction around human values?"
    },
    "d4e69c85639a90ddfc2ff0f5524c7446": {
      "source_id": "d4e69c85639a90ddfc2ff0f5524c7446",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15577,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Reward model hacking as a challenge for reward learning"
    },
    "095033de8cb4fb7a24570374ae286f46": {
      "source_id": "095033de8cb4fb7a24570374ae286f46",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2101,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Small Negative Result on Debate"
    },
    "5d53e2b7b111b0f256c7f0069cf08acb": {
      "source_id": "5d53e2b7b111b0f256c7f0069cf08acb",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9301,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Another list of theories of impact for interpretability"
    },
    "206fb01d3475aa8df9279696d31ebdb2": {
      "source_id": "206fb01d3475aa8df9279696d31ebdb2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2072,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What to include in a guest lecture on existential risks from AI?"
    },
    "3f249a0b9e72bb3195236a6286fcaa31": {
      "source_id": "3f249a0b9e72bb3195236a6286fcaa31",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4014,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Takeoff speeds have a huge effect on what it means to work on AI x-risk"
    },
    "953523a8e7b75c15b8d7e4306d284c53": {
      "source_id": "953523a8e7b75c15b8d7e4306d284c53",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6438,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Early 2022 Paper Round-up"
    },
    "376d20301ca8bfabed81b9d9fca01dbf": {
      "source_id": "376d20301ca8bfabed81b9d9fca01dbf",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8371,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Refine: An Incubator for Conceptual Alignment Research Bets"
    },
    "aca96838f38c2d640470d4a18079609b": {
      "source_id": "aca96838f38c2d640470d4a18079609b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27525,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Some reasons why a predictor wants to be a consequentialist"
    },
    "5bcf2b287c7f36ac165faf06b0dd0cc5": {
      "source_id": "5bcf2b287c7f36ac165faf06b0dd0cc5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10850,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Everything I Need To Know About Takeoff Speeds I Learned From Air Conditioner Ra"
    },
    "33569510e971b149257b2ab2567ba9a6": {
      "source_id": "33569510e971b149257b2ab2567ba9a6",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2047,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Concept extrapolation: key posts"
    },
    "2badc9b84e314ef36c7b6e6e8ed8fdf6": {
      "source_id": "2badc9b84e314ef36c7b6e6e8ed8fdf6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13161,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "\u201cPivotal Act\u201d Intentions: Negative Consequences and Fallacious Arguments"
    },
    "ff403a63935a605c19593ac04a81fa18": {
      "source_id": "ff403a63935a605c19593ac04a81fa18",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36585,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Intro to brain-like-AGI safety] 12. Two paths forward: \u201cControlled AGI\u201d and \u201cSo"
    },
    "c7b7e6cf691a3b5c8f702e8f7c24a121": {
      "source_id": "c7b7e6cf691a3b5c8f702e8f7c24a121",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5870,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "For every choice of AGI difficulty, conditioning on gradual take-off implies sho"
    },
    "8f91ea40fad506ad487c4fb95fdb8d98": {
      "source_id": "8f91ea40fad506ad487c4fb95fdb8d98",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61851,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Infra-Miscellanea"
    },
    "50b10948515ea82915f8524c1ae0e3f9": {
      "source_id": "50b10948515ea82915f8524c1ae0e3f9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50570,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Infra-Topology"
    },
    "ca847eee207168fe9a6ef165e41bf0ad": {
      "source_id": "ca847eee207168fe9a6ef165e41bf0ad",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8014,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[ASoT] Consequentialist models as a superset of mesaoptimizers"
    },
    "4e4c231ec50e66f166d1cb89ad1206da": {
      "source_id": "4e4c231ec50e66f166d1cb89ad1206da",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11070,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Intuitions about solving hard problems"
    },
    "8f150d983a9c597733bfae234f1c5f92": {
      "source_id": "8f150d983a9c597733bfae234f1c5f92",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9053,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Framings of Deceptive Alignment"
    },
    "399afd3da6f540c1b87a42cd1c4f39ca": {
      "source_id": "399afd3da6f540c1b87a42cd1c4f39ca",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6711,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[$20K in Prizes] AI Safety Arguments Competition"
    },
    "9ff9d35db58040fc92143422f71d4891": {
      "source_id": "9ff9d35db58040fc92143422f71d4891",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13985,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why Copilot Accelerates Timelines"
    },
    "8a02529f9bde6a7805b979fa84b5f8fa": {
      "source_id": "8a02529f9bde6a7805b979fa84b5f8fa",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5455,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "SERI ML Alignment Theory Scholars Program 2022"
    },
    "b684eb165fda0974f3b81f4a73611774": {
      "source_id": "b684eb165fda0974f3b81f4a73611774",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38379,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Intro to brain-like-AGI safety] 13. Symbol grounding & human social instincts"
    },
    "2a46a8e18e80615e76292010fe253724": {
      "source_id": "2a46a8e18e80615e76292010fe253724",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18747,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Law-Following AI 1: Sequence Introduction and Structure"
    },
    "3661f02bc5bd97f2798036ce6b754055": {
      "source_id": "3661f02bc5bd97f2798036ce6b754055",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13708,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Law-Following AI 2: Intent Alignment + Superintelligence \u2192 Lawless AI (By Defaul"
    },
    "74bcf969ab264d292f3702ed2afddbd7": {
      "source_id": "74bcf969ab264d292f3702ed2afddbd7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6476,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Law-Following AI 3: Lawless AI Agents Undermine Stabilizing Agreements"
    },
    "f6ad2b95ec7ff1b3018ae57782cf86cf": {
      "source_id": "f6ad2b95ec7ff1b3018ae57782cf86cf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42250,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Speed + Simplicity Prior is probably anti-deceptive"
    },
    "28c50c4252cb8b26cee98dd8d93fdb26": {
      "source_id": "28c50c4252cb8b26cee98dd8d93fdb26",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19879,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Prize for Alignment Research Tasks"
    },
    "f31244aa7efdb605e8c6f9b0210ebe05": {
      "source_id": "f31244aa7efdb605e8c6f9b0210ebe05",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40215,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Learning the smooth prior"
    },
    "caee676f4de2cb931ff38b7932bee953": {
      "source_id": "caee676f4de2cb931ff38b7932bee953",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6310,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Introducing the ML Safety Scholars Program"
    },
    "c8eefb6cc3a2d26f9f42b7625dddb85e": {
      "source_id": "c8eefb6cc3a2d26f9f42b7625dddb85e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19169,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "High-stakes alignment via adversarial training [Redwood Research report]"
    },
    "50963ff846fd21e404994d5d414e6612": {
      "source_id": "50963ff846fd21e404994d5d414e6612",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10779,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Apply to the second iteration of the ML for Alignment Bootcamp (MLAB 2) in Berke"
    },
    "93012c36052288ae5966f5a9f45ac525": {
      "source_id": "93012c36052288ae5966f5a9f45ac525",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 70701,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Open Problems in Negative Side Effect Minimization"
    },
    "2a5794e1ea93b2b34dbe8183da7fca82": {
      "source_id": "2a5794e1ea93b2b34dbe8183da7fca82",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4977,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The case for becoming a black-box investigator of language models"
    },
    "71f7e906aae63031cecdceaa318eb2ce": {
      "source_id": "71f7e906aae63031cecdceaa318eb2ce",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34271,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Elementary Infra-Bayesianism"
    },
    "ab6c549e4e9160d9ed3e4488bab2b8f7": {
      "source_id": "ab6c549e4e9160d9ed3e4488bab2b8f7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13413,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Updating Utility Functions"
    },
    "1a076c9e9a8d1e6f979436d9e941363c": {
      "source_id": "1a076c9e9a8d1e6f979436d9e941363c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1617,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Jobs: Help scale up LM alignment research at NYU"
    },
    "0899f3f56eed9eeebe8b4c5a28a7c723": {
      "source_id": "0899f3f56eed9eeebe8b4c5a28a7c723",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12762,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Introduction to Pragmatic AI Safety [Pragmatic AI Safety #1]"
    },
    "335dd68cf5f59664808dd673bcdf89c4": {
      "source_id": "335dd68cf5f59664808dd673bcdf89c4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 78936,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Bird's Eye View of the ML Field [Pragmatic AI Safety #2]"
    },
    "9ff3b9cf2addde5d63dc6074a1a44c11": {
      "source_id": "9ff3b9cf2addde5d63dc6074a1a44c11",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18687,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The limits of AI safety via debate"
    },
    "3454e6614bf8983908d3bf4eed31bec0": {
      "source_id": "3454e6614bf8983908d3bf4eed31bec0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42455,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Intro to brain-like-AGI safety] 14. Controlled AGI"
    },
    "194f38b20c7386c448cf97752ef17fde": {
      "source_id": "194f38b20c7386c448cf97752ef17fde",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2941,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Deepmind's Gato: Generalist Agent"
    },
    "538b9b748abe64b0624598e6ee29a576": {
      "source_id": "538b9b748abe64b0624598e6ee29a576",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19321,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Introduction to the sequence: Interpretability Research for the Most Important C"
    },
    "9627c97065d81191df68057f8295fb7a": {
      "source_id": "9627c97065d81191df68057f8295fb7a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 154416,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Interpretability\u2019s Alignment-Solving Potential: Analysis of 7 Scenarios"
    },
    "7d2c4c43fde53c4fb6ee6b574769c328": {
      "source_id": "7d2c4c43fde53c4fb6ee6b574769c328",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20117,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "DeepMind is hiring for the Scalable Alignment and Alignment Teams"
    },
    "744f58f340e54e5e10118d8b5411e548": {
      "source_id": "744f58f340e54e5e10118d8b5411e548",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33097,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "An observation about Hubinger et al.'s framework for learned optimization"
    },
    "4bbe665bd64e3b5de81c5a719302c733": {
      "source_id": "4bbe665bd64e3b5de81c5a719302c733",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44929,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Agency As a Natural Abstraction"
    },
    "4531836302574af063ddc103a993b807": {
      "source_id": "4531836302574af063ddc103a993b807",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5011,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Alignment as Constraints"
    },
    "de8a66243addc3e3be4f38f7fbb526c3": {
      "source_id": "de8a66243addc3e3be4f38f7fbb526c3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4877,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Frame for Take-Off Speeds to inform compute governance & scaling alignment"
    },
    "7c44ebe3a82149e7880716afa13eb4a5": {
      "source_id": "7c44ebe3a82149e7880716afa13eb4a5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24948,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Clarifying the confusion around inner alignment"
    },
    "6b30dd1ce01a0dd3dc705af780ef317d": {
      "source_id": "6b30dd1ce01a0dd3dc705af780ef317d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26882,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Proxy misspecification and the capabilities vs. value learning race"
    },
    "fb49c8713c399e9c874d7b8990a720b1": {
      "source_id": "fb49c8713c399e9c874d7b8990a720b1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35302,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Intro to brain-like-AGI safety] 15. Conclusion: Open problems, how to help, AMA"
    },
    "f8f4ae1ea6ca8963e675b461472e247d": {
      "source_id": "f8f4ae1ea6ca8963e675b461472e247d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5732,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Actionable-guidance and roadmap recommendations for the NIST AI Risk Management "
    },
    "da54f117676edbcccd72aaca0553f8e0": {
      "source_id": "da54f117676edbcccd72aaca0553f8e0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19055,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Gato's Generalisation: Predictions and Experiments I'd Like to See"
    },
    "76e00c16673d9f054082ce440d0f5a1c": {
      "source_id": "76e00c16673d9f054082ce440d0f5a1c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2041,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How to get into AI safety research"
    },
    "c33d8de28a3ee484c82083d973ee9b7e": {
      "source_id": "c33d8de28a3ee484c82083d973ee9b7e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36821,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How RL Agents Behave When Their Actions Are Modified? [Distillation post]"
    },
    "387e01631b10ca26aa6c15c71c6eb9ed": {
      "source_id": "387e01631b10ca26aa6c15c71c6eb9ed",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36044,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Adversarial attacks and optimal control"
    },
    "1cb8cfc11c9a75c585668d014434faac": {
      "source_id": "1cb8cfc11c9a75c585668d014434faac",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 106678,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 15 - Natural Abstractions with John Wentworth"
    },
    "34ad7f86a999f44af22a77f765cf200e": {
      "source_id": "34ad7f86a999f44af22a77f765cf200e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43140,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Complex Systems for AI Safety [Pragmatic AI Safety #3]"
    },
    "027507efc5639b69d03cfa774e355a1d": {
      "source_id": "027507efc5639b69d03cfa774e355a1d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36213,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The No Free Lunch theorems and their Razor"
    },
    "793adefe7a1eb5c7d056fc313ea9bfc1": {
      "source_id": "793adefe7a1eb5c7d056fc313ea9bfc1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10161,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "autonomy: the missing AGI ingredient?"
    },
    "9293c270df2306e21b13945b423d0e49": {
      "source_id": "9293c270df2306e21b13945b423d0e49",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43168,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "RL with KL penalties is better seen as Bayesian inference"
    },
    "ef1be1c5fe37111088ffe0e885601ce1": {
      "source_id": "ef1be1c5fe37111088ffe0e885601ce1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15312,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Problem With The Current State of AGI Definitions"
    },
    "d508327264bdf440e2fb046a5167a3f6": {
      "source_id": "d508327264bdf440e2fb046a5167a3f6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46503,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Reshaping the AI Industry"
    },
    "36502e8e71e358050f49e8f9ce82c05e": {
      "source_id": "36502e8e71e358050f49e8f9ce82c05e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27442,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Six Dimensions of Operational Adequacy in AGI Projects"
    },
    "5fbbfaf6e8cc2dda25f8abb53020c46f": {
      "source_id": "5fbbfaf6e8cc2dda25f8abb53020c46f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 70428,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Perform Tractable Research While Avoiding Capabilities Externalities [Pragmatic "
    },
    "d285610e7c6d7e953bd3a407dbf4af42": {
      "source_id": "d285610e7c6d7e953bd3a407dbf4af42",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9871,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Paper: Teaching GPT3 to express uncertainty in words"
    },
    "6c64a132b9aa65d0dd4ed1fbece6bb3d": {
      "source_id": "6c64a132b9aa65d0dd4ed1fbece6bb3d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20761,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Paradigms of AI alignment: components and enablers"
    },
    "7561f537b78015124ff569c7c555d1cc": {
      "source_id": "7561f537b78015124ff569c7c555d1cc",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8090,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Confused why a \"capabilities research is good for alignment progress\" position i"
    },
    "cc6371f74b7d20faf6e600879307b0b5": {
      "source_id": "cc6371f74b7d20faf6e600879307b0b5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3907,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The prototypical catastrophic AI action is getting root access to its datacenter"
    },
    "28ed16e008af5f70586389c304a8ba1f": {
      "source_id": "28ed16e008af5f70586389c304a8ba1f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4903,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Adversarial training, importance sampling, and anti-adversarial training for AI "
    },
    "111e80093c0d9a283cd073e03ff35abe": {
      "source_id": "111e80093c0d9a283cd073e03ff35abe",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10451,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[MLSN #4]: Many New Interpretability Papers, Virtual Logit Matching, Rationaliza"
    },
    "013b2d33d1ecb284b40891bf15d8500a": {
      "source_id": "013b2d33d1ecb284b40891bf15d8500a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11604,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing the Alignment of Complex Systems Research Group"
    },
    "16c2c71fedd15764d96fabcc8f57a04b": {
      "source_id": "16c2c71fedd15764d96fabcc8f57a04b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4282,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Deep Learning Systems Are Not Less Interpretable Than Logic/Probability/Etc"
    },
    "06dad18a48c4a7d97b05af695948c80a": {
      "source_id": "06dad18a48c4a7d97b05af695948c80a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56742,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AGI Ruin: A List of Lethalities"
    },
    "7112cbcd07b8c6661044cf0d93f093e7": {
      "source_id": "7112cbcd07b8c6661044cf0d93f093e7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22057,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Epistemological Vigilance for Alignment"
    },
    "a9d7feb3d7eefa079d2030b50896af0f": {
      "source_id": "a9d7feb3d7eefa079d2030b50896af0f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13910,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why agents are powerful"
    },
    "25ba01358b137ddce047bafdce3b0d2d": {
      "source_id": "25ba01358b137ddce047bafdce3b0d2d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12803,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Some ideas for follow-up projects to Redwood Research\u2019s recent paper"
    },
    "8cbaad4d2cc7ae30bfeae11955ff1ae4": {
      "source_id": "8cbaad4d2cc7ae30bfeae11955ff1ae4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15135,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Reading the ethicists 2: Hunting for AI alignment papers"
    },
    "5ae789eb8d7aaae3cfce0acfa4fc4b55": {
      "source_id": "5ae789eb8d7aaae3cfce0acfa4fc4b55",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30201,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Grokking \u201cForecasting TAI with biological anchors\u201d"
    },
    "f61d2ed27fabbff23fa29e2a3775803b": {
      "source_id": "f61d2ed27fabbff23fa29e2a3775803b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15605,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A descriptive, not prescriptive, overview of current AI Alignment Research"
    },
    "cb6ecbd5d316242e6e9ac223f159cc27": {
      "source_id": "cb6ecbd5d316242e6e9ac223f159cc27",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34305,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Who models the models that model models? An exploration of GPT-3's in-context mo"
    },
    "93b885673b0fae78b5a99c3f666fff9a": {
      "source_id": "93b885673b0fae78b5a99c3f666fff9a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43581,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Eliciting Latent Knowledge (ELK) - Distillation/Summary"
    },
    "4fb3295bb57c7551fad0d07ee82bdaa5": {
      "source_id": "4fb3295bb57c7551fad0d07ee82bdaa5",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7316,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How Do Selection Theorems Relate To Interpretability?"
    },
    "16386b40c311e7166490819cd1459088": {
      "source_id": "16386b40c311e7166490819cd1459088",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4775,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "You Only Get One Shot: an Intuition Pump for Embedded Agency"
    },
    "89f4f8ec618aa4f0b04b39b666f18239": {
      "source_id": "89f4f8ec618aa4f0b04b39b666f18239",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8515,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "why assume AGIs will optimize for fixed goals?"
    },
    "0fc982ab48364fada4dc2522eefcd018": {
      "source_id": "0fc982ab48364fada4dc2522eefcd018",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 78971,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Open Problems in AI X-Risk [PAIS #5]"
    },
    "695600f7b7881d8e40c2310c0e86a40e": {
      "source_id": "695600f7b7881d8e40c2310c0e86a40e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6214,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Godzilla Strategies"
    },
    "32e4738221031a1d8b244fdeb20e0077": {
      "source_id": "32e4738221031a1d8b244fdeb20e0077",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25430,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Training Trace Priors"
    },
    "21cad79d1af5b88c563ddd1b0592250e": {
      "source_id": "21cad79d1af5b88c563ddd1b0592250e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9790,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Continuity Assumptions"
    },
    "81ff36b0418b5dc51dd8dbd2a89d70ea": {
      "source_id": "81ff36b0418b5dc51dd8dbd2a89d70ea",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24868,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Investigating causal understanding in LLMs"
    },
    "d147bb63590c948a19fca2ec1f9462bd": {
      "source_id": "d147bb63590c948a19fca2ec1f9462bd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18891,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A central AI alignment problem: capabilities generalization, and the sharp left "
    },
    "a02ee8969b2a78b7e2c98856f2cdd6ee": {
      "source_id": "a02ee8969b2a78b7e2c98856f2cdd6ee",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37281,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Ten experiments in modularity, which we'd like you to run!"
    },
    "6351fc310549fe3b8e9d0ac6c5f1f33b": {
      "source_id": "6351fc310549fe3b8e9d0ac6c5f1f33b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4799,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Breaking Down Goal-Directed Behaviour"
    },
    "06a11b91b971b277e17986392ad39bd7": {
      "source_id": "06a11b91b971b277e17986392ad39bd7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8160,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Humans are very reliable agents"
    },
    "bb0fa1be996dff69b21144c65f3485ec": {
      "source_id": "bb0fa1be996dff69b21144c65f3485ec",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59343,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A transparency and interpretability tech tree"
    },
    "f22887c056cf14db1bd282096bd4a300": {
      "source_id": "f22887c056cf14db1bd282096bd4a300",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14697,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "wrapper-minds are the enemy"
    },
    "121703b9ca9475f63839c5b07a7a7298": {
      "source_id": "121703b9ca9475f63839c5b07a7a7298",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41552,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Quantifying General Intelligence"
    },
    "3b70d44482207323a67433ebc2c16b89": {
      "source_id": "3b70d44482207323a67433ebc2c16b89",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8702,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Pivotal outcomes and pivotal processes"
    },
    "9ed57de9a5430f86b6515c874df4371f": {
      "source_id": "9ed57de9a5430f86b6515c874df4371f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37853,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Where I agree and disagree with Eliezer"
    },
    "129332414ecb8f7c52405e9b0fc45b32": {
      "source_id": "129332414ecb8f7c52405e9b0fc45b32",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54849,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Causal confusion as an argument against the scaling hypothesis"
    },
    "cdc985f5c71b2747b7e3bedecdd19f15": {
      "source_id": "cdc985f5c71b2747b7e3bedecdd19f15",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16918,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Getting from an unaligned AGI to an aligned AGI?"
    },
    "d485ded980288fcfdc31c91b9b83cfd2": {
      "source_id": "d485ded980288fcfdc31c91b9b83cfd2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33091,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Reflection Mechanisms as an Alignment target: A survey"
    },
    "e9d21da9d603dc26f002e55ccff61f2e": {
      "source_id": "e9d21da9d603dc26f002e55ccff61f2e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25653,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Updated Deference is not a strong argument against the utility uncertainty appro"
    },
    "32a3573e4e729b839cd26be220922bde": {
      "source_id": "32a3573e4e729b839cd26be220922bde",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5769,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI-Written Critiques Help Humans Notice Flaws"
    },
    "5bec6d10fc52552916ac463b67d51b18": {
      "source_id": "5bec6d10fc52552916ac463b67d51b18",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18670,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Conditioning Generative Models"
    },
    "64a8aad2adacee2fa551840c268f26a5": {
      "source_id": "64a8aad2adacee2fa551840c268f26a5",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5622,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Training Trace Priors and Speed Priors"
    },
    "1003d180561f500509c1c55ba1c7399e": {
      "source_id": "1003d180561f500509c1c55ba1c7399e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6804,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing Epoch: A research organization investigating the road to Transformati"
    },
    "97743902620006556277dee19a1ebd26": {
      "source_id": "97743902620006556277dee19a1ebd26",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14216,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing the Inverse Scaling Prize ($250k Prize Pool)"
    },
    "a543b42f2036017ce2885cc49b3957f4": {
      "source_id": "a543b42f2036017ce2885cc49b3957f4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44782,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Deliberation, Reactions, and Control: Tentative Definitions and a Restatement of"
    },
    "29df865ef2e08513ee0fb113f8d7fbd6": {
      "source_id": "29df865ef2e08513ee0fb113f8d7fbd6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55001,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Deliberation Everywhere: Simple Examples"
    },
    "f139bc6f71c559aac9cc7c1cabfe7448": {
      "source_id": "f139bc6f71c559aac9cc7c1cabfe7448",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55003,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Exploring Mild Behaviour in Embedded Agents"
    },
    "09103d818ed13f90cd2ba8964486bb75": {
      "source_id": "09103d818ed13f90cd2ba8964486bb75",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5332,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Some alternative AI safety research projects"
    },
    "7430aa69585622cfa19b055ff539eaf2": {
      "source_id": "7430aa69585622cfa19b055ff539eaf2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1794,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What success looks like"
    },
    "354499b8f8e716b6189d014ad23a88d7": {
      "source_id": "354499b8f8e716b6189d014ad23a88d7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10465,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Will Capabilities Generalise More?"
    },
    "726feabf032b80cae4b1eabf677ddbc9": {
      "source_id": "726feabf032b80cae4b1eabf677ddbc9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27900,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Latent Adversarial Training"
    },
    "4279a39ba234fbfb2019f14376b19459": {
      "source_id": "4279a39ba234fbfb2019f14376b19459",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9840,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Gradient hacking: definitions and examples"
    },
    "e891d8a2e92bd0c8f33c115b44bf65bf": {
      "source_id": "e891d8a2e92bd0c8f33c115b44bf65bf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34560,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Formal Philosophy and Alignment Possible Projects"
    },
    "73568075d0536cf3490955a9a79aacb8": {
      "source_id": "73568075d0536cf3490955a9a79aacb8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3389,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Safetywashing"
    },
    "408f10c4603133ef73561b38cefcbe8f": {
      "source_id": "408f10c4603133ef73561b38cefcbe8f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44756,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What Is The True Name of Modularity?"
    },
    "9e2df1433f6b67965fae1069e2c7c662": {
      "source_id": "9e2df1433f6b67965fae1069e2c7c662",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 65508,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 16 - Preparing for Debate AI with Geoffrey Irving"
    },
    "d06a3b1bbda695afb16a09240c4fb6c1": {
      "source_id": "d06a3b1bbda695afb16a09240c4fb6c1",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 987,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Linkpost] Existential Risk Analysis in Empirical Research Papers"
    },
    "554a81242acc887ccb17d0019be52e3b": {
      "source_id": "554a81242acc887ccb17d0019be52e3b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53449,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Remaking EfficientZero (as best I can)"
    },
    "efa7e7df9ebf421b274cae34f78f90c2": {
      "source_id": "efa7e7df9ebf421b274cae34f78f90c2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9888,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Benchmark for successful concept extrapolation/avoiding goal misgeneralization"
    },
    "41bb5f86d43dd6f0d5b0e5ef80b84049": {
      "source_id": "41bb5f86d43dd6f0d5b0e5ef80b84049",
      "quality_score": 2.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 7140,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[AN #172] Sorry for the long hiatus!"
    },
    "7f8a5b019e4a44273b18832618c412cb": {
      "source_id": "7f8a5b019e4a44273b18832618c412cb",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8990,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Introducing the Fund for Alignment Research (We're Hiring!)"
    },
    "4ed4247a616da0fa65cd5fd291a0c0fb": {
      "source_id": "4ed4247a616da0fa65cd5fd291a0c0fb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18789,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Outer vs inner misalignment: three framings"
    },
    "6429f0c2ec742359a0c8cb940be3690d": {
      "source_id": "6429f0c2ec742359a0c8cb940be3690d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8907,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Principles for Alignment/Agency Projects"
    },
    "bfb844ec09db99ec5914f3ecea57db47": {
      "source_id": "bfb844ec09db99ec5914f3ecea57db47",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35544,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Race Along Rashomon Ridge"
    },
    "c3610209b323df2f0d62b169aa24485b": {
      "source_id": "c3610209b323df2f0d62b169aa24485b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30841,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Human values & biases are inaccessible to the genome"
    },
    "e4934023d857eae062fbe79bd2221531": {
      "source_id": "e4934023d857eae062fbe79bd2221531",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47168,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Safety considerations for online generative modeling"
    },
    "3f47582818ed9dbd0c5559be094cc443": {
      "source_id": "3f47582818ed9dbd0c5559be094cc443",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42535,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Making it harder for an AGI to \"trick\" us, with STVs"
    },
    "e2aa6228fce4fa5168a26583f896ffa8": {
      "source_id": "e2aa6228fce4fa5168a26583f896ffa8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30724,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Visualizing Neural networks, how to blame the bias"
    },
    "01d83b55c905bb1f34eb537dc44be546": {
      "source_id": "01d83b55c905bb1f34eb537dc44be546",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24674,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Grouped Loss may disfavor discontinuous capabilities"
    },
    "1a30968bcd96b4eb6e5e23a163801b06": {
      "source_id": "1a30968bcd96b4eb6e5e23a163801b06",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56137,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "On how various plans miss the hard bits of the alignment challenge"
    },
    "a7b0098393d418359f95329781f8cd07": {
      "source_id": "a7b0098393d418359f95329781f8cd07",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23081,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Mosaic and Palimpsests: Two Shapes of Research"
    },
    "b5e393063142fdeb237bc69d0244a371": {
      "source_id": "b5e393063142fdeb237bc69d0244a371",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37731,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Response to Blake Richards: AGI, generality, alignment, & loss functions"
    },
    "4e34206dda1ddf6c26e1d169b21c1af9": {
      "source_id": "4e34206dda1ddf6c26e1d169b21c1af9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3372,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Acceptability Verification: A Research Agenda"
    },
    "193ac8385174f4efe7756ebb94efe0f7": {
      "source_id": "193ac8385174f4efe7756ebb94efe0f7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8915,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Artificial Sandwiching: When can we test scalable alignment protocols without hu"
    },
    "f75de3e805867d9224480e9eca108a72": {
      "source_id": "f75de3e805867d9224480e9eca108a72",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 449,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Deep learning curriculum for large language model alignment"
    },
    "1904c9580bbdae92c423786ca0b9661e": {
      "source_id": "1904c9580bbdae92c423786ca0b9661e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21307,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Humans provide an untapped wealth of evidence about alignment"
    },
    "0d46a6817a520f141d281761906e19b1": {
      "source_id": "0d46a6817a520f141d281761906e19b1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 93704,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Circumventing interpretability: How to defeat mind-readers"
    },
    "7803c66d7c96999ca1b8b1638d9a5a6d": {
      "source_id": "7803c66d7c96999ca1b8b1638d9a5a6d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11040,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A note about differential technological development"
    },
    "256b2dbdb9bd6a9b3d8fff871a5fa98b": {
      "source_id": "256b2dbdb9bd6a9b3d8fff871a5fa98b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 65412,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Notes on Learning the Prior"
    },
    "8a9b57c0a263ab2287b4daf42ca9500f": {
      "source_id": "8a9b57c0a263ab2287b4daf42ca9500f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11798,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Safety Implications of LeCun's path to machine intelligence"
    },
    "0a292693e9c6c6e25db090dbbcfc5d3a": {
      "source_id": "0a292693e9c6c6e25db090dbbcfc5d3a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40186,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why you might expect homogeneous take-off: evidence from ML research"
    },
    "8672eb88a13d11086d6867e351000f7d": {
      "source_id": "8672eb88a13d11086d6867e351000f7d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 89752,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How Interpretability can be Impactful"
    },
    "715d6ce7af8cccc2b40bfd96832a8ec6": {
      "source_id": "715d6ce7af8cccc2b40bfd96832a8ec6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45928,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Deception?! I ain\u2019t got time for that!"
    },
    "372ff158811c3362afdc08abb5750541": {
      "source_id": "372ff158811c3362afdc08abb5750541",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21431,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A distillation of Evan Hubinger's training stories (for SERI MATS)"
    },
    "667c05311ee2eb7fa388ce81d386ee58": {
      "source_id": "667c05311ee2eb7fa388ce81d386ee58",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 60791,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Training goals for large language models"
    },
    "a470fc91b2334e1005956551fefe1473": {
      "source_id": "a470fc91b2334e1005956551fefe1473",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41052,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Conditioning Generative Models for Alignment"
    },
    "e44e289bb50d71e536140bda9b1ddd68": {
      "source_id": "e44e289bb50d71e536140bda9b1ddd68",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25530,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Quantilizers and Generative Models"
    },
    "d612ba92f2b6e514e233bb3aa5ad9311": {
      "source_id": "d612ba92f2b6e514e233bb3aa5ad9311",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 180241,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Without specific countermeasures, the easiest path to transformative AI likely l"
    },
    "65f19a82ba9b93065fc491b83da62153": {
      "source_id": "65f19a82ba9b93065fc491b83da62153",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3186,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Help ARC evaluate capabilities of current language models (still need people)"
    },
    "8fb85070db1c237b93c618e614846fab": {
      "source_id": "8fb85070db1c237b93c618e614846fab",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33379,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Bounded complexity of solving ELK and its implications"
    },
    "e2b42b57d6ac503422a3ddc4a854f186": {
      "source_id": "e2b42b57d6ac503422a3ddc4a854f186",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30645,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Abram Demski's ELK thoughts and proposal - distillation"
    },
    "9bf0ea3e8a1f76eecb972de39b75721f": {
      "source_id": "9bf0ea3e8a1f76eecb972de39b75721f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17472,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How to Diversify Conceptual Alignment: the Model Behind Refine"
    },
    "30bc71315f9641ec78c39bd509e7e747": {
      "source_id": "30bc71315f9641ec78c39bd509e7e747",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 18786,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[AN #173]\u00a0Recent language model results from DeepMind"
    },
    "df10f8fc78d3a6196a8798437f25efbf": {
      "source_id": "df10f8fc78d3a6196a8798437f25efbf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16482,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Conditioning Generative Models with Restrictions"
    },
    "7ac8f37eb1a31a9dfb8866421f87fa43": {
      "source_id": "7ac8f37eb1a31a9dfb8866421f87fa43",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5752,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Robustness to Scaling Down: More Important Than I Thought"
    },
    "cf09b90783f8a0e65cea3eae8b7dd280": {
      "source_id": "cf09b90783f8a0e65cea3eae8b7dd280",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22392,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Brainstorm of things that could force an AI team to burn their lead"
    },
    "72b8504e286d87e094f043d35d925364": {
      "source_id": "72b8504e286d87e094f043d35d925364",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43148,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Reward is not the optimization target"
    },
    "fc0952b20fa2ea3d6d99adc556efc311": {
      "source_id": "fc0952b20fa2ea3d6d99adc556efc311",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2663,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "NeurIPS ML Safety Workshop 2022"
    },
    "dc26c4e249c20b7d6f5ee2617dad4156": {
      "source_id": "dc26c4e249c20b7d6f5ee2617dad4156",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23808,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Active Inference as a formalisation of instrumental convergence"
    },
    "872d51370d1e0dd0fd1aaadc8e3200bd": {
      "source_id": "872d51370d1e0dd0fd1aaadc8e3200bd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34164,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "\u00abBoundaries\u00bb, Part 1: a key missing concept from utility theory"
    },
    "e09dca3b14edd4d0d280720d04286ea0": {
      "source_id": "e09dca3b14edd4d0d280720d04286ea0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12062,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AGI ruin scenarios are likely (and disjunctive)"
    },
    "0f8fd87e323fca6f87089c2a0b828ae7": {
      "source_id": "0f8fd87e323fca6f87089c2a0b828ae7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30705,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Levels of Pluralism"
    },
    "2b5d3c22c5d7eadfdd6082ee5e61273d": {
      "source_id": "2b5d3c22c5d7eadfdd6082ee5e61273d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10496,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Moral strategies at different capability levels"
    },
    "974697b818bd90ea021ac688d22f942d": {
      "source_id": "974697b818bd90ea021ac688d22f942d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13491,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Principles of Privacy for Alignment Research"
    },
    "430bb12e03092b3b25ab7c628938940a": {
      "source_id": "430bb12e03092b3b25ab7c628938940a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36443,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Abstracting The Hardness of Alignment: Unbounded Atomic Optimization"
    },
    "675957d55a602497ec8bfae3541ff22f": {
      "source_id": "675957d55a602497ec8bfae3541ff22f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34452,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Conjecture: Internal Infohazard Policy"
    },
    "a001fa2a76ad5ae391fbc1ac3704df7c": {
      "source_id": "a001fa2a76ad5ae391fbc1ac3704df7c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25148,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Comparing Four Approaches to Inner Alignment"
    },
    "d8cf65c793dccf36b41b4e6ce3e0c87d": {
      "source_id": "d8cf65c793dccf36b41b4e6ce3e0c87d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32019,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How transparency changed over time"
    },
    "5ae4e4da295b5da232f63d0db53d991b": {
      "source_id": "5ae4e4da295b5da232f63d0db53d991b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32562,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Two-year update on my personal AI timelines"
    },
    "a0a1d2eac4f31cb92bf3fcdc15aea633": {
      "source_id": "a0a1d2eac4f31cb92bf3fcdc15aea633",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13114,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Externalized reasoning oversight: a research direction for language model alignm"
    },
    "132a6c3dd6878461beb311b27cdeed0f": {
      "source_id": "132a6c3dd6878461beb311b27cdeed0f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46324,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Precursor checking for deceptive alignment"
    },
    "492e7f29b90b5f2c8beb367a69233349": {
      "source_id": "492e7f29b90b5f2c8beb367a69233349",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44707,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Convergence Towards World-Models: A Gears-Level Model"
    },
    "78614622e18748877a369f9accc01bd8": {
      "source_id": "78614622e18748877a369f9accc01bd8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11895,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "$20K In Bounties for AI Safety Public Materials"
    },
    "cf78071cf4fe8397de60fd6ea222649e": {
      "source_id": "cf78071cf4fe8397de60fd6ea222649e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46464,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Bridging Expected Utility Maximization and Optimization"
    },
    "96a9d9c64f1a59534759e76e5e247df8": {
      "source_id": "96a9d9c64f1a59534759e76e5e247df8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13545,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Rant on Problem Factorization for Alignment"
    },
    "d49273ef3611064e4e7f3be5b4da12c6": {
      "source_id": "d49273ef3611064e4e7f3be5b4da12c6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17841,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing the Introduction to ML Safety course"
    },
    "4304ff78db6aa96beb6f721ed5cb322a": {
      "source_id": "4304ff78db6aa96beb6f721ed5cb322a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10879,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Steganography in Chain of Thought Reasoning"
    },
    "a170d4f6c5c782e3c60b99c4ef0ddf0e": {
      "source_id": "a170d4f6c5c782e3c60b99c4ef0ddf0e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5851,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Interpretability/Tool-ness/Alignment/Corrigibility are not Composable"
    },
    "23835fdf8bf299529b3c5e0aefa84d0c": {
      "source_id": "23835fdf8bf299529b3c5e0aefa84d0c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12155,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Encultured AI Pre-planning, Part 1:  Enabling New Benchmarks"
    },
    "a386dd90266db2c43e0daa2f005d08d7": {
      "source_id": "a386dd90266db2c43e0daa2f005d08d7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19241,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Encultured AI, Part 1 Appendix: Relevant Research Examples"
    },
    "09f4cbd11ffdcc115f396747e92f606f": {
      "source_id": "09f4cbd11ffdcc115f396747e92f606f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3195,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "General alignment properties"
    },
    "798e08ce6075f1241838f3cf40d0e5f2": {
      "source_id": "798e08ce6075f1241838f3cf40d0e5f2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8752,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing: Mechanism Design for AI Safety - Reading Group"
    },
    "f5c955d11623a9fe6175ad0fd0b8e578": {
      "source_id": "f5c955d11623a9fe6175ad0fd0b8e578",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5561,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How To Go From Interpretability To Alignment: Just Retarget The Search"
    },
    "c4e264f15b16ec33a2bb72a2a252a261": {
      "source_id": "c4e264f15b16ec33a2bb72a2a252a261",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24812,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How Do We Align an AGI Without Getting Socially Engineered?  (Hint: Box It)"
    },
    "2940f276fbf9aa7a5738da4084a47b10": {
      "source_id": "2940f276fbf9aa7a5738da4084a47b10",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7086,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How much alignment data will we need in the long run?"
    },
    "41047b8d88f14f1d6ffebbc8a260189f": {
      "source_id": "41047b8d88f14f1d6ffebbc8a260189f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57863,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The alignment problem from a deep learning perspective"
    },
    "b6383501d3e862e19266f858e2079e35": {
      "source_id": "b6383501d3e862e19266f858e2079e35",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20436,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Shard Theory: An Overview"
    },
    "9b9b18bb45b552d28a8dbda8c6939355": {
      "source_id": "9b9b18bb45b552d28a8dbda8c6939355",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44834,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Language models seem to be much better than humans at next-token prediction"
    },
    "d1f6f3f6ad3562d40ab5a636c840a257": {
      "source_id": "d1f6f3f6ad3562d40ab5a636c840a257",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5866,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Encultured AI Pre-planning, Part 2:  Providing a Service"
    },
    "35e7c56f9cbff3078869d79b6df93feb": {
      "source_id": "35e7c56f9cbff3078869d79b6df93feb",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3349,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Seriously, what goes wrong with \"reward the agent when it makes you smile\"?"
    },
    "3203ef6a2ab36f39119f5c88db331816": {
      "source_id": "3203ef6a2ab36f39119f5c88db331816",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6456,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Refining the Sharp Left Turn threat model, part 1: claims and mechanisms"
    },
    "7503544570ac96d188a79766fc4720dd": {
      "source_id": "7503544570ac96d188a79766fc4720dd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29516,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "DeepMind alignment team opinions on AGI ruin arguments"
    },
    "a114e8892606b5913bfcb2ba8ae31792": {
      "source_id": "a114e8892606b5913bfcb2ba8ae31792",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10142,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Gradient descent doesn't select for inner search"
    },
    "381de5682ac7eceb19c5d2e94f280e90": {
      "source_id": "381de5682ac7eceb19c5d2e94f280e90",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3342,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "the Insulated Goal-Program idea"
    },
    "fe6769330476f5472e62d2c7cff6437c": {
      "source_id": "fe6769330476f5472e62d2c7cff6437c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4929,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Steelmining via Analogy"
    },
    "1e3e4a215724f78fd9d5ceb29767e3f8": {
      "source_id": "1e3e4a215724f78fd9d5ceb29767e3f8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9654,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How I think about alignment"
    },
    "2f9ce8bcac0f88b646f1d8fa939cf5e2": {
      "source_id": "2f9ce8bcac0f88b646f1d8fa939cf5e2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4752,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Shapes of Mind and Pluralism in Alignment"
    },
    "b91f5d00b723058b82b909d653799221": {
      "source_id": "b91f5d00b723058b82b909d653799221",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5032,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "goal-program bricks"
    },
    "9663d49a0a0339cc4ee9a4723519e8b1": {
      "source_id": "9663d49a0a0339cc4ee9a4723519e8b1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6437,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "I missed the crux of the alignment problem the whole time"
    },
    "db490f9e0ac4768c84e1671ff1013407": {
      "source_id": "db490f9e0ac4768c84e1671ff1013407",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4410,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Dumbest Possible Gets There First"
    },
    "7fc688847c29a5b98079382e274ca9a0": {
      "source_id": "7fc688847c29a5b98079382e274ca9a0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2003,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Refine's First Blog Post Day"
    },
    "3c235377bc892138d8c202ef6f2995c5": {
      "source_id": "3c235377bc892138d8c202ef6f2995c5",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8829,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "An extended rocket alignment analogy"
    },
    "93288cf0268dc0e6c04e80a273f05d00": {
      "source_id": "93288cf0268dc0e6c04e80a273f05d00",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16049,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Evolution is a bad analogy for AGI: inner alignment"
    },
    "d0a223c0a70fb782b866bffe4db2d873": {
      "source_id": "d0a223c0a70fb782b866bffe4db2d873",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3670,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Brain-like AGI project \"aintelope\""
    },
    "41c6ba01f2b7dad7ba74d9a2e05cd889": {
      "source_id": "41c6ba01f2b7dad7ba74d9a2e05cd889",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35788,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "All the posts I will never write"
    },
    "79281aed1df2c4206c563bc055e9e97f": {
      "source_id": "79281aed1df2c4206c563bc055e9e97f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 104190,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Mechanistic Interpretability Analysis of Grokking"
    },
    "5468557bf5551c51507de5afc7c3abe6": {
      "source_id": "5468557bf5551c51507de5afc7c3abe6",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4771,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Seeking Interns/RAs for Mechanistic Interpretability Projects"
    },
    "f353c1fdaaef1943b946b8a3059c8160": {
      "source_id": "f353c1fdaaef1943b946b8a3059c8160",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20009,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What's General-Purpose Search, And Why Might We Expect To See It In Trained ML S"
    },
    "eb5daf36f094733f74a1c36cb3e71a8c": {
      "source_id": "eb5daf36f094733f74a1c36cb3e71a8c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8815,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Autonomy as taking responsibility for reference maintenance"
    },
    "0b91f367b9e506f881e1f72c01db7bcb": {
      "source_id": "0b91f367b9e506f881e1f72c01db7bcb",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9893,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Human Mimicry Mainly Works When We\u2019re Already Close"
    },
    "0a48ef3ee34a41d862126444ea70e968": {
      "source_id": "0a48ef3ee34a41d862126444ea70e968",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18051,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Core of the Alignment Problem is..."
    },
    "5e5419467a60562a940dbfc3fef104ff": {
      "source_id": "5e5419467a60562a940dbfc3fef104ff",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25169,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Conditioning, Prompts, and Fine-Tuning"
    },
    "2655f400d92bbcda8a71a3a89ca8ec29": {
      "source_id": "2655f400d92bbcda8a71a3a89ca8ec29",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16425,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Concrete Advice for Forming Inside Views on AI Safety"
    },
    "9fd668c51b98caa5774da59379741406": {
      "source_id": "9fd668c51b98caa5774da59379741406",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6738,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing Encultured AI:  Building a Video Game"
    },
    "f7849f8a175fa3a29805e4498dcbc048": {
      "source_id": "f7849f8a175fa3a29805e4498dcbc048",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31917,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Discovering Agents"
    },
    "82a7f297636ed3eecb621eb51b59a946": {
      "source_id": "82a7f297636ed3eecb621eb51b59a946",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13210,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Epistemic Artefacts of (conceptual) AI alignment research"
    },
    "17b3f2bfe5a6634b24ed104c29182780": {
      "source_id": "17b3f2bfe5a6634b24ed104c29182780",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27715,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How to do theoretical research, a personal perspective"
    },
    "78056a98ed0215cc496f48a3d5b38938": {
      "source_id": "78056a98ed0215cc496f48a3d5b38938",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2728,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Reducing Goodhart: Announcement, Executive Summary"
    },
    "1c20f7599f1078819ba5bec4798df674": {
      "source_id": "1c20f7599f1078819ba5bec4798df674",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30840,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Benchmarking Proposals on Risk Scenarios"
    },
    "d6f0230436ed950b24fa790846b7d145": {
      "source_id": "d6f0230436ed950b24fa790846b7d145",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13882,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "PreDCA: vanessa kosoy's alignment protocol"
    },
    "dea4a560b4bea5d7c3d0b1d6eae590ae": {
      "source_id": "dea4a560b4bea5d7c3d0b1d6eae590ae",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16159,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What if we approach AI safety like a technical engineering safety problem"
    },
    "8da4ecb77a2f3b767167ab30971b814e": {
      "source_id": "8da4ecb77a2f3b767167ab30971b814e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4658,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "No One-Size-Fit-All Epistemic Strategy"
    },
    "7d3bb56a7c19b383ae9021bd7173fddf": {
      "source_id": "7d3bb56a7c19b383ae9021bd7173fddf",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1351,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Refine's Second Blog Post Day"
    },
    "8178814c4166b1cc4e7bb0bfca7b9aef": {
      "source_id": "8178814c4166b1cc4e7bb0bfca7b9aef",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37343,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Broad Picture of Human Values"
    },
    "9960cddbb7fc328ec64b27ff52ec97b2": {
      "source_id": "9960cddbb7fc328ec64b27ff52ec97b2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62194,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 17 - Training for Very High Reliability with Daniel Ziegler"
    },
    "62cbf25ae4cd8f8a2daffef71fde5d7c": {
      "source_id": "62cbf25ae4cd8f8a2daffef71fde5d7c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42486,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Finding Goals in the World Model"
    },
    "a54432ea0da26e5e226448ed2964ad84": {
      "source_id": "a54432ea0da26e5e226448ed2964ad84",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12948,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI alignment as \u201cnavigating the space of intelligent behaviour\u201d"
    },
    "320e9cc439fc802672a81d2a0bbb2630": {
      "source_id": "320e9cc439fc802672a81d2a0bbb2630",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2406,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AGI Timelines Are Mostly Not Strategically Relevant To Alignment"
    },
    "ac316d57f11fbdd5e91edd1a5d968119": {
      "source_id": "ac316d57f11fbdd5e91edd1a5d968119",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4180,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Interspecies diplomacy as a potentially productive lens on AGI alignment"
    },
    "e913a9def668e5bc8fd1a334f900c367": {
      "source_id": "e913a9def668e5bc8fd1a334f900c367",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13155,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Beliefs and Disagreements about Automating Alignment Research"
    },
    "36b7da3495940325e7bc8ff5a401c1e9": {
      "source_id": "36b7da3495940325e7bc8ff5a401c1e9",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 2183,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Google AI integrates PaLM with robotics: SayCan update [Linkpost]"
    },
    "96ee76507adc19e5953983dc6987ba3e": {
      "source_id": "96ee76507adc19e5953983dc6987ba3e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4363,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What Makes A Good Measurement Device?"
    },
    "d25217fec47e6812f38d06ad6317c9ae": {
      "source_id": "d25217fec47e6812f38d06ad6317c9ae",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8101,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Your posts should be on arXiv"
    },
    "a8b0c2233c16b0d1280ed093b52680a0": {
      "source_id": "a8b0c2233c16b0d1280ed093b52680a0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11272,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Common misconceptions about OpenAI"
    },
    "16376a8dcc4cb27b1785a58a60cb2413": {
      "source_id": "16376a8dcc4cb27b1785a58a60cb2413",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19786,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI strategy nearcasting"
    },
    "21742c78e1d88750d887322266397240": {
      "source_id": "21742c78e1d88750d887322266397240",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18056,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Test for Language Model Consciousness"
    },
    "b604183d0ab8cf0f741904803ff061a4": {
      "source_id": "b604183d0ab8cf0f741904803ff061a4",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6609,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Some conceptual alignment research projects"
    },
    "371e61b8e57348df8b8b32c07d59e25c": {
      "source_id": "371e61b8e57348df8b8b32c07d59e25c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3864,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Annual AGI Benchmarking Event"
    },
    "080829ea91a09e7211fe1d744277f0ed": {
      "source_id": "080829ea91a09e7211fe1d744277f0ed",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31180,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Basin broadness depends on the size and number of orthogonal features"
    },
    "d8bbd2fcdb966b3f57124374af45a021": {
      "source_id": "d8bbd2fcdb966b3f57124374af45a021",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5956,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Breaking down the training/deployment dichotomy"
    },
    "85a289b8cbfdbea088a7eb26ebea24f3": {
      "source_id": "85a289b8cbfdbea088a7eb26ebea24f3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 102256,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "(My understanding of) What Everyone in Technical Alignment is Doing and Why"
    },
    "138fc3daec9f3e9d442f05b8bd349184": {
      "source_id": "138fc3daec9f3e9d442f05b8bd349184",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 103608,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How might we align transformative AI if it\u2019s developed very soon?"
    },
    "0904add515f0f7a05bee473aef60fdc0": {
      "source_id": "0904add515f0f7a05bee473aef60fdc0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 572,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "*New* Canada AI Safety & Governance community"
    },
    "6016bd912cda5ea5c80c878ac304bac2": {
      "source_id": "6016bd912cda5ea5c80c878ac304bac2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 118555,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How likely is deceptive alignment?"
    },
    "a3c924c8470a45eab1246aa8be8ae95a": {
      "source_id": "a3c924c8470a45eab1246aa8be8ae95a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20045,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Worlds Where Iterative Design Fails"
    },
    "f79d2cf7adc0a32b79c4b8f0fdf16d80": {
      "source_id": "f79d2cf7adc0a32b79c4b8f0fdf16d80",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2714,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Survey of NLP Researchers: NLP is contributing to AGI progress; major catastroph"
    },
    "909341a4a8bdcf7de0d0b2661d69803e": {
      "source_id": "909341a4a8bdcf7de0d0b2661d69803e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36887,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Strategy For Conditioning Generative Models"
    },
    "a59bc543409f8a17d818bde299e0c7e5": {
      "source_id": "a59bc543409f8a17d818bde299e0c7e5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12528,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Safety and Neighboring Communities: A Quick-Start Guide, as of Summer 2022"
    },
    "6ad3c157b85711991b4914ffcb0e9034": {
      "source_id": "6ad3c157b85711991b4914ffcb0e9034",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3351,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI coordination needs clear wins"
    },
    "2e519828cf6704abc3d9e5e7e7261ec2": {
      "source_id": "2e519828cf6704abc3d9e5e7e7261ec2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5402,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Replacement for PONR concept"
    },
    "7fba945136f368e5db9314ee98610840": {
      "source_id": "7fba945136f368e5db9314ee98610840",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 95301,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Simulators"
    },
    "5e8e2d315b65bcb6db8c8782d69e38fd": {
      "source_id": "5e8e2d315b65bcb6db8c8782d69e38fd",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6131,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Sticky goals: a concrete experiment for understanding deceptive alignment"
    },
    "b38476b0b3d46c957dc0efa7b473774f": {
      "source_id": "b38476b0b3d46c957dc0efa7b473774f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29402,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Behaviour Manifolds and the Hessian of the Total Loss - Notes and Criticism"
    },
    "fb8bb51f4d531046b2025d6c8bc1cc1b": {
      "source_id": "fb8bb51f4d531046b2025d6c8bc1cc1b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3656,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "We may be able to see sharp left turns coming"
    },
    "180558ada892116f5710cec955cc1ee8": {
      "source_id": "180558ada892116f5710cec955cc1ee8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7479,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "An Update on Academia vs. Industry (one year into my faculty job)"
    },
    "df30a05a80254e91e914443de9009e5a": {
      "source_id": "df30a05a80254e91e914443de9009e5a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 70817,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 18 - Concept Extrapolation with Stuart Armstrong"
    },
    "1317083c3a42719465795ecf410ed9a6": {
      "source_id": "1317083c3a42719465795ecf410ed9a6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57251,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The shard theory of human values"
    },
    "60baddd9c952f6e3b6e64de15d9596f6": {
      "source_id": "60baddd9c952f6e3b6e64de15d9596f6",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9750,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Framing AI Childhoods"
    },
    "acfe9cba37b4f0581892c70ab9866f0c": {
      "source_id": "acfe9cba37b4f0581892c70ab9866f0c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6722,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI-assisted list of ten concrete alignment things to do right now"
    },
    "336f0061d1f7faa0834a38e98cf25390": {
      "source_id": "336f0061d1f7faa0834a38e98cf25390",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 78876,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What Should AI Owe To Us? Accountable and Aligned AI Systems via Contractualist "
    },
    "981696c5b8ce7fd21afc9469056fbafa": {
      "source_id": "981696c5b8ce7fd21afc9469056fbafa",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12288,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[An email with a bunch of links I sent an experienced ML researcher interested i"
    },
    "d48ddec4e658ddedf64a9f1c03cb5b0a": {
      "source_id": "d48ddec4e658ddedf64a9f1c03cb5b0a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16837,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Monitoring for deceptive alignment"
    },
    "a0e410b35f28334a52a0cb1780a1ea62": {
      "source_id": "a0e410b35f28334a52a0cb1780a1ea62",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5981,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Most People Start With The Same Few Bad Ideas"
    },
    "e1145db4e004afbb746ddde8d93ecfe8": {
      "source_id": "e1145db4e004afbb746ddde8d93ecfe8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22916,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Oversight Leagues: The Training Game as a Feature"
    },
    "08c896407e5f9f1eb4811b06c2f1b55a": {
      "source_id": "08c896407e5f9f1eb4811b06c2f1b55a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19065,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Evaluations project @ ARC is hiring a researcher and a webdev/engineer"
    },
    "f850bb1df91f08925f292e6822374e25": {
      "source_id": "f850bb1df91f08925f292e6822374e25",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2933,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Ought will host a factored cognition \u201cLab Meeting\u201d"
    },
    "d5a52c6476604f9053d2a527d3e16ade": {
      "source_id": "d5a52c6476604f9053d2a527d3e16ade",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20592,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Path dependence in ML inductive biases"
    },
    "25be01a66bb53a144247718b86693b00": {
      "source_id": "25be01a66bb53a144247718b86693b00",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19775,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Quintin's alignment papers roundup - week 1"
    },
    "b21a101fcc474621d20ef0f48575491c": {
      "source_id": "b21a101fcc474621d20ef0f48575491c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29090,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Ideological Inference Engines: Making Deontology Differentiable*"
    },
    "ffef5eb1b1c8a1942c2c21d85aef9c1d": {
      "source_id": "ffef5eb1b1c8a1942c2c21d85aef9c1d",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 4693,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Linkpost] A survey on over 300 works about interpretability in deep networks"
    },
    "a3ebf9be1c12e4e20948d7c6bbed0e09": {
      "source_id": "a3ebf9be1c12e4e20948d7c6bbed0e09",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3647,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "New tool for exploring EA Forum, LessWrong and Alignment Forum - Tree of Tags"
    },
    "312672c68680b89cd4bad484fe01bd95": {
      "source_id": "312672c68680b89cd4bad484fe01bd95",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27239,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Trying to find the underlying structure of computational systems"
    },
    "f0b7c735e3d1815afc68ade0d5f844e9": {
      "source_id": "f0b7c735e3d1815afc68ade0d5f844e9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8338,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Some ideas for epistles to the AI ethicists"
    },
    "9badb3d178b7ae57f6b6c152cddc5295": {
      "source_id": "9badb3d178b7ae57f6b6c152cddc5295",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12938,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Defender\u2019s Advantage of Interpretability"
    },
    "aa2e2820fd65002743c72d73df607db6": {
      "source_id": "aa2e2820fd65002743c72d73df607db6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17965,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "When does technical work to reduce AGI conflict make a difference?: Introduction"
    },
    "ff131b76d2744bb4efeae9afd1ccb4a8": {
      "source_id": "ff131b76d2744bb4efeae9afd1ccb4a8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49531,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "When would AGIs engage in conflict?"
    },
    "82328a5234ae35a9a47b23286188a48a": {
      "source_id": "82328a5234ae35a9a47b23286188a48a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39578,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "When is intent alignment sufficient or necessary to reduce AGI conflict?"
    },
    "a6408e1dcb66b86adec8f8c4aa31eb2b": {
      "source_id": "a6408e1dcb66b86adec8f8c4aa31eb2b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28920,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Coordinate-Free Interpretability Theory"
    },
    "55659f0b5ff3545cd73dcb555e657c5c": {
      "source_id": "55659f0b5ff3545cd73dcb555e657c5c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24113,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why deceptive alignment matters for AGI safety"
    },
    "aefc17d363d9f326609f1db0ec8e8049": {
      "source_id": "aefc17d363d9f326609f1db0ec8e8049",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35340,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Representational Tethers: Tying AI Latents To Human Ones"
    },
    "ff8b9790ab512e3f5eaec8ab591cb898": {
      "source_id": "ff8b9790ab512e3f5eaec8ab591cb898",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8522,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "ordering capability thresholds"
    },
    "3b4f9b3bd797e59c36feb577d1418f97": {
      "source_id": "3b4f9b3bd797e59c36feb577d1418f97",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13577,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Levels of goals and alignment"
    },
    "862cb17d8ffd21d27516d8806cf72424": {
      "source_id": "862cb17d8ffd21d27516d8806cf72424",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12979,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Takeaways from our robust injury classifier project [Redwood Research]"
    },
    "5e6e1c36d775b37689a1f403ceb5b5fb": {
      "source_id": "5e6e1c36d775b37689a1f403ceb5b5fb",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7776,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Prize and fast track to alignment research at ALTER"
    },
    "3cdf5c4646bd81e85d60429af20dc582": {
      "source_id": "3cdf5c4646bd81e85d60429af20dc582",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1201,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Refine's Third Blog Post Day/Week"
    },
    "9e74550eab62826b88001314381239d3": {
      "source_id": "9e74550eab62826b88001314381239d3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2488,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Inner alignment: what are we pointing at?"
    },
    "ae2416568dddd563c13a4c2556336d84": {
      "source_id": "ae2416568dddd563c13a4c2556336d84",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1553,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Summaries: Alignment Fundamentals Curriculum"
    },
    "ab662f999df95a93a94a45df40d2b805": {
      "source_id": "ab662f999df95a93a94a45df40d2b805",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10030,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Inter-Agent Facet of AI Alignment"
    },
    "2a644a7dcd30c13a633e6dfa2b0db357": {
      "source_id": "2a644a7dcd30c13a633e6dfa2b0db357",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40079,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Quintin's alignment papers roundup - week 2"
    },
    "b940a75ad76c4c15fc483ac3fb2d6afa": {
      "source_id": "b940a75ad76c4c15fc483ac3fb2d6afa",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1294,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "PIBBSS (AI alignment) is hiring for a Project Manager"
    },
    "a21d150030044409f91ebdbf033cfd30": {
      "source_id": "a21d150030044409f91ebdbf033cfd30",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6175,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Doing oversight from the very start of training seems hard"
    },
    "879f907d9fef7909b036d94127b9a55e": {
      "source_id": "879f907d9fef7909b036d94127b9a55e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54192,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Nearcast-based \"deployment problem\" analysis"
    },
    "97c845276dd6498a1606fc3cb1adaf94": {
      "source_id": "97c845276dd6498a1606fc3cb1adaf94",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 943,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing AISIC 2022 - the AI Safety Israel Conference, October 19-20"
    },
    "a43ef8bebf763179221917f87cdf1429": {
      "source_id": "a43ef8bebf763179221917f87cdf1429",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 160060,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Toy Models of Superposition"
    },
    "d622ef4f4013824fe487f1b28f1f67c4": {
      "source_id": "d622ef4f4013824fe487f1b28f1f67c4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19211,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Methodological Therapy: An Agenda For Tackling Research Bottlenecks"
    },
    "c77c51f3afedc8a0d2a4fb3b9b7516ee": {
      "source_id": "c77c51f3afedc8a0d2a4fb3b9b7516ee",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40199,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Interlude: But Who Optimizes The Optimizer?"
    },
    "1312c026223ba23f90f5dcaa69ea9a47": {
      "source_id": "1312c026223ba23f90f5dcaa69ea9a47",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 112233,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Interpreting Neural Networks through the Polytope Lens"
    },
    "0f3b977ef4bedb3a5e149deaa0cbb50a": {
      "source_id": "0f3b977ef4bedb3a5e149deaa0cbb50a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51537,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Brain-over-body biases, and the embodied value problem in AI alignment"
    },
    "5f8a0df3df2778127b47258aef429de1": {
      "source_id": "5f8a0df3df2778127b47258aef429de1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10120,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Planning capacity and daemons"
    },
    "48a1138663933cc4a03e89af0a951327": {
      "source_id": "48a1138663933cc4a03e89af0a951327",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9550,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Inverse Scaling Prize: Round 1 Winners"
    },
    "d94db509c0cd70c0ca799a67e5a85c03": {
      "source_id": "d94db509c0cd70c0ca799a67e5a85c03",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8686,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[MLSN #5]: Prize Compilation"
    },
    "665ccce62db84166a1a0335f00cb049c": {
      "source_id": "665ccce62db84166a1a0335f00cb049c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33851,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "My Thoughts on the ML Safety Course"
    },
    "a6bcc3669c2f620fbf3464129a106e72": {
      "source_id": "a6bcc3669c2f620fbf3464129a106e72",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13649,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Failure modes in a shard theory alignment plan"
    },
    "7390f51e0942f41b73a98dfa5fbdab1b": {
      "source_id": "7390f51e0942f41b73a98dfa5fbdab1b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22359,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "QAPR 3: interpretability-guided training of neural nets"
    },
    "0dbc635ea1a2d6a490f08490df3956f8": {
      "source_id": "0dbc635ea1a2d6a490f08490df3956f8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23943,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Safety Endgame Stories"
    },
    "ea1ef3c9a5671ec36d48d78240fdbb92": {
      "source_id": "ea1ef3c9a5671ec36d48d78240fdbb92",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 99090,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "LOVE in a simbox is all you need"
    },
    "40b8641f4db6d6de799647b2d5537a45": {
      "source_id": "40b8641f4db6d6de799647b2d5537a45",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18171,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Builder/Breaker for Deconfusion"
    },
    "9190794aecc6e6886194e74d2738c608": {
      "source_id": "9190794aecc6e6886194e74d2738c608",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7157,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "It matters when the first sharp left turn happens"
    },
    "00b3a2c675507b3e60fe92b0737c37bf": {
      "source_id": "00b3a2c675507b3e60fe92b0737c37bf",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8816,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Where I currently disagree with Ryan Greenblatt\u2019s version of the ELK approach"
    },
    "cfb49945d615adc8d91429a9bc1ee066": {
      "source_id": "cfb49945d615adc8d91429a9bc1ee066",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12277,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Clarifying the Agent-Like Structure Problem"
    },
    "028fec73040e0a910ca9fd40b357ae31": {
      "source_id": "028fec73040e0a910ca9fd40b357ae31",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27173,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Distribution Shifts and The Importance of AI Safety"
    },
    "de5f0cdf783161dc95aedcad8a58de85": {
      "source_id": "de5f0cdf783161dc95aedcad8a58de85",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39343,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "(Structural) Stability of Coupled Optimizers"
    },
    "11ed4a73fe216bf8ec2e52e6e520b8bf": {
      "source_id": "11ed4a73fe216bf8ec2e52e6e520b8bf",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6233,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Eli's review of \"Is power-seeking AI an existential risk?\""
    },
    "f1e845963b94804fc80e81971253b134": {
      "source_id": "f1e845963b94804fc80e81971253b134",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28488,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Four usages of \"loss\" in AI"
    },
    "afb24f897fec034d3c751d693451a41d": {
      "source_id": "afb24f897fec034d3c751d693451a41d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1718,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A review of the Bio-Anchors report"
    },
    "66ed6539be17b67cdae7d2a12ee1cf2a": {
      "source_id": "66ed6539be17b67cdae7d2a12ee1cf2a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 71310,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Recall and Regurgitation in GPT2"
    },
    "45141559dee2cf570d66107f5592e0da": {
      "source_id": "45141559dee2cf570d66107f5592e0da",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24581,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "my current outlook on AI risk mitigation"
    },
    "d1c1595d661ed18f1f9d52e87806eaf2": {
      "source_id": "d1c1595d661ed18f1f9d52e87806eaf2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1865,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Paper+Summary: OMNIGROK: GROKKING BEYOND ALGORITHMIC DATA"
    },
    "c530043d6bcc22842ae5f65707e46656": {
      "source_id": "c530043d6bcc22842ae5f65707e46656",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31502,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "CHAI, Assistance Games, And Fully-Updated Deference [Scott Alexander]"
    },
    "8350711dd782eaac9af05808f05bcb45": {
      "source_id": "8350711dd782eaac9af05808f05bcb45",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7244,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Smoke without fire is scary"
    },
    "2fbaf3477bdebf12a417b3a390513488": {
      "source_id": "2fbaf3477bdebf12a417b3a390513488",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24018,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How are you dealing with ontology identification?"
    },
    "4b0a355484bf58d449da2b5327fd5966": {
      "source_id": "4b0a355484bf58d449da2b5327fd5966",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15224,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Reflection Mechanisms as an Alignment target: A follow-up survey"
    },
    "7e685d3fe3a2f8d02c8f973c25750be9": {
      "source_id": "7e685d3fe3a2f8d02c8f973c25750be9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1865,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Tracking Compute Stocks and Flows: Case Studies?"
    },
    "8d5e37f042c7fb9b673a10dceedec33b": {
      "source_id": "8d5e37f042c7fb9b673a10dceedec33b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5178,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Warning Shots Probably Wouldn't Change The Picture Much"
    },
    "707b0f18a4bcd5106fa43e18e0837fce": {
      "source_id": "707b0f18a4bcd5106fa43e18e0837fce",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5987,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "confusion about alignment requirements"
    },
    "749fb09269e255026b2c4293be2a9257": {
      "source_id": "749fb09269e255026b2c4293be2a9257",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26566,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "More Recent Progress in the Theory of Neural Networks"
    },
    "d0ab448fd17ec6559858cabaf3d8769b": {
      "source_id": "d0ab448fd17ec6559858cabaf3d8769b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61102,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A shot at the diamond-alignment problem"
    },
    "e70a5747da682f8c078ba9c1ac9aa18a": {
      "source_id": "e70a5747da682f8c078ba9c1ac9aa18a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5331,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What does it mean for an AGI to be 'safe'?"
    },
    "a1277f9d07f0ca37c3587fe4e50239e2": {
      "source_id": "a1277f9d07f0ca37c3587fe4e50239e2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4019,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "More examples of goal misgeneralization"
    },
    "f84940eef99b90c22500e8f03ee0e9cc": {
      "source_id": "f84940eef99b90c22500e8f03ee0e9cc",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5898,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Polysemanticity and Capacity in Neural Networks"
    },
    "93297bebb0899b0cc5409431cee7c7db": {
      "source_id": "93297bebb0899b0cc5409431cee7c7db",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9279,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Don't leave your fingerprints on the future"
    },
    "3a15fbacb6030f7a5ba40202041a3bac": {
      "source_id": "3a15fbacb6030f7a5ba40202041a3bac",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10570,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "SERI MATS Program - Winter 2022 Cohort"
    },
    "9934100131cdef2c6b6329b677fa0763": {
      "source_id": "9934100131cdef2c6b6329b677fa0763",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43951,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Good ontologies induce commutative diagrams"
    },
    "276da65247cef6ae4814a33a44cad8cc": {
      "source_id": "276da65247cef6ae4814a33a44cad8cc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22960,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Lessons learned from talking to >100 academics about AI safety"
    },
    "f0b0ebbba552fe1232702a1ebed7a305": {
      "source_id": "f0b0ebbba552fe1232702a1ebed7a305",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9109,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Disentangling inner alignment failures"
    },
    "04c505d0836a2699e6df69a04a25595d": {
      "source_id": "04c505d0836a2699e6df69a04a25595d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57746,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "QAPR 4: Inductive biases"
    },
    "5383883d226bb63ae9064029207080e3": {
      "source_id": "5383883d226bb63ae9064029207080e3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38298,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Instrumental convergence in single-agent systems"
    },
    "733e3a8b401a263d8fd805d197b421a3": {
      "source_id": "733e3a8b401a263d8fd805d197b421a3",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9743,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Building a transformer from scratch - AI safety up-skilling challenge"
    },
    "98e868f9b587b081057c589f51166b51": {
      "source_id": "98e868f9b587b081057c589f51166b51",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2219,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Alignment 201 curriculum"
    },
    "13f10fde69da06fe65b474221aaf1936": {
      "source_id": "13f10fde69da06fe65b474221aaf1936",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15829,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[MLSN #6]: Transparency survey, provable robustness, ML models that predict the "
    },
    "a67434eedcaaeeb63138a2c17c7fc95b": {
      "source_id": "a67434eedcaaeeb63138a2c17c7fc95b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16189,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Niceness is unnatural"
    },
    "8672fef711aabcdc0e3ff2342c6df239": {
      "source_id": "8672fef711aabcdc0e3ff2342c6df239",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16107,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Cataloguing Priors in Theory and Practice"
    },
    "d3706da897c7bad8a5fddb2b31dfb687": {
      "source_id": "d3706da897c7bad8a5fddb2b31dfb687",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 67262,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Misalignment-by-default in multi-agent systems"
    },
    "4a4e5aefa77595cf58624f186ed21803": {
      "source_id": "4a4e5aefa77595cf58624f186ed21803",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36437,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Greed Is the Root of This Evil"
    },
    "6bb7f24aeb9f8cfb10d5de5201e1ec7f": {
      "source_id": "6bb7f24aeb9f8cfb10d5de5201e1ec7f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4652,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Contra shard theory, in the context of the diamond maximizer problem"
    },
    "b551dd4de2e0f1194b04754f1e1dae9a": {
      "source_id": "b551dd4de2e0f1194b04754f1e1dae9a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 63683,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Counterarguments to the basic AI x-risk case"
    },
    "2c2b09fd16005a4e53c2a904ec689dda": {
      "source_id": "2c2b09fd16005a4e53c2a904ec689dda",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58439,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Instrumental convergence: scale and physical interactions"
    },
    "86e085478451e33750a4be93ab7fc643": {
      "source_id": "86e085478451e33750a4be93ab7fc643",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 67921,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Decision theory does not imply that we get to have nice things"
    },
    "019866460972f247731409205eb5e35f": {
      "source_id": "019866460972f247731409205eb5e35f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8406,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Science of Deep Learning - a technical agenda"
    },
    "2c45988d7063aac3bb1bfb7d2333d8a8": {
      "source_id": "2c45988d7063aac3bb1bfb7d2333d8a8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55004,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A conversation about Katja's counterarguments to AI risk"
    },
    "6d5213a34f177041c94ba9bea99c39a0": {
      "source_id": "6d5213a34f177041c94ba9bea99c39a0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33985,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Distilled Representations Research Agenda"
    },
    "ee0bc51ea95cea9d5c7eda7f5b3329fc": {
      "source_id": "ee0bc51ea95cea9d5c7eda7f5b3329fc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25382,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "An Extremely Opinionated Annotated List of My Favourite Mechanistic Interpretabi"
    },
    "432917415aa8d2b64791b10cd5f37cc7": {
      "source_id": "432917415aa8d2b64791b10cd5f37cc7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46224,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Response to Katja Grace's AI x-risk counterarguments"
    },
    "a033a06136b5286555d856b2c632a04e": {
      "source_id": "a033a06136b5286555d856b2c632a04e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2214,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Scaling Laws for Reward Model Overoptimization"
    },
    "6090b818229c419edffe361724669363": {
      "source_id": "6090b818229c419edffe361724669363",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25714,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Intelligent behaviour across systems, scales and substrates"
    },
    "47e84320a8410321e7089c3bf003fbd4": {
      "source_id": "47e84320a8410321e7089c3bf003fbd4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 60508,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Empowerment is (almost) All We Need"
    },
    "820a1896bf62fc9036a66c0d56e4a7b4": {
      "source_id": "820a1896bf62fc9036a66c0d56e4a7b4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4079,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "POWERplay: An open-source toolchain to study AI power-seeking"
    },
    "d096069ab10df9cb9e4f7d84ee95c0b0": {
      "source_id": "d096069ab10df9cb9e4f7d84ee95c0b0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6761,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Barebones Guide to Mechanistic Interpretability Prerequisites"
    },
    "f7670474db4fbe5cd36e149a73004652": {
      "source_id": "f7670474db4fbe5cd36e149a73004652",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 80874,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What does it take to defend the world against out-of-control AGIs?"
    },
    "791cb542203fc35f5a2f38b618ce2688": {
      "source_id": "791cb542203fc35f5a2f38b618ce2688",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28138,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Beyond Kolmogorov and Shannon"
    },
    "f371a3926369dda65273fb63616f1903": {
      "source_id": "f371a3926369dda65273fb63616f1903",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9488,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Maps and Blueprint; the Two Sides of the Alignment Equation"
    },
    "b48ee048495bb03be5c562fc1e372da8": {
      "source_id": "b48ee048495bb03be5c562fc1e372da8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26916,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Apply to the Redwood Research Mechanistic Interpretability Experiment (REMIX), a"
    },
    "3a8f9486d9ddc7af26c9d765f8d2fb5f": {
      "source_id": "3a8f9486d9ddc7af26c9d765f8d2fb5f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2770,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Prizes for ML Safety Benchmark Ideas"
    },
    "eabeba07119e447abbdb5a5d1ad7b13e": {
      "source_id": "eabeba07119e447abbdb5a5d1ad7b13e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18598,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Some Lessons Learned from Studying Indirect Object Identification in GPT-2 small"
    },
    "0118700b6cb1c2aa7988828ee1af35ed": {
      "source_id": "0118700b6cb1c2aa7988828ee1af35ed",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49243,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "\u00abBoundaries\u00bb, Part 3a: Defining boundaries as directed Markov blankets"
    },
    "2c0e909fdd3c6048924f2ceaa4a66f8a": {
      "source_id": "2c0e909fdd3c6048924f2ceaa4a66f8a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41652,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Embedding safety in ML development"
    },
    "3c8cdd62dc11faeb0d5816418c92e103": {
      "source_id": "3c8cdd62dc11faeb0d5816418c92e103",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 79004,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Superintelligent AI is necessary for an amazing future, but far from sufficient"
    },
    "41f213846fbf4d05a24aa7c67481ebd5": {
      "source_id": "41f213846fbf4d05a24aa7c67481ebd5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4592,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "\"Cars and Elephants\": a handwavy argument/analogy against mechanistic interpreta"
    },
    "3f89cb3bdda8e44e0c8a730be62b65a4": {
      "source_id": "3f89cb3bdda8e44e0c8a730be62b65a4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14278,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What sorts of systems can be deceptive?"
    },
    "11df5f7380629db398f6e3984ea5cf3f": {
      "source_id": "11df5f7380629db398f6e3984ea5cf3f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15853,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Auditing games for high-level interpretability"
    },
    "8069601fd6446badbbea2f1469140efa": {
      "source_id": "8069601fd6446badbbea2f1469140efa",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10345,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Clarifying AI X-risk"
    },
    "578acf4cd0e673bfc10b4d8be81251ee": {
      "source_id": "578acf4cd0e673bfc10b4d8be81251ee",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 49380,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Threat Model Literature Review"
    },
    "1ca73f795674d7993895080a20bb1bf0": {
      "source_id": "1ca73f795674d7993895080a20bb1bf0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1541,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Real-Time Research Recording: Can a Transformer Re-Derive Positional Info?"
    },
    "0a9b8631bdcc53813b229101035b8fe1": {
      "source_id": "0a9b8631bdcc53813b229101035b8fe1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 103502,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI X-risk >35% mostly based on a recent peer-reviewed argument"
    },
    "60bf71c3fc1b3666dc66ccc88ed3d533": {
      "source_id": "60bf71c3fc1b3666dc66ccc88ed3d533",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2455,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Mechanistic Interpretability as Reverse Engineering (follow-up to \"cars and elep"
    },
    "0ed2489a3e3da2eacd97079576a717ec": {
      "source_id": "0ed2489a3e3da2eacd97079576a717ec",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25502,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A newcomer\u2019s guide to the technical AI safety field"
    },
    "cc6c86797448a379f328436dbd2782b3": {
      "source_id": "cc6c86797448a379f328436dbd2782b3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26949,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Toy Models and Tegum Products"
    },
    "7ed2c1ad1b5927151fbac4e80663f098": {
      "source_id": "7ed2c1ad1b5927151fbac4e80663f098",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59832,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "For ELK truth is mostly a distraction"
    },
    "d5cfe70d5c50fc67449f64cb9575b7f8": {
      "source_id": "d5cfe70d5c50fc67449f64cb9575b7f8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25897,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Slippery Slope from DALLE-2 to Deepfake Anarchy"
    },
    "348d043435e5b25f89943bee5d30f92e": {
      "source_id": "348d043435e5b25f89943bee5d30f92e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6411,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Walkthrough of Interpretability in the Wild (w/ authors Kevin Wang, Arthur Con"
    },
    "f3b4413eedea2d266819feed852c4e45": {
      "source_id": "f3b4413eedea2d266819feed852c4e45",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9175,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How could we know that an AGI system will have good consequences?"
    },
    "57ec7e5005ca8f131008cd336620e586": {
      "source_id": "57ec7e5005ca8f131008cd336620e586",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19197,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Some advice on independent research"
    },
    "1e368cbdeb3a84b2da3553f48f6908c4": {
      "source_id": "1e368cbdeb3a84b2da3553f48f6908c4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14483,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Applying superintelligence without collusion"
    },
    "f93ac2e1c4f35bbc59d87a71d130b6e5": {
      "source_id": "f93ac2e1c4f35bbc59d87a71d130b6e5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30666,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "People care about each other even though they have imperfect motivational pointe"
    },
    "22d45f5b5db0de5be793024da852681a": {
      "source_id": "22d45f5b5db0de5be793024da852681a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3082,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Inverse scaling can become U-shaped"
    },
    "86ec5c7a6a0ba377ff0819b0ceae2529": {
      "source_id": "86ec5c7a6a0ba377ff0819b0ceae2529",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7947,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Trying to Make a Treacherous Mesa-Optimizer"
    },
    "d4c7dc6937d571d819bd97fe2febd364": {
      "source_id": "d4c7dc6937d571d819bd97fe2febd364",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11148,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Vanessa Kosoy's PreDCA, distilled"
    },
    "788e36f08d8e10abb9bf678c9a66a5dd": {
      "source_id": "788e36f08d8e10abb9bf678c9a66a5dd",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9553,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A short critique of Vanessa Kosoy's PreDCA"
    },
    "f0b1beffb709565e141323d150020706": {
      "source_id": "f0b1beffb709565e141323d150020706",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12427,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The economy as an analogy for advanced AI systems"
    },
    "17b0f0348256279370c4e6497e3b7079": {
      "source_id": "17b0f0348256279370c4e6497e3b7079",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 89404,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Value Formation: An Overarching Model"
    },
    "3918af8566db2347450291d4f5c50390": {
      "source_id": "3918af8566db2347450291d4f5c50390",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25524,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Unpacking \"Shard Theory\" as Hunch, Question, Theory, and Insight"
    },
    "c81ae3145e43b11ec705476962d9890d": {
      "source_id": "c81ae3145e43b11ec705476962d9890d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26713,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Current themes in mechanistic interpretability research"
    },
    "d05247a1540529545aa46da21e342174": {
      "source_id": "d05247a1540529545aa46da21e342174",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7194,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Engineering Monosemanticity in Toy Models"
    },
    "8ddeab280a1c7b2088ef575635e6cdaa": {
      "source_id": "8ddeab280a1c7b2088ef575635e6cdaa",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46555,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Don't design agents which exploit adversarial inputs"
    },
    "9b3ce1aa3bb6ebe8e1bbb7e84564137a": {
      "source_id": "9b3ce1aa3bb6ebe8e1bbb7e84564137a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38983,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "By Default, GPTs Think In Plain Sight"
    },
    "48e10c7b6a58994ee8383ee2962a7a49": {
      "source_id": "48e10c7b6a58994ee8383ee2962a7a49",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5550,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Short Dialogue on the Meaning of Reward Functions"
    },
    "70f77d3df1dd7f33901e4c6131c1534e": {
      "source_id": "70f77d3df1dd7f33901e4c6131c1534e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4651,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "ARC paper: Formalizing the presumption of independence"
    },
    "b0528e9448968de8eedbc48298702370": {
      "source_id": "b0528e9448968de8eedbc48298702370",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1744,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Walkthrough of In-Context Learning and Induction Heads (w/ Charles Frye) Part "
    },
    "6b1ff0145c4ada0ccd559f4e77179f64": {
      "source_id": "6b1ff0145c4ada0ccd559f4e77179f64",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50770,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI will change the world, but won\u2019t take it over by playing \u201c3-dimensional chess"
    },
    "6be8d8f6b953622ca866aff538dd3fa2": {
      "source_id": "6be8d8f6b953622ca866aff538dd3fa2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7638,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing AI Alignment Awards: $100k research contests about goal misgeneraliza"
    },
    "cf9ddaf5c69bddd18cd9849eaaa6ec2f": {
      "source_id": "cf9ddaf5c69bddd18cd9849eaaa6ec2f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 60320,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Brute-forcing the universe: a non-standard shot at diamond alignment"
    },
    "a0f99b2a64216478b73a8c73e7a299eb": {
      "source_id": "a0f99b2a64216478b73a8c73e7a299eb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 70170,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Simulators, constraints, and goal agnosticism: porbynotes vol. 1"
    },
    "7afc8cb064f79090f1b9a83298d5a0e9": {
      "source_id": "7afc8cb064f79090f1b9a83298d5a0e9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17831,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing AI safety Mentors and Mentees"
    },
    "c28d9081cdca6a4bd4b7d1c78c78a738": {
      "source_id": "c28d9081cdca6a4bd4b7d1c78c78a738",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16242,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Conjecture: a retrospective after 8 months of work"
    },
    "d42e9743eaf6c9cc80a3464960a7ab9c": {
      "source_id": "d42e9743eaf6c9cc80a3464960a7ab9c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3671,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Conjecture Second Hiring Round"
    },
    "e50c969ab4b892d786f5e5cb428b8cd4": {
      "source_id": "e50c969ab4b892d786f5e5cb428b8cd4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3165,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Clarifying wireheading terminology"
    },
    "02e0fbf906c1d859a07a5a61c81b0fd8": {
      "source_id": "02e0fbf906c1d859a07a5a61c81b0fd8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9075,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What I Learned Running Refine"
    },
    "c2b9b9e5b34cc412affa5ccf72a75de3": {
      "source_id": "c2b9b9e5b34cc412affa5ccf72a75de3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18848,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Corrigibility Via Thought-Process Deference"
    },
    "7859ef6cbe29f7cfd918f4d2dce3017b": {
      "source_id": "7859ef6cbe29f7cfd918f4d2dce3017b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13415,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Refining the Sharp Left Turn threat model, part 2: applying alignment techniques"
    },
    "6197540a7bf7892d6b0e468ed7a2775a": {
      "source_id": "6197540a7bf7892d6b0e468ed7a2775a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39168,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Mechanistic anomaly detection and ELK"
    },
    "fe448cba74e1cd3478eb41d354a2ef6d": {
      "source_id": "fe448cba74e1cd3478eb41d354a2ef6d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57179,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Don't align agents to evaluations of plans"
    },
    "29aec3eaca84c0672432309773da7716": {
      "source_id": "29aec3eaca84c0672432309773da7716",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 78463,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Singular Value Decompositions of Transformer Weight Matrices are Highly Inte"
    },
    "32d3c2222bd09a28d9ad76e817144ef8": {
      "source_id": "32d3c2222bd09a28d9ad76e817144ef8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 69377,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "My take on Jacob Cannell\u2019s take on AGI safety"
    },
    "8825b596c5972b9942979d253540b345": {
      "source_id": "8825b596c5972b9942979d253540b345",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29851,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Searching for Search"
    },
    "57fecb30b9dc1db98992c395b7cae779": {
      "source_id": "57fecb30b9dc1db98992c395b7cae779",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58820,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Alignment allows \"nonrobust\" decision-influences and doesn't require robust grad"
    },
    "e7c437259761910096d595d3084bb7b4": {
      "source_id": "e7c437259761910096d595d3084bb7b4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 72500,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why Would AI \"Aim\" To Defeat Humanity?"
    },
    "bb7e49bcd51dc50d7662d7d4ae336279": {
      "source_id": "bb7e49bcd51dc50d7662d7d4ae336279",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10944,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Distinguishing test from training"
    },
    "73d776faf7ffd39ad668f809eb2817fa": {
      "source_id": "73d776faf7ffd39ad668f809eb2817fa",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30586,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Multi-Component Learning and S-Curves"
    },
    "999a092bdcf2cb64e5953635fdea60ed": {
      "source_id": "999a092bdcf2cb64e5953635fdea60ed",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20864,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Theories of impact for Science of Deep Learning"
    },
    "af87afe5569890f0a7fc7b8b701c7660": {
      "source_id": "af87afe5569890f0a7fc7b8b701c7660",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1461,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Research request (alignment strategy): Deep dive on \"making AI solve alignment f"
    },
    "31eba06c00879d8947dedb1ae04268eb": {
      "source_id": "31eba06c00879d8947dedb1ae04268eb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30275,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Finding gliders in the game of life"
    },
    "16b69ae99687f8a02eddb578322d7938": {
      "source_id": "16b69ae99687f8a02eddb578322d7938",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17917,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Plan - 2022 Update"
    },
    "18d7e22f241bcd9ddc8362eccb40582e": {
      "source_id": "18d7e22f241bcd9ddc8362eccb40582e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28289,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Re-Examining LayerNorm"
    },
    "a5b225b6dd158f5d5c9fa0fd57dcf9a0": {
      "source_id": "a5b225b6dd158f5d5c9fa0fd57dcf9a0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7191,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Take 1: We're not going to reverse-engineer the AI."
    },
    "65c6d41bf6cde411a0db518d15d7de6d": {
      "source_id": "65c6d41bf6cde411a0db518d15d7de6d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4381,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A challenge for AGI organizations, and a challenge for readers"
    },
    "3d62c7be7f8b97c53dd58d87430bba54": {
      "source_id": "3d62c7be7f8b97c53dd58d87430bba54",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 108345,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Inner and outer alignment decompose one hard problem into two extremely hard pro"
    },
    "e055f835a99f70e06bee4b4b426f519d": {
      "source_id": "e055f835a99f70e06bee4b4b426f519d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41402,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Deconfusing Direct vs Amortised Optimization"
    },
    "17c7338d1e1faa724978b4063227d26a": {
      "source_id": "17c7338d1e1faa724978b4063227d26a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31773,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Subsets and quotients in interpretability"
    },
    "4372f0fd634b3b54f939b4b0656aa872": {
      "source_id": "4372f0fd634b3b54f939b4b0656aa872",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3372,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Take 2: Building tools to help build FAI is a legitimate strategy, but it's dual"
    },
    "b77f53bf9f68f77f3f1451d1f6630ef7": {
      "source_id": "b77f53bf9f68f77f3f1451d1f6630ef7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 67309,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Causal Scrubbing: a method for rigorously testing interpretability hypotheses [R"
    },
    "7ef7600669dca42bfcad940e194f3a7b": {
      "source_id": "7ef7600669dca42bfcad940e194f3a7b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55113,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Causal scrubbing: Appendix"
    },
    "d77a3078df75e57ec7a58c935d4e6c11": {
      "source_id": "d77a3078df75e57ec7a58c935d4e6c11",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 82237,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Causal scrubbing: results on a paren balance checker"
    },
    "3dbcaa891fa6111d1833920a7e1ed9be": {
      "source_id": "3dbcaa891fa6111d1833920a7e1ed9be",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 77344,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Causal scrubbing: results on induction heads"
    },
    "184933f15bcea481608e372620fcf2cc": {
      "source_id": "184933f15bcea481608e372620fcf2cc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 75879,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Logical induction for software engineers"
    },
    "95e59a7e030209dc78774f3309437605": {
      "source_id": "95e59a7e030209dc78774f3309437605",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3767,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Take 3: No indescribable heavenworlds."
    },
    "fcadc4aed200a836674ca3d6308894b2": {
      "source_id": "fcadc4aed200a836674ca3d6308894b2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2650,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Take 4: One problem with natural abstractions is there's too many of them."
    },
    "aec3656004f22da334d740f317969584": {
      "source_id": "aec3656004f22da334d740f317969584",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28664,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Steering Behaviour: Testing for (Non-)Myopia in Language Models"
    },
    "fe6d313e344e7c99cc7f5ed0e8b79057": {
      "source_id": "fe6d313e344e7c99cc7f5ed0e8b79057",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 173,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Link] Why I\u2019m optimistic about OpenAI\u2019s alignment approach"
    },
    "d7ee6e7e1e8f3e2526a1e06964f6daa1": {
      "source_id": "d7ee6e7e1e8f3e2526a1e06964f6daa1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1568,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Verification Is Not Easier Than Generation In General"
    },
    "37e1c81347fb42382dbdbc31f517cd57": {
      "source_id": "37e1c81347fb42382dbdbc31f517cd57",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5181,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Take 5: Another problem for natural abstractions is laziness."
    },
    "ac7537b288cf61df9e357b401cb261ba": {
      "source_id": "ac7537b288cf61df9e357b401cb261ba",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18260,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Using GPT-Eliezer against ChatGPT Jailbreaking"
    },
    "a1800dca5b6fee68efac245aa0449144": {
      "source_id": "a1800dca5b6fee68efac245aa0449144",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31869,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Mesa-Optimizers via Grokking"
    },
    "2324ee5be9913ef76e56060e140ed45f": {
      "source_id": "2324ee5be9913ef76e56060e140ed45f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3479,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "In defense of probably wrong mechanistic models"
    },
    "f7254a89067ce55f60e5f7cbba1f859a": {
      "source_id": "f7254a89067ce55f60e5f7cbba1f859a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4628,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Take 6: CAIS is actually Orwellian."
    },
    "5047bcb0980950ab5aac79b1c0d278d8": {
      "source_id": "5047bcb0980950ab5aac79b1c0d278d8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14311,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Thoughts on AGI organizations and capabilities work"
    },
    "87553a00586ea99d47e64f89bcffcf3e": {
      "source_id": "87553a00586ea99d47e64f89bcffcf3e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3561,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Take 7: You should talk about \"the human's utility function\" less."
    },
    "7893b9e52d487381d6739506d90999b2": {
      "source_id": "7893b9e52d487381d6739506d90999b2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12084,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Notes on OpenAI\u2019s alignment plan"
    },
    "0e9c8405a567102747dc0d56139b60cb": {
      "source_id": "0e9c8405a567102747dc0d56139b60cb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29286,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "You can still fetch the coffee today if you're dead tomorrow"
    },
    "1fdb33f411613c5c8c52d3a7aa706439": {
      "source_id": "1fdb33f411613c5c8c52d3a7aa706439",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2833,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Working towards AI alignment is better"
    },
    "dee987fb47d19bbdaba308cbfee91b7d": {
      "source_id": "dee987fb47d19bbdaba308cbfee91b7d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3335,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Take 8: Queer the inner/outer alignment dichotomy."
    },
    "c8f68987c3f08f77f5ce66f5cd4056f3": {
      "source_id": "c8f68987c3f08f77f5ce66f5cd4056f3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11098,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "My thoughts on OpenAI's Alignment plan"
    },
    "e18f8394eaa29ad1ac2606f479895874": {
      "source_id": "e18f8394eaa29ad1ac2606f479895874",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 738,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How promising are legal avenues to restrict AI training data?"
    },
    "967a03f801b061a55d70eca165785257": {
      "source_id": "967a03f801b061a55d70eca165785257",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2489,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[ASoT] Natural abstractions and AlphaZero"
    },
    "e03f08a11d3fafd5a4864efd7ed13bbc": {
      "source_id": "e03f08a11d3fafd5a4864efd7ed13bbc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29689,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Reframing inner alignment"
    },
    "94a3602d35d29f062ac6ca4c49573021": {
      "source_id": "94a3602d35d29f062ac6ca4c49573021",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45539,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Finite Factored Sets in Pictures"
    },
    "ba8c66c146a20a467dadc4ef18a3db0d": {
      "source_id": "ba8c66c146a20a467dadc4ef18a3db0d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40440,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Reflections on the PIBBSS Fellowship 2022"
    },
    "ff9016bea5f2494b479a1e4b511e5e88": {
      "source_id": "ff9016bea5f2494b479a1e4b511e5e88",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3613,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Take 9: No, RLHF/IDA/debate doesn't solve outer alignment."
    },
    "c74661a73bfc4c2a57ad86b7bcb46e27": {
      "source_id": "c74661a73bfc4c2a57ad86b7bcb46e27",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 88474,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Alignment with argument-networks and assessment-predictions"
    },
    "ca52e696b3eb4e3f5c37e4cd992f9f0d": {
      "source_id": "ca52e696b3eb4e3f5c37e4cd992f9f0d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4212,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Take 10: Fine-tuning with RLHF is aesthetically unsatisfying."
    },
    "221dca4f42998c39190515d5ced11009": {
      "source_id": "221dca4f42998c39190515d5ced11009",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3416,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI alignment is distinct from its near-term applications"
    },
    "1e6edd06b60ae4f715b11471f4cf7c3b": {
      "source_id": "1e6edd06b60ae4f715b11471f4cf7c3b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6080,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Existential AI Safety is NOT separate from near-term applications"
    },
    "8553a3feb8e16a1e02f5835e89f89e1f": {
      "source_id": "8553a3feb8e16a1e02f5835e89f89e1f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 64213,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Interim research report] Taking features out of superposition with sparse autoe"
    },
    "88277fffbaef80ed7b0bc6fdf1e4e66d": {
      "source_id": "88277fffbaef80ed7b0bc6fdf1e4e66d",
      "quality_score": 3.0,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4763,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Applications open for AGI Safety Fundamentals: Alignment Course"
    },
    "e67cc5f8e5e0f64c03002b90c0cdf193": {
      "source_id": "e67cc5f8e5e0f64c03002b90c0cdf193",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12846,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Trying to disambiguate different questions about whether RLHF is \u201cgood\u201d"
    },
    "6e7ddba8e3896e5d31cf00e10f61a1e0": {
      "source_id": "6e7ddba8e3896e5d31cf00e10f61a1e0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44139,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Extracting and Evaluating Causal Direction in LLMs' Activations"
    },
    "2d1e4f0d4acbf0016454ce69ed8f64bd": {
      "source_id": "2d1e4f0d4acbf0016454ce69ed8f64bd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15090,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "My AGI safety research\u20142022 review, \u201923 plans"
    },
    "f1c266c6933d592bfb17b112fa5524c8": {
      "source_id": "f1c266c6933d592bfb17b112fa5524c8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44464,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "\u00abBoundaries\u00bb, Part 3b: Alignment problems in terms of boundaries"
    },
    "0b3753e8d245ff2ea700a14442ebd947": {
      "source_id": "0b3753e8d245ff2ea700a14442ebd947",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25339,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Neorealism: a threat model & success criterion for existential safety"
    },
    "f897ea92e87f5c14b5b0512b192888d0": {
      "source_id": "f897ea92e87f5c14b5b0512b192888d0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 75987,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The next decades might be wild"
    },
    "9ea86c6941ef24dabb7b7b0524a7a22f": {
      "source_id": "9ea86c6941ef24dabb7b7b0524a7a22f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43757,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "High-level hopes for AI alignment"
    },
    "b3c06fa19a68ca3d1a5bae0a37abdb29": {
      "source_id": "b3c06fa19a68ca3d1a5bae0a37abdb29",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31173,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How \"Discovering Latent Knowledge in Language Models Without Supervision\" Fits I"
    },
    "5e7b772bc5256769508c30eeabba4bc1": {
      "source_id": "5e7b772bc5256769508c30eeabba4bc1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59561,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Proper scoring rules don\u2019t guarantee predicting fixed points"
    },
    "91b887a73e41d64eef03adc3cf6986a5": {
      "source_id": "91b887a73e41d64eef03adc3cf6986a5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17296,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Can we efficiently explain model behaviors?"
    },
    "3a7f98666663bfe88f6a503d63cf5031": {
      "source_id": "3a7f98666663bfe88f6a503d63cf5031",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2550,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Looking for an alignment tutor"
    },
    "900235722850463f8a57917b21bfe8a4": {
      "source_id": "900235722850463f8a57917b21bfe8a4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3714,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Positive values seem more robust and lasting than prohibitions"
    },
    "9319dc084c5c1c5788e956af42e2b011": {
      "source_id": "9319dc084c5c1c5788e956af42e2b011",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3609,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Take 11: \"Aligning language models\" should be weirder."
    },
    "33a9781a12b1d2229e1bdbc19fbce607": {
      "source_id": "33a9781a12b1d2229e1bdbc19fbce607",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 966,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Event [Berkeley]: Alignment Collaborator Speed-Meeting"
    },
    "8e8d989f7f9218bd7d482d930cd6d029": {
      "source_id": "8e8d989f7f9218bd7d482d930cd6d029",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38909,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Results from a survey on tool use and workflows in alignment research"
    },
    "12d2215008ef53299cc4dec129cbf70f": {
      "source_id": "12d2215008ef53299cc4dec129cbf70f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37769,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Towards Hodge-podge Alignment"
    },
    "39846d8662f268fa3e4f4672003461da": {
      "source_id": "39846d8662f268fa3e4f4672003461da",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39269,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Shard Theory in Nine Theses: a Distillation and Critical Appraisal"
    },
    "4070c76eb20924618566256c1824bc89": {
      "source_id": "4070c76eb20924618566256c1824bc89",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6103,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Take 12: RLHF's use is evidence that orgs will jam RL at real-world problems."
    },
    "d46acd25886b664e1e97cd1e9bab6c30": {
      "source_id": "d46acd25886b664e1e97cd1e9bab6c30",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31072,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "An Open Agency Architecture for Safe Transformative AI"
    },
    "d886f30373c922a849c41f1232a32a22": {
      "source_id": "d886f30373c922a849c41f1232a32a22",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14413,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Discovering Language Model Behaviors with Model-Written Evaluations"
    },
    "347c2e7135df52c961b8950e50b02862": {
      "source_id": "347c2e7135df52c961b8950e50b02862",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39805,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "CIRL Corrigibility is Fragile"
    },
    "8b3d928da4fbcd1ef13ac60dfe649d97": {
      "source_id": "8b3d928da4fbcd1ef13ac60dfe649d97",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6690,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Comprehensive Mechanistic Interpretability Explainer & Glossary"
    },
    "c82a78ba1412637e54083611264c9574": {
      "source_id": "c82a78ba1412637e54083611264c9574",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4847,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Take 13: RLHF bad, conditioning good."
    },
    "2d6450e6e4008ebc64f9ba5a0e04fb6c": {
      "source_id": "2d6450e6e4008ebc64f9ba5a0e04fb6c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11735,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Response to Holden\u2019s alignment plan"
    },
    "2fcb62fe1c1b282c0da9cbfbd4318da2": {
      "source_id": "2fcb62fe1c1b282c0da9cbfbd4318da2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36241,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Some Notes on the mathematics of Toy Autoencoding Problems"
    },
    "efa59dbe562d192dbc85fa98c8c5d899": {
      "source_id": "efa59dbe562d192dbc85fa98c8c5d899",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 75693,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Let\u2019s think about slowing down AI"
    },
    "e7473aa4a7a1759302832fbeea40952e": {
      "source_id": "e7473aa4a7a1759302832fbeea40952e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5293,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Take 14: Corrigibility isn't that great."
    },
    "f48e2be556fc4487576810e6ba773d78": {
      "source_id": "f48e2be556fc4487576810e6ba773d78",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26531,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Concrete Steps to Get Started in Transformer Mechanistic Interpretability"
    },
    "fdacec29cc50b5b09c9dd781c133e3c5": {
      "source_id": "fdacec29cc50b5b09c9dd781c133e3c5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18831,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Analogies between Software Reverse Engineering and Mechanistic Interpretability"
    },
    "0b95b3b1894da2944ed58d77f0ee4121": {
      "source_id": "0b95b3b1894da2944ed58d77f0ee4121",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28723,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Coherent extrapolated dreaming"
    },
    "f611cea23c6ad9bfc0922853201f2340": {
      "source_id": "f611cea23c6ad9bfc0922853201f2340",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9759,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Avoiding perpetual risk from TAI"
    },
    "6b5bfb86be8f808604a03ce9eb3d21a9": {
      "source_id": "6b5bfb86be8f808604a03ce9eb3d21a9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29245,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Can we efficiently distinguish different mechanisms?"
    },
    "3868ba4372b406b67caff3f108df8683": {
      "source_id": "3868ba4372b406b67caff3f108df8683",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9421,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why The Focus on Expected Utility Maximisers?"
    },
    "a7817017fa9cb58310940e65fde5de76": {
      "source_id": "a7817017fa9cb58310940e65fde5de76",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6367,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What AI Safety Materials Do ML Researchers Find Compelling?"
    },
    "fa5ff5366f063d2f4543d675e7bea116": {
      "source_id": "fa5ff5366f063d2f4543d675e7bea116",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 159711,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Getting up to Speed on the Speed Prior in 2022"
    },
    "e2a68a1277fb4a35128bfb8090313450": {
      "source_id": "e2a68a1277fb4a35128bfb8090313450",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24904,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "In Defense of Wrapper-Minds"
    },
    "a746402f4085b51332a5939427149653": {
      "source_id": "a746402f4085b51332a5939427149653",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22253,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "200 Concrete Open Problems in Mechanistic Interpretability: Introduction"
    },
    "9caf5de61b753e239b8d87e3d99ff845": {
      "source_id": "9caf5de61b753e239b8d87e3d99ff845",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16035,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "200 COP in MI: The Case for Analysing Toy Language Models"
    },
    "30feffec5184a1c787d8352b221fe40a": {
      "source_id": "30feffec5184a1c787d8352b221fe40a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2957,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "CFP for Rebellion and Disobedience in AI workshop"
    },
    "cbde4e197c5e88e3c71374e25ef02aa1": {
      "source_id": "cbde4e197c5e88e3c71374e25ef02aa1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31858,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Internal Interfaces Are a High-Priority Interpretability Target"
    },
    "abb8c8b4fde7d4d5ac1afa21e8a77a08": {
      "source_id": "abb8c8b4fde7d4d5ac1afa21e8a77a08",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26247,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "200 COP in MI: Looking for Circuits in the Wild"
    },
    "46c1042c49ca19e8f944b3af7c3a3198": {
      "source_id": "46c1042c49ca19e8f944b3af7c3a3198",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53999,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "But is it really in Rome? An investigation of the ROME model editing technique"
    },
    "f00f6a6710c47e9d3d20815133691cb1": {
      "source_id": "f00f6a6710c47e9d3d20815133691cb1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9449,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Models Don't \"Get Reward\""
    },
    "1e12b92ad14fa8c3a4955d36d23b2b6c": {
      "source_id": "1e12b92ad14fa8c3a4955d36d23b2b6c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21772,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "200 COP in MI: Interpreting Algorithmic Problems"
    },
    "f20d780272f0881e29fcc6ce204243ea": {
      "source_id": "f20d780272f0881e29fcc6ce204243ea",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45736,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Soft optimization makes the value target bigger"
    },
    "cf0caa57d185f002fdd6fa6112bd78ae": {
      "source_id": "cf0caa57d185f002fdd6fa6112bd78ae",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7981,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Simulators seminar sequence] #1 Background & shared assumptions"
    },
    "826f9e652a76329f6c7876c5a8bf0ded": {
      "source_id": "826f9e652a76329f6c7876c5a8bf0ded",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48724,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "200 COP in MI: Exploring Polysemanticity and Superposition"
    },
    "9cb631633a7920dc842483e3bee4130f": {
      "source_id": "9cb631633a7920dc842483e3bee4130f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35169,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Touch reality as soon as possible (when doing machine learning research)"
    },
    "1ea17b90ec252f0f4635a61b95a5efb4": {
      "source_id": "1ea17b90ec252f0f4635a61b95a5efb4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16811,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Causal representation learning as a technique to prevent goal misgeneralization"
    },
    "3cac5976fb7cea4c7708267a6d8f96f5": {
      "source_id": "3cac5976fb7cea4c7708267a6d8f96f5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18647,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Basic Facts about Language Model Internals"
    },
    "5591d35effa1cdf3bad9706bf369906b": {
      "source_id": "5591d35effa1cdf3bad9706bf369906b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28744,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "200 COP in MI: Analysing Training Dynamics"
    },
    "05c828d7b15f8a7e2c2f1cde69508bab": {
      "source_id": "05c828d7b15f8a7e2c2f1cde69508bab",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3567,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why I'm joining Anthropic"
    },
    "bff77de2441e4e5e2d0ecd4462073745": {
      "source_id": "bff77de2441e4e5e2d0ecd4462073745",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7667,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Camp, Virtual Edition 2023"
    },
    "e516208576db41ee398f5cf1fb97b8c2": {
      "source_id": "e516208576db41ee398f5cf1fb97b8c2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33240,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "200 COP in MI: Techniques, Tooling and Automation"
    },
    "d8e8fa60ea1d59733348efb7f719dba7": {
      "source_id": "d8e8fa60ea1d59733348efb7f719dba7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26683,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Definitions of \u201cobjective\u201d should be Probable and Predictive"
    },
    "25f32f6a5b15d3997c5ba5b2ce0bc895": {
      "source_id": "25f32f6a5b15d3997c5ba5b2ce0bc895",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16039,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Categorizing failures as \u201couter\u201d or \u201cinner\u201d misalignment is often confused"
    },
    "725f53cdab36b333f2b3c61e6e3cab42": {
      "source_id": "725f53cdab36b333f2b3c61e6e3cab42",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13483,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "200 COP in MI: Image Model Interpretability"
    },
    "d96f85b1c92cf786331027456bfaf0cf": {
      "source_id": "d96f85b1c92cf786331027456bfaf0cf",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4039,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Simulacra are Things"
    },
    "41d52eeb9c9c3c0d23426ce842b1a0e4": {
      "source_id": "41d52eeb9c9c3c0d23426ce842b1a0e4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16616,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Trying to isolate objectives: approaches toward high-level interpretability"
    },
    "78a1e60b5ebd92318eb82f6be75b6470": {
      "source_id": "78a1e60b5ebd92318eb82f6be75b6470",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13928,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[MLSN #7]: an example of an emergent internal optimizer"
    },
    "034979d5fe12ab25520759914ce30b4e": {
      "source_id": "034979d5fe12ab25520759914ce30b4e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4557,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Review AI Alignment posts to help figure out how to make a proper AI Alignment r"
    },
    "c65a99e5ee5528e8f0b4c5d20e708797": {
      "source_id": "c65a99e5ee5528e8f0b4c5d20e708797",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 100822,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Alignment Problem from a Deep Learning Perspective  (major rewrite)"
    },
    "6fe529869b3a2ae29b40c706ce4d6e31": {
      "source_id": "6fe529869b3a2ae29b40c706ce4d6e31",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20190,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "200 COP in MI: Interpreting Reinforcement Learning"
    },
    "845fac173c039bee2de4025ce6cfab6e": {
      "source_id": "845fac173c039bee2de4025ce6cfab6e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4611,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Reward is not Necessary: How to Create a Compositional Self-Preserving Agent for"
    },
    "abf6e4741235a4d3189afa719674f172": {
      "source_id": "abf6e4741235a4d3189afa719674f172",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2892,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing the 2023 PIBBSS Summer Research Fellowship"
    },
    "866c4d5a42d414c07c109101869f75b2": {
      "source_id": "866c4d5a42d414c07c109101869f75b2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13145,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Alignment Problems"
    },
    "4ac57bcfe70da809618713e1369f767f": {
      "source_id": "4ac57bcfe70da809618713e1369f767f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6297,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AGISF adaptation for in-person groups"
    },
    "9396c5af078218faf6133aa7deafe3fd": {
      "source_id": "9396c5af078218faf6133aa7deafe3fd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42087,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Disentangling Shard Theory into Atomic Claims"
    },
    "9b30d26ac60fd681edab927339179162": {
      "source_id": "9b30d26ac60fd681edab927339179162",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29470,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Some Arguments Against Strong Scaling"
    },
    "e883292944af736bc739fc966347acdf": {
      "source_id": "e883292944af736bc739fc966347acdf",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1239,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Tracr: Compiled Transformers as a Laboratory for Interpretability | DeepMind"
    },
    "2984be7fda11a6d959b1bb607ba73df9": {
      "source_id": "2984be7fda11a6d959b1bb607ba73df9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7196,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[ASoT] Simulators show us behavioural properties by default"
    },
    "542ecaec7d2d003469385ef9aa46efb6": {
      "source_id": "542ecaec7d2d003469385ef9aa46efb6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31952,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Concrete Reasons for Hope about AI"
    },
    "4948b4856de5b4230139702e2798599c": {
      "source_id": "4948b4856de5b4230139702e2798599c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 64766,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "World-Model Interpretability Is All We Need"
    },
    "8b00c5a40cdf0d33efd87bd17245e4d1": {
      "source_id": "8b00c5a40cdf0d33efd87bd17245e4d1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37840,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Underspecification of Oracle AI"
    },
    "54f92d5b43fdfaac4c0307b350975030": {
      "source_id": "54f92d5b43fdfaac4c0307b350975030",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13744,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Speculation on Path-Dependance in Large Language Models."
    },
    "dbf27937faf307745179f48493b26e45": {
      "source_id": "dbf27937faf307745179f48493b26e45",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52226,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Experiment Idea: RL Agents Evading Learned Shutdownability"
    },
    "6ea8dbc43b1dae19ce47bcc06c364f56": {
      "source_id": "6ea8dbc43b1dae19ce47bcc06c364f56",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48583,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Neural networks generalize because of this one weird trick"
    },
    "0818747b43a7d1259ca0babe2b48ac17": {
      "source_id": "0818747b43a7d1259ca0babe2b48ac17",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30691,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Gradient Filtering"
    },
    "f336ea23da882f7b4fee17c26471972c": {
      "source_id": "f336ea23da882f7b4fee17c26471972c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 77244,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "200 COP in MI: Studying Learned Features in Language Models"
    },
    "ac377fa0d85784a1683110e17a85232c": {
      "source_id": "ac377fa0d85784a1683110e17a85232c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3708,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Thoughts on refusing harmful requests to large language models"
    },
    "23aa0e3fdcf8203f7ac285f11dbbbf6c": {
      "source_id": "23aa0e3fdcf8203f7ac285f11dbbbf6c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5390,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Shard theory alignment has important, often-overlooked free parameters."
    },
    "0b2ea597d46051bf2f845ebe955f869a": {
      "source_id": "0b2ea597d46051bf2f845ebe955f869a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 64070,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Critique of some recent philosophy of LLMs\u2019 minds"
    },
    "b1b797724f588fdceb3cc630e8a6ae3b": {
      "source_id": "b1b797724f588fdceb3cc630e8a6ae3b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4776,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Large language models learn to represent the world"
    },
    "703950eeb219f1f96f697fc466d11e5e": {
      "source_id": "703950eeb219f1f96f697fc466d11e5e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40573,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What a compute-centric framework says about AI takeoff speeds"
    },
    "26e7de6ad320e752b0095c1ad2b71b4d": {
      "source_id": "26e7de6ad320e752b0095c1ad2b71b4d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43711,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Some of my disagreements with List of Lethalities"
    },
    "c56601afc09931b0edbc7ac84ab0abda": {
      "source_id": "c56601afc09931b0edbc7ac84ab0abda",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56582,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Thoughts on hardware / compute requirements for AGI"
    },
    "e11392ed5acaeca6ec2da845a593c604": {
      "source_id": "e11392ed5acaeca6ec2da845a593c604",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14650,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\u201cEndgame safety\u201d for AGI"
    },
    "44e78ea5687f222ef947d19aa802cce0": {
      "source_id": "44e78ea5687f222ef947d19aa802cce0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11080,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Gradient hacking is extremely difficult"
    },
    "bf39b9bfd691a5db49293930cf568c27": {
      "source_id": "bf39b9bfd691a5db49293930cf568c27",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33064,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How-to Transformer Mechanistic Interpretability\u2014in 50 lines of code or less!"
    },
    "75fb8b5dd72f90d609b2576d8dca63fe": {
      "source_id": "75fb8b5dd72f90d609b2576d8dca63fe",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30777,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Inverse Scaling Prize: Second Round Winners"
    },
    "b1ad002c5805f333a7985cec5aba9145": {
      "source_id": "b1ad002c5805f333a7985cec5aba9145",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47980,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Alexander and Yudkowsky on AGI goals"
    },
    "53e5ae3e8534bece6a6b18eba5979602": {
      "source_id": "53e5ae3e8534bece6a6b18eba5979602",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2782,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Quick thoughts on \"scalable oversight\" / \"super-human feedback\" research"
    },
    "da267a3abb735aa6bca2105234f62b30": {
      "source_id": "da267a3abb735aa6bca2105234f62b30",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16545,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Thoughts on the impact of RLHF research"
    },
    "10352725b7a5377f755ce1c214c4812a": {
      "source_id": "10352725b7a5377f755ce1c214c4812a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48654,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AGI will have learnt utility functions"
    },
    "32ba2f4efd1450c3a36055d8c2381ce7": {
      "source_id": "32ba2f4efd1450c3a36055d8c2381ce7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20950,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The role of Bayesian ML in AI safety - an overview"
    },
    "ef876ace4c35fa1f9adc855f7c6d824c": {
      "source_id": "ef876ace4c35fa1f9adc855f7c6d824c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26175,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Spooky action at a distance in the loss landscape"
    },
    "50effa31ba204d2c5df10ca31b13d492": {
      "source_id": "50effa31ba204d2c5df10ca31b13d492",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 66899,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Stop-gradients lead to fixed point predictions"
    },
    "d1128fccde16fd1c77c2d38c1a250e62": {
      "source_id": "d1128fccde16fd1c77c2d38c1a250e62",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4113,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "formal alignment: what it is, and some proposals"
    },
    "67393fcea6ccda985837f48b342f9596": {
      "source_id": "67393fcea6ccda985837f48b342f9596",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34401,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Structure, creativity, and novelty"
    },
    "4aff9f741c5b4fe899f9cb201e5abdd4": {
      "source_id": "4aff9f741c5b4fe899f9cb201e5abdd4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4554,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Model-driven feedback could amplify alignment failures"
    },
    "3ecedd95c8d0b2a0b2f8e58cb72d204f": {
      "source_id": "3ecedd95c8d0b2a0b2f8e58cb72d204f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4411,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What I mean by \"alignment is in large part about making cognition aimable at all"
    },
    "7f18deaa4e343abd217adb913a76f780": {
      "source_id": "7f18deaa4e343abd217adb913a76f780",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2497,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Call for submissions: \u201c(In)human Values and Artificial Agency\u201d, ALIFE 2023"
    },
    "87bbae84319619709872e4f94353fea9": {
      "source_id": "87bbae84319619709872e4f94353fea9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3156,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why I hate the \"accident vs. misuse\" AI x-risk dichotomy (quick thoughts on \"str"
    },
    "f0bfe501d337186f601d9319f20d595e": {
      "source_id": "f0bfe501d337186f601d9319f20d595e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8386,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Inner Misalignment in \"Simulator\" LLMs"
    },
    "6b2ac595710fd8667590571fd4c1aeb8": {
      "source_id": "6b2ac595710fd8667590571fd4c1aeb8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13647,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Mechanistic Interpretability Quickstart Guide"
    },
    "d60dbd209fb688a70160b39988dd64e1": {
      "source_id": "d60dbd209fb688a70160b39988dd64e1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14269,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Criticism of the main framework in AI alignment"
    },
    "17414883961c557893926c61cacaf468": {
      "source_id": "17414883961c557893926c61cacaf468",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9868,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "On value in humans, other animals, and AI"
    },
    "4e8eb43553226d57dbf730ced45fec3e": {
      "source_id": "4e8eb43553226d57dbf730ced45fec3e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 669,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The effect of horizon length on scaling laws"
    },
    "65c4eb5cc8b70dd51a978fd31da0c053": {
      "source_id": "65c4eb5cc8b70dd51a978fd31da0c053",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11750,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Trends in the dollar training cost of machine learning systems"
    },
    "41f88640f20336abfa9f558a998ec0ab": {
      "source_id": "41f88640f20336abfa9f558a998ec0ab",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4646,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Language Models can be Utility-Maximising Agents"
    },
    "9020dbe5e722f9ed52c6b28bb6432d47": {
      "source_id": "9020dbe5e722f9ed52c6b28bb6432d47",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 60158,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "More findings on Memorization and double descent"
    },
    "8e65e9b6cfe36a99d898542a49417929": {
      "source_id": "8e65e9b6cfe36a99d898542a49417929",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 92402,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Research agenda: Formalizing abstractions of computations"
    },
    "572510279055ebf9947f8fb824e27bb5": {
      "source_id": "572510279055ebf9947f8fb824e27bb5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42234,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "More findings on maximal data dimension"
    },
    "67c2e377b7dd9b56dbd89da9a891b7b5": {
      "source_id": "67c2e377b7dd9b56dbd89da9a891b7b5",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8624,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Normative vs Descriptive Models of Agency"
    },
    "939d8213f82904d86a538f2f7bb9a369": {
      "source_id": "939d8213f82904d86a538f2f7bb9a369",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31841,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Conditioning Predictive Models: Large language models as predictors"
    },
    "0144003ab670921c3c9dd6f46176f224": {
      "source_id": "0144003ab670921c3c9dd6f46176f224",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 121905,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Conditioning Predictive Models: Outer alignment via careful conditioning"
    },
    "5d9895026f176973c1675f30576fed2a": {
      "source_id": "5d9895026f176973c1675f30576fed2a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 208336,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 19 - Mechanistic Interpretability with Neel Nanda"
    },
    "f0d4fbcb5a21ceb795de489a32dee134": {
      "source_id": "f0d4fbcb5a21ceb795de489a32dee134",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 641,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Mech Interp Project Advising Call: Memorisation in GPT-2 Small"
    },
    "bd35ffd5eb04f698fa2beb51f2800367": {
      "source_id": "bd35ffd5eb04f698fa2beb51f2800367",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31309,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Evaluations (of new AI Safety researchers) can be noisy"
    },
    "a85f13a01b78393ec2147cee178409db": {
      "source_id": "a85f13a01b78393ec2147cee178409db",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37240,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Control"
    },
    "d97a0f196931aed5d343635908e2a8a2": {
      "source_id": "d97a0f196931aed5d343635908e2a8a2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30332,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "SolidGoldMagikarp (plus, prompt generation)"
    },
    "e2aa26ba29c6d24a75e931b257147ebc": {
      "source_id": "e2aa26ba29c6d24a75e931b257147ebc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29634,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Gradient surfing: the hidden role of regularization"
    },
    "5eb9bf3a5348dc092f45dc74c252d473": {
      "source_id": "5eb9bf3a5348dc092f45dc74c252d473",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51464,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Decision Transformer Interpretability"
    },
    "cc6b1cb04414f779fa044d4d5ea02acb": {
      "source_id": "cc6b1cb04414f779fa044d4d5ea02acb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37809,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "SolidGoldMagikarp II: technical details and more recent findings"
    },
    "2215ecbd70ad469f43c4fd7db22f669c": {
      "source_id": "2215ecbd70ad469f43c4fd7db22f669c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23491,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Conditioning Predictive Models: The case for competitiveness"
    },
    "a54a6257311b0be06d30f6263289b3d7": {
      "source_id": "a54a6257311b0be06d30f6263289b3d7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39612,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Conditioning Predictive Models: Making inner alignment as easy as possible"
    },
    "faf5fda32f997d39a0f52507364b60e1": {
      "source_id": "faf5fda32f997d39a0f52507364b60e1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 79304,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A multi-disciplinary view on AI safety research"
    },
    "6d0767c41f24d704a48077616e0b98a2": {
      "source_id": "6d0767c41f24d704a48077616e0b98a2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41183,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Conditioning Predictive Models: Interactions with other approaches"
    },
    "b364dcec5e49e6ce1e52d178a93dc21d": {
      "source_id": "b364dcec5e49e6ce1e52d178a93dc21d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2080,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A (EtA: quick) note on terminology:  AI Alignment != AI x-safety"
    },
    "415771a684551c9c4aa061daea6c7610": {
      "source_id": "415771a684551c9c4aa061daea6c7610",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16875,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Anomalous tokens reveal the original identities of Instruct models"
    },
    "f1b8e7d690c5b05c984d1292a649492b": {
      "source_id": "f1b8e7d690c5b05c984d1292a649492b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11950,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "On Developing a Mathematical Theory of Interpretability"
    },
    "7b4c01cc02574d776c08af7a0e40d2b3": {
      "source_id": "7b4c01cc02574d776c08af7a0e40d2b3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1272,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Notes on the Mathematics of LLM Architectures"
    },
    "3e0911d44ea90b062c8798d48b794f63": {
      "source_id": "3e0911d44ea90b062c8798d48b794f63",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6500,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Engineer\u2019s Interpretability Sequence (EIS) I: Intro"
    },
    "f5601087a38d6cf31b4a549cd36d38d9": {
      "source_id": "f5601087a38d6cf31b4a549cd36d38d9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7428,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "EIS II: What is \u201cInterpretability\u201d?"
    },
    "7d3009298224052a513177dc2d9af1f0": {
      "source_id": "7d3009298224052a513177dc2d9af1f0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20282,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Conditioning Predictive Models: Deployment strategy"
    },
    "5cba1d093d6ee5880af17bf9dab22569": {
      "source_id": "5cba1d093d6ee5880af17bf9dab22569",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73973,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "FLI Podcast: Connor Leahy on AI Progress, Chimps, Memes, and Markets (Part 1/3)"
    },
    "69f5299a82d5866ec41bea2f915147fa": {
      "source_id": "69f5299a82d5866ec41bea2f915147fa",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 78767,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Cyborgism"
    },
    "9dcb8805d1247aa5f1bcdecd2227aa06": {
      "source_id": "9dcb8805d1247aa5f1bcdecd2227aa06",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40291,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Conditioning Predictive Models: Open problems, Conclusion, and Appendix"
    },
    "3fce0a395ed3d615161b1132ceb672e4": {
      "source_id": "3fce0a395ed3d615161b1132ceb672e4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19938,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why I\u2019m not working on {debate, RRM, ELK, natural abstractions}"
    },
    "76ae6dfa68375ff136e48277e2f3ec65": {
      "source_id": "76ae6dfa68375ff136e48277e2f3ec65",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39791,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A proposed method for forecasting transformative AI"
    },
    "55d735df11f896ed2c97c8ff10bfa36d": {
      "source_id": "55d735df11f896ed2c97c8ff10bfa36d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16301,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A note on 'semiotic physics'"
    },
    "b2218283d3e0e60096cfa4d9a7881f0d": {
      "source_id": "b2218283d3e0e60096cfa4d9a7881f0d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38164,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "We Found An Neuron in GPT-2"
    },
    "ff95acf309f13e437f0ae611cd0beb7a": {
      "source_id": "ff95acf309f13e437f0ae611cd0beb7a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48683,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why almost every RL agent does learned optimization"
    },
    "6b23607ac1a1c2ec3ea7270671c065ac": {
      "source_id": "6b23607ac1a1c2ec3ea7270671c065ac",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25164,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The conceptual Doppelg\u00e4nger problem"
    },
    "f58c9a68218911ad3570679f701fc2b2": {
      "source_id": "f58c9a68218911ad3570679f701fc2b2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45846,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "LLM Basics: Embedding Spaces - Transformer Token Vectors Are Not Points in Space"
    },
    "e50c68c0bceaed464830f57cdff3d518": {
      "source_id": "e50c68c0bceaed464830f57cdff3d518",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4619,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Linguistic Blind Spot of Value-Aligned Agency, Natural and Artificial"
    },
    "88e9f4696ba03286b8856bdbb18471dd": {
      "source_id": "88e9f4696ba03286b8856bdbb18471dd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24244,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "EIS III: Broad Critiques of Interpretability Research"
    },
    "c66e63b9572d2e83d0246377cf8e2e9d": {
      "source_id": "c66e63b9572d2e83d0246377cf8e2e9d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11196,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Don't accelerate problems you're trying to solve"
    },
    "007c4e6d7ec3fa8ac5336ee4e69beb60": {
      "source_id": "007c4e6d7ec3fa8ac5336ee4e69beb60",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8989,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "EIS IV: A Spotlight on Feature Attribution/Saliency"
    },
    "deef020b339ef1b78b69bb7d44eb9094": {
      "source_id": "deef020b339ef1b78b69bb7d44eb9094",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40540,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "EIS V: Blind Spots In AI Safety Interpretability Research"
    },
    "5c5fff809eda89d16c9e4fa4ca0cdcad": {
      "source_id": "5c5fff809eda89d16c9e4fa4ca0cdcad",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30047,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Non-Unitary Quantum Logic -- SERI MATS Research Sprint"
    },
    "e627cc1ca064017cf9370c9029321703": {
      "source_id": "e627cc1ca064017cf9370c9029321703",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3661,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Paper: The Capacity for Moral Self-Correction in Large Language Models (Anthropi"
    },
    "6171171b91334d13b38d6ab74e5336e2": {
      "source_id": "6171171b91334d13b38d6ab74e5336e2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6253,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Powerful mesa-optimisation is already here"
    },
    "a9a4d86238ff4fcd0cec1d990586971b": {
      "source_id": "a9a4d86238ff4fcd0cec1d990586971b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19975,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Automating Consistency"
    },
    "b67b368c7e73ae224844e14a82f12320": {
      "source_id": "b67b368c7e73ae224844e14a82f12320",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12287,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "One-layer transformers aren\u2019t equivalent to a set of skip-trigrams"
    },
    "b4ec43d2b209acf69611e1bf5b37923b": {
      "source_id": "b4ec43d2b209acf69611e1bf5b37923b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27235,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "EIS VI: Critiques of Mechanistic Interpretability Work in AI Safety"
    },
    "ad4047216dcaef67ea6ee2456face1e1": {
      "source_id": "ad4047216dcaef67ea6ee2456face1e1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28700,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Two problems with \u2018Simulators\u2019 as a frame"
    },
    "4496ab74b376a74dd41a413fbc9a527a": {
      "source_id": "4496ab74b376a74dd41a413fbc9a527a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5058,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "EIS VII: A Challenge for Mechanists"
    },
    "c80db4a45371eccafc31e79bbec0fd1e": {
      "source_id": "c80db4a45371eccafc31e79bbec0fd1e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4984,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Parametrically retargetable decision-makers tend to seek power"
    },
    "25f123be0cba9145925e29cb293d6849": {
      "source_id": "25f123be0cba9145925e29cb293d6849",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13790,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AGI in sight: our look at the game board"
    },
    "ac08c86b4faa2032e63ef0cdee4ceb6c": {
      "source_id": "ac08c86b4faa2032e63ef0cdee4ceb6c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14715,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Does novel understanding imply novel agency / values?"
    },
    "1cc7cb600c6aef251ec976495aabcaf9": {
      "source_id": "1cc7cb600c6aef251ec976495aabcaf9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8285,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "EIS VIII: An Engineer\u2019s Understanding of Deceptive Alignment"
    },
    "7d23f8b7a66e82afeb827e1548e45168": {
      "source_id": "7d23f8b7a66e82afeb827e1548e45168",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51225,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A Neural Network undergoing Gradient-based Training as a Complex System"
    },
    "6271613390b4530ea64944d691a2df95": {
      "source_id": "6271613390b4530ea64944d691a2df95",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30449,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Emergent Deception and Emergent Optimization"
    },
    "832971d3637807e09f8a44e809053e9f": {
      "source_id": "832971d3637807e09f8a44e809053e9f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12198,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[MLSN #8] Mechanistic interpretability, using law to inform AI alignment, scalin"
    },
    "4dadaa890230502d5ed71c388d494504": {
      "source_id": "4dadaa890230502d5ed71c388d494504",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19019,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "EIS IX: Interpretability and Adversaries"
    },
    "757b257a2b75ab8122caaafef5b6de49": {
      "source_id": "757b257a2b75ab8122caaafef5b6de49",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45506,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A circuit for Python docstrings in a 4-layer attention-only transformer"
    },
    "01e5c1b060bf313ee2598117d5671f1f": {
      "source_id": "01e5c1b060bf313ee2598117d5671f1f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62168,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "There are no coherence theorems"
    },
    "264446ee1fc38d604705d5cf1a9facc4": {
      "source_id": "264446ee1fc38d604705d5cf1a9facc4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16754,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Behavioral and mechanistic definitions (often confuse AI alignment discussions)"
    },
    "c8eb96ff44a1978a0d555b928f1559a5": {
      "source_id": "c8eb96ff44a1978a0d555b928f1559a5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13275,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Instrumentality makes agents agenty"
    },
    "feba38882d6f08d3bb6c6575bd83fe54": {
      "source_id": "feba38882d6f08d3bb6c6575bd83fe54",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55411,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Basic facts about language models during training"
    },
    "016c175b5b4c534b42da5b71f126fb61": {
      "source_id": "016c175b5b4c534b42da5b71f126fb61",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6146,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "EIS X: Continual Learning, Modularity, Compression, and Biological Brains"
    },
    "c58b39e8801622c9379a8507fc1cd938": {
      "source_id": "c58b39e8801622c9379a8507fc1cd938",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25974,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Pretraining Language Models with Human Preferences"
    },
    "712d8e07f5c39d7acc504e7502c7d58d": {
      "source_id": "712d8e07f5c39d7acc504e7502c7d58d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10269,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Open Agency Model"
    },
    "56e6ce9336c6685147b04dca9370338a": {
      "source_id": "56e6ce9336c6685147b04dca9370338a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11009,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Cyborg Periods: There will be multiple AI transitions"
    },
    "de5394c9543546064606b206ab94636b": {
      "source_id": "de5394c9543546064606b206ab94636b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37577,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "EIS XI: Moving Forward"
    },
    "221b8882dc603b5b3343473655d46124": {
      "source_id": "221b8882dc603b5b3343473655d46124",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 129201,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Full Transcript: Eliezer Yudkowsky on the Bankless podcast"
    },
    "5a04342a186de59431c3ba5954f30ce5": {
      "source_id": "5a04342a186de59431c3ba5954f30ce5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14753,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "EIS XII: Summary"
    },
    "924e6094047cacd859ff70284e98fe08": {
      "source_id": "924e6094047cacd859ff70284e98fe08",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5833,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI that shouldn't work, yet kind of does"
    },
    "37a9d41ff1dce3ba21e4f8212be88d16": {
      "source_id": "37a9d41ff1dce3ba21e4f8212be88d16",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13342,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Teleosemantics!"
    },
    "65ac5546ea1c7ebb7cdf8e58d5ac86a8": {
      "source_id": "65ac5546ea1c7ebb7cdf8e58d5ac86a8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13205,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Sam Altman: \"Planning for AGI and beyond\""
    },
    "6067921cdae34b550f9ebff46e6b885e": {
      "source_id": "6067921cdae34b550f9ebff46e6b885e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4742,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Retrospective on the 2022 Conjecture AI Discussions"
    },
    "d620e0e8c1548336e17b6c1b56fa8f1a": {
      "source_id": "d620e0e8c1548336e17b6c1b56fa8f1a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 86438,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Christiano (ARC) and GA (Conjecture) Discuss Alignment Cruxes"
    },
    "ca6da8576b80007a82b59c02e2e26345": {
      "source_id": "ca6da8576b80007a82b59c02e2e26345",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7552,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Agents vs. Predictors: Concrete differentiating factors"
    },
    "ac5d648650602b072fe3e5992587b206": {
      "source_id": "ac5d648650602b072fe3e5992587b206",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11765,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Cognitive Emulation: A Naive AI Safety Proposal"
    },
    "b7e645dc9f4c31f38aa5dd331c13ac5c": {
      "source_id": "b7e645dc9f4c31f38aa5dd331c13ac5c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11795,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A mechanistic explanation for SolidGoldMagikarp-like tokens in GPT2"
    },
    "9a2931cc1b8a598b08e3f670d015b040": {
      "source_id": "9a2931cc1b8a598b08e3f670d015b040",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21575,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Preference Fulfillment Hypothesis"
    },
    "f023115459e3d67ceb3bac5b437ddb63": {
      "source_id": "f023115459e3d67ceb3bac5b437ddb63",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 69033,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Simulators seminar sequence] #2 Semiotic physics - revamped"
    },
    "ee5b57bcfa4872e7d9ade98aee2e6bbf": {
      "source_id": "ee5b57bcfa4872e7d9ade98aee2e6bbf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44599,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Counting-down vs. counting-up coherence"
    },
    "3b94b00f0ce9635da481d47a90834d7c": {
      "source_id": "3b94b00f0ce9635da481d47a90834d7c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1304,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "$20 Million in NSF Grants for Safety Research"
    },
    "34452235365e0abc6824e5a79a26aeea": {
      "source_id": "34452235365e0abc6824e5a79a26aeea",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34379,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Power-seeking can be probable and predictive for trained agents"
    },
    "3f5e4872dfee734e5b28c245036977f3": {
      "source_id": "3f5e4872dfee734e5b28c245036977f3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 85906,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Inside the mind of a superhuman Go model: How does Leela Zero read ladders?"
    },
    "a52cd9eaa0f1b0cbc5274bd3ba6a64e3": {
      "source_id": "a52cd9eaa0f1b0cbc5274bd3ba6a64e3",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8349,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Implied \"utilities\" of simulators are broad, dense, and shallow"
    },
    "8221c31f7dee4eb92043f413593864e6": {
      "source_id": "8221c31f7dee4eb92043f413593864e6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28548,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Predictions for shard theory mechanistic interpretability results"
    },
    "3039edd28ab8bbcd60c92bbd4ef6c2e5": {
      "source_id": "3039edd28ab8bbcd60c92bbd4ef6c2e5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52240,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Waluigi Effect (mega-post)"
    },
    "ea0906ca508bfb62b08f6f90db9cc045": {
      "source_id": "ea0906ca508bfb62b08f6f90db9cc045",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6523,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "state of my alignment research, and what needs work"
    },
    "b99f673a5d7721f5c0d1b7b1da4931db": {
      "source_id": "b99f673a5d7721f5c0d1b7b1da4931db",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33196,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A reply to Byrnes on the Free Energy Principle"
    },
    "89905928a6ac89567d51c8aa5658b273": {
      "source_id": "89905928a6ac89567d51c8aa5658b273",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24585,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why are counterfactuals elusive?"
    },
    "827aab889c0ca5c2b5293bbea51b9d10": {
      "source_id": "827aab889c0ca5c2b5293bbea51b9d10",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14709,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Acausal normalcy"
    },
    "c422f170399d53753a8cd5a06f970f49": {
      "source_id": "c422f170399d53753a8cd5a06f970f49",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13831,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why Not Just... Build Weak AI Tools For AI Alignment Research?"
    },
    "e68ec1fad43b87345598e72245ea1410": {
      "source_id": "e68ec1fad43b87345598e72245ea1410",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29764,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Do humans derive values from fictitious imputed coherence?"
    },
    "62d9e59f035496b184005fb86feb29e5": {
      "source_id": "62d9e59f035496b184005fb86feb29e5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 10195,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] Some high-level thoughts on the DeepMind alignment team's strategy"
    },
    "22b6dfd3475953e3a5d0e8355cee399f": {
      "source_id": "22b6dfd3475953e3a5d0e8355cee399f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 83257,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety in a World of Vulnerable Machine Learning Systems"
    },
    "a88eb6ff85cc195f96daa1007d8ad45b": {
      "source_id": "a88eb6ff85cc195f96daa1007d8ad45b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3482,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Squeezing foundations research assistance out of formal logic narrow AI."
    },
    "0606d718a0b8bc03cfb77b195b0282fe": {
      "source_id": "0606d718a0b8bc03cfb77b195b0282fe",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1895,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Utility uncertainty vs. expected information gain"
    },
    "128c585dc78359b0a9c76d0fe95cdb46": {
      "source_id": "128c585dc78359b0a9c76d0fe95cdb46",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59028,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Translucent Thoughts Hypotheses and Their Implications"
    },
    "a2f63c0dee0b62c37a5228e31d6c6cf7": {
      "source_id": "a2f63c0dee0b62c37a5228e31d6c6cf7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3564,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Anthropic's Core Views on AI Safety"
    },
    "a8b48ad96ab0931b3559a1fb16529343": {
      "source_id": "a8b48ad96ab0931b3559a1fb16529343",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17650,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why Not Just Outsource Alignment Research To An AI?"
    },
    "de34a6df9bda0c8756d7d12bf6059d9c": {
      "source_id": "de34a6df9bda0c8756d7d12bf6059d9c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1828,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Japan AI Alignment Conference"
    },
    "1777b8623c8c0972e4efc098e3cf2979": {
      "source_id": "1777b8623c8c0972e4efc098e3cf2979",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 76391,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Understanding and controlling a maze-solving policy network"
    },
    "653e1906bf2c2c56fdb657f9b154365f": {
      "source_id": "653e1906bf2c2c56fdb657f9b154365f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40789,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Compositional language for hypotheses about computations"
    },
    "2e3a1436b9ac0868d5832d8f26439374": {
      "source_id": "2e3a1436b9ac0868d5832d8f26439374",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1452,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Paper Replication Walkthrough: Reverse-Engineering Modular Addition"
    },
    "87c769ace080ce9c5c7b401609d0411d": {
      "source_id": "87c769ace080ce9c5c7b401609d0411d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20254,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Are there cognitive realms?"
    },
    "eb25a2d242f97a408016d04227b98399": {
      "source_id": "eb25a2d242f97a408016d04227b98399",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26772,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Plan for mediocre alignment of brain-like [model-based RL] AGI"
    },
    "d49b423c23bb5b68d3dba36789f29f90": {
      "source_id": "d49b423c23bb5b68d3dba36789f29f90",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40411,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What Discovering Latent Knowledge Did and Did Not Find"
    },
    "de0fa539dd68139c938716b25d622844": {
      "source_id": "de0fa539dd68139c938716b25d622844",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43455,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Discussion with Nate Soares on a key alignment difficulty"
    },
    "5d8a0d991e0c539d9beb9e678c70a325": {
      "source_id": "5d8a0d991e0c539d9beb9e678c70a325",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37866,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Fixed points in mortal population games"
    },
    "3ba7770534e773ba35282d1af298b917": {
      "source_id": "3ba7770534e773ba35282d1af298b917",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24897,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Storytelling Makes GPT-3.5 Deontologist: Unexpected Effects of Context on LLM Be"
    },
    "e2c0a6b20333102cc6baf9e06961c97a": {
      "source_id": "e2c0a6b20333102cc6baf9e06961c97a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32304,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What is a definition, how can it be extrapolated?"
    },
    "23ddbeccb2c3691cb1e6040e32861ecf": {
      "source_id": "23ddbeccb2c3691cb1e6040e32861ecf",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2034,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "GPT can write Quines now (GPT-4)"
    },
    "5911c139d96c04f47e715652068bcccf": {
      "source_id": "5911c139d96c04f47e715652068bcccf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11549,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Towards understanding-based safety evaluations"
    },
    "10e5ebd78f541fcbeb9595f7c4d64503": {
      "source_id": "10e5ebd78f541fcbeb9595f7c4d64503",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11046,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Want to predict/explain/control the output of GPT-4? Then learn about the world,"
    },
    "8b29e09b266add8ac4a291a349b25aee": {
      "source_id": "8b29e09b266add8ac4a291a349b25aee",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10316,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[ASoT] Some thoughts on human abstractions"
    },
    "ed9d7785ca76a9e9a76974c5ae574f86": {
      "source_id": "ed9d7785ca76a9e9a76974c5ae574f86",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 263,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What organizations other than Conjecture have (esp. public) info-hazard policies"
    },
    "5e783a88b8d66e030763bcc678afe2ed": {
      "source_id": "5e783a88b8d66e030763bcc678afe2ed",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 123433,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Natural Abstractions: Key claims, Theorems, and Critiques"
    },
    "c2fb6bb0d9b3f158a7f8ad6186042fcf": {
      "source_id": "c2fb6bb0d9b3f158a7f8ad6186042fcf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47129,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Appendix] Natural Abstractions: Key Claims, Theorems, and Critiques"
    },
    "81410cb57301c5d05d60d7b994a76333": {
      "source_id": "81410cb57301c5d05d60d7b994a76333",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 129786,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Attribution Patching: Activation Patching At Industrial Scale"
    },
    "fb939f8d2b79381c8d207acd51696300": {
      "source_id": "fb939f8d2b79381c8d207acd51696300",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2754,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\"Publish or Perish\" (a quick note on why you should try to make your work legibl"
    },
    "62d1dc8d0dbe71f5771ed05fe63c52a2": {
      "source_id": "62d1dc8d0dbe71f5771ed05fe63c52a2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15995,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "More information about the dangerous capability evaluations we did with GPT-4 an"
    },
    "800be35b01f320d5257312c4616c1c38": {
      "source_id": "800be35b01f320d5257312c4616c1c38",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8639,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Shell games"
    },
    "a9803d743a1c01216562831d742238bb": {
      "source_id": "a9803d743a1c01216562831d742238bb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 106701,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "My Objections to \"We\u2019re All Gonna Die with Eliezer Yudkowsky\""
    },
    "0562083e21ff7ff3b78543d6387e6a64": {
      "source_id": "0562083e21ff7ff3b78543d6387e6a64",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31905,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Deep Deceptiveness"
    },
    "a8f65f32b82aec6932cd0faf68ff3481": {
      "source_id": "a8f65f32b82aec6932cd0faf68ff3481",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19402,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Clarifying mesa-optimization"
    },
    "013d3ad2c1b71ce7f97d89241faf5ee9": {
      "source_id": "013d3ad2c1b71ce7f97d89241faf5ee9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4923,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "the QACI alignment plan: table of contents"
    },
    "4555935df2af0a4950e93103e47f4091": {
      "source_id": "4555935df2af0a4950e93103e47f4091",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10130,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Truth and Advantage: Response to a draft of \"AI safety seems hard to measure\""
    },
    "d75b3b972329e67eb2edea2e81ff79aa": {
      "source_id": "d75b3b972329e67eb2edea2e81ff79aa",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10243,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The space of systems and the space of maps"
    },
    "c5ff62313be98e12ae6ea50bb53ea9c2": {
      "source_id": "c5ff62313be98e12ae6ea50bb53ea9c2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54219,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "EAI Alignment Speaker Series #1: Challenges for Safe & Beneficial Brain-Like Art"
    },
    "d7c1fde062540515d257ca87fd999598": {
      "source_id": "d7c1fde062540515d257ca87fd999598",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25419,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Wittgenstein and ML \u2014 parameters vs architecture"
    },
    "7e7fcf5816c18cdb12bac917649d3638": {
      "source_id": "7e7fcf5816c18cdb12bac917649d3638",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32820,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A stylized dialogue on John Wentworth's claims about markets and optimization"
    },
    "e036f5e2942395db27ad8d09044953df": {
      "source_id": "e036f5e2942395db27ad8d09044953df",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8928,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The alignment stability problem"
    },
    "a5e3b6c8e8b42f2a6dbbda17b4004b9b": {
      "source_id": "a5e3b6c8e8b42f2a6dbbda17b4004b9b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4688,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Descriptive vs. specifiable values"
    },
    "86d4023cbf0bdd49264b5f845639f86d": {
      "source_id": "86d4023cbf0bdd49264b5f845639f86d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 101410,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "LLM Modularity: The Separability of Capabilities in Large Language Models"
    },
    "5a7cb606b0671d672397c4a525f11348": {
      "source_id": "5a7cb606b0671d672397c4a525f11348",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43734,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Practical Pitfalls of Causal Scrubbing"
    },
    "d051de4d97b0c0f7e6c258a61693da9a": {
      "source_id": "d051de4d97b0c0f7e6c258a61693da9a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20914,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Lessons from Convergent Evolution for AI Alignment"
    },
    "c6c470af53f9686bdd3b5ef8d643248d": {
      "source_id": "c6c470af53f9686bdd3b5ef8d643248d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54671,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A rough and incomplete review of some of John Wentworth's research"
    },
    "d887057348b56879a17752d6e852b771": {
      "source_id": "d887057348b56879a17752d6e852b771",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40308,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Actually, Othello-GPT Has A Linear Emergent World Representation"
    },
    "7014ba262c6d636aa26c7d69c12c4b2b": {
      "source_id": "7014ba262c6d636aa26c7d69c12c4b2b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 64697,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Othello-GPT: Future Work I Am Excited About"
    },
    "3983846562a57423fe20fc056f82cba6": {
      "source_id": "3983846562a57423fe20fc056f82cba6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28570,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Othello-GPT: Reflections on the Research Process"
    },
    "9fbdae1814aed33db662644e93cfe93c": {
      "source_id": "9fbdae1814aed33db662644e93cfe93c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23810,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Imitation Learning from Language Feedback"
    },
    "e76b70c76ab4d1c2bf956db9965919e0": {
      "source_id": "e76b70c76ab4d1c2bf956db9965919e0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22636,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Role Architectures: Applying LLMs to consequential tasks"
    },
    "bf133d98930de9ac37bfa4de1bbf25bd": {
      "source_id": "bf133d98930de9ac37bfa4de1bbf25bd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45004,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Maze-solving agents: Add a top-right vector, make the agent go to the top-right"
    },
    "59d94302b18846bc20d470cbb79704b4": {
      "source_id": "59d94302b18846bc20d470cbb79704b4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3591,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Singularities against the Singularity: Announcing Workshop on Singular Learning "
    },
    "36a0da7d5f21b52f9f885765382a719b": {
      "source_id": "36a0da7d5f21b52f9f885765382a719b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22537,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety via Luck"
    },
    "e481c59ea2b618d110e35ed02531e2eb": {
      "source_id": "e481c59ea2b618d110e35ed02531e2eb",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8413,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Transparency for Generalizing Alignment from Toy Models"
    },
    "35fda68fedad76f5e662f5b99d5e85f0": {
      "source_id": "35fda68fedad76f5e662f5b99d5e85f0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59503,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Ultimate ends may be easily hidable behind convergent subgoals"
    },
    "5bc5a071f7a5c3d830ad468e4bf5021b": {
      "source_id": "5bc5a071f7a5c3d830ad468e4bf5021b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23954,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Exploratory Analysis of RLHF Transformers with TransformerLens"
    },
    "b97cdaff85afc936c7cf2093f21f1793": {
      "source_id": "b97cdaff85afc936c7cf2093f21f1793",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3433,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "If interpretability research goes well, it may get dangerous"
    },
    "87245f0e5a2e62e4867f9fd6ab1f6c00": {
      "source_id": "87245f0e5a2e62e4867f9fd6ab1f6c00",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11838,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Giant (In)scrutable Matrices: (Maybe) the Best of All Possible Worlds"
    },
    "2accd92473a2e3cb836dcd39a5177ea8": {
      "source_id": "2accd92473a2e3cb836dcd39a5177ea8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 841,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Penalize Model Complexity Via Self-Distillation"
    },
    "48b857926a78e665ab68f3d54b2fb474": {
      "source_id": "48b857926a78e665ab68f3d54b2fb474",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19015,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\"Corrigibility at some small length\" by dath ilan"
    },
    "553ec539e6078a0c0bf4c31d9d548a60": {
      "source_id": "553ec539e6078a0c0bf4c31d9d548a60",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25166,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Universality and Hidden Information in Concept Bottleneck Models"
    },
    "e203817cfce86f6d9c9d24a46763a24a": {
      "source_id": "e203817cfce86f6d9c9d24a46763a24a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 87694,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Computational Anatomy of Human Values"
    },
    "9fe53744b3e53acf3ad73524cdb0c69f": {
      "source_id": "9fe53744b3e53acf3ad73524cdb0c69f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7628,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Misgeneralization as a misnomer"
    },
    "69ceedfc54b407c979b7b2548dfcbda8": {
      "source_id": "69ceedfc54b407c979b7b2548dfcbda8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24142,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Beren's \"Deconfusing Direct vs Amortised Optimisation\""
    },
    "b81dab6e589e6a7bf61279cea0aed201": {
      "source_id": "b81dab6e589e6a7bf61279cea0aed201",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3744,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Environments for Measuring Deception, Resource Acquisition, and Ethical Violatio"
    },
    "a602e04121bc23814927e42b9c74766c": {
      "source_id": "a602e04121bc23814927e42b9c74766c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10956,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Expanding the domain of discourse reveals structure already there but hidden"
    },
    "ed1149312eae6028b1c5e44cbdcf7ec3": {
      "source_id": "ed1149312eae6028b1c5e44cbdcf7ec3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18301,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why Simulator AIs want to be Active Inference AIs"
    },
    "662774851f837a4c0427a67c888a349a": {
      "source_id": "662774851f837a4c0427a67c888a349a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15628,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[MLSN #9] Verifying large training runs, security risks from LLM access to APIs,"
    },
    "7ea807cc65f48fa09787ae81b98fbda4": {
      "source_id": "7ea807cc65f48fa09787ae81b98fbda4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52252,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Evolution provides no evidence for the sharp left turn"
    },
    "23b94fdfe3a6f1beac41eea34e1e7468": {
      "source_id": "23b94fdfe3a6f1beac41eea34e1e7468",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57942,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Gradient Descent in Activation Space: a Tale of Two Papers"
    },
    "e13134cc76f47f65dd9172a39f55151c": {
      "source_id": "e13134cc76f47f65dd9172a39f55151c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4967,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Natural language alignment"
    },
    "af4017d8aa0191cee3379afe4aea9a94": {
      "source_id": "af4017d8aa0191cee3379afe4aea9a94",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6989,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AGI goal space is big, but narrowing might not be as hard as it seems."
    },
    "343d0bd4f984ca647e8f39534391cf3c": {
      "source_id": "343d0bd4f984ca647e8f39534391cf3c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 117710,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 20 - \u2018Reform\u2019 AI Alignment with Scott Aaronson"
    },
    "11c3deb285ab4342f44718e04c9b7a52": {
      "source_id": "11c3deb285ab4342f44718e04c9b7a52",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39002,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI x-risk, approximately ordered by embarrassment"
    },
    "032cd82a62484971ec9be22b4c00a55f": {
      "source_id": "032cd82a62484971ec9be22b4c00a55f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12223,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\"Aligned\" foundation models don't imply aligned systems"
    },
    "63c095a625033f2b47706a5b87d724ae": {
      "source_id": "63c095a625033f2b47706a5b87d724ae",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9991,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Shapley Value Attribution in Chain of Thought"
    },
    "3ad149149dc764c29b942bc96400afb0": {
      "source_id": "3ad149149dc764c29b942bc96400afb0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19759,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The self-unalignment problem"
    },
    "413206170b955d75bf638b3fa32493e2": {
      "source_id": "413206170b955d75bf638b3fa32493e2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11442,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Possibilizing vs. actualizing"
    },
    "728d2e6254b3ae05cdb7704fc0c8f6cf": {
      "source_id": "728d2e6254b3ae05cdb7704fc0c8f6cf",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6151,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "But why would the AI kill us?"
    },
    "0d30379da55891feeebd297b49f25880": {
      "source_id": "0d30379da55891feeebd297b49f25880",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47517,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Capabilities and alignment of LLM cognitive architectures"
    },
    "29124a196ba7989695089b7c9814d6bc": {
      "source_id": "29124a196ba7989695089b7c9814d6bc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27256,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Paying the corrigibility tax"
    },
    "7cb837e077ce5908aba17f9d858f34d3": {
      "source_id": "7cb837e077ce5908aba17f9d858f34d3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 140050,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Learning-Theoretic Agenda: Status 2023"
    },
    "4618ae9a59893f3737b521928e4c6b17": {
      "source_id": "4618ae9a59893f3737b521928e4c6b17",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62466,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Davidad's Bold Plan for Alignment: An In-Depth Explanation"
    },
    "736b654729a6f4dbd5c702f199375f51": {
      "source_id": "736b654729a6f4dbd5c702f199375f51",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16001,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Language Models are a Potentially Safe Path to Human-Level AGI"
    },
    "5ccb3a50f2f7523b1709410dd6657fe2": {
      "source_id": "5ccb3a50f2f7523b1709410dd6657fe2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44200,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Behavioural statistics for a maze-solving agent"
    },
    "1dddc776294070e5d92003736b746569": {
      "source_id": "1dddc776294070e5d92003736b746569",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26982,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Should we publish mechanistic interpretability research?"
    },
    "57ab4832e3c1eb14792d5155751e209a": {
      "source_id": "57ab4832e3c1eb14792d5155751e209a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30410,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Thinking about maximization and corrigibility"
    },
    "1629cb4b61ca9b692b76eeb3f9a04802": {
      "source_id": "1629cb4b61ca9b692b76eeb3f9a04802",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29192,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Endo-, Dia-, Para-, and Ecto-systemic novelty"
    },
    "d3830ff8a972d58cf1ad71fed404b656": {
      "source_id": "d3830ff8a972d58cf1ad71fed404b656",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2182,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why do we care about agency for alignment?"
    },
    "f75d057b668079e01b586afb26c0d95b": {
      "source_id": "f75d057b668079e01b586afb26c0d95b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12761,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "For alignment, we should simultaneously use multiple theories of cognition and v"
    },
    "c36bd7385064695c0afd34e86eb98f1f": {
      "source_id": "c36bd7385064695c0afd34e86eb98f1f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11299,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Making Nanobots isn't a one-shot process, even for an artificial superintelligan"
    },
    "aef9e00ebead0d703aa3d461d7ec7b3c": {
      "source_id": "aef9e00ebead0d703aa3d461d7ec7b3c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17524,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI doom from an LLM-plateau-ist perspective"
    },
    "a293b770b2ede95915d9384675524ec7": {
      "source_id": "a293b770b2ede95915d9384675524ec7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46421,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Infrafunctions and Robust Optimization"
    },
    "bb5b9de904c4b95867f33742cadc2bfc": {
      "source_id": "bb5b9de904c4b95867f33742cadc2bfc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46851,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Research agenda: Supervising AIs improving AIs"
    },
    "eb04e4bf509bd9005731eb260030e266": {
      "source_id": "eb04e4bf509bd9005731eb260030e266",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12730,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The voyage of novelty"
    },
    "4b4c4196dac955f1c03150df0745f1c7": {
      "source_id": "4b4c4196dac955f1c03150df0745f1c7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21716,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Connectomics seems great from an AI x-risk perspective"
    },
    "1186b65620012eb6690ffe0aa3274b02": {
      "source_id": "1186b65620012eb6690ffe0aa3274b02",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1669,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A small update to the Sparse Coding interim research report"
    },
    "5e5912f5b833cac61c5733f824cf1145": {
      "source_id": "5e5912f5b833cac61c5733f824cf1145",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53361,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Shah (DeepMind) and Leahy (Conjecture) Discuss Alignment Cruxes"
    },
    "a2497fadc72e820d01c41be66cb66263": {
      "source_id": "a2497fadc72e820d01c41be66cb66263",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 120336,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 21 - Interpretability for Engineers with Stephen Casper"
    },
    "be11cac4f8ab7ebc793d8a0a732d68fe": {
      "source_id": "be11cac4f8ab7ebc793d8a0a732d68fe",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27690,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AGI safety career advice"
    },
    "9a99baa0350682fc7ca6b7421edd9ca9": {
      "source_id": "9a99baa0350682fc7ca6b7421edd9ca9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3498,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Systems that cannot be unsafe cannot be safe"
    },
    "1105f3957f6c483d81dd2c12bc103053": {
      "source_id": "1105f3957f6c483d81dd2c12bc103053",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6902,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Avoiding xrisk from AI doesn't mean focusing on AI xrisk"
    },
    "6c813ea32198a44dd082777f104b24e3": {
      "source_id": "6c813ea32198a44dd082777f104b24e3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48643,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A Case for the Least Forgiving Take On Alignment"
    },
    "62450a433e5df301fc37dda766090d88": {
      "source_id": "62450a433e5df301fc37dda766090d88",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2452,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How much do personal biases in risk assessment affect assessment of AI risks?"
    },
    "d462010f5e3c62a0c00cf9bea37161ab": {
      "source_id": "d462010f5e3c62a0c00cf9bea37161ab",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3248,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Finding Neurons in a Haystack: Case Studies with Sparse Probing"
    },
    "29893942cc97da88fa98a1944aa7b183": {
      "source_id": "29893942cc97da88fa98a1944aa7b183",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20497,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Prizes for matrix completion problems"
    },
    "9f2636038f90192cdae970adc16034e8": {
      "source_id": "9f2636038f90192cdae970adc16034e8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7617,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Clarifying and predicting AGI"
    },
    "45e8033e10b7b4728fc72b7958ad1744": {
      "source_id": "45e8033e10b7b4728fc72b7958ad1744",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9583,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Orthogonal's Formal-Goal Alignment theory of change"
    },
    "b31f3e0b3aefb9110d63e4ca574d8b8b": {
      "source_id": "b31f3e0b3aefb9110d63e4ca574d8b8b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32906,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An anthropomorphic AI dilemma"
    },
    "debc877f7da477fdce5bb5dfc0906686": {
      "source_id": "debc877f7da477fdce5bb5dfc0906686",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 67072,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An artificially structured argument for expecting AGI ruin"
    },
    "7feaeb33baea20c98cdca99ab6a4eb93": {
      "source_id": "7feaeb33baea20c98cdca99ab6a4eb93",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19049,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A technical note on bilinear layers for interpretability"
    },
    "0fb123485d52d54653a0fa1ba96ac3ac": {
      "source_id": "0fb123485d52d54653a0fa1ba96ac3ac",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30884,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "LeCun\u2019s \u201cA Path Towards Autonomous Machine Intelligence\u201d has an unsolved technic"
    },
    "23cc0468747edb6db46f1bf13cf4266a": {
      "source_id": "23cc0468747edb6db46f1bf13cf4266a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4477,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing \u201cKey Phenomena in AI Risk\u201d (facilitated reading group)"
    },
    "f1c8d39450c1654840f460e0ffdbd1be": {
      "source_id": "f1c8d39450c1654840f460e0ffdbd1be",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35557,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "When is Goodhart catastrophic?"
    },
    "d4a0bed3338254ed720f94e57d3c8ce3": {
      "source_id": "d4a0bed3338254ed720f94e57d3c8ce3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21509,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Solving the Mechanistic Interpretability challenges: EIS VII Challenge 1"
    },
    "72656a22028d41e524d7e8f4b03ea842": {
      "source_id": "72656a22028d41e524d7e8f4b03ea842",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 86539,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Input Swap Graphs: Discovering the role of neural network components at scale"
    },
    "b1ef7afef788e36347b524a7d0e474f9": {
      "source_id": "b1ef7afef788e36347b524a7d0e474f9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6431,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Turning off lights with model editing"
    },
    "926bd0e5ccfec031031b50b5b72ee9cb": {
      "source_id": "926bd0e5ccfec031031b50b5b72ee9cb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61804,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Aggregating Utilities for Corrigible AI [Feedback Draft]"
    },
    "d61ab1f2a33f8b772be4c68f1679ae46": {
      "source_id": "d61ab1f2a33f8b772be4c68f1679ae46",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 138002,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Steering GPT-2-XL by adding an activation vector"
    },
    "f9ca2f28d134b22ec884de56144957e8": {
      "source_id": "f9ca2f28d134b22ec884de56144957e8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12380,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A strong mind continues its trajectory of creativity"
    },
    "4104a3e26d5f95fff408a0bf9762ab54": {
      "source_id": "4104a3e26d5f95fff408a0bf9762ab54",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17908,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Difficulties in making powerful aligned AI"
    },
    "ffa4a8b2d0784140a89ba35648dd6f32": {
      "source_id": "ffa4a8b2d0784140a89ba35648dd6f32",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13226,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Reward is the optimization target (of capabilities researchers)"
    },
    "f0ba6cdea0495ec3403878b3d075ad0f": {
      "source_id": "f0ba6cdea0495ec3403878b3d075ad0f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45558,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Some Summaries of Agent Foundations Work"
    },
    "44acde736f10fd7c7add6410b7ec4fb5": {
      "source_id": "44acde736f10fd7c7add6410b7ec4fb5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26163,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Simple experiments with deceptive alignment"
    },
    "e8f14dd3c9a4d1da1070256e659a279c": {
      "source_id": "e8f14dd3c9a4d1da1070256e659a279c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39790,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Will Not Want to Self-Improve"
    },
    "8ce61ca4210fa95f7655088efc7a8beb": {
      "source_id": "8ce61ca4210fa95f7655088efc7a8beb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56329,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Let\u2019s use AI to harden human defenses against AI manipulation"
    },
    "a7b9aacf89dcd273fc1fd31870c47730": {
      "source_id": "a7b9aacf89dcd273fc1fd31870c47730",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17464,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Collective Identity"
    },
    "d0d959f6b7758b290c277b18143799b2": {
      "source_id": "d0d959f6b7758b290c277b18143799b2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18756,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Some background for reasoning about dual-use alignment research"
    },
    "ec5e0e1e1537ef47d65c7367177136bd": {
      "source_id": "ec5e0e1e1537ef47d65c7367177136bd",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6971,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Conjecture internal survey: AGI timelines and probability of human extinction fr"
    },
    "15ae6db9cdee6124fd798492383b6afc": {
      "source_id": "15ae6db9cdee6124fd798492383b6afc",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7926,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "'Fundamental' vs 'applied' mechanistic interpretability research"
    },
    "88d98f772361f6b03d17d708947bd09b": {
      "source_id": "88d98f772361f6b03d17d708947bd09b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 103968,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Polarity Problem [Draft]"
    },
    "c1f90ece6279a502a68b80888ad02aff": {
      "source_id": "c1f90ece6279a502a68b80888ad02aff",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10606,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Aligned AI via monitoring objectives in AutoGPT-like systems"
    },
    "e4e43a127c56d584bafc752c54170932": {
      "source_id": "e4e43a127c56d584bafc752c54170932",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 4493,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] Interpretability Dreams"
    },
    "66d228de2fb83ac38a3da31db40df5e1": {
      "source_id": "66d228de2fb83ac38a3da31db40df5e1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45907,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Solving the Mechanistic Interpretability challenges: EIS VII Challenge 2"
    },
    "4afd62204628d239da0003e8ed1d853b": {
      "source_id": "4afd62204628d239da0003e8ed1d853b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21658,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Before smart AI, there will be many mediocre or specialized AIs"
    },
    "db650fb8ec5d1f21598fd7bead8550bb": {
      "source_id": "db650fb8ec5d1f21598fd7bead8550bb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17765,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Some thoughts on automating alignment research"
    },
    "72edf7433278b22d658b4981472d4675": {
      "source_id": "72edf7433278b22d658b4981472d4675",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 64264,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Conditional Prediction with Zero-Sum Training Solves Self-Fulfilling Prophecies"
    },
    "bfc203e145e7940cf405f028c75ca1b2": {
      "source_id": "bfc203e145e7940cf405f028c75ca1b2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 84835,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is Deontological AI Safe? [Feedback Draft]"
    },
    "e4890e86f7850c31d85e61d2efd322b5": {
      "source_id": "e4890e86f7850c31d85e61d2efd322b5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28154,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Hands-On Experience Is Not Magic"
    },
    "e7090a31103a05658cdf3f3ea7a409bf": {
      "source_id": "e7090a31103a05658cdf3f3ea7a409bf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51981,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Language Agents Reduce the Risk of Existential Catastrophe"
    },
    "dd321185a6ba12c4b4958cf6090680f1": {
      "source_id": "dd321185a6ba12c4b4958cf6090680f1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4376,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "TinyStories: Small Language Models That Still Speak Coherent English"
    },
    "3a984d5f71cf3cee0805919b96705777": {
      "source_id": "3a984d5f71cf3cee0805919b96705777",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 82276,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Aligning an H-JEPA agent via training on the outputs of an LLM-based \"exemplary "
    },
    "53fb771579c651ab8d7813e3d697b0d7": {
      "source_id": "53fb771579c651ab8d7813e3d697b0d7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30231,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An LLM-based \u201cexemplary actor\u201d"
    },
    "2c74fca229f72b4df614f656cc3399e4": {
      "source_id": "2c74fca229f72b4df614f656cc3399e4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1654,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Wikipedia as an introduction to the alignment problem"
    },
    "200176051dc36e3329fdc0a5948558cd": {
      "source_id": "200176051dc36e3329fdc0a5948558cd",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2992,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Sentience matters"
    },
    "00f5cdd06f232ba3cdba0649cfc07c88": {
      "source_id": "00f5cdd06f232ba3cdba0649cfc07c88",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 975,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Statement on AI Extinction - Signed by AGI Labs, Top Academics, and Many Other N"
    },
    "0c6e7c0b8359f025eeeb04d2b45d61e5": {
      "source_id": "0c6e7c0b8359f025eeeb04d2b45d61e5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16446,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing Apollo Research"
    },
    "24462c8df5673df0f98760b076f64796": {
      "source_id": "24462c8df5673df0f98760b076f64796",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3005,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "LIMA: Less Is More for Alignment"
    },
    "463ccb99b105006c10c652ba5593299c": {
      "source_id": "463ccb99b105006c10c652ba5593299c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3999,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A push towards interactive transformer decoding"
    },
    "f1682e2f7cfaab8b512bdffed6a37917": {
      "source_id": "f1682e2f7cfaab8b512bdffed6a37917",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35688,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Shutdown-Seeking AI"
    },
    "4f2a89bde154df625a2aaec814c1bde4": {
      "source_id": "4f2a89bde154df625a2aaec814c1bde4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21133,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Short Remark on the (subjective) mathematical 'naturalness' of the Nanda--Lieber"
    },
    "74cb5fde0eba44504a1250c2122a5109": {
      "source_id": "74cb5fde0eba44504a1250c2122a5109",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13265,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Uncertainty about the future does not imply that AGI will go well"
    },
    "7a9b94ab6089c446236b3185e690f2ee": {
      "source_id": "7a9b94ab6089c446236b3185e690f2ee",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26904,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Think carefully before calling RL policies  \"agents\""
    },
    "37a3bb6fa6ac3aa16a6cd29feb9f870b": {
      "source_id": "37a3bb6fa6ac3aa16a6cd29feb9f870b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2886,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Replication] Conjecture's Sparse Coding in Toy Models"
    },
    "e8d229a563fbc95d79f5a4fdd25959ad": {
      "source_id": "e8d229a563fbc95d79f5a4fdd25959ad",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15438,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Unfaithful Explanations in Chain-of-Thought Prompting"
    },
    "3ed7bf0deb3003796f5f4615ce4a6230": {
      "source_id": "3ed7bf0deb3003796f5f4615ce4a6230",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37537,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How to Think About Activation Patching"
    },
    "61517e12a3b06e959801e44ef94e4a83": {
      "source_id": "61517e12a3b06e959801e44ef94e4a83",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2805,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Wildfire of strategicness"
    },
    "faeb48e796f12e9dd721c88be8277df1": {
      "source_id": "faeb48e796f12e9dd721c88be8277df1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30369,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A Playbook for AI Risk Reduction (focused on misaligned AI)"
    },
    "c73d3f72d92b340d006283e3f0fff936": {
      "source_id": "c73d3f72d92b340d006283e3f0fff936",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16583,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An Exercise to Build Intuitions on AGI Risk"
    },
    "1fd2ad88e66b14eb5f28a05c202f93d0": {
      "source_id": "1fd2ad88e66b14eb5f28a05c202f93d0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50913,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What will GPT-2030 look like?"
    },
    "b31eff7152d49579c1f57ae91ca692cc": {
      "source_id": "b31eff7152d49579c1f57ae91ca692cc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14446,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Takeaways from the Mechanistic Interpretability Challenges"
    },
    "8f1ed5eac362a0487f6835fbb1196866": {
      "source_id": "8f1ed5eac362a0487f6835fbb1196866",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 63401,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A comparison of causal scrubbing, causal abstractions, and related methods"
    },
    "83da9beef7af992e47376218e3be6721": {
      "source_id": "83da9beef7af992e47376218e3be6721",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21693,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How biosafety could inform AI standards"
    },
    "6636edbc9693cca5a1be7ce8d7051f29": {
      "source_id": "6636edbc9693cca5a1be7ce8d7051f29",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43828,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "formalizing the QACI alignment formal-goal"
    },
    "9cf129aec6ca218e05f9389aeb650a15": {
      "source_id": "9cf129aec6ca218e05f9389aeb650a15",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 105298,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "an Evangelion dialogue explaining the QACI alignment plan"
    },
    "49d55fbe7a77c789a631bdb74d4d4d3b": {
      "source_id": "49d55fbe7a77c789a631bdb74d4d4d3b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49935,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Explicitness"
    },
    "99d7ca625fb1933aafb88912bffd786a": {
      "source_id": "99d7ca625fb1933aafb88912bffd786a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9912,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Introduction to Towards Causal Foundations of Safe AGI"
    },
    "484566e98d8676ccaf99500ccbfce9d4": {
      "source_id": "484566e98d8676ccaf99500ccbfce9d4",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7960,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "ARC is hiring theoretical researchers"
    },
    "6c6477b695dd9724fbab08bfebf8698b": {
      "source_id": "6c6477b695dd9724fbab08bfebf8698b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33969,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Contingency: A Conceptual Tool from Evolutionary Biology for Alignment"
    },
    "82a687eda8604ec09757c95f47df6ba0": {
      "source_id": "82a687eda8604ec09757c95f47df6ba0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1724,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "TASRA: A Taxonomy and Analysis of Societal-Scale Risks from AI"
    },
    "81b610caa8a05e48592d1afd21a9c4f3": {
      "source_id": "81b610caa8a05e48592d1afd21a9c4f3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31087,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "MetaAI: less is less for alignment."
    },
    "62cb84fd41da699a5fcdc5712861e0a1": {
      "source_id": "62cb84fd41da699a5fcdc5712861e0a1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 81431,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Instrumental Convergence? [Draft]"
    },
    "b88cf3221761e592b808bdd0b53eef99": {
      "source_id": "b88cf3221761e592b808bdd0b53eef99",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 172641,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 22 - Shard Theory with Quintin Pope"
    },
    "43ce6c06fcf37401769f885d51ec2067": {
      "source_id": "43ce6c06fcf37401769f885d51ec2067",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31090,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "DSLT 0. Distilling Singular Learning Theory"
    },
    "d772551a04ddc0fbb69bd1d0a4d5d3e0": {
      "source_id": "d772551a04ddc0fbb69bd1d0a4d5d3e0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41769,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Scaffolded LLMs: Less Obvious Concerns"
    },
    "1d2a16674e7b9c871694dd71d9c6073d": {
      "source_id": "1d2a16674e7b9c871694dd71d9c6073d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32571,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "LLMs Sometimes Generate Purely Negatively-Reinforced Text"
    },
    "8a3362d04bc1846d5d3e98615b414d5c": {
      "source_id": "8a3362d04bc1846d5d3e98615b414d5c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12222,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Replication] Conjecture's Sparse Coding in Small Transformers"
    },
    "aacccf496562f91c0419e266f49dbe58": {
      "source_id": "aacccf496562f91c0419e266f49dbe58",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8091,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Updating Drexler's CAIS model"
    },
    "dab3e24749acf489bc631c3cde793ace": {
      "source_id": "dab3e24749acf489bc631c3cde793ace",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10514,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Experiments in Evaluating Steering Vectors"
    },
    "64877a97bf7d4fe600ad8b05411ccd4e": {
      "source_id": "64877a97bf7d4fe600ad8b05411ccd4e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25888,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Ban development of unpredictable powerful models?"
    },
    "c7543bf05d10ea591fa55d2e5fca7e64": {
      "source_id": "c7543bf05d10ea591fa55d2e5fca7e64",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31881,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Causality: A Brief Introduction"
    },
    "8ab87e0a23697bfd845a6d95d18ed67e": {
      "source_id": "8ab87e0a23697bfd845a6d95d18ed67e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2829,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Hubinger lectures on AGI safety: an introductory lecture series"
    },
    "9da823e733cca9b289f629250e48a701": {
      "source_id": "9da823e733cca9b289f629250e48a701",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14405,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Catastrophic Risks from AI #1: Summary"
    },
    "eb7e4bdddbebf15a980eb91515c639b5": {
      "source_id": "eb7e4bdddbebf15a980eb91515c639b5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34832,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Catastrophic Risks from AI #2: Malicious Use"
    },
    "70e11d5d56e1a3f6d4b642a96fdb9b3c": {
      "source_id": "70e11d5d56e1a3f6d4b642a96fdb9b3c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45587,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why Not Subagents?"
    },
    "aa95d6f995953c8531b202992b93e257": {
      "source_id": "aa95d6f995953c8531b202992b93e257",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57324,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Catastrophic Risks from AI #3: AI Race"
    },
    "705cc62a472f799e484207dbe8681712": {
      "source_id": "705cc62a472f799e484207dbe8681712",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53655,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The fraught voyage of aligned novelty"
    },
    "f79616b90ea116b5d951ccb0e33e8fba": {
      "source_id": "f79616b90ea116b5d951ccb0e33e8fba",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42564,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Catastrophic Risks from AI #4: Organizational Risks"
    },
    "f8b07041a450b2db1e8b0b066964e7bb": {
      "source_id": "f8b07041a450b2db1e8b0b066964e7bb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42872,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Catastrophic Risks from AI #5: Rogue AIs"
    },
    "20b5ac4d58badda2f5f0d9810b93ee56": {
      "source_id": "20b5ac4d58badda2f5f0d9810b93ee56",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25840,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Catastrophic Risks from AI #6: Discussion and FAQ"
    },
    "4051375cc499cae4d5e0b65347fbecb0": {
      "source_id": "4051375cc499cae4d5e0b65347fbecb0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24416,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Introducing EffiSciences\u2019 AI Safety Unit"
    },
    "58b17ede2cd10f2ef70b9ea509081427": {
      "source_id": "58b17ede2cd10f2ef70b9ea509081427",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17815,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Agency from a causal perspective"
    },
    "d77a0692eca7e9dbb300d89cf9faf1ac": {
      "source_id": "d77a0692eca7e9dbb300d89cf9faf1ac",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1085,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Elements of Computational Philosophy, Vol. I: Truth"
    },
    "013ebe7e7a5a81ff61f61df4aaf7ad1f": {
      "source_id": "013ebe7e7a5a81ff61f61df4aaf7ad1f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5146,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Using (Uninterpretable) LLMs to Generate Interpretable AI Code"
    },
    "a7a0c9ba5185c37c3ca16d66824b4b9e": {
      "source_id": "a7a0c9ba5185c37c3ca16d66824b4b9e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49837,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Quantitative cruxes in Alignment"
    },
    "5ea08dd3c34069125cb44490d9781fd0": {
      "source_id": "5ea08dd3c34069125cb44490d9781fd0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29699,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Sources of evidence in Alignment"
    },
    "654bec114e71d3a35c35d983698a3bb2": {
      "source_id": "654bec114e71d3a35c35d983698a3bb2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35543,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "VC Theory Overview"
    },
    "454c63f4484afda463dfb87523b6ed43": {
      "source_id": "454c63f4484afda463dfb87523b6ed43",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30844,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Ten Levels of AI Alignment Difficulty"
    },
    "93323c8dd1bf8177934c0f323408fa8d": {
      "source_id": "93323c8dd1bf8177934c0f323408fa8d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19615,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Animal Weapons: Lessons for Humans in the Age of X-Risk"
    },
    "25e9d6b974ccf630a27fd7c31168ec59": {
      "source_id": "25e9d6b974ccf630a27fd7c31168ec59",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 2331,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] Introducing Superalignment"
    },
    "ed76e08b9d8657f5c958e9918b06e455": {
      "source_id": "ed76e08b9d8657f5c958e9918b06e455",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8203,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Jesse Hoogland on Developmental Interpretability and Singular Learning Theory"
    },
    "a5ecda85777f92b1185e78a47ac18cf1": {
      "source_id": "a5ecda85777f92b1185e78a47ac18cf1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33362,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Internal independent review for language model agent alignment"
    },
    "7bcc7d47948af84ac1f03830cdf5f510": {
      "source_id": "7bcc7d47948af84ac1f03830cdf5f510",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25647,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Views on when AGI comes and on strategy to reduce existential risk"
    },
    "f676ca14157e86caf9d9f0013c561c5e": {
      "source_id": "f676ca14157e86caf9d9f0013c561c5e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17364,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Continuous Adversarial Quality Assurance: Extending RLHF and Constitutional AI"
    },
    "2eb24e5520185e1141e9cbe31f10e3b8": {
      "source_id": "2eb24e5520185e1141e9cbe31f10e3b8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13909,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\"Concepts of Agency in Biology\" (Okasha, 2023) - Brief Paper Summary"
    },
    "2772523fec1e7251f46933bfdaffba69": {
      "source_id": "2772523fec1e7251f46933bfdaffba69",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13977,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Seven Strategies for Tackling the Hard Part of the Alignment Problem"
    },
    "818b3537e3cb4eb91fe96f9ef7bb8d32": {
      "source_id": "818b3537e3cb4eb91fe96f9ef7bb8d32",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19398,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Consciousness as a conflationary alliance term"
    },
    "45a8be8b1654a6a08eb7a7de5353a0a4": {
      "source_id": "45a8be8b1654a6a08eb7a7de5353a0a4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49718,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Open-minded updatelessness"
    },
    "e2ff94eefdc50fcb74d2415c730198ba": {
      "source_id": "e2ff94eefdc50fcb74d2415c730198ba",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31158,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\u201cReframing Superintelligence\u201d + LLMs + 4 years"
    },
    "1e3b4c5843b4edb3977301eba78f5d52": {
      "source_id": "1e3b4c5843b4edb3977301eba78f5d52",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16180,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Incentives from a causal perspective"
    },
    "aef8057b37bd3344d2f7901caf5c9fb9": {
      "source_id": "aef8057b37bd3344d2f7901caf5c9fb9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30215,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Goal-Direction for Simulated Agents"
    },
    "76af4848aaa60469191efba3f4d13d66": {
      "source_id": "76af4848aaa60469191efba3f4d13d66",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38714,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Towards Developmental Interpretability"
    },
    "847ae8f500e86faf34db664240c5c00b": {
      "source_id": "847ae8f500e86faf34db664240c5c00b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 598,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What does the launch of x.ai mean for AI Safety?"
    },
    "60ed3ccebb19be3d8a2c0e4741e57d2a": {
      "source_id": "60ed3ccebb19be3d8a2c0e4741e57d2a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5241,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Eric Michaud on the Quantization Model of Neural Scaling, Interpretability and G"
    },
    "8fa03d4f043d4817ba6892e62bff9c8a": {
      "source_id": "8fa03d4f043d4817ba6892e62bff9c8a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38093,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Robustness of Model-Graded Evaluations and Automated Interpretability"
    },
    "0c0355f97e40703c02b7d89cc8292841": {
      "source_id": "0c0355f97e40703c02b7d89cc8292841",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16135,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AutoInterpretation Finds Sparse Coding Beats Alternatives"
    },
    "a15c0b4f7d65e60e262ae105c3e9d086": {
      "source_id": "a15c0b4f7d65e60e262ae105c3e9d086",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51104,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Thoughts on \u201cProcess-Based Supervision\u201d"
    },
    "25fb3fb22dc4aa76f933ea9cafda3535": {
      "source_id": "25fb3fb22dc4aa76f933ea9cafda3535",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14504,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Measuring and Improving the Faithfulness of Model-Generated Reasoning"
    },
    "5d48d3fddb3acc5ac166fe66fdfede4b": {
      "source_id": "5d48d3fddb3acc5ac166fe66fdfede4b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62193,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Still no Lie Detector for LLMs"
    },
    "19c662d2467aa188739c003415af71b2": {
      "source_id": "19c662d2467aa188739c003415af71b2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15915,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Tiny Mech Interp Projects: Emergent Positional Embeddings of Words"
    },
    "30ad8cb29e77869d56e33c68c76102af": {
      "source_id": "30ad8cb29e77869d56e33c68c76102af",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40381,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Hedonic Loops and Taming RL"
    },
    "467683bce5140c5fcda05f08499f973c": {
      "source_id": "467683bce5140c5fcda05f08499f973c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2599,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Alignment Grantmaking is Funding-Limited Right Now"
    },
    "cfac591a5147e918ace849be9ee988d0": {
      "source_id": "cfac591a5147e918ace849be9ee988d0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10530,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Speculative inferences about path dependence in LLM supervised fine-tuning from "
    },
    "9cc5d74589261014dba194ebacff1088": {
      "source_id": "9cc5d74589261014dba194ebacff1088",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4700,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Does Circuit Analysis Interpretability Scale? Evidence from Multiple Choice Capa"
    },
    "df106473d2a1f9431102e6f4cbfa97ac": {
      "source_id": "df106473d2a1f9431102e6f4cbfa97ac",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23432,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Even Superhuman Go AIs Have Surprising Failure Modes"
    },
    "85cefb716c24699c3d3765b79a5cf424": {
      "source_id": "85cefb716c24699c3d3765b79a5cf424",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 68730,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Training Process Transparency through Gradient Interpretability: Early experimen"
    },
    "6b899992ea00773e4d1afef3bbdfce0c": {
      "source_id": "6b899992ea00773e4d1afef3bbdfce0c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11943,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Priorities for the UK Foundation Models Taskforce"
    },
    "507bffb30a6562fb85de6b8509f8b139": {
      "source_id": "507bffb30a6562fb85de6b8509f8b139",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18306,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Reward Hacking from a Causal Perspective"
    },
    "4dcc94c361bcee20c098753d6b77b78d": {
      "source_id": "4dcc94c361bcee20c098753d6b77b78d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4147,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Compute Thresholds: proposed rules to mitigate risk of a \u201clab leak\u201d accident dur"
    },
    "e9594c2f0ee9299ee8cb5bf9d135faf1": {
      "source_id": "e9594c2f0ee9299ee8cb5bf9d135faf1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11294,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Examples of Prompts that Make GPT-4 Output Falsehoods"
    },
    "cce6a49a1d9c32cfd4f8fc84f66359b4": {
      "source_id": "cce6a49a1d9c32cfd4f8fc84f66359b4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21560,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "QAPR 5: grokking is maybe not *that* big a deal?"
    },
    "073249adc2612e4838a678a5b0546db9": {
      "source_id": "073249adc2612e4838a678a5b0546db9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18812,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How LLMs are and are not myopic"
    },
    "b67b8b7b1b4acd36d2f6a0dbf887e7ce": {
      "source_id": "b67b8b7b1b4acd36d2f6a0dbf887e7ce",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7876,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Frontier Model Security"
    },
    "44a1037f22d690c72dcc6497648b7be1": {
      "source_id": "44a1037f22d690c72dcc6497648b7be1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53208,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Meta-level adversarial evaluation of oversight techniques might allow robust mea"
    },
    "149978e98c0bce1af5cb5ca59ebb1233": {
      "source_id": "149978e98c0bce1af5cb5ca59ebb1233",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 123608,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 23 - Mechanistic Anomaly Detection with Mark Xu"
    },
    "588f0502bf8155d7a5711632bbdb264a": {
      "source_id": "588f0502bf8155d7a5711632bbdb264a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 121069,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 24 - Superalignment with Jan Leike"
    },
    "be18f5bc2c7bc46c6f02a3709e9f5b03": {
      "source_id": "be18f5bc2c7bc46c6f02a3709e9f5b03",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17832,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Reducing sycophancy and improving honesty via activation steering"
    },
    "d271c88059b4ba213e23cd68fd11513b": {
      "source_id": "d271c88059b4ba213e23cd68fd11513b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18973,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "When can we trust model evaluations?"
    },
    "203aca392c9d35f08606b48d0af2a144": {
      "source_id": "203aca392c9d35f08606b48d0af2a144",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5529,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Open Problems and Fundamental Limitations of RLHF"
    },
    "64bbf30922ff226bb27d166e06e80170": {
      "source_id": "64bbf30922ff226bb27d166e06e80170",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25071,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Thoughts on sharing information about language model capabilities"
    },
    "d0f7cd421ddae4094fd110acc6002f70": {
      "source_id": "d0f7cd421ddae4094fd110acc6002f70",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1856,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Watermarking considered overrated?"
    },
    "18845e66faac5770831f125f561e4b04": {
      "source_id": "18845e66faac5770831f125f561e4b04",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25718,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The \u201cno sandbagging on checkable tasks\u201d hypothesis"
    },
    "200d7f393cdeb2764dab220ee866be7f": {
      "source_id": "200d7f393cdeb2764dab220ee866be7f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11065,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "ARC Evals new report: Evaluating Language-Model Agents on Realistic Autonomous T"
    },
    "43d6874e67597e6f6fd5fd372e5288d1": {
      "source_id": "43d6874e67597e6f6fd5fd372e5288d1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14056,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "3 levels of threat obfuscation"
    },
    "8362ced20d41507447badc1057a0d0e2": {
      "source_id": "8362ced20d41507447badc1057a0d0e2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15720,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Password-locked models: a stress case for capabilities evaluation"
    },
    "ca8bb5179187b5edb889de1a1b8453f4": {
      "source_id": "ca8bb5179187b5edb889de1a1b8453f4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2969,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Ground-Truth Label Imbalance Impairs Contrast-Consistent Search Performance"
    },
    "052d1f79829536e242ed93773e5ecae0": {
      "source_id": "052d1f79829536e242ed93773e5ecae0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1339,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Yann LeCun on AGI and AI Safety"
    },
    "0691576303dcbd179ceb1b5bff179f6b": {
      "source_id": "0691576303dcbd179ceb1b5bff179f6b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40281,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Optimisation Measures: Desiderata, Impossibility, Proposals"
    },
    "20077e44ebf080958da3045b806aaff8": {
      "source_id": "20077e44ebf080958da3045b806aaff8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21055,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An interactive introduction to grokking and mechanistic interpretability"
    },
    "61abc3d0b7a60e3783c8d19f80d935f3": {
      "source_id": "61abc3d0b7a60e3783c8d19f80d935f3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36983,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Model Organisms of Misalignment: The Case for a New Pillar of Alignment Research"
    },
    "c7aae8c757bcd6746fea63c8ebcd48eb": {
      "source_id": "c7aae8c757bcd6746fea63c8ebcd48eb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26190,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Modulating sycophancy in an RLHF model via activation steering"
    },
    "c1d2b211ca58a5584f660b69624c056b": {
      "source_id": "c1d2b211ca58a5584f660b69624c056b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29620,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The positional embedding matrix and previous-token heads: how do they actually w"
    },
    "925e8351c22cf4b54b1ae21399ab3db4": {
      "source_id": "925e8351c22cf4b54b1ae21399ab3db4",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6169,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "When discussing AI risks, talk about capabilities, not intelligence"
    },
    "054ba2c7b21056315b226e097ede92dc": {
      "source_id": "054ba2c7b21056315b226e097ede92dc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35157,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Autonomous replication and adaptation: an attempt at a concrete danger threshold"
    },
    "0d8cfef643818ce7af6da9fc3a305286": {
      "source_id": "0d8cfef643818ce7af6da9fc3a305286",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5725,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Managing risks of our own work"
    },
    "fa51c30d3ab88100bfa8979010281083": {
      "source_id": "fa51c30d3ab88100bfa8979010281083",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30349,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An Overview of Catastrophic AI Risks: Summary"
    },
    "ac8793c0f209192cc87e536d88f3bbf4": {
      "source_id": "ac8793c0f209192cc87e536d88f3bbf4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4086,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "We can do better than DoWhatIMean"
    },
    "167a64c1d8329a757dded483985f6325": {
      "source_id": "167a64c1d8329a757dded483985f6325",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6026,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\u201cDirty concepts\u201d in AI alignment discourses, and some guesses for how to deal wi"
    },
    "9a5d3423edd91347c8aa1f3ddf56e5bb": {
      "source_id": "9a5d3423edd91347c8aa1f3ddf56e5bb",
      "quality_score": 5.0,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42410,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "Implications of evidential cooperation in large worlds"
    },
    "5086e32cf9a0a9d31ad2306804adcc93": {
      "source_id": "5086e32cf9a0a9d31ad2306804adcc93",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 71288,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A Model-based Approach to AI Existential Risk"
    },
    "20c183ec6e139b841a87c9637325d03b": {
      "source_id": "20c183ec6e139b841a87c9637325d03b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18322,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Red-teaming language models via activation engineering"
    },
    "2ec49ba9a62cf9e05a66bf8324e5f7db": {
      "source_id": "2ec49ba9a62cf9e05a66bf8324e5f7db",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15380,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A list of core AI safety problems and how I hope to solve them"
    },
    "5f8718dde0516630a54342aefb0bee1b": {
      "source_id": "5f8718dde0516630a54342aefb0bee1b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33872,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Paradigms and Theory Choice in AI: Adaptivity, Economy and Control"
    },
    "e9296f9b1e144763f72114d5207728cc": {
      "source_id": "e9296f9b1e144763f72114d5207728cc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59487,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An Interpretability Illusion for Activation Patching of Arbitrary Subspaces"
    },
    "cc1b85afe3617b661cd48bf43bbbfd19": {
      "source_id": "cc1b85afe3617b661cd48bf43bbbfd19",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32594,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Deception: A Survey of Examples, Risks, and Potential Solutions"
    },
    "789f1704a3eee3865cd14303a45c218d": {
      "source_id": "789f1704a3eee3865cd14303a45c218d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1860,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Barriers to Mechanistic Interpretability for AGI Safety"
    },
    "df2eb83bd5719027143efc2a41cbbd7b": {
      "source_id": "df2eb83bd5719027143efc2a41cbbd7b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 710,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Paper Walkthrough: Automated Circuit Discovery with Arthur Conmy"
    },
    "9f86bc380c2bb1a2b951fda05b807c48": {
      "source_id": "9f86bc380c2bb1a2b951fda05b807c48",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5690,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Meta Questions about Metaphilosophy"
    },
    "8b51315b024b7e336aaa2da433d5bb66": {
      "source_id": "8b51315b024b7e336aaa2da433d5bb66",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5924,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "PIBBSS Summer Symposium 2023"
    },
    "f1b8ea1f0997b7b6b4cec537d068409e": {
      "source_id": "f1b8ea1f0997b7b6b4cec537d068409e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26682,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Fundamental question: What determines a mind's effects?"
    },
    "28c4918132c03f912b8ff14683053f39": {
      "source_id": "28c4918132c03f912b8ff14683053f39",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10788,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Paper: On measuring situational awareness in LLMs"
    },
    "feda58b5ee6743f4bd6897a5283fd694": {
      "source_id": "feda58b5ee6743f4bd6897a5283fd694",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45539,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Benchmarks for Detecting Measurement Tampering [Redwood Research]"
    },
    "15220984504d436816312e281430e2d7": {
      "source_id": "15220984504d436816312e281430e2d7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25705,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What I would do if I wasn\u2019t at ARC Evals"
    },
    "0d403074025f84e666d74b216cb3f093": {
      "source_id": "0d403074025f84e666d74b216cb3f093",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2063,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Focus on the Hardest Part First"
    },
    "3c4fe0c78bb46a2d2732ce27af4e3291": {
      "source_id": "3c4fe0c78bb46a2d2732ce27af4e3291",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5260,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How to talk about reasons why AGI might not be near?"
    },
    "5f9b18b249a84d0c200bf8e27b2a4701": {
      "source_id": "5f9b18b249a84d0c200bf8e27b2a4701",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 452,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Where might I direct promising-to-me researchers to apply for alignment jobs/gra"
    },
    "d2d1d10d5c0a5dbfb888eb6c9286d970": {
      "source_id": "d2d1d10d5c0a5dbfb888eb6c9286d970",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9189,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Anthropic's Responsible Scaling Policy & Long-Term Benefit Trust"
    },
    "11ef5b46164a5ca611c3c0aab956d6bc": {
      "source_id": "11ef5b46164a5ca611c3c0aab956d6bc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31487,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "There should be more AI safety orgs"
    },
    "95e45961c775b797e841302fa5144bcd": {
      "source_id": "95e45961c775b797e841302fa5144bcd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28404,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Sparse Autoencoders Find Highly Interpretable Directions in Language Models"
    },
    "2ec41738dcce037f1a630c5abbe144b9": {
      "source_id": "2ec41738dcce037f1a630c5abbe144b9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13549,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Sparse Autoencoders: Future Work"
    },
    "e4d5133f4124866818651bb95d31d2a4": {
      "source_id": "e4d5133f4124866818651bb95d31d2a4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15238,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Understanding strategic deception and deceptive alignment"
    },
    "d751ab175630bf00da5410a957c01426": {
      "source_id": "d751ab175630bf00da5410a957c01426",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17612,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Impact stories for model internals: an exercise for interpretability researchers"
    },
    "3edb6498934983ba7552d51d58c50d1e": {
      "source_id": "3edb6498934983ba7552d51d58c50d1e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9213,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing the CNN Interpretability Competition"
    },
    "9b201a1901ee4dcc292c7266a69d7af3": {
      "source_id": "9b201a1901ee4dcc292c7266a69d7af3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22077,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Different views of alignment have different consequences for imperfect methods"
    },
    "e8c736368f285041cf442bbcb164dec9": {
      "source_id": "e8c736368f285041cf442bbcb164dec9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3575,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Alignment Workshop talks"
    },
    "d98c4944e4558b02f2506548798f5982": {
      "source_id": "d98c4944e4558b02f2506548798f5982",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47690,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How model editing could help with the alignment problem "
    },
    "ee7935ce43b676da25734bbc0c85c438": {
      "source_id": "ee7935ce43b676da25734bbc0c85c438",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17027,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Some Quick Follow-Up Experiments to \u201cTaken out of context: On measuring situatio"
    },
    "b189ac56fe43a35942a7b05f6b1f1617": {
      "source_id": "b189ac56fe43a35942a7b05f6b1f1617",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 161952,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AXRP Episode 25 - Cooperative AI with Caspar Oesterheld"
    },
    "9998c9c787f720b451f18d882e7eed6e": {
      "source_id": "9998c9c787f720b451f18d882e7eed6e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13678,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How to solve deception and still fail."
    },
    "f474e8b4b4e6fcdfe052ed4cd03a5cf9": {
      "source_id": "f474e8b4b4e6fcdfe052ed4cd03a5cf9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5515,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Towards Monosemanticity: Decomposing Language Models With Dictionary Learning"
    },
    "3305494fabc480887e1913394da2c460": {
      "source_id": "3305494fabc480887e1913394da2c460",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11125,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Don't Dismiss Simple Alignment Approaches"
    },
    "c302a02846cfe80758fbb018d8dc2598": {
      "source_id": "c302a02846cfe80758fbb018d8dc2598",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27332,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Comparing Anthropic's Dictionary Learning to Ours"
    },
    "af4a8300202c36bcb9c021869a25639f": {
      "source_id": "af4a8300202c36bcb9c021869a25639f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12240,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "We don't understand what happened with culture enough"
    },
    "eaaa2cf87cdb5e7edcf21db1dd5d033a": {
      "source_id": "eaaa2cf87cdb5e7edcf21db1dd5d033a",
      "quality_score": 5.0,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17892,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "Non-superintelligent paperclip maximizers are normal"
    },
    "0db1e306ab87bd60b8c4fd1af57086e1": {
      "source_id": "0db1e306ab87bd60b8c4fd1af57086e1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13607,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Become a PIBBSS Research Affiliate"
    },
    "615a6e6fb7cd1fae9efc67ab2c4e424f": {
      "source_id": "615a6e6fb7cd1fae9efc67ab2c4e424f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47277,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "You\u2019re Measuring Model Complexity Wrong"
    },
    "962e05c33a3650a1089416c30a8decf0": {
      "source_id": "962e05c33a3650a1089416c30a8decf0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32949,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Attributing to interactions with GCPD and GWPD"
    },
    "46fbc68a1308a410eb4a0e89894e21d9": {
      "source_id": "46fbc68a1308a410eb4a0e89894e21d9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14239,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "RSPs are pauses done right"
    },
    "bdbfa2fbda6f88f342c786db2a14d311": {
      "source_id": "bdbfa2fbda6f88f342c786db2a14d311",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47624,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Investigating the learning coefficient of modular addition: hackathon project"
    },
    "cc612c188373036f95e0e0718e7f1b4e": {
      "source_id": "cc612c188373036f95e0e0718e7f1b4e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3065,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing new round of \"Key Phenomena in AI Risk\" Reading Group"
    },
    "381460d3db9a45abd3562f807f546805": {
      "source_id": "381460d3db9a45abd3562f807f546805",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13950,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing Timaeus"
    },
    "544e265a50364dd21eb4fb4839fa47f3": {
      "source_id": "544e265a50364dd21eb4fb4839fa47f3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11194,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "VLM-RM: Specifying Rewards with Natural Language"
    },
    "e6f7d2f0992bcbeab24640bcbb8c92a7": {
      "source_id": "e6f7d2f0992bcbeab24640bcbb8c92a7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41336,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Machine Unlearning Evaluations as Interpretability Benchmarks"
    },
    "b7f20f71e789ed25173fe92a8e91350d": {
      "source_id": "b7f20f71e789ed25173fe92a8e91350d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31720,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Programmatic backdoors: DNNs can use SGD to run arbitrary stateful computation"
    },
    "fc4aed977d6544392c20e204c5bd4db1": {
      "source_id": "fc4aed977d6544392c20e204c5bd4db1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18738,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Open Source Replication & Commentary on Anthropic's Dictionary Learning Paper"
    },
    "6a9390d4dadb2932c8bc520d6cdb41e5": {
      "source_id": "6a9390d4dadb2932c8bc520d6cdb41e5",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7505,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Towards Understanding Sycophancy in Language Models"
    },
    "2024a0ee7b0037bd17f968bb04e17ca9": {
      "source_id": "2024a0ee7b0037bd17f968bb04e17ca9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36584,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Human wanting"
    },
    "877c8ba6273d24f17cd0b38f64634654": {
      "source_id": "877c8ba6273d24f17cd0b38f64634654",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9803,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Lying is Cowardice, not Strategy"
    },
    "55ea8cb640d972f15ee47e3d7a66ff1c": {
      "source_id": "55ea8cb640d972f15ee47e3d7a66ff1c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11845,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Thoughts on responsible scaling policies and regulation"
    },
    "5749aac277b5569308d7fb4bff90d280": {
      "source_id": "5749aac277b5569308d7fb4bff90d280",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12189,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Compositional preference models for aligning LMs"
    },
    "111e3ffcee18e33f71af7bb78e782d6c": {
      "source_id": "111e3ffcee18e33f71af7bb78e782d6c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21704,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI as a science, and three obstacles to alignment strategies"
    },
    "c4bbec06fbfe83092e49b09dbe1630e8": {
      "source_id": "c4bbec06fbfe83092e49b09dbe1630e8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3109,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Apply to the Constellation Visiting Researcher Program and Astra Fellowship, in "
    },
    "c6226a6d597e552ea17fec37e8fefaee": {
      "source_id": "c6226a6d597e552ea17fec37e8fefaee",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7650,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "3. Premise three & Conclusion: AI systems can affect value change trajectories  "
    },
    "bc4d943926f564f6c3ec2400cd7fd559": {
      "source_id": "bc4d943926f564f6c3ec2400cd7fd559",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17252,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "5. Risks from preventing legitimate value change (value collapse)"
    },
    "1e4b2de25ca610feb33d03a9ea91d519": {
      "source_id": "1e4b2de25ca610feb33d03a9ea91d519",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43194,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Preventing Language Models from hiding their reasoning"
    },
    "7fe61ff7febab37a83c01195b7ea0c71": {
      "source_id": "7fe61ff7febab37a83c01195b7ea0c71",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25036,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "My thoughts on the social response to AI risk"
    },
    "5018befaec766725acabf621f765b34d": {
      "source_id": "5018befaec766725acabf621f765b34d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40409,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Thoughts on open source AI"
    },
    "7a72e273a36433c156f78662b92db440": {
      "source_id": "7a72e273a36433c156f78662b92db440",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10299,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Untrusted smart models and trusted dumb models"
    },
    "d81a9b3909049ccdb3422b7da6b55be2": {
      "source_id": "d81a9b3909049ccdb3422b7da6b55be2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35462,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Genetic fitness is a measure of selection strength, not the selection target"
    },
    "6481f90d1d72040ec92bf40a8404d866": {
      "source_id": "6481f90d1d72040ec92bf40a8404d866",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1836,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing TAIS 2024"
    },
    "7b1aab851a46359aa897c131802a0e7e": {
      "source_id": "7b1aab851a46359aa897c131802a0e7e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16880,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Box inversion revisited"
    },
    "bc51b557c9041c46dec4c91aa5328339": {
      "source_id": "bc51b557c9041c46dec4c91aa5328339",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4434,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Scalable And Transferable Black-Box Jailbreaks For Language Models Via Persona M"
    },
    "12b0204aedc5f9422a2b2217e053020d": {
      "source_id": "12b0204aedc5f9422a2b2217e053020d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50998,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Growth and Form in a Toy Model of Superposition"
    },
    "dec012a150d1105ed2f9a6cf2e9da3c3": {
      "source_id": "dec012a150d1105ed2f9a6cf2e9da3c3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 67939,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Tall Tales at Different Scales: Evaluating Scaling Trends For Deception In Langu"
    },
    "c93cfc6d18ea81ce346f107fc588de2d": {
      "source_id": "c93cfc6d18ea81ce346f107fc588de2d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3833,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Learning-theoretic agenda reading list"
    },
    "b99dc9e0c3b7ed7c646124b6e549f770": {
      "source_id": "b99dc9e0c3b7ed7c646124b6e549f770",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 93017,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Timelines"
    },
    "e135aa67265b6482afb14215fd8df545": {
      "source_id": "e135aa67265b6482afb14215fd8df545",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14867,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "We have promising alignment plans with low taxes"
    },
    "fb20c5b274f69a56ac09005b1ad00c92": {
      "source_id": "fb20c5b274f69a56ac09005b1ad00c92",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4741,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Open Phil releases RFPs on LLM Benchmarks and Forecasting"
    },
    "ffd0300c3bf91448c9eeaa1191b83d06": {
      "source_id": "ffd0300c3bf91448c9eeaa1191b83d06",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37565,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Theories of Change for AI Auditing"
    },
    "7a0768b0e0a27bd33779ea9bcfdf6358": {
      "source_id": "7a0768b0e0a27bd33779ea9bcfdf6358",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42433,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Incidental polysemanticity"
    },
    "fb4282470cb89c23d27111dfcfd358f3": {
      "source_id": "fb4282470cb89c23d27111dfcfd358f3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32102,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Experiences and learnings from both sides of the AI safety job market"
    },
    "3bd99cb50fa2f2c115a51220e91cce5a": {
      "source_id": "3bd99cb50fa2f2c115a51220e91cce5a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "alignmentforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 104626,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "New report: \"Scheming AIs: Will AIs fake alignment during training in order to g"
    },
    "4a1054779386836e2f5a0a629d4be60c": {
      "source_id": "4a1054779386836e2f5a0a629d4be60c",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26785,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Energetics of the brain and AI"
    },
    "2a9728dfa4edd6fd4ca83f5cfc73d0ba": {
      "source_id": "2a9728dfa4edd6fd4ca83f5cfc73d0ba",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 95731,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Parametric Bounded L\u00f6b's Theorem and Robust Cooperation of Bounded Agents"
    },
    "2831a92843a5e4894e843a5bcd863a02": {
      "source_id": "2831a92843a5e4894e843a5bcd863a02",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61490,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier"
    },
    "4f40d85a64ad679498eb38f70bc0f0b7": {
      "source_id": "4f40d85a64ad679498eb38f70bc0f0b7",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42763,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Limits to Verification and Validation of Agentic Behavior"
    },
    "867cf2251f9d32584e34aac6d9e2cda3": {
      "source_id": "867cf2251f9d32584e34aac6d9e2cda3",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57448,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Self-Modification of Policy and Utility Function in Rational Agents"
    },
    "2ad044ccbe86ca04e11cddcd42ee81aa": {
      "source_id": "2ad044ccbe86ca04e11cddcd42ee81aa",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 84514,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Avoiding Wireheading with Value Reinforcement Learning"
    },
    "6192ac5138b95d9ba7a6e15955b6639f": {
      "source_id": "6192ac5138b95d9ba7a6e15955b6639f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 90419,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Concrete Problems in AI Safety"
    },
    "d2248d916a22dd163258f77e05ba1cb4": {
      "source_id": "d2248d916a22dd163258f77e05ba1cb4",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37082,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Mammalian Value Systems"
    },
    "713254917f596bccea593a4652c31de9": {
      "source_id": "713254917f596bccea593a4652c31de9",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 593555,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Logical Induction"
    },
    "557bfceacbe79950a26b4a61c3cf31a4": {
      "source_id": "557bfceacbe79950a26b4a61c3cf31a4",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73839,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Google's Neural Machine Translation System: Bridging the Gap between Human and M"
    },
    "839abeea475aefba4c831163a3cdc59e": {
      "source_id": "839abeea475aefba4c831163a3cdc59e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42843,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Artificial Intelligence Safety and Cybersecurity: a Timeline of AI Failures"
    },
    "bf605e3eb967ec3033dc26177fcf2dd9": {
      "source_id": "bf605e3eb967ec3033dc26177fcf2dd9",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51463,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Neural Architecture Search with Reinforcement Learning"
    },
    "a69c2e99982903599f1ef0631a8d5b09": {
      "source_id": "a69c2e99982903599f1ef0631a8d5b09",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45163,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles"
    },
    "42706567777fd6de60b6cc7f293041bf": {
      "source_id": "42706567777fd6de60b6cc7f293041bf",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 99039,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Toward negotiable reinforcement learning: shifting priorities in Pareto optimal "
    },
    "26679affba27c26529db833017df9a72": {
      "source_id": "26679affba27c26529db833017df9a72",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48355,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Enabling Robots to Communicate their Objectives"
    },
    "68b377556f43831964291a398603458e": {
      "source_id": "68b377556f43831964291a398603458e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39846,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Right for the Right Reasons: Training Differentiable Models by Constraining thei"
    },
    "3d2e35721e7e6af2493c419cc2c3365b": {
      "source_id": "3d2e35721e7e6af2493c419cc2c3365b",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34662,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Dynamic Safe Interruptibility for Decentralized Multi-Agent Reinforcement Learni"
    },
    "e0208f404de76bd7b5b21d897aa45b57": {
      "source_id": "e0208f404de76bd7b5b21d897aa45b57",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58023,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "That is not dead which can eternal lie: the aestivation hypothesis for resolving"
    },
    "dc62ec723cf1430d839c54a149073e76": {
      "source_id": "dc62ec723cf1430d839c54a149073e76",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 71517,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Robot Planning with Mathematical Models of Human State and Action"
    },
    "56382c60c6c3e7b0d8f09fbe4da7e390": {
      "source_id": "56382c60c6c3e7b0d8f09fbe4da7e390",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 211770,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Reinforcement Learning with a Corrupted Reward Channel"
    },
    "85d693126567d48366b4cb6c0adfbc03": {
      "source_id": "85d693126567d48366b4cb6c0adfbc03",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23000,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "When Will AI Exceed Human Performance? Evidence from AI Experts"
    },
    "9888ab8acacc8f4a0edc876afb49ef59": {
      "source_id": "9888ab8acacc8f4a0edc876afb49ef59",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41494,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Universal Reinforcement Learning Algorithms: Survey and Experiments"
    },
    "3bc060c075113a3acd60bdc9fee45db1": {
      "source_id": "3bc060c075113a3acd60bdc9fee45db1",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41603,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Low Impact Artificial Intelligences"
    },
    "ac6144846c25f722ba9b2bba77ac908f": {
      "source_id": "ac6144846c25f722ba9b2bba77ac908f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37532,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Deep reinforcement learning from human preferences"
    },
    "abbee081bc54481999271ce83d546e3d": {
      "source_id": "abbee081bc54481999271ce83d546e3d",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52216,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Trial without Error: Towards Safe Reinforcement Learning via Human Intervention"
    },
    "d83deddb25098692a2b5bb7c85a4b94e": {
      "source_id": "d83deddb25098692a2b5bb7c85a4b94e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16827,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Pragmatic-Pedagogic Value Alignment"
    },
    "f0e7df67a2fa5a4543ddfa70efa5b668": {
      "source_id": "f0e7df67a2fa5a4543ddfa70efa5b668",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58734,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Guidelines for Artificial Intelligence Containment"
    },
    "5bba428001708f8d96fcec39f81d9810": {
      "source_id": "5bba428001708f8d96fcec39f81d9810",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42574,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "A Formal Approach to the Problem of Logical Non-Omniscience"
    },
    "259e8b768252584d63d8f7a6652637eb": {
      "source_id": "259e8b768252584d63d8f7a6652637eb",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26893,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "DropoutDAgger: A Bayesian Approach to Safe Imitation Learning"
    },
    "1781dfeed21085a6a7ee0a0b68749e3e": {
      "source_id": "1781dfeed21085a6a7ee0a0b68749e3e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39400,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Incorrigibility in the CIRL Framework"
    },
    "b61d7e33ba6251a41c6c156ef2e639a4": {
      "source_id": "b61d7e33ba6251a41c6c156ef2e639a4",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39206,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Servant of Many Masters: Shifting priorities in Pareto-optimal sequential decisi"
    },
    "7e5e07b1807afa4ed5462f42b26642d9": {
      "source_id": "7e5e07b1807afa4ed5462f42b26642d9",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27671,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Good and safe uses of AI Oracles"
    },
    "cab1fd1544e648fd00584cde4e2007e1": {
      "source_id": "cab1fd1544e648fd00584cde4e2007e1",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31905,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Leave no Trace: Learning to Reset for Safe and Autonomous Reinforcement Learning"
    },
    "9c5d157ee6114e5f0c16006da7478fa0": {
      "source_id": "9c5d157ee6114e5f0c16006da7478fa0",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62584,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "AI Safety Gridworlds"
    },
    "0de42c1e48b1ed5251f903790c642a3e": {
      "source_id": "0de42c1e48b1ed5251f903790c642a3e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35682,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "A Low-Cost Ethics Shaping Approach for Designing Reinforcement Learning Agents"
    },
    "bae9f6db20a311d37cf63b106c587304": {
      "source_id": "bae9f6db20a311d37cf63b106c587304",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8434,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "AI Safety and Reproducibility: Establishing Robust Foundations for the Neuropsyc"
    },
    "901b2797a974e58060ca150e820104fe": {
      "source_id": "901b2797a974e58060ca150e820104fe",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41356,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Occam's razor is insufficient to infer the preferences of irrational agents"
    },
    "caf3b68cdb1358556df0c374f522f8d0": {
      "source_id": "caf3b68cdb1358556df0c374f522f8d0",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42755,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Indifference' methods for managing agent rewards"
    },
    "580086687492613b7515df11cd314efb": {
      "source_id": "580086687492613b7515df11cd314efb",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43421,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Safe Exploration in Continuous Action Spaces"
    },
    "cb0bea2dbf3f6dba4eef81703a81cf38": {
      "source_id": "cb0bea2dbf3f6dba4eef81703a81cf38",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40666,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Learning from Richer Human Guidance: Augmenting Comparison-Based Learning with F"
    },
    "1f79ae6b4d4c0df3339849be9199cfd4": {
      "source_id": "1f79ae6b4d4c0df3339849be9199cfd4",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61094,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Goal Inference Improves Objective and Perceived Performance in Human-Robot Colla"
    },
    "8a86edf03dc7b48ac1e14e8e763f0b2c": {
      "source_id": "8a86edf03dc7b48ac1e14e8e763f0b2c",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 146565,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "More Robust Doubly Robust Off-policy Evaluation"
    },
    "ae99d6d74bc1c08e015eb5238fb4d718": {
      "source_id": "ae99d6d74bc1c08e015eb5238fb4d718",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 242586,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitig"
    },
    "9e9525f3735aa4c6e6e545e673b0de84": {
      "source_id": "9e9525f3735aa4c6e6e545e673b0de84",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 64861,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Machine Theory of Mind"
    },
    "c5e91218315409dd2b62d5bf047a0f3e": {
      "source_id": "c5e91218315409dd2b62d5bf047a0f3e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 98143,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "The Surprising Creativity of Digital Evolution: A Collection of Anecdotes from t"
    },
    "0ef3ae9d9df8bf40db98446623243249": {
      "source_id": "0ef3ae9d9df8bf40db98446623243249",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27244,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Categorizing Variants of Goodhart's Law"
    },
    "b6b762b2e10ccbe99dd3fce5a97cdb0d": {
      "source_id": "b6b762b2e10ccbe99dd3fce5a97cdb0d",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 75680,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learn"
    },
    "45ed72f40204d0dbb657eda01ea55146": {
      "source_id": "45ed72f40204d0dbb657eda01ea55146",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 84203,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Fractal AI: A fragile theory of intelligence"
    },
    "24008e5ce4a89c6c59440f9f964cdfca": {
      "source_id": "24008e5ce4a89c6c59440f9f964cdfca",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35124,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Neural Network Quine"
    },
    "bb3ed7bc24be17f9113b3d56eaa37513": {
      "source_id": "bb3ed7bc24be17f9113b3d56eaa37513",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43345,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Adversarial Logit Pairing"
    },
    "21267b4187d0fc7eb4ab752aaf89b0d2": {
      "source_id": "21267b4187d0fc7eb4ab752aaf89b0d2",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56610,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Learning-based Model Predictive Control for Safe Exploration"
    },
    "2030b02686788da3b51878f5c01a2df9": {
      "source_id": "2030b02686788da3b51878f5c01a2df9",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 115080,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Computational Power and the Social Impact of Artificial Intelligence"
    },
    "522f7a056dc115d329a63668811cb659": {
      "source_id": "522f7a056dc115d329a63668811cb659",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49495,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Ma"
    },
    "a2c958c9052a7d8d538e5a00f047af19": {
      "source_id": "a2c958c9052a7d8d538e5a00f047af19",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45021,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Large scale distributed neural network training through online distillation"
    },
    "043fe6dc0beaa8b2568709fcda4eb27c": {
      "source_id": "043fe6dc0beaa8b2568709fcda4eb27c",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39670,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Emergent Communication through Negotiation"
    },
    "62f122481baeefc37839452c033b625c": {
      "source_id": "62f122481baeefc37839452c033b625c",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40783,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Adversarial Attacks Against Medical Deep Learning Systems"
    },
    "30f1a7a1789ef9246894978888c3b349": {
      "source_id": "30f1a7a1789ef9246894978888c3b349",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46800,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Zero-Shot Visual Imitation"
    },
    "721ce41554be015d041a7feee9e241c5": {
      "source_id": "721ce41554be015d041a7feee9e241c5",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49393,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Realistic Evaluation of Deep Semi-Supervised Learning Algorithms"
    },
    "acd42e38d07345ab51f01dcc2d0b38db": {
      "source_id": "acd42e38d07345ab51f01dcc2d0b38db",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34884,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation"
    },
    "e20fd9f7d083bd38f5269711cd12433a": {
      "source_id": "e20fd9f7d083bd38f5269711cd12433a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 85977,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "AI safety via debate"
    },
    "f941eca7326ad9c4cc771ae52ba5abc9": {
      "source_id": "f941eca7326ad9c4cc771ae52ba5abc9",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 123028,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "The Blessings of Multiple Causes"
    },
    "c5fc3042c65ffa8907ca5bdf23f58f41": {
      "source_id": "c5fc3042c65ffa8907ca5bdf23f58f41",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 81087,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Unsupervised Learning of Neural Networks to Explain Neural Networks"
    },
    "779a2317c0abb60273c9386a7709371f": {
      "source_id": "779a2317c0abb60273c9386a7709371f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 72572,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Constrained Policy Improvement for Safe and Efficient Reinforcement Learning"
    },
    "9c912055d2d387eea03c6bbf866ee7a5": {
      "source_id": "9c912055d2d387eea03c6bbf866ee7a5",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35600,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "A Framework and Method for Online Inverse Reinforcement Learning"
    },
    "c92e4d9890809f73dfdbac7f58100d2f": {
      "source_id": "c92e4d9890809f73dfdbac7f58100d2f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73826,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Learning Safe Policies with Expert Guidance"
    },
    "59bdc581d12f5d74d4ed64335e3dd8ec": {
      "source_id": "59bdc581d12f5d74d4ed64335e3dd8ec",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36139,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Maximum Causal Tsallis Entropy Imitation Learning"
    },
    "f9427d97b1de83b720ad86f95bcd3984": {
      "source_id": "f9427d97b1de83b720ad86f95bcd3984",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58406,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Training verified learners with learned verifiers"
    },
    "408fdf74dfa3936ad822ac8a9b94b385": {
      "source_id": "408fdf74dfa3936ad822ac8a9b94b385",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33630,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Playing hard exploration games by watching YouTube"
    },
    "44db885f14f4567f72154fbc506a3380": {
      "source_id": "44db885f14f4567f72154fbc506a3380",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51212,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Explaining Explanations: An Overview of Interpretability of Machine Learning"
    },
    "02d29384d4f1acc9458c26dad3e8d8e1": {
      "source_id": "02d29384d4f1acc9458c26dad3e8d8e1",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48521,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Probabilistically Safe Robot Planning with Confidence-Based Human Predictions"
    },
    "870cfbdf19d603ef0501a0241321a229": {
      "source_id": "870cfbdf19d603ef0501a0241321a229",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39102,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Between Progress and Potential Impact of AI: the Neglected Dimensions"
    },
    "a8daf511a90c10f666ef32399e8d2a51": {
      "source_id": "a8daf511a90c10f666ef32399e8d2a51",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55467,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Sufficient Conditions for Idealised Models to Have No Adversarial Examples: a Th"
    },
    "71e4b5b262c8176a5bbd4fe79c068215": {
      "source_id": "71e4b5b262c8176a5bbd4fe79c068215",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40257,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "An Efficient, Generalized Bellman Update For Cooperative Inverse Reinforcement L"
    },
    "f7b6498293e5e00f72e44c8bc0425f72": {
      "source_id": "f7b6498293e5e00f72e44c8bc0425f72",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29073,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Adaptive Mechanism Design: Learning to Promote Cooperation"
    },
    "b7eb706ddf3fc687cdf60148a631401e": {
      "source_id": "b7eb706ddf3fc687cdf60148a631401e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32685,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Scrutinizing and De-Biasing Intuitive Physics with Neural Stethoscopes"
    },
    "6c1540dbd5a19818cf1b3df4f2101c6c": {
      "source_id": "6c1540dbd5a19818cf1b3df4f2101c6c",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39829,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Evolving simple programs for playing Atari games"
    },
    "d50b5ef4912f0d1aa4c7aa536c8b740f": {
      "source_id": "d50b5ef4912f0d1aa4c7aa536c8b740f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 107549,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "A Survey of Inverse Reinforcement Learning: Challenges, Methods and Progress"
    },
    "137bbec0e331870d3d466b58da7f706d": {
      "source_id": "137bbec0e331870d3d466b58da7f706d",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 288715,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "RUDDER: Return Decomposition for Delayed Rewards"
    },
    "60ce6df24e15aa3fbcafa1dfa793cd47": {
      "source_id": "60ce6df24e15aa3fbcafa1dfa793cd47",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30829,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Resource-Efficient Neural Architect"
    },
    "0a524cefae2d947063c5c78a8300092f": {
      "source_id": "0a524cefae2d947063c5c78a8300092f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29599,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Interpretable Discovery in Large Image Data Sets"
    },
    "18f8987e4b8187c656a90cccdfabe6bf": {
      "source_id": "18f8987e4b8187c656a90cccdfabe6bf",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 85075,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Human-Interactive Subgoal Supervision for Efficient Inverse Reinforcement Learni"
    },
    "e58ee43c60372af136cca9bab0a40b9d": {
      "source_id": "e58ee43c60372af136cca9bab0a40b9d",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39215,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "On Adversarial Examples for Character-Level Neural Machine Translation"
    },
    "52818dc9c9b0ec8ff07188cb0370ed9d": {
      "source_id": "52818dc9c9b0ec8ff07188cb0370ed9d",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 202312,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Multi-agent Inverse Reinforcement Learning for Certain General-sum Stochastic Ga"
    },
    "0e3cde25cfb8379f8939ce496f2ada1f": {
      "source_id": "0e3cde25cfb8379f8939ce496f2ada1f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50445,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Adversarial Active Exploration for Inverse Dynamics Model Learning"
    },
    "66b16ddb540dbf79c7963bd85697a6f4": {
      "source_id": "66b16ddb540dbf79c7963bd85697a6f4",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17868,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Towards Mixed Optimization for Reinforcement Learning with Program Synthesis"
    },
    "ad7cc0e44a27d325e9114a161fc7cc30": {
      "source_id": "ad7cc0e44a27d325e9114a161fc7cc30",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33904,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Ranked Reward: Enabling Self-Play Reinforcement Learning for Combinatorial Optim"
    },
    "13c24361877d0d2f290241ceb8da15c8": {
      "source_id": "13c24361877d0d2f290241ceb8da15c8",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 122896,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "A Game-Based Approximate Verification of Deep Neural Networks with Provable Guar"
    },
    "f9434e9f3ee20787531f59b411ecd12d": {
      "source_id": "f9434e9f3ee20787531f59b411ecd12d",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32015,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Universal Transformers"
    },
    "f2582a779889fe2c31fff53cd6859b17": {
      "source_id": "f2582a779889fe2c31fff53cd6859b17",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 60447,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Safe Reinforcement Learning via Probabilistic Shields"
    },
    "d3a402637ed5f7a2997b5e788862f6c5": {
      "source_id": "d3a402637ed5f7a2997b5e788862f6c5",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30815,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Interpretable Latent Spaces for Learning from Demonstration"
    },
    "8d97dd0f7dbc55a01bc3e78473bca73e": {
      "source_id": "8d97dd0f7dbc55a01bc3e78473bca73e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41661,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Safe Option-Critic: Learning Safety in the Option-Critic Architecture"
    },
    "3b8e895af2010f42738083d679a2e50a": {
      "source_id": "3b8e895af2010f42738083d679a2e50a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48998,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "EnsembleDAgger: A Bayesian Approach to Safe Imitation Learning"
    },
    "92a5e7db3083500c6bf32244c23bdb93": {
      "source_id": "92a5e7db3083500c6bf32244c23bdb93",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21014,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Evaluating and Understanding the Robustness of Adversarial Logit Pairing"
    },
    "c66e65c42875adef72c388edcafa5eae": {
      "source_id": "c66e65c42875adef72c388edcafa5eae",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34369,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Variational Option Discovery Algorithms"
    },
    "0d235ae393c51863c6308726872964cb": {
      "source_id": "0d235ae393c51863c6308726872964cb",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 107114,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Security and Privacy Issues in Deep Learning"
    },
    "71ea3916b563f9c45c47c16bdde645c8": {
      "source_id": "71ea3916b563f9c45c47c16bdde645c8",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 88672,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Generalization Error in Deep Learning"
    },
    "5cc4fc269b34b5b6b1f592e7b79014f8": {
      "source_id": "5cc4fc269b34b5b6b1f592e7b79014f8",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36276,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Building Safer AGI by introducing Artificial Stupidity"
    },
    "f1216e608f8dd839d2e88816f23fda43": {
      "source_id": "f1216e608f8dd839d2e88816f23fda43",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41447,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Directed Policy Gradient for Safe Reinforcement Learning with Human Advice"
    },
    "319dc219983bf377a60116c9f31ff29a": {
      "source_id": "319dc219983bf377a60116c9f31ff29a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48465,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Analyzing Inverse Problems with Invertible Neural Networks"
    },
    "c50214c8f80f3b4095b8afe83d047c97": {
      "source_id": "c50214c8f80f3b4095b8afe83d047c97",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49414,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "The Social Cost of Strategic Classification"
    },
    "ffbaa6c6637a57a216c019c045639253": {
      "source_id": "ffbaa6c6637a57a216c019c045639253",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35738,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Why Self-Attention? A Targeted Evaluation of Neural Machine Translation Architec"
    },
    "1413c089690f9c7066420e31ae3b76a7": {
      "source_id": "1413c089690f9c7066420e31ae3b76a7",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45189,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "A Roadmap for Robust End-to-End Alignment"
    },
    "68473420afe61cd854f075520a1f5cb7": {
      "source_id": "68473420afe61cd854f075520a1f5cb7",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33577,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Reinforcement Learning under Threats"
    },
    "07f0f2a80bb55b2df9de2c2129245ad5": {
      "source_id": "07f0f2a80bb55b2df9de2c2129245ad5",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17648,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Learning Invariances for Policy Generalization"
    },
    "4d58fc236181a582f1daeb47956e4ad2": {
      "source_id": "4d58fc236181a582f1daeb47956e4ad2",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34414,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Ad"
    },
    "2d7d2d0004b786679678cfec274aa018": {
      "source_id": "2d7d2d0004b786679678cfec274aa018",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28189,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Expert-augmented actor-critic for ViZDoom and Montezumas Revenge"
    },
    "2be3bbe1029a6ad6235888b8d6c29189": {
      "source_id": "2be3bbe1029a6ad6235888b8d6c29189",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33581,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Abstraction Learning"
    },
    "ec316c9e111cb696ebd078e8368e87ff": {
      "source_id": "ec316c9e111cb696ebd078e8368e87ff",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37707,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "CM3: Cooperative Multi-goal Multi-stage Multi-agent Reinforcement Learning"
    },
    "999fd36ceabc972b84a58f24733406fc": {
      "source_id": "999fd36ceabc972b84a58f24733406fc",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 88331,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Towards Better Interpretability in Deep Q-Networks"
    },
    "100ba189bf0dc01a921bdc8cd245b545": {
      "source_id": "100ba189bf0dc01a921bdc8cd245b545",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19163,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Interpretable Reinforcement Learning with Ensemble Methods"
    },
    "dd92a06770fa00e4f80be247dd90ed59": {
      "source_id": "dd92a06770fa00e4f80be247dd90ed59",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49810,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Playing the Game of Universal Adversarial Perturbations"
    },
    "21fe8264295b133a2f69396a25c13a72": {
      "source_id": "21fe8264295b133a2f69396a25c13a72",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40690,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Interpretable Multi-Objective Reinforcement Learning through Policy Orchestratio"
    },
    "6a8d9093f9310ee68f223417d1409ef8": {
      "source_id": "6a8d9093f9310ee68f223417d1409ef8",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25878,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Stakeholders in Explainable AI"
    },
    "92555068989b194c19551823acd9be11": {
      "source_id": "92555068989b194c19551823acd9be11",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43925,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "SmartChoices: Hybridizing Programming and Machine Learning"
    },
    "b750fa887406a8834947bcbfb4af7fa4": {
      "source_id": "b750fa887406a8834947bcbfb4af7fa4",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 112890,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Training Machine Learning Models by Regularizing their Explanations"
    },
    "b1131d9d90cd50993fc20955aec24c01": {
      "source_id": "b1131d9d90cd50993fc20955aec24c01",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36360,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Bayesian Policy Optimization for Model Uncertainty"
    },
    "2bc37a9bb4a9990532da320e9bb1731a": {
      "source_id": "2bc37a9bb4a9990532da320e9bb1731a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 69743,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Reinforcement Learning with Perturbed Rewards"
    },
    "2cddd5559522d63033dee6882eac8238": {
      "source_id": "2cddd5559522d63033dee6882eac8238",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 229780,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Unsupervised Learning via Meta-Learning"
    },
    "aa96e047b272d327b3f4f0482e83d282": {
      "source_id": "aa96e047b272d327b3f4f0482e83d282",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 60723,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Sanity Checks for Saliency Maps"
    },
    "ba8057b3b54d04c0915585918bebad63": {
      "source_id": "ba8057b3b54d04c0915585918bebad63",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43105,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Fast Context Adaptation via Meta-Learning"
    },
    "c8093ac4da9fd19b5eda6923f84962ff": {
      "source_id": "c8093ac4da9fd19b5eda6923f84962ff",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73209,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "The 30-Year Cycle In The AI Debate"
    },
    "301c7ed4b11f8ec0772b27961098f70b": {
      "source_id": "301c7ed4b11f8ec0772b27961098f70b",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57192,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Batch Active Preference-Based Learning of Reward Functions"
    },
    "2e2b27a6cd1a3469f83ae94cc8cf65d2": {
      "source_id": "2e2b27a6cd1a3469f83ae94cc8cf65d2",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24874,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Secure Deep Learning Engineering: A Software Quality Assurance Perspective"
    },
    "2cca17ac0cccda95db666a3539a070b2": {
      "source_id": "2cca17ac0cccda95db666a3539a070b2",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47106,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
    },
    "03dacb5f6ba0911a12ae607d9e6b2824": {
      "source_id": "03dacb5f6ba0911a12ae607d9e6b2824",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38210,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Deep Imitative Models for Flexible Inference, Planning, and Control"
    },
    "235d4287bd5bc4f31d1d838ba4e48ecb": {
      "source_id": "235d4287bd5bc4f31d1d838ba4e48ecb",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 64630,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Expressing Robot Incapability"
    },
    "ff9aa344fe987ce15f4521f145c7488c": {
      "source_id": "ff9aa344fe987ce15f4521f145c7488c",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35896,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Establishing Appropriate Trust via Critical States"
    },
    "14670c094dee4d81f48f5d7ff247dd71": {
      "source_id": "14670c094dee4d81f48f5d7ff247dd71",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27884,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Supervising strong learners by amplifying weak experts"
    },
    "078647ecabd0967199b33e371b7c0166": {
      "source_id": "078647ecabd0967199b33e371b7c0166",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33935,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Safe Reinforcement Learning with Model Uncertainty Estimates"
    },
    "34d8f5ef5275a7d8b02bbffdfc308ce9": {
      "source_id": "34d8f5ef5275a7d8b02bbffdfc308ce9",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 67908,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Do Deep Generative Models Know What They Don't Know?"
    },
    "39f0309e9578100dcefae1a10d3017cc": {
      "source_id": "39f0309e9578100dcefae1a10d3017cc",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43858,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Applying Deep Learning To Airbnb Search"
    },
    "f8a26d70a7cb3ec9206f4f3e84cc159a": {
      "source_id": "f8a26d70a7cb3ec9206f4f3e84cc159a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35840,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Toward an AI Physicist for Unsupervised Learning"
    },
    "f64435dc982350b15034a68d457c7446": {
      "source_id": "f64435dc982350b15034a68d457c7446",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36704,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "One-Shot Hierarchical Imitation Learning of Compound Visuomotor Tasks"
    },
    "a52b988d2135f29986a05e830907945a": {
      "source_id": "a52b988d2135f29986a05e830907945a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 87027,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Neural Modular Control for Embodied Question Answering"
    },
    "8ba0cd4cd001a53e9526016491c3845d": {
      "source_id": "8ba0cd4cd001a53e9526016491c3845d",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46837,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Efficiently Combining Human Demonstrations and Interventions for Safe Training o"
    },
    "f27415a8ea03c98fce1bff903f76dbdc": {
      "source_id": "f27415a8ea03c98fce1bff903f76dbdc",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17606,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "On the Effectiveness of Interval Bound Propagation for Training Verifiably Robus"
    },
    "9d9b44a5a161898099d0e6c6063d1959": {
      "source_id": "9d9b44a5a161898099d0e6c6063d1959",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51469,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "A Marauder's Map of Security and Privacy in Machine Learning"
    },
    "1a1dc45a67dd7af20cdaf83b6c672551": {
      "source_id": "1a1dc45a67dd7af20cdaf83b6c672551",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49744,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Explaining Explanations in AI"
    },
    "5b3fc1caecb2bdfbdd16fbffc23096b1": {
      "source_id": "5b3fc1caecb2bdfbdd16fbffc23096b1",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25735,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "A Model for General Intelligence"
    },
    "241a89b020f41ca29e68b27e3787a6b3": {
      "source_id": "241a89b020f41ca29e68b27e3787a6b3",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 78301,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "MixTrain: Scalable Training of Verifiably Robust Neural Networks"
    },
    "edcfb7b14bcd019f01ed28e5e9e307d7": {
      "source_id": "edcfb7b14bcd019f01ed28e5e9e307d7",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 94710,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "A Geometric Perspective on the Transferability of Adversarial Directions"
    },
    "ee44771acb20d893238525b687082625": {
      "source_id": "ee44771acb20d893238525b687082625",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18199,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Intrinsic Geometric Vulnerability of High-Dimensional Artificial Intelligence"
    },
    "3585f4371df3bbed5bb38a934723aa8b": {
      "source_id": "3585f4371df3bbed5bb38a934723aa8b",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57170,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Towards Governing Agent's Efficacy: Action-Conditional $\u03b2$-VAE for Deep Transpar"
    },
    "f219190c3da3ab10fa21b8b0f3b3f77b": {
      "source_id": "f219190c3da3ab10fa21b8b0f3b3f77b",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 70742,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Learning Latent Dynamics for Planning from Pixels"
    },
    "f283b89018a0ba9f0a18d5d57f5a03bf": {
      "source_id": "f283b89018a0ba9f0a18d5d57f5a03bf",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19589,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Emergence of Addictive Behaviors in Reinforcement Learning Agents"
    },
    "aff106819250bbd2fda234ac03c836bf": {
      "source_id": "aff106819250bbd2fda234ac03c836bf",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30744,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Deeper Interpretability of Deep Networks"
    },
    "86930a39f73f75bf6a1a7439ac8585b1": {
      "source_id": "86930a39f73f75bf6a1a7439ac8585b1",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73422,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Safely Probabilistically Complete Real-Time Planning and Exploration in Unknown "
    },
    "19f1abcbac7010a11159da9709aef14d": {
      "source_id": "19f1abcbac7010a11159da9709aef14d",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 98004,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Scalable agent alignment via reward modeling: a research direction"
    },
    "f9b3c39fa45299751448eb02e0f62e10": {
      "source_id": "f9b3c39fa45299751448eb02e0f62e10",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56369,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "GAN Dissection: Visualizing and Understanding Generative Adversarial Networks"
    },
    "347aeee287686933b139cc41d2c6821d": {
      "source_id": "347aeee287686933b139cc41d2c6821d",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39845,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Exploring Restart Distributions"
    },
    "0475b257aaff02e46ebf334dc623b968": {
      "source_id": "0475b257aaff02e46ebf334dc623b968",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33309,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Building Ethics into Artificial Intelligence"
    },
    "b489d7cfa3b043cdd54a644aa2cb10e7": {
      "source_id": "b489d7cfa3b043cdd54a644aa2cb10e7",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23372,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Building Ethically Bounded AI"
    },
    "2731015320ee6b204aea7a9251f923a1": {
      "source_id": "2731015320ee6b204aea7a9251f923a1",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33568,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Human-AI Learning Performance in Multi-Armed Bandits"
    },
    "45bb5f743065a655f55c40afdd0b8c94": {
      "source_id": "45bb5f743065a655f55c40afdd0b8c94",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41359,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Learning Not to Learn: Training Deep Neural Networks with Biased Data"
    },
    "30d197f2abc4241ff2e83d3701c25509": {
      "source_id": "30d197f2abc4241ff2e83d3701c25509",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47786,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Theoretically Principled Trade-off between Robustness and Accuracy"
    },
    "b63f209cc6a759ef2e075137c82a818d": {
      "source_id": "b63f209cc6a759ef2e075137c82a818d",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39630,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Forecasting Transformative AI: An Expert Survey"
    },
    "f950f006f5efb0120eb9dee0cce6e6c4": {
      "source_id": "f950f006f5efb0120eb9dee0cce6e6c4",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49929,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Lyapunov-based Safe Policy Optimization for Continuous Control"
    },
    "50eceef4c4b20c6eb868b1193d898439": {
      "source_id": "50eceef4c4b20c6eb868b1193d898439",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19934,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Human-Centered Artificial Intelligence and Machine Learning"
    },
    "90b5d7af9f5da8bf23e5e5b257801a3f": {
      "source_id": "90b5d7af9f5da8bf23e5e5b257801a3f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40710,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Hybrid Models with Deep and Invertible Features"
    },
    "7a25f9dac2f07281da16f94325ffa083": {
      "source_id": "7a25f9dac2f07281da16f94325ffa083",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50744,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Certified Adversarial Robustness via Randomized Smoothing"
    },
    "e10bd434793cbcb959da40a40b8ebe69": {
      "source_id": "e10bd434793cbcb959da40a40b8ebe69",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35043,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Preferences Implicit in the State of the World"
    },
    "fd1a8691241568fdea23389e94e6d488": {
      "source_id": "fd1a8691241568fdea23389e94e6d488",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41697,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Deep Reinforcement Learning from Policy-Dependent Human Feedback"
    },
    "42b5c7670cdc45c040d2a40caa773e27": {
      "source_id": "42b5c7670cdc45c040d2a40caa773e27",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 123598,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey"
    },
    "919161b4469fbbd27a582c674cfb5ec9": {
      "source_id": "919161b4469fbbd27a582c674cfb5ec9",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48090,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Parenting: Safe Reinforcement Learning from Human Input"
    },
    "c47368892bef3139e5e80a2c8c846521": {
      "source_id": "c47368892bef3139e5e80a2c8c846521",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41000,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Regularizing Black-box Models for Improved Interpretability"
    },
    "96cde62c4dd6e7be161f0df82b1b1e83": {
      "source_id": "96cde62c4dd6e7be161f0df82b1b1e83",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45179,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Meta-Weight-Net: Learning an Explicit Mapping For Sample Weighting"
    },
    "4b97d1dac7514262eae5edd5cb42782b": {
      "source_id": "4b97d1dac7514262eae5edd5cb42782b",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49393,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "World Discovery Models"
    },
    "0ab857cd2ee86671502df2e380403f1d": {
      "source_id": "0ab857cd2ee86671502df2e380403f1d",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 114949,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Embedded Agency"
    },
    "f5844f3a6e4347ca877dc243cded9814": {
      "source_id": "f5844f3a6e4347ca877dc243cded9814",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37130,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Using Causal Analysis to Learn Specifications from Task Demonstrations"
    },
    "9ab3cecfa4c1951e55b7e2a5d128856b": {
      "source_id": "9ab3cecfa4c1951e55b7e2a5d128856b",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45195,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Learning Exploration Policies for Navigation"
    },
    "2fe8faa00c606c51a8a2c3b46ab2fd84": {
      "source_id": "2fe8faa00c606c51a8a2c3b46ab2fd84",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43898,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Learning Latent Plans from Play"
    },
    "1bb63b4bece57ce3ad8319c63c479e7e": {
      "source_id": "1bb63b4bece57ce3ad8319c63c479e7e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42655,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples"
    },
    "83849de1b9cb57cf72aef0469b6c9dc6": {
      "source_id": "83849de1b9cb57cf72aef0469b6c9dc6",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48844,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Deep Reinforcement Learning with Feedback-based Exploration"
    },
    "e0cdee14a523d8d2dad74cb1d271241a": {
      "source_id": "e0cdee14a523d8d2dad74cb1d271241a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 119164,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Gradient Descent with Early Stopping is Provably Robust to Label Noise for Overp"
    },
    "047b16216740d354a2ee5d8d7e21144d": {
      "source_id": "047b16216740d354a2ee5d8d7e21144d",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 82682,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Predicting human decisions with behavioral theories and machine learning"
    },
    "4ba32345a0367d2bd3b18a59598528c6": {
      "source_id": "4ba32345a0367d2bd3b18a59598528c6",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 67100,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Optimization and Abstraction: A Synergistic Approach for Analyzing Neural Networ"
    },
    "e551f77f4bbceddcfccc7e010d960faa": {
      "source_id": "e551f77f4bbceddcfccc7e010d960faa",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16600,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Transfer of Adversarial Robustness Between Perturbation Types"
    },
    "6353ef31023a168ceea35bc577748baf": {
      "source_id": "6353ef31023a168ceea35bc577748baf",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42768,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Adversarial Examples Are Not Bugs, They Are Features"
    },
    "2ff079707f38077331526ea3ee5ce378": {
      "source_id": "2ff079707f38077331526ea3ee5ce378",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39592,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Cognitive Model Priors for Predicting Human Decisions"
    },
    "aa9a7266e2a3f6e8f34d60effc31a650": {
      "source_id": "aa9a7266e2a3f6e8f34d60effc31a650",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48311,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Asymptotically Unambitious Artificial General Intelligence"
    },
    "5d45e51f2ea6d22bdcb9d30310c79a00": {
      "source_id": "5d45e51f2ea6d22bdcb9d30310c79a00",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55255,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Adversarial Robustness as a Prior for Learned Representations"
    },
    "7775b0d3b8cbad1703c53161c4e12115": {
      "source_id": "7775b0d3b8cbad1703c53161c4e12115",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41382,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Can You Trust Your Model's Uncertainty? Evaluating Predictive Uncertainty Under "
    },
    "8e8ab37d7a89166c80aa3ca36539e811": {
      "source_id": "8e8ab37d7a89166c80aa3ca36539e811",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23142,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "An Extensible Interactive Interface for Agent Design"
    },
    "0b830fb1671c291a00adc2516fc8fd9b": {
      "source_id": "0b830fb1671c291a00adc2516fc8fd9b",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43606,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Likelihood Ratios for Out-of-Distribution Detection"
    },
    "0a1c13b3bb93cd641700d3f269e30a86": {
      "source_id": "0a1c13b3bb93cd641700d3f269e30a86",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37912,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Weight Agnostic Neural Networks"
    },
    "30334862e967a2341fef9742c2e699b0": {
      "source_id": "30334862e967a2341fef9742c2e699b0",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32219,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Categorizing Wireheading in Partially Embedded Agents"
    },
    "060a27387c4518c01b642d1e5bb387d2": {
      "source_id": "060a27387c4518c01b642d1e5bb387d2",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30797,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Image Synthesis with a Single (Robust) Classifier"
    },
    "6d55735612b0d6459ba51dc5f6d07b5c": {
      "source_id": "6d55735612b0d6459ba51dc5f6d07b5c",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43791,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Reinforcement Learning with Competitive Ensembles of Information-Constrained Pri"
    },
    "8921c4e2df86ea1656794ff5682c1f63": {
      "source_id": "8921c4e2df86ea1656794ff5682c1f63",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35638,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Generalizing from a few environments in safety-critical reinforcement learning"
    },
    "a2fa77ab4077cf22ca4255482ea069af": {
      "source_id": "a2fa77ab4077cf22ca4255482ea069af",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 87805,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "The Role of Cooperation in Responsible AI Development"
    },
    "3514608b30257527e6af3fcc3acf59ed": {
      "source_id": "3514608b30257527e6af3fcc3acf59ed",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 90555,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "An Inductive Synthesis Framework for Verifiable Reinforcement Learning"
    },
    "fadbd429d0fa7b3ff2fc4e373dd95b00": {
      "source_id": "fadbd429d0fa7b3ff2fc4e373dd95b00",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37686,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Reducing malicious use of synthetic media research: Considerations and potential"
    },
    "82972a89dab65e8fae8f8521ae4a290f": {
      "source_id": "82972a89dab65e8fae8f8521ae4a290f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 139921,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Reward Tampering Problems and Solutions in Reinforcement Learning: A Causal Infl"
    },
    "669a2a89fe0b6b8658602a2d069bba39": {
      "source_id": "669a2a89fe0b6b8658602a2d069bba39",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34947,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Implications of Quantum Computing for Artificial Intelligence alignment research"
    },
    "3d733b9f6a6b6091cb45b2bea11e5c93": {
      "source_id": "3d733b9f6a6b6091cb45b2bea11e5c93",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59707,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Testing Robustness Against Unforeseen Adversaries"
    },
    "f48be4c3fb9d9ad0592fb15af644c0fb": {
      "source_id": "f48be4c3fb9d9ad0592fb15af644c0fb",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 116902,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Release Strategies and the Social Impacts of Language Models"
    },
    "855de84aa73b3e514946a208515b7694": {
      "source_id": "855de84aa73b3e514946a208515b7694",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38268,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Achieving Verified Robustness to Symbol Substitutions via Interval Bound Propaga"
    },
    "4f0c4f943196c1b6b7b663a661ba7c0f": {
      "source_id": "4f0c4f943196c1b6b7b663a661ba7c0f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46308,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Meta-Inverse Reinforcement Learning with Probabilistic Context Variables"
    },
    "59f6f938d8b690b2c9ee1a0aa314e35a": {
      "source_id": "59f6f938d8b690b2c9ee1a0aa314e35a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6188,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Formal Language Constraints for Markov Decision Processes"
    },
    "73478b418cc331431af728c2ee6d56db": {
      "source_id": "73478b418cc331431af728c2ee6d56db",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37818,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Scaled Autonomy: Enabling Human Operators to Control Robot Fleets"
    },
    "9bb1056693c6746e757975141d1574ca": {
      "source_id": "9bb1056693c6746e757975141d1574ca",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39351,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "On the Utility of Learning about Humans for Human-AI Coordination"
    },
    "5c831da76432b236a058fa254d49b1c4": {
      "source_id": "5c831da76432b236a058fa254d49b1c4",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62839,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "An Alternative Surrogate Loss for PGD-based Adversarial Testing"
    },
    "6026676ef70b61b371b5a8945a90540c": {
      "source_id": "6026676ef70b61b371b5a8945a90540c",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37496,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Lea"
    },
    "d2f51e0350d3522167886b4f5b8d42e2": {
      "source_id": "d2f51e0350d3522167886b4f5b8d42e2",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 77469,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "A Hamilton-Jacobi Reachability-Based Framework for Predicting and Analyzing Huma"
    },
    "6c033586fd63cd2eef2c414f74b9d305": {
      "source_id": "6c033586fd63cd2eef2c414f74b9d305",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 176202,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "On the Measure of Intelligence"
    },
    "5223826fba8bc976904ad4b739288025": {
      "source_id": "5223826fba8bc976904ad4b739288025",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42503,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Nonverbal Robot Feedback for Human Teachers"
    },
    "135efea1cd78b777ce408b28bc082fee": {
      "source_id": "135efea1cd78b777ce408b28bc082fee",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 107116,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "(When) Is Truth-telling Favored in AI Debate?"
    },
    "623d2a613c808d33657d2068cf143f40": {
      "source_id": "623d2a613c808d33657d2068cf143f40",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39048,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Scaling Out-of-Distribution Detection for Real-World Settings"
    },
    "cdb5c302cf99a7be2bc503ca5fa99588": {
      "source_id": "cdb5c302cf99a7be2bc503ca5fa99588",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35908,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "SafeLife 1.0: Exploring Side Effects in Complex Environments"
    },
    "352fdb904551171a1a3031f5b2c0e608": {
      "source_id": "352fdb904551171a1a3031f5b2c0e608",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38220,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Optimal Policies Tend to Seek Power"
    },
    "fae8082a3663346be5c37dae351c0c1f": {
      "source_id": "fae8082a3663346be5c37dae351c0c1f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44307,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Learning Efficient Representation for Intrinsic Motivation"
    },
    "bedbb9cfa9a577ebe9376c55927c4d9f": {
      "source_id": "bedbb9cfa9a577ebe9376c55927c4d9f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38011,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Deep Ensembles: A Loss Landscape Perspective"
    },
    "e05f8c3e7a81ae955fe7f37b1972e757": {
      "source_id": "e05f8c3e7a81ae955fe7f37b1972e757",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 90038,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Learning Human Objectives by Evaluating Hypothetical Behavior"
    },
    "ecfece2c5b40a7df6a174d6db46cc72e": {
      "source_id": "ecfece2c5b40a7df6a174d6db46cc72e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57910,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Dota 2 with Large Scale Deep Reinforcement Learning"
    },
    "f69600bf4fb8749b09909298aeb68f8a": {
      "source_id": "f69600bf4fb8749b09909298aeb68f8a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45149,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Generative Teaching Networks: Accelerating Neural Architecture Search by Learnin"
    },
    "b09f079287d7fbd3f53897adf2ac57ca": {
      "source_id": "b09f079287d7fbd3f53897adf2ac57ca",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36609,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Mastering Complex Control in MOBA Games with Deep Reinforcement Learning"
    },
    "fa408ad6b951e2be15de9bf172f8df04": {
      "source_id": "fa408ad6b951e2be15de9bf172f8df04",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 118820,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Asking the Right Questions: Learning Interpretable Action Models Through Query A"
    },
    "01422b8e083200ef2cd47b6d3563f6d2": {
      "source_id": "01422b8e083200ef2cd47b6d3563f6d2",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 91952,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "The Logic of Strategic Assets: From Oil to Artificial Intelligence"
    },
    "bd414a44f110c5bc6ecba9b47cec694f": {
      "source_id": "bd414a44f110c5bc6ecba9b47cec694f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34509,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Beyond Near- and Long-Term: Towards a Clearer Account of Research Priorities in "
    },
    "894271b0598a47c63a47d1833d6a38fa": {
      "source_id": "894271b0598a47c63a47d1833d6a38fa",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62198,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "The Incentives that Shape Behaviour"
    },
    "6311d79b1c153e4a7a4ff3fd932f3dea": {
      "source_id": "6311d79b1c153e4a7a4ff3fd932f3dea",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42822,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Silly rules improve the capacity of agents to learn stable enforcement and compl"
    },
    "79c7fe8d20495ec5f5860550c56b661b": {
      "source_id": "79c7fe8d20495ec5f5860550c56b661b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48766,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "The Conditional Entropy Bottleneck"
    },
    "fa2a0311913b34e3d5b91dcef29ca7ba": {
      "source_id": "fa2a0311913b34e3d5b91dcef29ca7ba",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48135,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "CEB Improves Model Robustness"
    },
    "646147045c9c2ce65458a1f1e812740f": {
      "source_id": "646147045c9c2ce65458a1f1e812740f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50557,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Safe Imitation Learning via Fast Bayesian Reward Inference from Preferences"
    },
    "a0da85a1768c4325dbfaa2fdbf1883b4": {
      "source_id": "a0da85a1768c4325dbfaa2fdbf1883b4",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44350,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Coherent Gradients: An Approach to Understanding Generalization in Gradient Desc"
    },
    "44220c5f671b2e284c3340a64342c7fd": {
      "source_id": "44220c5f671b2e284c3340a64342c7fd",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18019,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "TanksWorld: A Multi-Agent Environment for AI Safety Research"
    },
    "6e217576bd92ec66a88c9f70b6e543eb": {
      "source_id": "6e217576bd92ec66a88c9f70b6e543eb",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47588,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Generalized Hindsight for Reinforcement Learning"
    },
    "1cf3dc49f86f8b079cde5c3acc994861": {
      "source_id": "1cf3dc49f86f8b079cde5c3acc994861",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45426,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Pruned Neural Networks are Surprisingly Modular"
    },
    "2869e3c18f717d2825bcfcaf13294372": {
      "source_id": "2869e3c18f717d2825bcfcaf13294372",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 108095,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "An empirical investigation of the challenges of real-world reinforcement learnin"
    },
    "160879eef4774db728ed3a67ab6c61c0": {
      "source_id": "160879eef4774db728ed3a67ab6c61c0",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47102,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Agent57: Outperforming the Atari Human Benchmark"
    },
    "ca295111ff1ec76d23bde1461f348b31": {
      "source_id": "ca295111ff1ec76d23bde1461f348b31",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 91448,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Certifiable Robustness to Adversarial State Uncertainty in Deep Reinforcement Le"
    },
    "ce9119bdee8da16b4102a973aef0c122": {
      "source_id": "ce9119bdee8da16b4102a973aef0c122",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 164937,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims"
    },
    "424bac6c22c04486793dc18858eae5d0": {
      "source_id": "424bac6c22c04486793dc18858eae5d0",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36505,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "BERT-ATTACK: Adversarial Attack Against BERT Using BERT"
    },
    "a644f0a3cb02d2e283987fa8cfba14b9": {
      "source_id": "a644f0a3cb02d2e283987fa8cfba14b9",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 108293,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Pitfalls of learning a reward function online"
    },
    "98c0ce5ebb1c5dc957312a2c12f1fe5b": {
      "source_id": "98c0ce5ebb1c5dc957312a2c12f1fe5b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 337698,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Probl"
    },
    "6f3bebfdf31991d1bc7dfe03c9d80208": {
      "source_id": "6f3bebfdf31991d1bc7dfe03c9d80208",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62040,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Measuring the Algorithmic Efficiency of Neural Networks"
    },
    "cf093524c33472b7d2bad652d87a100a": {
      "source_id": "cf093524c33472b7d2bad652d87a100a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57771,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Language Conditioned Imitation Learning over Unstructured Data"
    },
    "81e89e9c2a18756580bd928426b5f834": {
      "source_id": "81e89e9c2a18756580bd928426b5f834",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 285897,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Rational Consensus"
    },
    "3ff44c4c933a57fcce7aea425c095a0d": {
      "source_id": "3ff44c4c933a57fcce7aea425c095a0d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 63930,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "What Makes for Good Views for Contrastive Learning?"
    },
    "af691406a00ffa9a57a67af95ece6355": {
      "source_id": "af691406a00ffa9a57a67af95ece6355",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56022,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "From ImageNet to Image Classification: Contextualizing Progress on Benchmarks"
    },
    "d57f07c9b5b2fcaaf48688e0ff97466b": {
      "source_id": "d57f07c9b5b2fcaaf48688e0ff97466b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 72965,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Curiosity Killed or Incapacitated the Cat and the Asymptotically Optimal Agent"
    },
    "581e6b835ead35ec8683f2d00738203f": {
      "source_id": "581e6b835ead35ec8683f2d00738203f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58713,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Reinforcement Learning Under Moral Uncertainty"
    },
    "bc1ffc64424f8b74fb6d9aed7120f82a": {
      "source_id": "bc1ffc64424f8b74fb6d9aed7120f82a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 398887,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "AI Research Considerations for Human Existential Safety (ARCHES)"
    },
    "a7adb7958fc7de7bc480d227f96ee174": {
      "source_id": "a7adb7958fc7de7bc480d227f96ee174",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 81319,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Pessimism About Unknown Unknowns Inspires Conservatism"
    },
    "c45a03222f9a2430fa33b561fa6d7b58": {
      "source_id": "c45a03222f9a2430fa33b561fa6d7b58",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21491,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Robust Learning with Frequency Domain Regularization"
    },
    "1b9933161043299517ce7853c55d4f35": {
      "source_id": "1b9933161043299517ce7853c55d4f35",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 81763,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Decolonial AI: Decolonial Theory as Sociotechnical Foresight in Artificial Intel"
    },
    "8d6bfe9fd2b3c4557965b7df7d48e12b": {
      "source_id": "8d6bfe9fd2b3c4557965b7df7d48e12b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31233,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Machine Learning Explainability for External Stakeholders"
    },
    "74d2bed93d6eaa90f103b55a9c68edec": {
      "source_id": "74d2bed93d6eaa90f103b55a9c68edec",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 71868,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Hidden Incentives for Auto-Induced Distributional Shift"
    },
    "9e6cbed97f1b3bc35f05d1c30d23f055": {
      "source_id": "9e6cbed97f1b3bc35f05d1c30d23f055",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58594,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Neurosymbolic Reinforcement Learning with Formally Verified Exploration"
    },
    "b4892a585fac1e8ce7515129da55504b": {
      "source_id": "b4892a585fac1e8ce7515129da55504b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40893,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Learning Rewards from Linguistic Feedback"
    },
    "5cb441d6c32c9e98786b25a7848624be": {
      "source_id": "5cb441d6c32c9e98786b25a7848624be",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62467,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Safe Reinforcement Learning with Natural Language Constraints"
    },
    "18f734504931d5cf478ace5a8ddaff69": {
      "source_id": "18f734504931d5cf478ace5a8ddaff69",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37494,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
    },
    "59be6f181258141623388beae3f3024f": {
      "source_id": "59be6f181258141623388beae3f3024f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38119,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Learning to be Safe: Deep RL with a Safety Critic"
    },
    "f699ce072a0d412e90ebd7a2ad07eeaf": {
      "source_id": "f699ce072a0d412e90ebd7a2ad07eeaf",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 68615,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Recovery RL: Safe Reinforcement Learning with Learned Recovery Zones"
    },
    "0da8cb466c437708553b34cd1c225ded": {
      "source_id": "0da8cb466c437708553b34cd1c225ded",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 511793,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "A Theory of Universal Learning"
    },
    "a76d89c0283d4a2edfcf38bf651500ac": {
      "source_id": "a76d89c0283d4a2edfcf38bf651500ac",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 220374,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Performance of Bounded-Rational Agents With the Ability to Self-Modify"
    },
    "9395c3d0914d369d4e9a4d55112904d5": {
      "source_id": "9395c3d0914d369d4e9a4d55112904d5",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24258,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Preventing Repeated Real World AI Failures by Cataloging Incidents: The AI Incid"
    },
    "0631100f62ec42fb8eeaaf52acf7081c": {
      "source_id": "0631100f62ec42fb8eeaaf52acf7081c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 78417,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "REALab: An Embedded Perspective on Tampering"
    },
    "a4d7c73ba1684f7f17c1d58a1d0edad4": {
      "source_id": "a4d7c73ba1684f7f17c1d58a1d0edad4",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51879,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Value Alignment Verification"
    },
    "84120dc4b15ae3897b67cea93e572e1c": {
      "source_id": "84120dc4b15ae3897b67cea93e572e1c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 80020,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "An overview of 11 proposals for building safe advanced AI"
    },
    "eaef206260f37f45a1e981ed388d5161": {
      "source_id": "eaef206260f37f45a1e981ed388d5161",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 85676,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Extracting Training Data from Large Language Models"
    },
    "26323c8f3a2e65098b8b69701e99db23": {
      "source_id": "26323c8f3a2e65098b8b69701e99db23",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55152,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Evaluating the Robustness of Collaborative Agents"
    },
    "3c7ec65d65c787492d9f80fc6540154c": {
      "source_id": "3c7ec65d65c787492d9f80fc6540154c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54126,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Shielding Atari Games with Bounded Prescience"
    },
    "218ce086ce67d5739ddde8794db7f87c": {
      "source_id": "218ce086ce67d5739ddde8794db7f87c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46553,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Accumulating Risk Capital Through Investing in Cooperation"
    },
    "cbd42f5f1fdb1a3bd6edaad51406e535": {
      "source_id": "cbd42f5f1fdb1a3bd6edaad51406e535",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 83949,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Agent Incentives: A Causal Perspective"
    },
    "dadd385d71c754d216ffda1325140d24": {
      "source_id": "dadd385d71c754d216ffda1325140d24",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19092,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Understanding the Capabilities, Limitations, and Societal Impact of Large Langua"
    },
    "62ef0e364eab59718630edc0016f83ee": {
      "source_id": "62ef0e364eab59718630edc0016f83ee",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 123389,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Consequences of Misaligned AI"
    },
    "c171694c2a004f27a32a583c0ed8db7b": {
      "source_id": "c171694c2a004f27a32a583c0ed8db7b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42678,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "AI Development for the Public Interest: From Abstraction Traps to Sociotechnical"
    },
    "b521f441eb2544a1c71ef1683ce417a1": {
      "source_id": "b521f441eb2544a1c71ef1683ce417a1",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42310,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Zero-Shot Text-to-Image Generation"
    },
    "2693c7142eae6286c2f17d17b5435a70": {
      "source_id": "2693c7142eae6286c2f17d17b5435a70",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62262,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Causal Analysis of Agent Behavior for AI Safety"
    },
    "7f8331f6c517ac35ef8f069317e4374a": {
      "source_id": "7f8331f6c517ac35ef8f069317e4374a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52594,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Pretrained Transformers as Universal Computation Engines"
    },
    "3f1c98bc443cac76d1c2dadc2d1dc290": {
      "source_id": "3f1c98bc443cac76d1c2dadc2d1dc290",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 415611,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "The AI Index 2021 Annual Report"
    },
    "da2deeeadbeab0866eb3a993f88f48db": {
      "source_id": "da2deeeadbeab0866eb3a993f88f48db",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 508225,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Replacing Rewards with Examples: Example-Based Policy Search via Recursive Class"
    },
    "53c3414e76f6b1bcc506da879e7d50e4": {
      "source_id": "53c3414e76f6b1bcc506da879e7d50e4",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59902,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Alignment of Language Agents"
    },
    "441024d88860cc5552cc12869e401a7c": {
      "source_id": "441024d88860cc5552cc12869e401a7c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42465,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Detection of Dataset Shifts in Learning-Enabled Cyber-Physical Systems using Var"
    },
    "31a5fe3f499ab05b2cf59866600148b2": {
      "source_id": "31a5fe3f499ab05b2cf59866600148b2",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62860,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Gradient-based Adversarial Attacks against Text Transformers"
    },
    "a57f6329c975e596dd8713ab7ff5f72f": {
      "source_id": "a57f6329c975e596dd8713ab7ff5f72f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 130929,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Ethics and Governance of Artificial Intelligence: Evidence from a Survey of Mach"
    },
    "0a11a1aed371713f1c6e9cd580feecaa": {
      "source_id": "0a11a1aed371713f1c6e9cd580feecaa",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48715,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Leveraging Sparse Linear Layers for Debuggable Deep Networks"
    },
    "50e653fce3d60282155679ae4629da1e": {
      "source_id": "50e653fce3d60282155679ae4629da1e",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45264,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Axes for Sociotechnical Inquiry in AI Research"
    },
    "aa2a65a3e15dd26da0af907a5ca3f7c8": {
      "source_id": "aa2a65a3e15dd26da0af907a5ca3f7c8",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37710,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Agree to Disagree: When Deep Learning Models With Identical Architectures Produc"
    },
    "cc4d70762dab69e18daf8c5ec854430b": {
      "source_id": "cc4d70762dab69e18daf8c5ec854430b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34765,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "AI and Shared Prosperity"
    },
    "b6f519be57b453ca6a68621ae7b0b805": {
      "source_id": "b6f519be57b453ca6a68621ae7b0b805",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37499,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Goal Misgeneralization in Deep Reinforcement Learning"
    },
    "05f9af1daa2926cf92fee0f088a6f5ca": {
      "source_id": "05f9af1daa2926cf92fee0f088a6f5ca",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 84326,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Provably Robust Detection of Out-of-distribution Data (almost) for free"
    },
    "4d86e7039be72db776dd12d767e5f1e3": {
      "source_id": "4d86e7039be72db776dd12d767e5f1e3",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 108976,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Engines of Power: Electricity, AI, and General-Purpose Military Transformations"
    },
    "022a0b73d5f487fae44178bcee6a8703": {
      "source_id": "022a0b73d5f487fae44178bcee6a8703",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57715,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "There Is No Turning Back: A Self-Supervised Approach for Reversibility-Aware Rei"
    },
    "ea0d3cf025dcd15408fd7876f15bc655": {
      "source_id": "ea0d3cf025dcd15408fd7876f15bc655",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58082,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "PEBBLE: Feedback-Efficient Interactive Reinforcement Learning via Relabeling Exp"
    },
    "ac7c2b65f2dc94f98f15b5809da2edbe": {
      "source_id": "ac7c2b65f2dc94f98f15b5809da2edbe",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49135,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Revisiting the Calibration of Modern Neural Networks"
    },
    "6473bf92d37686f5ee1b1c1b8d9fbfed": {
      "source_id": "6473bf92d37686f5ee1b1c1b8d9fbfed",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45739,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "How Well do Feature Visualizations Support Causal Understanding of CNN Activatio"
    },
    "6e0f2c882ed2ded9333f20cc47412966": {
      "source_id": "6e0f2c882ed2ded9333f20cc47412966",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51841,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "The MineRL BASALT Competition on Learning from Human Feedback"
    },
    "ca9b96625c777525c419959f2af82f3d": {
      "source_id": "ca9b96625c777525c419959f2af82f3d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26048,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "What are you optimizing for? Aligning Recommender Systems with Human Values"
    },
    "e413f8bb0dea4865235e8a2dc0f34bbf": {
      "source_id": "e413f8bb0dea4865235e8a2dc0f34bbf",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51481,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Standardized Max Logits: A Simple yet Effective Approach for Identifying Unexpec"
    },
    "62048503a42e769816742a6e31cf93e5": {
      "source_id": "62048503a42e769816742a6e31cf93e5",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 261613,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Open-Ended Learning Leads to Generally Capable Agents"
    },
    "4c1601e7b988fad5844599c6678524ce": {
      "source_id": "4c1601e7b988fad5844599c6678524ce",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34669,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Soft Calibration Objectives for Neural Networks"
    },
    "f9ade5d3a5d6007790c5f35affa0d28f": {
      "source_id": "f9ade5d3a5d6007790c5f35affa0d28f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50209,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Triggering Failures: Out-Of-Distribution detection by learning from local advers"
    },
    "0b1f4debe314fa2ea7476d73425a6120": {
      "source_id": "0b1f4debe314fa2ea7476d73425a6120",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 89486,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Asleep at the Keyboard? Assessing the Security of GitHub Copilot's Code Contribu"
    },
    "80458dc82661aceb9b67ed0e0c31ca1c": {
      "source_id": "80458dc82661aceb9b67ed0e0c31ca1c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 65265,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Robust fine-tuning of zero-shot models"
    },
    "40199422e213e4674f2b87653ce8663e": {
      "source_id": "40199422e213e4674f2b87653ce8663e",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41348,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Augmenting Decision Making via Interactive What-If Analysis"
    },
    "43da39bb4352078c85659806a2a487fc": {
      "source_id": "43da39bb4352078c85659806a2a487fc",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51956,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Challenges in Detoxifying Language Models"
    },
    "70b81709b37af2f60fb175073d836d0e": {
      "source_id": "70b81709b37af2f60fb175073d836d0e",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58821,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Recursively Summarizing Books with Human Feedback"
    },
    "380bb59b80887c6e766c66477d82370f": {
      "source_id": "380bb59b80887c6e766c66477d82370f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 94851,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Cartesian Frames"
    },
    "c328090bc430541575f05eb6ea8418f8": {
      "source_id": "c328090bc430541575f05eb6ea8418f8",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37282,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "RAFT: A Real-World Few-Shot Text Classification Benchmark"
    },
    "03b945a38102e0816f37dd67b7e975a4": {
      "source_id": "03b945a38102e0816f37dd67b7e975a4",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 102256,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Can Machines Learn Morality? The Delphi Experiment"
    },
    "27c6059e550e8ff65617559023400b1c": {
      "source_id": "27c6059e550e8ff65617559023400b1c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37993,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Certified Patch Robustness via Smoothed Vision Transformers"
    },
    "8fad072693ba66f91ea02e912436c655": {
      "source_id": "8fad072693ba66f91ea02e912436c655",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45366,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Quantifying Local Specialization in Deep Neural Networks"
    },
    "e66bebdb252a6220eda22876d977a84c": {
      "source_id": "e66bebdb252a6220eda22876d977a84c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38468,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Analyzing Dynamic Adversarial Training Data in the Limit"
    },
    "15eb203180cab2f1b3c05f723a37f90c": {
      "source_id": "15eb203180cab2f1b3c05f723a37f90c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40772,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "MEMO: Test Time Robustness via Adaptation and Augmentation"
    },
    "df96fcd4101b5279b55d051013e57a44": {
      "source_id": "df96fcd4101b5279b55d051013e57a44",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42306,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "What Would Jiminy Cricket Do? Towards Agents That Behave Morally"
    },
    "6e27957f99ea08be41b331e52e28515b": {
      "source_id": "6e27957f99ea08be41b331e52e28515b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40995,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Toward a Theory of Justice for Artificial Intelligence"
    },
    "32193b4c5013c697aaa495098f6121cf": {
      "source_id": "32193b4c5013c697aaa495098f6121cf",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48703,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "AI Ethics Statements -- Analysis and lessons learnt from NeurIPS Broader Impact "
    },
    "5249c85b08bb42cad7baa16536c30594": {
      "source_id": "5249c85b08bb42cad7baa16536c30594",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52941,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Adversarial GLUE: A Multi-Task Benchmark for Robustness Evaluation of Language M"
    },
    "43f3d019e5a786f9e13ad48165961649": {
      "source_id": "43f3d019e5a786f9e13ad48165961649",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 84930,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "B-Pref: Benchmarking Preference-Based Reinforcement Learning"
    },
    "88857fbe01e7fa536b3546526a91b7a7": {
      "source_id": "88857fbe01e7fa536b3546526a91b7a7",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23551,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Linguistic Cues of Deception in a Multilingual April Fools' Day Context"
    },
    "b990438c3d2f4172f63ed3fb376fc7ac": {
      "source_id": "b990438c3d2f4172f63ed3fb376fc7ac",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41286,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Data Augmentation Can Improve Robustness"
    },
    "b344183bfa91e6390d52521000889e57": {
      "source_id": "b344183bfa91e6390d52521000889e57",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57286,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Solving Probability and Statistics Problems by Program Synthesis"
    },
    "20e257a61198f4b85412e3111d39b638": {
      "source_id": "20e257a61198f4b85412e3111d39b638",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58098,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Discrete Representations Strengthen Vision Transformer Robustness"
    },
    "f3ed9ac8b53110c3f6800e3db67e8dfb": {
      "source_id": "f3ed9ac8b53110c3f6800e3db67e8dfb",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45010,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "ReAct: Out-of-distribution Detection With Rectified Activations"
    },
    "02cb990df1910ff181c0ac70d969f3c2": {
      "source_id": "02cb990df1910ff181c0ac70d969f3c2",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24929,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Normative Disagreement as a Challenge for Cooperative AI"
    },
    "122063637b044550e340b44b05203408": {
      "source_id": "122063637b044550e340b44b05203408",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42186,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Pyramid Adversarial Training Improves ViT Performance"
    },
    "c07dc0e7916bb37d8a25132e2685d02c": {
      "source_id": "c07dc0e7916bb37d8a25132e2685d02c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 79615,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Certified Adversarial Defenses Meet Out-of-Distribution Corruptions: Benchmarkin"
    },
    "26f49ad8f2b64b02085bf9211104583b": {
      "source_id": "26f49ad8f2b64b02085bf9211104583b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 112693,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "A General Language Assistant as a Laboratory for Alignment"
    },
    "481bd6001ca2446636547dd0484ada51": {
      "source_id": "481bd6001ca2446636547dd0484ada51",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35784,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "PixMix: Dreamlike Pictures Comprehensively Improve Safety Measures"
    },
    "b743fa8ab99bc9f240cc52c50dbed97c": {
      "source_id": "b743fa8ab99bc9f240cc52c50dbed97c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26901,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Execute Order 66: Targeted Data Poisoning for Reinforcement Learning"
    },
    "386e990bbee71f34f9331846cdc36a84": {
      "source_id": "386e990bbee71f34f9331846cdc36a84",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29767,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Robust Self-Supervised Audio-Visual Speech Recognition"
    },
    "c8c6e6b65ff731ba4dcc96325494815c": {
      "source_id": "c8c6e6b65ff731ba4dcc96325494815c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40582,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "The Effects of Reward Misspecification: Mapping and Mitigating Misaligned Models"
    },
    "a8b94f643fb93c8095347c9e7f7472a2": {
      "source_id": "a8b94f643fb93c8095347c9e7f7472a2",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40598,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Safe Deep RL in 3D Environments using Human Feedback"
    },
    "fef5f9443f14647102b30ed036ee471b": {
      "source_id": "fef5f9443f14647102b30ed036ee471b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40580,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Identifying Adversarial Attacks on Text Classifiers"
    },
    "9ee7e2ee3bd5913087d23cabcc3082c6": {
      "source_id": "9ee7e2ee3bd5913087d23cabcc3082c6",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73800,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Towards Safe Reinforcement Learning with a Safety Editor Policy"
    },
    "2f21646ae78f5f10ed77fcaad20e4eaa": {
      "source_id": "2f21646ae78f5f10ed77fcaad20e4eaa",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73653,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Certifying Model Accuracy under Distribution Shifts"
    },
    "d3e76392f9627e93fe968970ca175315": {
      "source_id": "d3e76392f9627e93fe968970ca175315",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 65000,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "VOS: Learning What You Don't Know by Virtual Outlier Synthesis"
    },
    "0dfde4014fcd105b01e35bc80e2c8f67": {
      "source_id": "0dfde4014fcd105b01e35bc80e2c8f67",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 84668,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Certifying Out-of-Domain Generalization for Blackbox Functions"
    },
    "964be84536460180a9ffd3513b89f304": {
      "source_id": "964be84536460180a9ffd3513b89f304",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48956,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "The Met Dataset: Instance-level Recognition for Artworks"
    },
    "5b9b42f6b9b6a09222b6882b91115c5c": {
      "source_id": "5b9b42f6b9b6a09222b6882b91115c5c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 79038,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Red Teaming Language Models with Language Models"
    },
    "15a7dd0611e9002e7e9a0142d2faf3b1": {
      "source_id": "15a7dd0611e9002e7e9a0142d2faf3b1",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42430,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Locating and Editing Factual Associations in GPT"
    },
    "d41c93555f5da094cf7fef12df27bd38": {
      "source_id": "d41c93555f5da094cf7fef12df27bd38",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55540,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Predicting Out-of-Distribution Error with the Projection Norm"
    },
    "a26655f80e9f293214e71c18243aa6ec": {
      "source_id": "a26655f80e9f293214e71c18243aa6ec",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 67049,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Predictability and Surprise in Large Generative Models"
    },
    "3a9a29b53f0b3b7e81e94cb652ebe4af": {
      "source_id": "3a9a29b53f0b3b7e81e94cb652ebe4af",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 63879,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Safe Reinforcement Learning by Imagining the Near Future"
    },
    "81a46f2c0a82c9ffc3fa5982e4dec3d3": {
      "source_id": "81a46f2c0a82c9ffc3fa5982e4dec3d3",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53869,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Deconstructing Distributions: A Pointwise Framework of Learning"
    },
    "42e2a4ce0af6455ab611ff9d90231490": {
      "source_id": "42e2a4ce0af6455ab611ff9d90231490",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40231,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    "71844bc4a557c4d12fffc882003fc23a": {
      "source_id": "71844bc4a557c4d12fffc882003fc23a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52713,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "3D Common Corruptions and Data Augmentation"
    },
    "16b35f91b280207d8c17bd0b5e0493d3": {
      "source_id": "16b35f91b280207d8c17bd0b5e0493d3",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54417,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "The Singularity Controversy, Part I: Lessons Learned and Open Questions: Conclus"
    },
    "ba7514433f5f71f0e5ead90b6fd6524a": {
      "source_id": "ba7514433f5f71f0e5ead90b6fd6524a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37002,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Research Priorities for Robust and Beneficial Artificial Intelligence"
    },
    "058f69adbea22c2d895c56cf69f3df24": {
      "source_id": "058f69adbea22c2d895c56cf69f3df24",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23843,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Designing Intelligent Instruments"
    },
    "2fd7f04f95ad51715e96693da14e7dce": {
      "source_id": "2fd7f04f95ad51715e96693da14e7dce",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19897,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "The Singularity May Never Be Near"
    },
    "176a4ddb834e0c5f8c4922c7f6406ba2": {
      "source_id": "176a4ddb834e0c5f8c4922c7f6406ba2",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42004,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Latent Skill Embedding for Personalized Lesson Sequence Recommendation"
    },
    "ca4584e9771465a220203544ca9bf1e4": {
      "source_id": "ca4584e9771465a220203544ca9bf1e4",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20877,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Moving Beyond the Turing Test with the Allen AI Science Challenge"
    },
    "e57df4802928e8e2e7509e33bfaca007": {
      "source_id": "e57df4802928e8e2e7509e33bfaca007",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 67501,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "An artificial intelligence tool for heterogeneous team formation in the classroo"
    },
    "9330b17f4620fb2e19e5cd076527a7ce": {
      "source_id": "9330b17f4620fb2e19e5cd076527a7ce",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48649,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Towards A Virtual Assistant That Can Be Taught New Tasks In Any Domain By Its En"
    },
    "2fd3950d429dc65a41d3ae55ce75c11e": {
      "source_id": "2fd3950d429dc65a41d3ae55ce75c11e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 74225,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "A Hybrid POMDP-BDI Agent Architecture with Online Stochastic Planning and Plan C"
    },
    "2b4f7f998245e2411e5495426874fc24": {
      "source_id": "2b4f7f998245e2411e5495426874fc24",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42755,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Predicting Enemy's Actions Improves Commander Decision-Making"
    },
    "533541b26e68390c36521119379d06e3": {
      "source_id": "533541b26e68390c36521119379d06e3",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 348308,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Graph Aggregation"
    },
    "a18e21777c6faa10beb3e9c24f616c14": {
      "source_id": "a18e21777c6faa10beb3e9c24f616c14",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32112,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Long-Term Trends in the Public Perception of Artificial Intelligence"
    },
    "4c0cd90e3924e3412e7825dbcc6258e0": {
      "source_id": "4c0cd90e3924e3412e7825dbcc6258e0",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40641,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "A stochastically verifiable autonomous control architecture with reasoning"
    },
    "e62b5fe6bcdefb18020c648704d5ecc0": {
      "source_id": "e62b5fe6bcdefb18020c648704d5ecc0",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43353,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Improving Policy Gradient by Exploring Under-appreciated Rewards"
    },
    "db7e00145997644b20053d2a0432071a": {
      "source_id": "db7e00145997644b20053d2a0432071a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28323,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Neuro-symbolic EDA-based Optimisation using ILP-enhanced DBNs"
    },
    "aef861ddf773883385b2b328babc4173": {
      "source_id": "aef861ddf773883385b2b328babc4173",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 162552,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "A Base Camp for Scaling AI"
    },
    "402f917ef1f85b47c506866bb78d84f9": {
      "source_id": "402f917ef1f85b47c506866bb78d84f9",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31548,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Designing a Safe Autonomous Artificial Intelligence Agent based on Human Self-Re"
    },
    "db731640470abad78ef709a530ad95dc": {
      "source_id": "db731640470abad78ef709a530ad95dc",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 122769,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Practical Reasoning with Norms for Autonomous Software Agents (Full Edition)"
    },
    "d0d350b2ac6e04b80d5870a09dc10d04": {
      "source_id": "d0d350b2ac6e04b80d5870a09dc10d04",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41623,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Plan Explanations as Model Reconciliation: Moving Beyond Explanation as Soliloqu"
    },
    "26e147e49fc695c92311bc2395a9e663": {
      "source_id": "26e147e49fc695c92311bc2395a9e663",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47902,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Synergistic Team Composition"
    },
    "beb12a23a42976450182359dcde0702e": {
      "source_id": "beb12a23a42976450182359dcde0702e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21800,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Don't Fear the Reaper: Refuting Bostrom's Superintelligence Argument"
    },
    "0e186b0d516bdeb5605722bc5e6c6948": {
      "source_id": "0e186b0d516bdeb5605722bc5e6c6948",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39643,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Strategically knowing how"
    },
    "e434ded2d51769f0242d251fba5544f0": {
      "source_id": "e434ded2d51769f0242d251fba5544f0",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19897,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "The Singularity May Be Near"
    },
    "90075e5d06ca1445c532c2e9d7e2b9a2": {
      "source_id": "90075e5d06ca1445c532c2e9d7e2b9a2",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34580,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Responsible Autonomy"
    },
    "3f2a112d14cc408019266ba6954d54f1": {
      "source_id": "3f2a112d14cc408019266ba6954d54f1",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26746,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "RAIL: Risk-Averse Imitation Learning"
    },
    "b995fa8df519db15caae77bb73062d03": {
      "source_id": "b995fa8df519db15caae77bb73062d03",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27791,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Using Program Induction to Interpret Transition System Dynamics"
    },
    "7cdb1233cf82deb93064bb2177ffb77a": {
      "source_id": "7cdb1233cf82deb93064bb2177ffb77a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 133094,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Safe Reinforcement Learning via Shielding"
    },
    "01e708118256c8679df0d69f97d1af1c": {
      "source_id": "01e708118256c8679df0d69f97d1af1c",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 127046,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Knowledge Transfer Between Artificial Intelligence Systems"
    },
    "05f3a92ca4a98b9f2206b81662131b4a": {
      "source_id": "05f3a92ca4a98b9f2206b81662131b4a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 148873,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Autonomous Agents Modelling Other Agents: A Comprehensive Survey and Open Proble"
    },
    "08b82a9d28b9a5af07a4dc3f8032b3a5": {
      "source_id": "08b82a9d28b9a5af07a4dc3f8032b3a5",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9752,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Using KL-divergence to focus Deep Visual Explanation"
    },
    "a8804756ba4b9e2cd91deecd611d5501": {
      "source_id": "a8804756ba4b9e2cd91deecd611d5501",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39630,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Deterministic Policy Optimization by Combining Pathwise and Score Function Estim"
    },
    "b05147510dbab92f01b5919f178ba32a": {
      "source_id": "b05147510dbab92f01b5919f178ba32a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58690,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "A Berkeley View of Systems Challenges for AI"
    },
    "37ebf1f6d3262bef36a49ba6b9c7eb6e": {
      "source_id": "37ebf1f6d3262bef36a49ba6b9c7eb6e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31997,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Antifragility for Intelligent Autonomous Systems"
    },
    "36c9d30e5926d5154a0f11d59964839b": {
      "source_id": "36c9d30e5926d5154a0f11d59964839b",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31846,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Value Alignment, Fair Play, and the Rights of Service Robots"
    },
    "9c87c9876c628a0d073b186134baa08d": {
      "source_id": "9c87c9876c628a0d073b186134baa08d",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 76988,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Institutional Metaphors for Designing Large-Scale Distributed AI versus AI Techn"
    },
    "a69b3787f140388f5d62a304306d529c": {
      "source_id": "a69b3787f140388f5d62a304306d529c",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46281,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "The Challenge of Crafting Intelligible Intelligence"
    },
    "1d2c96ed448dacfcc360262e81f03e3a": {
      "source_id": "1d2c96ed448dacfcc360262e81f03e3a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46874,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Artificial Intelligence and its Role in Near Future"
    },
    "a2adaf3e37e06221a98ef9f488cf1743": {
      "source_id": "a2adaf3e37e06221a98ef9f488cf1743",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15714,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "First Experiments with a Flexible Infrastructure for Normative Reasoning"
    },
    "fe539961451698cb4301a12d094dbed2": {
      "source_id": "fe539961451698cb4301a12d094dbed2",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 95369,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "A Logic of Agent Organizations"
    },
    "4776a7ac86b1c7dd7556b25555cf8e0c": {
      "source_id": "4776a7ac86b1c7dd7556b25555cf8e0c",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 66878,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Automated Mechanism Design via Neural Networks"
    },
    "0a373355a323506a9a62cd9091b75c3d": {
      "source_id": "0a373355a323506a9a62cd9091b75c3d",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18966,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Understanding the Meaning of Understanding"
    },
    "e5d9799933b8dfd5a7562ada5ca1a875": {
      "source_id": "e5d9799933b8dfd5a7562ada5ca1a875",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33058,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Interpretable to Whom? A Role-based Model for Analyzing Interpretable Machine Le"
    },
    "fa6d0106af1c5665a81188e680c061a5": {
      "source_id": "fa6d0106af1c5665a81188e680c061a5",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25810,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "The Foundations of Deep Learning with a Path Towards General Intelligence"
    },
    "b4ac7edad0c3c69182b211405f0b6188": {
      "source_id": "b4ac7edad0c3c69182b211405f0b6188",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40016,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Knowledge Integration for Disease Characterization: A Breast Cancer Example"
    },
    "9bba061071a331e95bcf1bb58fab4549": {
      "source_id": "9bba061071a331e95bcf1bb58fab4549",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30181,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Adding Neural Network Controllers to Behavior Trees without Destroying Performan"
    },
    "cabb1d4226057aa67da05e9a27e87cce": {
      "source_id": "cabb1d4226057aa67da05e9a27e87cce",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 81145,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Optimizing Agent Behavior over Long Time Scales by Transporting Value"
    },
    "19553eb276e20e1bea36b0eff216cfe6": {
      "source_id": "19553eb276e20e1bea36b0eff216cfe6",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26643,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Mimetic vs Anchored Value Alignment in Artificial Intelligence"
    },
    "55b08e232187491f1a93b7e5cfa79b20": {
      "source_id": "55b08e232187491f1a93b7e5cfa79b20",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 103720,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "The Responsibility Quantification (ResQu) Model of Human Interaction with Automa"
    },
    "4af897b4f7e8de9e446732f52ed7c827": {
      "source_id": "4af897b4f7e8de9e446732f52ed7c827",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33128,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Economics of Human-AI Ecosystem: Value Bias and Lost Utility in Multi-Dimensiona"
    },
    "16e9dd5f9342483a8f7944aea1bea73a": {
      "source_id": "16e9dd5f9342483a8f7944aea1bea73a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39923,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Deep Learning Application in Security and Privacy -- Theory and Practice: A Posi"
    },
    "8c44535e5835b120beecc8031ef06b63": {
      "source_id": "8c44535e5835b120beecc8031ef06b63",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19779,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Linking Artificial Intelligence Principles"
    },
    "f9f91ab90cec59be762198e92e3c7aca": {
      "source_id": "f9f91ab90cec59be762198e92e3c7aca",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40065,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "IRLAS: Inverse Reinforcement Learning for Architecture Search"
    },
    "b4656685cd55f878c25512c54fce5843": {
      "source_id": "b4656685cd55f878c25512c54fce5843",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51265,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Making AI meaningful again"
    },
    "61517cf54fe17bd587b28e6d2c6bd513": {
      "source_id": "61517cf54fe17bd587b28e6d2c6bd513",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21874,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "A New Tensioning Method using Deep Reinforcement Learning for Surgical Pattern C"
    },
    "1ae584b18d1d3cb27b8f7da4f90e6af2": {
      "source_id": "1ae584b18d1d3cb27b8f7da4f90e6af2",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43443,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "PUTWorkbench: Analysing Privacy in AI-intensive Systems"
    },
    "f568f9a05f383d1d188dbed83de33efb": {
      "source_id": "f568f9a05f383d1d188dbed83de33efb",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46732,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Ask Not What AI Can Do, But What AI Should Do: Towards a Framework of Task Deleg"
    },
    "8dfe174756251e0dc34b08231bdd7920": {
      "source_id": "8dfe174756251e0dc34b08231bdd7920",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17486,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Hacking Google reCAPTCHA v3 using Reinforcement Learning"
    },
    "266a1fefecfd5b204686ddce2ff10447": {
      "source_id": "266a1fefecfd5b204686ddce2ff10447",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52765,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Challenges for an Ontology of Artificial Intelligence"
    },
    "6d9c643dc346070e111e011b89b0227d": {
      "source_id": "6d9c643dc346070e111e011b89b0227d",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 82787,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "The Ethics of AI Ethics -- An Evaluation of Guidelines"
    },
    "4e6e866ec66e13ee6a0eb816ebf7bff4": {
      "source_id": "4e6e866ec66e13ee6a0eb816ebf7bff4",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31835,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Improving Safety in Reinforcement Learning Using Model-Based Architectures and H"
    },
    "2c321a00435b902b01d250e9d3350687": {
      "source_id": "2c321a00435b902b01d250e9d3350687",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 153036,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Designing Normative Theories for Ethical and Legal Reasoning: LogiKEy Framework,"
    },
    "7260b5451ca708a208e5c3b0819d2a8f": {
      "source_id": "7260b5451ca708a208e5c3b0819d2a8f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 105536,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Informed Machine Learning -- A Taxonomy and Survey of Integrating Knowledge into"
    },
    "486e51b6eca9e0218cb92722a407efc5": {
      "source_id": "486e51b6eca9e0218cb92722a407efc5",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30944,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Extending planning knowledge using ontologies for goal opportunities"
    },
    "ec9006a24eeee38c1528c90760ba4e47": {
      "source_id": "ec9006a24eeee38c1528c90760ba4e47",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38955,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Counterfactual Visual Explanations"
    },
    "45fa4bad8ce1fd796f7b3835c1b8711d": {
      "source_id": "45fa4bad8ce1fd796f7b3835c1b8711d",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 130897,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Risk Structures: Towards Engineering Risk-aware Autonomous Systems"
    },
    "cbf09e13232824de9b9b3fbeaae7fdb6": {
      "source_id": "cbf09e13232824de9b9b3fbeaae7fdb6",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 65321,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Knowing When to Stop: Evaluation and Verification of Conformity to Output-size S"
    },
    "f3f72edbee43cb389d03527008deceac": {
      "source_id": "f3f72edbee43cb389d03527008deceac",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35483,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "The relationship between Biological and Artificial Intelligence"
    },
    "f2b465bed533cd9fbfab2e631f50f26f": {
      "source_id": "f2b465bed533cd9fbfab2e631f50f26f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 258638,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Lie on the Fly: Strategic Voting in an Iterative Preference Elicitation Process"
    },
    "1d8c98b2b9f9dbab05957e92aa8c598f": {
      "source_id": "1d8c98b2b9f9dbab05957e92aa8c598f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 88145,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "From What to How: An Initial Review of Publicly Available AI Ethics Tools, Metho"
    },
    "a9df46959c30e10d9aba7e5e093629b6": {
      "source_id": "a9df46959c30e10d9aba7e5e093629b6",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37992,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "On modelling the emergence of logical thinking"
    },
    "9b07c785b4cee566bb90f482705f0831": {
      "source_id": "9b07c785b4cee566bb90f482705f0831",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15381,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Better Future through AI: Avoiding Pitfalls and Guiding AI Towards its Full Pote"
    },
    "f39e06c0ba93613877b99ea3f9030997": {
      "source_id": "f39e06c0ba93613877b99ea3f9030997",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 104783,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Learner-aware Teaching: Inverse Reinforcement Learning with Preferences and Cons"
    },
    "18def41ad9ebddf14f29e506e7df9d1b": {
      "source_id": "18def41ad9ebddf14f29e506e7df9d1b",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25544,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "An AGI with Time-Inconsistent Preferences"
    },
    "acb8ec6d2eca4a070ddd9844ffd23626": {
      "source_id": "acb8ec6d2eca4a070ddd9844ffd23626",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 75507,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Integration of Imitation Learning using GAIL and Reinforcement Learning using Ta"
    },
    "5de2b48b2c1f89fb21bb09c8b0d58030": {
      "source_id": "5de2b48b2c1f89fb21bb09c8b0d58030",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 93737,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Artificial Intelligence Governance and Ethics: Global Perspectives"
    },
    "3f342b07edb81627f49fa61b3db643a4": {
      "source_id": "3f342b07edb81627f49fa61b3db643a4",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47225,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Grounding Value Alignment with Ethical Principles"
    },
    "8c5a3cc4714aba1a63218bf0c79cc805": {
      "source_id": "8c5a3cc4714aba1a63218bf0c79cc805",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38641,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "A system of different layers of abstraction for artificial intelligence"
    },
    "bcfb223ceb5af178f44cf065cdee9397": {
      "source_id": "bcfb223ceb5af178f44cf065cdee9397",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 103575,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Towards a Theory of Intentions for Human-Robot Collaboration"
    },
    "a7ee381d857e98a8e9c68be066943f70": {
      "source_id": "a7ee381d857e98a8e9c68be066943f70",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 68765,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Neural Simplex Architecture"
    },
    "423dcda046865535a079901768f2ebba": {
      "source_id": "423dcda046865535a079901768f2ebba",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12775,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Better AI through Logical Scaffolding"
    },
    "eb20cd0d24a7d6850d36c21a96aab7ee": {
      "source_id": "eb20cd0d24a7d6850d36c21a96aab7ee",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37663,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Emergent Tool Use From Multi-Agent Autocurricula"
    },
    "1dc156388ea7c94a7c61a1352ee40af4": {
      "source_id": "1dc156388ea7c94a7c61a1352ee40af4",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27996,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "From the Internet of Information to the Internet of Intelligence"
    },
    "4a42a1e94a9df88b4eae9a33bc1df6e3": {
      "source_id": "4a42a1e94a9df88b4eae9a33bc1df6e3",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48953,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Towards Deployment of Robust AI Agents for Human-Machine Partnerships"
    },
    "ad8f9548298ee5468a1ba59b120ac242": {
      "source_id": "ad8f9548298ee5468a1ba59b120ac242",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36851,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Can We Distinguish Machine Learning from Human Learning?"
    },
    "18135125de8f50d6919b5fe9d7a86e5b": {
      "source_id": "18135125de8f50d6919b5fe9d7a86e5b",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 68064,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Improving Generalization in Meta Reinforcement Learning using Learned Objectives"
    },
    "3507b1dfd2ca4512a7cc8812569ce409": {
      "source_id": "3507b1dfd2ca4512a7cc8812569ce409",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57818,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Asking Easy Questions: A User-Friendly Approach to Active Reward Learning"
    },
    "0ea949bb15660a63ac8a9da71860db9a": {
      "source_id": "0ea949bb15660a63ac8a9da71860db9a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17470,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "The Quest for Interpretable and Responsible Artificial Intelligence"
    },
    "a5e4ac92c362434f205fc758473236b6": {
      "source_id": "a5e4ac92c362434f205fc758473236b6",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34612,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Using AI/ML to gain situational understanding from passive network observations"
    },
    "1e39f0a284624af12b314836b846b149": {
      "source_id": "1e39f0a284624af12b314836b846b149",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36769,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "How can AI Automate End-to-End Data Science?"
    },
    "0e7d9ea18dd95c60fb274334a5aaf66e": {
      "source_id": "0e7d9ea18dd95c60fb274334a5aaf66e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51148,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Generating Justifications for Norm-Related Agent Decisions"
    },
    "b7e2676767766152882c5bda31a9d97d": {
      "source_id": "b7e2676767766152882c5bda31a9d97d",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 65761,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "The relationship between trust in AI and trustworthy machine learning technologi"
    },
    "8ac12fda3d81382980f33ad55338ce49": {
      "source_id": "8ac12fda3d81382980f33ad55338ce49",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41784,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Adaptive Online Planning for Continual Lifelong Learning"
    },
    "dcd0a0556ebfc56ad048df9140c995f3": {
      "source_id": "dcd0a0556ebfc56ad048df9140c995f3",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16177,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Interactive AI with a Theory of Mind"
    },
    "285e08b9eeca3f268751d175ee7145dd": {
      "source_id": "285e08b9eeca3f268751d175ee7145dd",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 71234,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Anti-Alignments -- Measuring The Precision of Process Models and Event Logs"
    },
    "f1558dd5b768a5226ec3044cc2f4aced": {
      "source_id": "f1558dd5b768a5226ec3044cc2f4aced",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28385,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Why we need an AI-resilient society"
    },
    "8284c45318e073dcda8af159093bc838": {
      "source_id": "8284c45318e073dcda8af159093bc838",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 84783,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Questions to Guide the Future of Artificial Intelligence Research"
    },
    "6963078acea43dbac5071b09cf57cb9e": {
      "source_id": "6963078acea43dbac5071b09cf57cb9e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54603,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Defining AI in Policy versus Practice"
    },
    "b9a647ad554c990a5507d0f57de0a513": {
      "source_id": "b9a647ad554c990a5507d0f57de0a513",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54735,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Uncertainty-Based Out-of-Distribution Classification in Deep Reinforcement Learn"
    },
    "77b8610cfe330f24d522d19456f7635c": {
      "source_id": "77b8610cfe330f24d522d19456f7635c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59790,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Auditing and Debugging Deep Learning Models via Decision Boundaries: Individual-"
    },
    "01150a46b8a08cef7aeb36334350ab03": {
      "source_id": "01150a46b8a08cef7aeb36334350ab03",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34172,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "A Framework for Democratizing AI"
    },
    "fae9b2be0f99a17996eebfb8f3ee4f83": {
      "source_id": "fae9b2be0f99a17996eebfb8f3ee4f83",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43587,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Activism by the AI Community: Analysing Recent Achievements and Future Prospects"
    },
    "e6d0c3b2488775e39e5424c24377dcdc": {
      "source_id": "e6d0c3b2488775e39e5424c24377dcdc",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24282,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Teaching Software Engineering for AI-Enabled Systems"
    },
    "d2386b5bab1151ae84700ec595a55c69": {
      "source_id": "d2386b5bab1151ae84700ec595a55c69",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 103281,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Explaining Data-Driven Decisions made by AI Systems: The Counterfactual Approach"
    },
    "46a3f714374e488dc70bde99ee3474cd": {
      "source_id": "46a3f714374e488dc70bde99ee3474cd",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41588,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Engineering AI Systems: A Research Agenda"
    },
    "f528c0b9ea26bd08239a7a6ad382134d": {
      "source_id": "f528c0b9ea26bd08239a7a6ad382134d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 98119,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Optimal by Design: Model-Driven Synthesis of Adaptation Strategies for Autonomou"
    },
    "361d1c2119b692fdf854e1f56baf2195": {
      "source_id": "361d1c2119b692fdf854e1f56baf2195",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52021,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Bridging the Gap: Providing Post-Hoc Symbolic Explanations for Sequential Decisi"
    },
    "94c39b5469e869810a0ce1df4725c8af": {
      "source_id": "94c39b5469e869810a0ce1df4725c8af",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49351,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Leveraging Rationales to Improve Human Task Performance"
    },
    "8c6ea1b019a85b11405ab027033bdd55": {
      "source_id": "8c6ea1b019a85b11405ab027033bdd55",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 132277,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Analyzing Differentiable Fuzzy Logic Operators"
    },
    "0ae9c9a9e757ef788b4ebcc81d147aa2": {
      "source_id": "0ae9c9a9e757ef788b4ebcc81d147aa2",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57267,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "A Road Map to Strong Intelligence"
    },
    "e7bcd86ebcadbd8e0fcd441d97f76c08": {
      "source_id": "e7bcd86ebcadbd8e0fcd441d97f76c08",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 66358,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "The Pragmatic Turn in Explainable Artificial Intelligence (XAI)"
    },
    "38dcb38fbe42141ddf07534d1117cdeb": {
      "source_id": "38dcb38fbe42141ddf07534d1117cdeb",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 109327,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Cautious Reinforcement Learning with Logical Constraints"
    },
    "3dfc5c5b2dbf412a1a8a81d3e421c5de": {
      "source_id": "3dfc5c5b2dbf412a1a8a81d3e421c5de",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35654,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "On Safety Assessment of Artificial Intelligence"
    },
    "50e1a7109df31a843ae823ed54ed2610": {
      "source_id": "50e1a7109df31a843ae823ed54ed2610",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46368,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Marketplace for AI Models"
    },
    "393de4ce26114b76507f296a0fc15512": {
      "source_id": "393de4ce26114b76507f296a0fc15512",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34134,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Two Decades of AI4NETS-AI/ML for Data Networks: Challenges & Research Directions"
    },
    "bb50754d1bf1a3e3ecfa531ccd2c25a2": {
      "source_id": "bb50754d1bf1a3e3ecfa531ccd2c25a2",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 87118,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Dividing the Ontology Alignment Task with Semantic Embeddings and Logic-based Mo"
    },
    "56272308af8ac1b88486e07f97cd1225": {
      "source_id": "56272308af8ac1b88486e07f97cd1225",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36171,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "The Conflict Between People's Urge to Punish AI and Legal Systems"
    },
    "d706ac5200178150cf7afc4796a43776": {
      "source_id": "d706ac5200178150cf7afc4796a43776",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 82418,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Three Modern Roles for Logic in AI"
    },
    "53872389fe614b7b66434c6da39b8378": {
      "source_id": "53872389fe614b7b66434c6da39b8378",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11370,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Responsible AI and Its Stakeholders"
    },
    "3aad3548ca62dc4d17e328f709c06032": {
      "source_id": "3aad3548ca62dc4d17e328f709c06032",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48638,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Is the Most Accurate AI the Best Teammate? Optimizing AI for Teamwork"
    },
    "294dc6a8d1cbb403dd6266dabb93b0ca": {
      "source_id": "294dc6a8d1cbb403dd6266dabb93b0ca",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 71680,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "A multi-component framework for the analysis and design of explainable artificia"
    },
    "05d065dde75a50551187da7a6dd4ed02": {
      "source_id": "05d065dde75a50551187da7a6dd4ed02",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44074,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "AI Forensics: Did the Artificial Intelligence System Do It? Why?"
    },
    "f794febf4f9decf7520ca8c3574650bb": {
      "source_id": "f794febf4f9decf7520ca8c3574650bb",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18545,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Ethical Considerations for AI Researchers"
    },
    "87702a5b51dcf88ecd5171e67bb40052": {
      "source_id": "87702a5b51dcf88ecd5171e67bb40052",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16334,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "The Social Contract for AI"
    },
    "e8c73364ac5f27fa6128f2061dddda57": {
      "source_id": "e8c73364ac5f27fa6128f2061dddda57",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22779,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Formal Verification of End-to-End Learning in Cyber-Physical Systems: Progress a"
    },
    "d802a08e209a39aacb5429ec2af36745": {
      "source_id": "d802a08e209a39aacb5429ec2af36745",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 92818,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "SAMBA: Safe Model-Based & Active Reinforcement Learning"
    },
    "b4b1eff26b3cd1d9e6d19a0e0a9960a5": {
      "source_id": "b4b1eff26b3cd1d9e6d19a0e0a9960a5",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49513,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "IReEn: Reverse-Engineering of Black-Box Functions via Iterative Neural Program S"
    },
    "25cf381fb83a38b6522457d92f1273ba": {
      "source_id": "25cf381fb83a38b6522457d92f1273ba",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 80293,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Safe Reinforcement Learning via Curriculum Induction"
    },
    "92d190e68f6baabbd38db0f4585623e8": {
      "source_id": "92d190e68f6baabbd38db0f4585623e8",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 91709,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Does the Whole Exceed its Parts? The Effect of AI Explanations on Complementary "
    },
    "4ec878851f211ef9a47b3098ba313493": {
      "source_id": "4ec878851f211ef9a47b3098ba313493",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51456,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Unifying Model Explainability and Robustness via Machine-Checkable Concepts"
    },
    "e303c3cd7f0d8ebf1dc872cd5bbef297": {
      "source_id": "e303c3cd7f0d8ebf1dc872cd5bbef297",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35475,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Customized Handling of Unintended Interface Operation in Assistive Robots"
    },
    "ee8a49ce57bed686095bb065f529b35f": {
      "source_id": "ee8a49ce57bed686095bb065f529b35f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55242,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Failures of Contingent Thinking"
    },
    "0b2cdf50657fa90e00771003b9e3501f": {
      "source_id": "0b2cdf50657fa90e00771003b9e3501f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 107713,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Technologies for Trustworthy Machine Learning: A Survey in a Socio-Technical Con"
    },
    "b4fccbd27d6e5e6a50bd85b00717a11a": {
      "source_id": "b4fccbd27d6e5e6a50bd85b00717a11a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47013,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Improving Competence for Reliable Autonomy"
    },
    "c618fea8fc278406af26612a96fc0467": {
      "source_id": "c618fea8fc278406af26612a96fc0467",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 70467,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Bridging the Imitation Gap by Adaptive Insubordination"
    },
    "56d0c65d1754d56352bd1f6235dbcccf": {
      "source_id": "56d0c65d1754d56352bd1f6235dbcccf",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48724,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Toward Campus Mail Delivery Using BDI"
    },
    "0e7a23bf62ca3f623af64bdbf973409d": {
      "source_id": "0e7a23bf62ca3f623af64bdbf973409d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 82241,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Collecting the Public Perception of AI and Robot Rights"
    },
    "616a90eae506a42d5a77d7c7e9aa70f7": {
      "source_id": "616a90eae506a42d5a77d7c7e9aa70f7",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 145230,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Forward and inverse reinforcement learning sharing network weights and hyperpara"
    },
    "58d2f516697b4e3af9a17e8e8a3bcdf7": {
      "source_id": "58d2f516697b4e3af9a17e8e8a3bcdf7",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 85774,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Artificial Intelligence is stupid and causal reasoning won't fix it"
    },
    "86d35e688b6e822a34415ac47896b7c6": {
      "source_id": "86d35e688b6e822a34415ac47896b7c6",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 66290,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Runtime-Safety-Guided Policy Repair"
    },
    "0dc012241e048d4d5f503359db502796": {
      "source_id": "0dc012241e048d4d5f503359db502796",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37970,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "A Composable Specification Language for Reinforcement Learning Tasks"
    },
    "5d7cfd2d76544f71b84bb2f76112550f": {
      "source_id": "5d7cfd2d76544f71b84bb2f76112550f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 84632,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "A Framework for Improving Scholarly Neural Network Diagrams"
    },
    "c237d4275da9341e2530047697e75b6a": {
      "source_id": "c237d4275da9341e2530047697e75b6a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30237,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "The AIQ Meta-Testbed: Pragmatically Bridging Academic AI Testing and Industrial "
    },
    "ebbdc0ac967f34cdd47187b74c0f6814": {
      "source_id": "ebbdc0ac967f34cdd47187b74c0f6814",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 66416,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Towards the Quantification of Safety Risks in Deep Neural Networks"
    },
    "e48b8a2aed3d856e97cb63de14fa31fa": {
      "source_id": "e48b8a2aed3d856e97cb63de14fa31fa",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 96985,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Beneficial and Harmful Explanatory Machine Learning"
    },
    "55080c9319c2415f18bd606b82cc5d08": {
      "source_id": "55080c9319c2415f18bd606b82cc5d08",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 92456,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Learnable Strategies for Bilateral Agent Negotiation over Multiple Issues"
    },
    "52cdcc7c93c441569e3ddc1f92d999de": {
      "source_id": "52cdcc7c93c441569e3ddc1f92d999de",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26767,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Enterprise AI Canvas -- Integrating Artificial Intelligence into Business"
    },
    "eadaa3228b2bbaf98d871a0c244ae4e3": {
      "source_id": "eadaa3228b2bbaf98d871a0c244ae4e3",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52970,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Trust-Region Method with Deep Reinforcement Learning in Analog Design Space Expl"
    },
    "efd2865183fd7466c7997b47e372ff69": {
      "source_id": "efd2865183fd7466c7997b47e372ff69",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 91670,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Mediating Artificial Intelligence Developments through Negative and Positive Inc"
    },
    "ad6d23e1b1a90af6bcdcd81088a34325": {
      "source_id": "ad6d23e1b1a90af6bcdcd81088a34325",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15893,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Providing Actionable Feedback in Hiring Marketplaces using Generative Adversaria"
    },
    "f5b852a2a9e6735018d31b477424d8d7": {
      "source_id": "f5b852a2a9e6735018d31b477424d8d7",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26746,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "A framework for predicting, interpreting, and improving Learning Outcomes"
    },
    "230fb9bb493fe9e0c8b38f82a6ee65f8": {
      "source_id": "230fb9bb493fe9e0c8b38f82a6ee65f8",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34219,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Information-Driven Adaptive Sensing Based on Deep Reinforcement Learning"
    },
    "f3812df783dc106f5fd3217400bc3be4": {
      "source_id": "f3812df783dc106f5fd3217400bc3be4",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22702,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Do's and Don'ts for Human and Digital Worker Integration"
    },
    "10237dc02782641388da598c58bfbca8": {
      "source_id": "10237dc02782641388da598c58bfbca8",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36188,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Chance-Constrained Control with Lexicographic Deep Reinforcement Learning"
    },
    "95aad70e56a97db653bf057ee4027c6d": {
      "source_id": "95aad70e56a97db653bf057ee4027c6d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37480,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Exploring the Nuances of Designing (with/for) Artificial Intelligence"
    },
    "e25da3f1799e8a257dafb79d416d1e10": {
      "source_id": "e25da3f1799e8a257dafb79d416d1e10",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46862,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Risk Assessment for Machine Learning Models"
    },
    "d093b4fbe7c5d4230b6c4db99cb7f3f1": {
      "source_id": "d093b4fbe7c5d4230b6c4db99cb7f3f1",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50252,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Learning Latent Representations to Influence Multi-Agent Interaction"
    },
    "b788e4590d7267be8529186617c40d93": {
      "source_id": "b788e4590d7267be8529186617c40d93",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40313,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Emergent Road Rules In Multi-Agent Driving Environments"
    },
    "00ccb2340d8ada5a143e794408a04e8c": {
      "source_id": "00ccb2340d8ada5a143e794408a04e8c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48797,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "BARS: Joint Search of Cell Topology and Layout for Accurate and Efficient Binary"
    },
    "44bc639cf9816b05fc3371889c0c26f5": {
      "source_id": "44bc639cf9816b05fc3371889c0c26f5",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57506,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Contract Scheduling With Predictions"
    },
    "6eaa8320041fb81d270985de24dd32b1": {
      "source_id": "6eaa8320041fb81d270985de24dd32b1",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15898,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Interdisciplinary Approaches to Understanding Artificial Intelligence's Impact o"
    },
    "2da04dc77304832bf07ce53277a31364": {
      "source_id": "2da04dc77304832bf07ce53277a31364",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41963,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Exploring Fluent Query Reformulations with Text-to-Text Transformers and Reinfor"
    },
    "106bc20476a329122eb0262b7a5df3a5": {
      "source_id": "106bc20476a329122eb0262b7a5df3a5",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54932,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Taking Principles Seriously: A Hybrid Approach to Value Alignment"
    },
    "0d1bdcf29c07ba19a0a428ab6a519a20": {
      "source_id": "0d1bdcf29c07ba19a0a428ab6a519a20",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41477,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Augmenting Policy Learning with Routines Discovered from a Single Demonstration"
    },
    "3e08a4bd71197293a420b277aa1f4087": {
      "source_id": "3e08a4bd71197293a420b277aa1f4087",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 65275,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Antitrust and Artificial Intelligence (AAI): Antitrust Vigilance Lifecycle and A"
    },
    "c54433ebfff783d782221de95d43abd4": {
      "source_id": "c54433ebfff783d782221de95d43abd4",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47507,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Multi-Principal Assistance Games: Definition and Collegial Mechanisms"
    },
    "334413a1e3315407cc5d7ea040822e21": {
      "source_id": "334413a1e3315407cc5d7ea040822e21",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 118426,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Socially Responsible AI Algorithms: Issues, Purposes, and Challenges"
    },
    "6ccfec6178816685bb9aa5f5e8fc7e0e": {
      "source_id": "6ccfec6178816685bb9aa5f5e8fc7e0e",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42797,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Bridging In- and Out-of-distribution Samples for Their Better Discriminability"
    },
    "6c87991453243015ac3212ffff727cec": {
      "source_id": "6c87991453243015ac3212ffff727cec",
      "quality_score": 7.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7898,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Teaming up with information agents"
    },
    "8e0b3bede15d2844f624a09eb2f55d0c": {
      "source_id": "8e0b3bede15d2844f624a09eb2f55d0c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48504,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Adversarial Interaction Attack: Fooling AI to Misinterpret Human Intentions"
    },
    "c7b84bc87ee9cfb76f442a2d17610af6": {
      "source_id": "c7b84bc87ee9cfb76f442a2d17610af6",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62310,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Making Responsible AI the Norm rather than the Exception"
    },
    "3220cd2617965b938e4126aae21b286a": {
      "source_id": "3220cd2617965b938e4126aae21b286a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51997,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Fairness through Social Welfare Optimization"
    },
    "cf6d86c6187b65515c75270394302627": {
      "source_id": "cf6d86c6187b65515c75270394302627",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 174722,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Counterfactual Planning in AGI Systems"
    },
    "e02500165c9882ce286184172d1ad1c0": {
      "source_id": "e02500165c9882ce286184172d1ad1c0",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24933,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Exploring Beyond-Demonstrator via Meta Learning-Based Reward Extrapolation"
    },
    "191e09b94ec233fdbfb7aa23877a7f2d": {
      "source_id": "191e09b94ec233fdbfb7aa23877a7f2d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52994,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "A Decentralized Approach towards Responsible AI in Social Ecosystems"
    },
    "dff8aedeb662848f79bc90a27eaf8f5a": {
      "source_id": "dff8aedeb662848f79bc90a27eaf8f5a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50155,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Mitigating Negative Side Effects via Environment Shaping"
    },
    "913763e4d36b0f9e4d7d12502362fa2e": {
      "source_id": "913763e4d36b0f9e4d7d12502362fa2e",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 372955,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "On the Equilibrium Elicitation of Markov Games Through Information Design"
    },
    "beb53e03ce611e669108a73fc0145a00": {
      "source_id": "beb53e03ce611e669108a73fc0145a00",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43354,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Machine Learning Model Development from a Software Engineering Perspective: A Sy"
    },
    "2fa1b68cb500bcd1bf76eefa3a22b52f": {
      "source_id": "2fa1b68cb500bcd1bf76eefa3a22b52f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 94457,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "How RL Agents Behave When Their Actions Are Modified"
    },
    "9312ad006aca35cb95f60f5b08fb07f2": {
      "source_id": "9312ad006aca35cb95f60f5b08fb07f2",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 74206,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Training a Resilient Q-Network against Observational Interference"
    },
    "f1a46dbfbe90205f6d7d41fe82900dab": {
      "source_id": "f1a46dbfbe90205f6d7d41fe82900dab",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 74834,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Software Architecture for Next-Generation AI Planning Systems"
    },
    "99cb587661c88b56aa49ea81468c8f74": {
      "source_id": "99cb587661c88b56aa49ea81468c8f74",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46976,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Beyond Fine-Tuning: Transferring Behavior in Reinforcement Learning"
    },
    "4d29d4a065f90b60d68fd63bd6e70d60": {
      "source_id": "4d29d4a065f90b60d68fd63bd6e70d60",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 67135,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Secure Evaluation of Knowledge Graph Merging Gain"
    },
    "9985528a03f79df7ab395d787a35ab92": {
      "source_id": "9985528a03f79df7ab395d787a35ab92",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 116076,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Evaluating Robustness of Counterfactual Explanations"
    },
    "378d3427c0ffac7400092b06246f15cb": {
      "source_id": "378d3427c0ffac7400092b06246f15cb",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12184,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Symbolic Reinforcement Learning for Safe RAN Control"
    },
    "b71c7e1c9618e211deb045c196821411": {
      "source_id": "b71c7e1c9618e211deb045c196821411",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17622,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Towards Risk Modeling for Collaborative AI"
    },
    "7349535db7a4ab6a9ec3cd0a369f4d4d": {
      "source_id": "7349535db7a4ab6a9ec3cd0a369f4d4d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46284,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Success Weighted by Completion Time: A Dynamics-Aware Evaluation Criteria for Em"
    },
    "3887e5490a7a9880f242d7505634adbc": {
      "source_id": "3887e5490a7a9880f242d7505634adbc",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35958,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Lyapunov Barrier Policy Optimization"
    },
    "1717dd816d939c979042176b5a004557": {
      "source_id": "1717dd816d939c979042176b5a004557",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17788,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Systematic Mapping Study on the Machine Learning Lifecycle"
    },
    "59f90d6e3944f784abd2420111e95882": {
      "source_id": "59f90d6e3944f784abd2420111e95882",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 94914,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Combining Reward Information from Multiple Sources"
    },
    "715784c647249f72190e8326440e99e0": {
      "source_id": "715784c647249f72190e8326440e99e0",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 209951,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Assured Learning-enabled Autonomy: A Metacognitive Reinforcement Learning Framew"
    },
    "a359baed17693d647b41f3135eab958c": {
      "source_id": "a359baed17693d647b41f3135eab958c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61661,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Counterfactual Explanation with Multi-Agent Reinforcement Learning for Drug Targ"
    },
    "fcc1ea7b94857d53fab935650a85f7b7": {
      "source_id": "fcc1ea7b94857d53fab935650a85f7b7",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50934,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "W2WNet: a two-module probabilistic Convolutional Neural Network with embedded da"
    },
    "7bec26c394380c20518e354080a16aba": {
      "source_id": "7bec26c394380c20518e354080a16aba",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43117,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "A Bayesian Approach to Identifying Representational Errors"
    },
    "e1dbcfab2d880dae2e20d8eee2c4a15f": {
      "source_id": "e1dbcfab2d880dae2e20d8eee2c4a15f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18921,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Towards An Ethics-Audit Bot"
    },
    "0141cd563881ab4f5cc5498335ded12d": {
      "source_id": "0141cd563881ab4f5cc5498335ded12d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58245,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Voluntary safety commitments provide an escape from over-regulation in AI develo"
    },
    "cdeea8d88c36ce156a4d0e9f8ca81701": {
      "source_id": "cdeea8d88c36ce156a4d0e9f8ca81701",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 127756,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Artificial intelligence, human rights, democracy, and the rule of law: a primer"
    },
    "ea8c2d32c25666984e45793dae543f09": {
      "source_id": "ea8c2d32c25666984e45793dae543f09",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25707,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "The Atari Data Scraper"
    },
    "5fd293522bc3b6b6ce0a980ce21d644f": {
      "source_id": "5fd293522bc3b6b6ce0a980ce21d644f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48185,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Action Advising with Advice Imitation in Deep Reinforcement Learning"
    },
    "f0c09aed3d03e5275006cb2565d8ea9f": {
      "source_id": "f0c09aed3d03e5275006cb2565d8ea9f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39447,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Causal Learning for Socially Responsible AI"
    },
    "73643a60bb86bf2fd0995a74ce06f8b7": {
      "source_id": "73643a60bb86bf2fd0995a74ce06f8b7",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45525,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "A Framework for Ethical AI at the United Nations"
    },
    "bae10359a6547ffdba5e45b9df0c3ee7": {
      "source_id": "bae10359a6547ffdba5e45b9df0c3ee7",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33112,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "pyBKT: An Accessible Python Library of Bayesian Knowledge Tracing Models"
    },
    "7d73ab05546a6fcfd82aa9713733128c": {
      "source_id": "7d73ab05546a6fcfd82aa9713733128c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30649,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Hybrid Intelligence"
    },
    "41bc4ce3496b2fe92fd57bb393b3edfd": {
      "source_id": "41bc4ce3496b2fe92fd57bb393b3edfd",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41430,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "RL-IoT: Reinforcement Learning to Interact with IoT Devices"
    },
    "f02af23f63156be9f54dad25a690fffe": {
      "source_id": "f02af23f63156be9f54dad25a690fffe",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 77767,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "AI Risk Skepticism"
    },
    "b92f2e30b3f18ed7058d7b8eba660c49": {
      "source_id": "b92f2e30b3f18ed7058d7b8eba660c49",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50114,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Finding the unicorn: Predicting early stage startup success through a hybrid int"
    },
    "7b0d451e8356828929085352e215f289": {
      "source_id": "7b0d451e8356828929085352e215f289",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55057,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Hard Choices and Hard Limits for Artificial Intelligence"
    },
    "a729a26f4f765bad65dc0151c3ecf8e7": {
      "source_id": "a729a26f4f765bad65dc0151c3ecf8e7",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 67889,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "An Offline Risk-aware Policy Selection Method for Bayesian Markov Decision Proce"
    },
    "aa2397b1dcdda034045dbaf26525b126": {
      "source_id": "aa2397b1dcdda034045dbaf26525b126",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 90579,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Towards a Mathematical Theory of Abstraction"
    },
    "49d1e059b5b2252b1792f7fb47553887": {
      "source_id": "49d1e059b5b2252b1792f7fb47553887",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 102371,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Definitions of intent suitable for algorithms"
    },
    "96d146702316db2130833097d65c5d6a": {
      "source_id": "96d146702316db2130833097d65c5d6a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 101495,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Curriculum Design for Teaching via Demonstrations: Theory and Applications"
    },
    "357c9172db62c1a56eeea59cf764267c": {
      "source_id": "357c9172db62c1a56eeea59cf764267c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34165,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Synthesising Reinforcement Learning Policies through Set-Valued Inductive Rule L"
    },
    "f9ac5781faaed74d3e26472bd1a7ed17": {
      "source_id": "f9ac5781faaed74d3e26472bd1a7ed17",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 71270,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Developing a Fidelity Evaluation Approach for Interpretable Machine Learning"
    },
    "feb742285ce9f746cedcd7f73b797083": {
      "source_id": "feb742285ce9f746cedcd7f73b797083",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 86357,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Hard Choices in Artificial Intelligence"
    },
    "950357c48af628620ea7265ca9713fc6": {
      "source_id": "950357c48af628620ea7265ca9713fc6",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37366,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Institutionalising Ethics in AI through Broader Impact Requirements"
    },
    "b49589e94ad75d344a9c2a5305b8549f": {
      "source_id": "b49589e94ad75d344a9c2a5305b8549f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44101,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Not all users are the same: Providing personalized explanations for sequential d"
    },
    "d196c5722d7015956a5930d50bbc52ad": {
      "source_id": "d196c5722d7015956a5930d50bbc52ad",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 78913,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "The Threat of Offensive AI to Organizations"
    },
    "942a97fcf69f4e992d9690a156fc986b": {
      "source_id": "942a97fcf69f4e992d9690a156fc986b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21856,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "ML-Quadrat & DriotData: A Model-Driven Engineering Tool and a Low-Code Platform "
    },
    "342c6984900004ffe5467063dbc8ec6d": {
      "source_id": "342c6984900004ffe5467063dbc8ec6d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23325,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Integrating Planning, Execution and Monitoring in the presence of Open World Nov"
    },
    "93b71b609bfa6bfb22fb3aa9b2634396": {
      "source_id": "93b71b609bfa6bfb22fb3aa9b2634396",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38297,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Aligning an optical interferometer with beam divergence control and continuous a"
    },
    "a1647aa4fae04ddf206f1473ff6efda3": {
      "source_id": "a1647aa4fae04ddf206f1473ff6efda3",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53132,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Not Quite 'Ask a Librarian': AI on the Nature, Value, and Future of LIS"
    },
    "a0c29a80d370bee9e8c3ce0041e224a6": {
      "source_id": "a0c29a80d370bee9e8c3ce0041e224a6",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58815,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "aiSTROM -- A roadmap for developing a successful AI strategy"
    },
    "839c200889ebc513bdd5cf615ccac273": {
      "source_id": "839c200889ebc513bdd5cf615ccac273",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 125615,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Deep Adaptive Multi-Intention Inverse Reinforcement Learning"
    },
    "349b721fcb4e01cea631d2b13ae9a0c6": {
      "source_id": "349b721fcb4e01cea631d2b13ae9a0c6",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34940,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "A Modulation Layer to Increase Neural Network Robustness Against Data Quality Is"
    },
    "62e683d54a625beee14632594079b8dd": {
      "source_id": "62e683d54a625beee14632594079b8dd",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38619,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "On the Veracity of Local, Model-agnostic Explanations in Audio Classification: T"
    },
    "ffcecabe153f9af6ee57bd3da9f4a991": {
      "source_id": "ffcecabe153f9af6ee57bd3da9f4a991",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33121,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Towards Industrial Private AI: A two-tier framework for data and model security"
    },
    "ef2214c5eb3122eb7c35d6a85bd07b78": {
      "source_id": "ef2214c5eb3122eb7c35d6a85bd07b78",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50033,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "A Reflection on Learning from Data: Epistemology Issues and Limitations"
    },
    "46ba239757968f3f4a8421e9a457b1db": {
      "source_id": "46ba239757968f3f4a8421e9a457b1db",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 99641,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Discovering User-Interpretable Capabilities of Black-Box Planning Agents"
    },
    "844cb18b7b1f087bfc6df9709bc4dca8": {
      "source_id": "844cb18b7b1f087bfc6df9709bc4dca8",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42654,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "An Ethical Framework for Guiding the Development of Affectively-Aware Artificial"
    },
    "56ff800292644bea1be30f18f97ff2f3": {
      "source_id": "56ff800292644bea1be30f18f97ff2f3",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 754563,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "The Role of Social Movements, Coalitions, and Workers in Resisting Harmful Artif"
    },
    "e279806c12c8a6682a05f0a33c5aacb0": {
      "source_id": "e279806c12c8a6682a05f0a33c5aacb0",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 95494,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "A Decision Model for Decentralized Autonomous Organization Platform Selection: T"
    },
    "577ffc18173d346a11c90cd1a1f861d6": {
      "source_id": "577ffc18173d346a11c90cd1a1f861d6",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48021,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "DySR: A Dynamic Representation Learning and Aligning based Model for Service Bun"
    },
    "f53e1e0c49789ad663c2d392f6f2470d": {
      "source_id": "f53e1e0c49789ad663c2d392f6f2470d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28845,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Beyond Fairness Metrics: Roadblocks and Challenges for Ethical AI in Practice"
    },
    "95b381a292b906e9691057da8db17d1b": {
      "source_id": "95b381a292b906e9691057da8db17d1b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 81325,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "A Framework for Understanding AI-Induced Field Change: How AI Technologies are L"
    },
    "ec9b13447a3e2519a1e3752b9e389386": {
      "source_id": "ec9b13447a3e2519a1e3752b9e389386",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 71024,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Safe Transformative AI via a Windfall Clause"
    },
    "1a84b206594ab34ba77a101bd54bdf80": {
      "source_id": "1a84b206594ab34ba77a101bd54bdf80",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 96936,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Learning Causal Models of Autonomous Agents using Interventions"
    },
    "c085d2d1d8ede63323f432acd928c2d8": {
      "source_id": "c085d2d1d8ede63323f432acd928c2d8",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24174,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "With One Voice: Composing a Travel Voice Assistant from Re-purposed Models"
    },
    "759a6e91ea8575e1e5b79c948bf9f426": {
      "source_id": "759a6e91ea8575e1e5b79c948bf9f426",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62541,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Why and How Governments Should Monitor AI Development"
    },
    "4d68272ca50e9711e6f8c83ac804cc15": {
      "source_id": "4d68272ca50e9711e6f8c83ac804cc15",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 64153,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Problem Learning: Towards the Free Will of Machines"
    },
    "714861efdafd1851c3f7f71989d97e6a": {
      "source_id": "714861efdafd1851c3f7f71989d97e6a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36141,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Towards Resilient Artificial Intelligence: Survey and Research Issues"
    },
    "b2ad8022e71fd93f6a46722dd4a4cb3a": {
      "source_id": "b2ad8022e71fd93f6a46722dd4a4cb3a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26959,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Learning to Assist Agents by Observing Them"
    },
    "6843e44989aaddcc3d44fe9d11c0b1b0": {
      "source_id": "6843e44989aaddcc3d44fe9d11c0b1b0",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73681,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Procedure Planning in Instructional Videos via Contextual Modeling and Model-bas"
    },
    "c515598ed82b0e38f43042f1abda5cfb": {
      "source_id": "c515598ed82b0e38f43042f1abda5cfb",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20484,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Thinking Fast and Slow in AI: the Role of Metacognition"
    },
    "3f5d47ddec0cbf30f633913932b9d488": {
      "source_id": "3f5d47ddec0cbf30f633913932b9d488",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41963,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Fingerprinting Multi-exit Deep Neural Network Models via Inference Time"
    },
    "bb5283252d7c5fdc2b489cb390913447": {
      "source_id": "bb5283252d7c5fdc2b489cb390913447",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27940,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Robustness of different loss functions and their impact on networks learning cap"
    },
    "ae08d781c06efe3de684d4e6e8f576ad": {
      "source_id": "ae08d781c06efe3de684d4e6e8f576ad",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36780,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Evaluating the Faithfulness of Importance Measures in NLP by Recursively Masking"
    },
    "e2b71b5b174e59cc7bfaf121367dd320": {
      "source_id": "e2b71b5b174e59cc7bfaf121367dd320",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33713,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Improving End-To-End Modeling for Mispronunciation Detection with Effective Augm"
    },
    "d9b74722526e4fcd13dbf56813df0311": {
      "source_id": "d9b74722526e4fcd13dbf56813df0311",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 64218,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Value alignment: a formal approach"
    },
    "6ae1ff25b772be686ef8c0fd75dfef94": {
      "source_id": "6ae1ff25b772be686ef8c0fd75dfef94",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18407,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Risks of AI Foundation Models in Education"
    },
    "38262fb2240896fac01b0db87dcb1b82": {
      "source_id": "38262fb2240896fac01b0db87dcb1b82",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28756,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "QuantifyML: How Good is my Machine Learning Model?"
    },
    "ffb3cdbe1647ac78495d6f64df006a37": {
      "source_id": "ffb3cdbe1647ac78495d6f64df006a37",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48285,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Understanding Interlocking Dynamics of Cooperative Rationalization"
    },
    "efc0cd3231bac3feea8077db475167c3": {
      "source_id": "efc0cd3231bac3feea8077db475167c3",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54120,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Learning to Be Cautious"
    },
    "76fd04d6177fa7e4a6fbf85c305943c9": {
      "source_id": "76fd04d6177fa7e4a6fbf85c305943c9",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40396,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "A Word on Machine Ethics: A Response to Jiang et al. (2021)"
    },
    "2d0f8fbf5aa491553e23b73b106a6494": {
      "source_id": "2d0f8fbf5aa491553e23b73b106a6494",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58064,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Efficient estimates of optimal transport via low-dimensional embeddings"
    },
    "6c313d37e8b148d6c69057adb3280c5b": {
      "source_id": "6c313d37e8b148d6c69057adb3280c5b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12162,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Lymph Node Detection in T2 MRI with Transformers"
    },
    "542736ebb8aad1d00128b39f55844a50": {
      "source_id": "542736ebb8aad1d00128b39f55844a50",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 118798,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Explainable AI (XAI): A Systematic Meta-Survey of Current Challenges and Future "
    },
    "464de48531ae3c80a92faabee44103bf": {
      "source_id": "464de48531ae3c80a92faabee44103bf",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36700,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Improving Learning from Demonstrations by Learning from Experience"
    },
    "315b5d43a0d58bb6e2f341beb803c650": {
      "source_id": "315b5d43a0d58bb6e2f341beb803c650",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40503,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Software Engineering for Responsible AI: An Empirical Study and Operationalised "
    },
    "da0cfd50754b61801a17af771fae27fd": {
      "source_id": "da0cfd50754b61801a17af771fae27fd",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14659,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Finding Useful Predictions by Meta-gradient Descent to Improve Decision-making"
    },
    "7e373da22bc9542af1e24fca4f84aeee": {
      "source_id": "7e373da22bc9542af1e24fca4f84aeee",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 69024,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Machines & Influence: An Information Systems Lens"
    },
    "118b4f6716338f5b7736a9034fb5cc63": {
      "source_id": "118b4f6716338f5b7736a9034fb5cc63",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 91038,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Learning from learning machines: a new generation of AI technology to meet the n"
    },
    "9f93c053bb136fda9f6c788de50ac321": {
      "source_id": "9f93c053bb136fda9f6c788de50ac321",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34401,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Weighing the Milky Way and Andromeda with Artificial Intelligence"
    },
    "9c44e9033875db80d47817cbec8dba9c": {
      "source_id": "9c44e9033875db80d47817cbec8dba9c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49790,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "AI and the Everything in the Whole Wide World Benchmark"
    },
    "0a76ecf713853808cf41547d4342fbad": {
      "source_id": "0a76ecf713853808cf41547d4342fbad",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56704,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "MESA: Offline Meta-RL for Safe Adaptation and Fault Tolerance"
    },
    "f9b16944b77e75a3da916261754db651": {
      "source_id": "f9b16944b77e75a3da916261754db651",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22684,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Filling gaps in trustworthy development of AI"
    },
    "226dad31be434c16248ac394a0fce33c": {
      "source_id": "226dad31be434c16248ac394a0fce33c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 180478,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Programmatic Reward Design by Example"
    },
    "7c7c5101e999d894cf598473be662dae": {
      "source_id": "7c7c5101e999d894cf598473be662dae",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46368,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "WebGPT: Browser-assisted question-answering with human feedback"
    },
    "aa42112787cbc41499c090721f1c03b9": {
      "source_id": "aa42112787cbc41499c090721f1c03b9",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57402,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Demanding and Designing Aligned Cognitive Architectures"
    },
    "3983b42c3f367b5a9daf0012c37eef39": {
      "source_id": "3983b42c3f367b5a9daf0012c37eef39",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 74988,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Modeling Human-AI Team Decision Making"
    },
    "aee49bba8b9aac67bb7daed672ebed42": {
      "source_id": "aee49bba8b9aac67bb7daed672ebed42",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42376,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "The Turing Trap: The Promise & Peril of Human-Like Artificial Intelligence"
    },
    "56829389fad04d54124fd47a7416b6a7": {
      "source_id": "56829389fad04d54124fd47a7416b6a7",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25539,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "The Concept of Criticality in AI Safety"
    },
    "85f393e0d24a929a33e4c2f1049af1ef": {
      "source_id": "85f393e0d24a929a33e4c2f1049af1ef",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44687,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Tools and Practices for Responsible AI Engineering"
    },
    "e086e270e0fa1cda183f1a14d92ee0d8": {
      "source_id": "e086e270e0fa1cda183f1a14d92ee0d8",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54888,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Measuring Non-Probabilistic Uncertainty: A cognitive, logical and computational "
    },
    "b229b98591d4895d292b9e5a694de11b": {
      "source_id": "b229b98591d4895d292b9e5a694de11b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 129960,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Planning Not to Talk: Multiagent Systems that are Robust to Communication Loss"
    },
    "ee653d87f7edfc977fb9cca26814fbce": {
      "source_id": "ee653d87f7edfc977fb9cca26814fbce",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22290,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Improving Behavioural Cloning with Human-Driven Dynamic Dataset Augmentation"
    },
    "2cc6d95d810cf3d71b92851d44975413": {
      "source_id": "2cc6d95d810cf3d71b92851d44975413",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 118371,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Safety-Aware Multi-Agent Apprenticeship Learning"
    },
    "54fce49dfd17b9cfa83507f08a7c58f5": {
      "source_id": "54fce49dfd17b9cfa83507f08a7c58f5",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58798,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Priors, Hierarchy, and Information Asymmetry for Skill Transfer in Reinforcement"
    },
    "0e530f67c0d529102e834063a922cb2c": {
      "source_id": "0e530f67c0d529102e834063a922cb2c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 138624,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Scaling Up Knowledge Graph Creation to Large and Heterogeneous Data Sources"
    },
    "813db9ba4098d5fb4b2ddc0895b07eb5": {
      "source_id": "813db9ba4098d5fb4b2ddc0895b07eb5",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 111600,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Safe AI -- How is this Possible?"
    },
    "aa8c44de8cf70353c88770a9c799bcf9": {
      "source_id": "aa8c44de8cf70353c88770a9c799bcf9",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23195,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Cybertrust: From Explainable to Actionable and Interpretable AI (AI2)"
    },
    "8726f32562cff5eb4970ce4dd019aecc": {
      "source_id": "8726f32562cff5eb4970ce4dd019aecc",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 90961,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Human-centered mechanism design with Democratic AI"
    },
    "41880a502afdcb9f299595d0399975f4": {
      "source_id": "41880a502afdcb9f299595d0399975f4",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32841,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Explaining Reinforcement Learning Policies through Counterfactual Trajectories"
    },
    "d2fb125a5bdcf1e208a2487003e720bf": {
      "source_id": "d2fb125a5bdcf1e208a2487003e720bf",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49318,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "CIC: Contrastive Intrinsic Control for Unsupervised Skill Discovery"
    },
    "ca70467cf934e8af009ebff45f0809d8": {
      "source_id": "ca70467cf934e8af009ebff45f0809d8",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 926957,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Technology Ethics in Action: Critical and Interdisciplinary Perspectives"
    },
    "62776f407519f655311008a8dfe1e694": {
      "source_id": "62776f407519f655311008a8dfe1e694",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 74133,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Solving Dynamic Principal-Agent Problems with a Rationally Inattentive Principal"
    },
    "837f414b898df86918590cca683a9489": {
      "source_id": "837f414b898df86918590cca683a9489",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 622672,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Human rights, democracy, and the rule of law assurance framework for AI systems:"
    },
    "1aef4c64a68bc52e6074ba825f1f9af5": {
      "source_id": "1aef4c64a68bc52e6074ba825f1f9af5",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20309,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "The 6-Ds of Creating AI-Enabled Systems"
    },
    "407a89d50dd6ff35530bbbaff199e89a": {
      "source_id": "407a89d50dd6ff35530bbbaff199e89a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 138005,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Knowledge-Integrated Informed AI for National Security"
    },
    "97a6e556f7ea88f7d1fa5efe9878afd1": {
      "source_id": "97a6e556f7ea88f7d1fa5efe9878afd1",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73458,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Reward is not enough: can we liberate AI from the reinforcement learning paradig"
    },
    "36215638a79b3cecd93e87deee0d59b7": {
      "source_id": "36215638a79b3cecd93e87deee0d59b7",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41287,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Local Explanations for Reinforcement Learning"
    },
    "0b8e091c821c1248912096d41cf720af": {
      "source_id": "0b8e091c821c1248912096d41cf720af",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 83342,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Machine Explanations and Human Understanding"
    },
    "a9e748f28cffc1038924c8a3d387a61e": {
      "source_id": "a9e748f28cffc1038924c8a3d387a61e",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55511,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Interpretable pipelines with evolutionarily optimized modules for RL tasks with "
    },
    "7d71464129d360de614a26734b6ae910": {
      "source_id": "7d71464129d360de614a26734b6ae910",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73006,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Trust in AI: Interpretability is not necessary or sufficient, while black-box in"
    },
    "cad61abb903ac95e2b2b98070f868ad1": {
      "source_id": "cad61abb903ac95e2b2b98070f868ad1",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53472,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Uncalibrated Models Can Improve Human-AI Collaboration"
    },
    "4ede69fce8724f7a4bd4199f0764b04a": {
      "source_id": "4ede69fce8724f7a4bd4199f0764b04a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41645,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Zero-Shot Assistance in Sequential Decision Problems"
    },
    "cc61b8282355a9715a9ed0882d3e1064": {
      "source_id": "cc61b8282355a9715a9ed0882d3e1064",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26809,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Critical Checkpoints for Evaluating Defence Models Against Adversarial Attack an"
    },
    "c9041a9f9410d0e0b2d217c99f6480a2": {
      "source_id": "c9041a9f9410d0e0b2d217c99f6480a2",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34694,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "HCMD-zero: Learning Value Aligned Mechanisms from Data"
    },
    "68da4ab0079db5203d58905d9bcae9d0": {
      "source_id": "68da4ab0079db5203d58905d9bcae9d0",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36836,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Investigations of Performance and Bias in Human-AI Teamwork in Hiring"
    },
    "a330fb6324994e695e44a867aabcdd40": {
      "source_id": "a330fb6324994e695e44a867aabcdd40",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51876,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Composing Complex and Hybrid AI Solutions"
    },
    "8fc7eef981a673d2daecfe81f1eb8f28": {
      "source_id": "8fc7eef981a673d2daecfe81f1eb8f28",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21215,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "OCR-IDL: OCR Annotations for Industry Document Library Dataset"
    },
    "ff56b064384bb82c28b1977f1618fb80": {
      "source_id": "ff56b064384bb82c28b1977f1618fb80",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28297,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "The dangers in algorithms learning humans' values and irrationalities"
    },
    "c65b99f477ddc2a692b97080326405ea": {
      "source_id": "c65b99f477ddc2a692b97080326405ea",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18968,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Responsible-AI-by-Design: a Pattern Collection for Designing Responsible AI Syst"
    },
    "205e847060cffe5809d9f1141cb6db68": {
      "source_id": "205e847060cffe5809d9f1141cb6db68",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46818,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Reasoning about Counterfactuals to Improve Human Inverse Reinforcement Learning"
    },
    "71955245b24a9957bf6e043baa4c84ed": {
      "source_id": "71955245b24a9957bf6e043baa4c84ed",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56120,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Graph Neural Networks for Multimodal Single-Cell Data Integration"
    },
    "12ae1fc6cb0a054e9ef921589995bc69": {
      "source_id": "12ae1fc6cb0a054e9ef921589995bc69",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61854,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "A Typology for Exploring the Mitigation of Shortcut Behavior"
    },
    "411295d672508f9356c6ff76adf01066": {
      "source_id": "411295d672508f9356c6ff76adf01066",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 343401,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Algebraic Learning: Towards Interpretable Information Modeling"
    },
    "c52390c5cf7e651ab370878d7f885fe3": {
      "source_id": "c52390c5cf7e651ab370878d7f885fe3",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 87256,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "CMKD: CNN/Transformer-Based Cross-Model Knowledge Distillation for Audio Classif"
    },
    "f8f35509051016e1c1b72a86c8339381": {
      "source_id": "f8f35509051016e1c1b72a86c8339381",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49607,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Building AI Innovation Labs together with Companies"
    },
    "d1469829e90fd39d090da256176b09dd": {
      "source_id": "d1469829e90fd39d090da256176b09dd",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56502,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Towards a Roadmap on Software Engineering for Responsible AI"
    },
    "f0c30e26a6a5c846b704c41a0da9ceb6": {
      "source_id": "f0c30e26a6a5c846b704c41a0da9ceb6",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 69286,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Robust Action Gap Increasing with Clipped Advantage Learning"
    },
    "f0761751cbd78c674ae07f234625b21c": {
      "source_id": "f0761751cbd78c674ae07f234625b21c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49355,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "A Rationale-Centric Framework for Human-in-the-loop Machine Learning"
    },
    "038cf60b42288177c5cb9a386f5f0266": {
      "source_id": "038cf60b42288177c5cb9a386f5f0266",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61279,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Quality Assurance of Generative Dialog Models in an Evolving Conversational Agen"
    },
    "e194d39761efb0bc3c8e86dcca0e544b": {
      "source_id": "e194d39761efb0bc3c8e86dcca0e544b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56920,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Graph-in-Graph (GiG): Learning interpretable latent graphs in non-Euclidean doma"
    },
    "4b80438954bd57fdfadcef5fdf71e631": {
      "source_id": "4b80438954bd57fdfadcef5fdf71e631",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 123265,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Robust Event-Driven Interactions in Cooperative Multi-Agent Learning"
    },
    "c86d638a79093201bccd9c3e9143f311": {
      "source_id": "c86d638a79093201bccd9c3e9143f311",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56669,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Enhancing the Robustness, Efficiency, and Diversity of Differentiable Architectu"
    },
    "827b75911b8bf55aff890e0f750f937f": {
      "source_id": "827b75911b8bf55aff890e0f750f937f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20439,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Linguistic communication as (inverse) reward design"
    },
    "da59e3fffc6d024a2b5e102b64502912": {
      "source_id": "da59e3fffc6d024a2b5e102b64502912",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 74348,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Metaethical Perspectives on 'Benchmarking' AI Ethics"
    },
    "fa94eb811e4ed6f48785234381e8a61d": {
      "source_id": "fa94eb811e4ed6f48785234381e8a61d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57501,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Flexible Multiple-Objective Reinforcement Learning for Chip Placement"
    },
    "81d6196790eb7f2fc6d5fc43b5d449ce": {
      "source_id": "81d6196790eb7f2fc6d5fc43b5d449ce",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54182,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Contextualizing Artificially Intelligent Morality: A Meta-Ethnography of Top-Dow"
    },
    "1aa18a5cdb5e7320bf1775144de3f08c": {
      "source_id": "1aa18a5cdb5e7320bf1775144de3f08c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73051,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "The Risks of Machine Learning Systems"
    },
    "d66efe89f7edc9c798b9626524d4f891": {
      "source_id": "d66efe89f7edc9c798b9626524d4f891",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53225,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Path-Specific Objectives for Safer Agent Incentives"
    },
    "568da857b5fce82c55c2186ea9e4ad26": {
      "source_id": "568da857b5fce82c55c2186ea9e4ad26",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 221413,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "A Survey on XAI for Beyond 5G Security: Technical Aspects, Use Cases, Challenges"
    },
    "37c071c07d3ab37d154da7a8274878ee": {
      "source_id": "37c071c07d3ab37d154da7a8274878ee",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24019,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "A Deep Reinforcement Learning Framework for Rapid Diagnosis of Whole Slide Patho"
    },
    "398f8d39b2bd93d775c118b74596d8de": {
      "source_id": "398f8d39b2bd93d775c118b74596d8de",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 394683,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "The AI Index 2022 Annual Report"
    },
    "2034930e8b818514d927fd04cbe8ed89": {
      "source_id": "2034930e8b818514d927fd04cbe8ed89",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 75302,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "A Survey on AI Sustainability: Emerging Trends on Learning Algorithms and Resear"
    },
    "f92a4eb8634567a04e48c3858c7a35ea": {
      "source_id": "f92a4eb8634567a04e48c3858c7a35ea",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 69336,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Aligned with Whom? Direct and social goals for AI systems"
    },
    "2f05d4ecf6a6e80f936e32bea90e54b2": {
      "source_id": "2f05d4ecf6a6e80f936e32bea90e54b2",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57017,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "How Different Groups Prioritize Ethical Values for Responsible AI"
    },
    "8fb6f61cf1e07a5bd68ae56f841ee0b6": {
      "source_id": "8fb6f61cf1e07a5bd68ae56f841ee0b6",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 211337,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Mimicking Behaviors in Separated Domains"
    },
    "1dbd17639184d9aad73547f20f4e02bc": {
      "source_id": "1dbd17639184d9aad73547f20f4e02bc",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 113474,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Exploring the Trade-off between Plausibility, Change Intensity and Adversarial P"
    },
    "0530e7dcfd24a85db0a160d66986e159": {
      "source_id": "0530e7dcfd24a85db0a160d66986e159",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17777,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Responsible Artificial Intelligence -- from Principles to Practice"
    },
    "3d1babdf4c39457041ad6638196a327c": {
      "source_id": "3d1babdf4c39457041ad6638196a327c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20763,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "A Human-Centric Assessment Framework for AI"
    },
    "c3fe4405e8d21673c4200e989141782e": {
      "source_id": "c3fe4405e8d21673c4200e989141782e",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44821,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "GALOIS: Boosting Deep Reinforcement Learning via Generalizable Logic Synthesis"
    },
    "d9ef3d1c335087535791133204004d14": {
      "source_id": "d9ef3d1c335087535791133204004d14",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41204,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Personalized Algorithmic Recourse with Preference Elicitation"
    },
    "e0f20ce2810fbb03e95833c6e3aff86d": {
      "source_id": "e0f20ce2810fbb03e95833c6e3aff86d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39794,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Multi-Game Decision Transformers"
    },
    "cc24dc9a9485949057e532780b322613": {
      "source_id": "cc24dc9a9485949057e532780b322613",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24871,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "HYCEDIS: HYbrid Confidence Engine for Deep Document Intelligence System"
    },
    "bce64cd381cfaef8c8ac7f81d0b1bc59": {
      "source_id": "bce64cd381cfaef8c8ac7f81d0b1bc59",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39679,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Improving Model Understanding and Trust with Counterfactual Explanations of Mode"
    },
    "08f6fc9e4b21ce87e5612e5a9fe3aac5": {
      "source_id": "08f6fc9e4b21ce87e5612e5a9fe3aac5",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25954,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "CAISAR: A platform for Characterizing Artificial Intelligence Safety and Robustn"
    },
    "87cef25502a7208a08d7982e414d1ba9": {
      "source_id": "87cef25502a7208a08d7982e414d1ba9",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38762,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Towards Safe Reinforcement Learning via Constraining Conditional Value-at-Risk"
    },
    "996788ee14c025d6976db4f937b7b9dc": {
      "source_id": "996788ee14c025d6976db4f937b7b9dc",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38740,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Towards Autonomous Grading In The Real World"
    },
    "bf30366d2c83852331c4d5275f15c51b": {
      "source_id": "bf30366d2c83852331c4d5275f15c51b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44283,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Characteristics of Harmful Text: Towards Rigorous Benchmarking of Language Model"
    },
    "e7aa7614cdd5882a2ac01fd0bef0acd5": {
      "source_id": "e7aa7614cdd5882a2ac01fd0bef0acd5",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 346791,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Modeling Transformative AI Risks (MTAIR) Project -- Summary Report"
    },
    "24824a8aca1cb4f169e5c5afd1d925d8": {
      "source_id": "24824a8aca1cb4f169e5c5afd1d925d8",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11908,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Uncertainty Quantification for Competency Assessment of Autonomous Agents"
    },
    "12d4b77ba820650328a66f9c1bfdcf1c": {
      "source_id": "12d4b77ba820650328a66f9c1bfdcf1c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28883,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Formalizing the Problem of Side Effect Regularization"
    },
    "40b8cefc2fc84f5a3237d4ce204d2acb": {
      "source_id": "40b8cefc2fc84f5a3237d4ce204d2acb",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 825341,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "On Avoiding Power-Seeking by Artificial Intelligence"
    },
    "e2f6a639eab01084ec7e0f76673c92e3": {
      "source_id": "e2f6a639eab01084ec7e0f76673c92e3",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 195907,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Multi-Modal and Multi-Factor Branching Time Active Inference"
    },
    "5f679aa5f67a93ba59a8e9c8281af336": {
      "source_id": "5f679aa5f67a93ba59a8e9c8281af336",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52866,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Parametrically Retargetable Decision-Makers Tend To Seek Power"
    },
    "fc8a8d2a6ce0ac6b0658ef6b282cf97e": {
      "source_id": "fc8a8d2a6ce0ac6b0658ef6b282cf97e",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37899,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Auditing Visualizations: Transparency Methods Struggle to Detect Anomalous Behav"
    },
    "72206017b1892b4eadba657bde41ab54": {
      "source_id": "72206017b1892b4eadba657bde41ab54",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 106686,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "The Linguistic Blind Spot of Value-Aligned Agency, Natural and Artificial"
    },
    "b53638f9eff11ba5b861edf394b8addd": {
      "source_id": "b53638f9eff11ba5b861edf394b8addd",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18331,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Inferring and Conveying Intentionality: Beyond Numerical Rewards to Logical Inte"
    },
    "a15c6ca1174331707173dbcf21fc54a1": {
      "source_id": "a15c6ca1174331707173dbcf21fc54a1",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13235,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Boolean Decision Rules for Reinforcement Learning Policy Summarisation"
    },
    "a20e7aa50600de9a7811e920a3fc5b14": {
      "source_id": "a20e7aa50600de9a7811e920a3fc5b14",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53040,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "The Need for a Meta-Architecture for Robot Autonomy"
    },
    "16071e9e4803e5d35d76d898117df2c8": {
      "source_id": "16071e9e4803e5d35d76d898117df2c8",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49815,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Discriminator-Weighted Offline Imitation Learning from Suboptimal Demonstrations"
    },
    "3673d000a2f561d403d057914c6a0fba": {
      "source_id": "3673d000a2f561d403d057914c6a0fba",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 64912,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Toward Supporting Perceptual Complementarity in Human-AI Collaboration via Refle"
    },
    "813257bd6020c6436bfd74af92e7044c": {
      "source_id": "813257bd6020c6436bfd74af92e7044c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19950,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Latent Properties of Lifelong Learning Systems"
    },
    "4ae4bd88689053a34a21932c4cee6b60": {
      "source_id": "4ae4bd88689053a34a21932c4cee6b60",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 249211,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "The History of AI Rights Research"
    },
    "6b2e6017f5a03ddce8d9c629f4bb4c32": {
      "source_id": "6b2e6017f5a03ddce8d9c629f4bb4c32",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38389,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Recognition of All Categories of Entities by AI"
    },
    "1cb7117de1a9757a88adfe9a4f8db0b6": {
      "source_id": "1cb7117de1a9757a88adfe9a4f8db0b6",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 74371,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "A Review of the Convergence of 5G/6G Architecture and Deep Learning"
    },
    "cada59fae9928dc643027aa3fccf7281": {
      "source_id": "cada59fae9928dc643027aa3fccf7281",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23797,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Discovering Agents"
    },
    "ade5f50f2414624de91669067bb2e6de": {
      "source_id": "ade5f50f2414624de91669067bb2e6de",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48312,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Information-Theoretic Equivalence of Entropic Multi-Marginal Optimal Transport: "
    },
    "41f01220cbd1248ed9e690314dafb6ca": {
      "source_id": "41f01220cbd1248ed9e690314dafb6ca",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 411487,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "The Brussels Effect and Artificial Intelligence: How EU regulation will impact t"
    },
    "49fd4c87928829fec0d60f6258537895": {
      "source_id": "49fd4c87928829fec0d60f6258537895",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12601,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Reinforcement Learning for Hardware Security: Opportunities, Developments, and C"
    },
    "013103aafe00cc7cd75a562d9bebc30f": {
      "source_id": "013103aafe00cc7cd75a562d9bebc30f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31159,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Correct-by-Construction Runtime Enforcement in AI -- A Survey"
    },
    "a52d7e463ed251177b52686e7428a683": {
      "source_id": "a52d7e463ed251177b52686e7428a683",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57786,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "A Technique to Create Weaker Abstract Board Game Agents via Reinforcement Learni"
    },
    "eb041408df75f83a2e148e47bee0ec16": {
      "source_id": "eb041408df75f83a2e148e47bee0ec16",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49093,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Improving Language Model Prompting in Support of Semi-autonomous Task Learning"
    },
    "8bd5e5d8b24864fde396560cd272721a": {
      "source_id": "8bd5e5d8b24864fde396560cd272721a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48685,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazi"
    },
    "b9f4aa2968038b7d64602b63cdc934eb": {
      "source_id": "b9f4aa2968038b7d64602b63cdc934eb",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45184,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "LCRL: Certified Policy Synthesis via Logically-Constrained Reinforcement Learnin"
    },
    "df249401a5807eac2045fb9774bcff48": {
      "source_id": "df249401a5807eac2045fb9774bcff48",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54728,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Understanding Hindsight Goal Relabeling from a Divergence Minimization Perspecti"
    },
    "ab6a3d0259d742188cc5db00faf891c0": {
      "source_id": "ab6a3d0259d742188cc5db00faf891c0",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 66255,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Learning When to Advise Human Decision Makers"
    },
    "81938f6faa998c07c6d7ff5111dddc8e": {
      "source_id": "81938f6faa998c07c6d7ff5111dddc8e",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 67856,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Repairing Bugs in Python Assignments Using Large Language Models"
    },
    "1ba9a6fd67dca3f83480f37d6a86fdcb": {
      "source_id": "1ba9a6fd67dca3f83480f37d6a86fdcb",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43629,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Quantifying Harm"
    },
    "d89dc844516a9ac02e01b504b89427f3": {
      "source_id": "d89dc844516a9ac02e01b504b89427f3",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18532,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Establishing Meta-Decision-Making for AI: An Ontology of Relevance, Representati"
    },
    "96251f8fa8c416e4bcb044e7d9e74196": {
      "source_id": "96251f8fa8c416e4bcb044e7d9e74196",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35778,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Knowledge-Grounded Reinforcement Learning"
    },
    "819170fb22a3fc275106d95277eab8da": {
      "source_id": "819170fb22a3fc275106d95277eab8da",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46014,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Generating Executable Action Plans with Environmentally-Aware Language Models"
    },
    "7d0c1226cf8dfc6c92d542d55db67c13": {
      "source_id": "7d0c1226cf8dfc6c92d542d55db67c13",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43700,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Human-AI Coordination via Human-Regularized Search and Learning"
    },
    "0a40d2de6851709b88321bb64d77e4a6": {
      "source_id": "0a40d2de6851709b88321bb64d77e4a6",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42174,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Toward Next-Generation Artificial Intelligence: Catalyzing the NeuroAI Revolutio"
    },
    "51462a55534263d1947608fbc3e4d9ef": {
      "source_id": "51462a55534263d1947608fbc3e4d9ef",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 197310,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "A.I. Robustness: a Human-Centered Perspective on Technological Challenges and Op"
    },
    "40adcd148ad64c639258cb6501b2feba": {
      "source_id": "40adcd148ad64c639258cb6501b2feba",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 315580,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Gathering Strength, Gathering Storms: The One Hundred Year Study on Artificial I"
    },
    "311e5bef699a091625a3d1296b228fd2": {
      "source_id": "311e5bef699a091625a3d1296b228fd2",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46899,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Relative Behavioral Attributes: Filling the Gap between Symbolic Goal Specificat"
    },
    "ae1cd229c3a155b3dfd0e6dcafcdb8f0": {
      "source_id": "ae1cd229c3a155b3dfd0e6dcafcdb8f0",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 86577,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Liability regimes in the age of AI: a use-case driven analysis of the burden of "
    },
    "c0390431ab3a215a3f4cc26ded0043e0": {
      "source_id": "c0390431ab3a215a3f4cc26ded0043e0",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 106204,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Examining the Differential Risk from High-level Artificial Intelligence and the "
    },
    "dfc4726f702c6b413458d237cec85e99": {
      "source_id": "dfc4726f702c6b413458d237cec85e99",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 79682,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Verifiable Reinforcement Learning via Policy Extraction"
    },
    "2d77f5b7adcea3e2894cdf4f02ab6b8b": {
      "source_id": "2d77f5b7adcea3e2894cdf4f02ab6b8b",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 63270,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "To Trust Or Not To Trust A Classifier"
    },
    "7d06b53a7df5e114f681ccfbdb97df41": {
      "source_id": "7d06b53a7df5e114f681ccfbdb97df41",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 139511,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Relational inductive biases, deep learning, and graph networks"
    },
    "f1853376f2ccc7f00be031224a4be5c2": {
      "source_id": "f1853376f2ccc7f00be031224a4be5c2",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29262,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Relational Deep Reinforcement Learning"
    },
    "583c6e401e206e4040db4b5538838945": {
      "source_id": "583c6e401e206e4040db4b5538838945",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33090,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Benchmarking Neural Network Robustness to Common Corruptions and Surface Variati"
    },
    "bfaa915ab1de8d52588c4ac72b59e731": {
      "source_id": "bfaa915ab1de8d52588c4ac72b59e731",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54985,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Deep Learning in the Wild"
    },
    "b6618e5296fd0bba272efb4857db70ce": {
      "source_id": "b6618e5296fd0bba272efb4857db70ce",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57218,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Learning Plannable Representations with Causal InfoGAN"
    },
    "8ef5690345b73a743df15a558ea00844": {
      "source_id": "8ef5690345b73a743df15a558ea00844",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40656,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Learning Actionable Representations from Visual Observations"
    },
    "490dfc6810f0f52ebd4d2408e4667a8d": {
      "source_id": "490dfc6810f0f52ebd4d2408e4667a8d",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 106484,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Adversarial Vision Challenge"
    },
    "e1689a1cb524a05d91cb438338f99d2e": {
      "source_id": "e1689a1cb524a05d91cb438338f99d2e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24885,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Cycle-of-Learning for Autonomous Systems from Human Interaction"
    },
    "84fc757d197d496d48115712641d4413": {
      "source_id": "84fc757d197d496d48115712641d4413",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34777,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Neural Guided Constraint Logic Programming for Program Synthesis"
    },
    "4aede7012db72353b00aed02610dfbe3": {
      "source_id": "4aede7012db72353b00aed02610dfbe3",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42120,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Training for Faster Adversarial Robustness Verification via Inducing ReLU Stabil"
    },
    "a0402d3a00d97e1ef8fdf756457d1fc1": {
      "source_id": "a0402d3a00d97e1ef8fdf756457d1fc1",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55604,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Episodic Curiosity through Reachability"
    },
    "7cfec0e7f7a0495a698449ab0ce02fcc": {
      "source_id": "7cfec0e7f7a0495a698449ab0ce02fcc",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59586,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Meta-Learning: A Survey"
    },
    "5d8d41b153d13a07ae64c039e96fd6f4": {
      "source_id": "5d8d41b153d13a07ae64c039e96fd6f4",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27841,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "CURIOUS: Intrinsically Motivated Modular Multi-Goal Reinforcement Learning"
    },
    "0ebf56aabf1e884f7b17b2c15bef9f65": {
      "source_id": "0ebf56aabf1e884f7b17b2c15bef9f65",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42776,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Assessing Generalization in Deep Reinforcement Learning"
    },
    "7a4d122a4cd5209895b35ae56a0f877f": {
      "source_id": "7a4d122a4cd5209895b35ae56a0f877f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43756,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Woulda, Coulda, Shoulda: Counterfactually-Guided Policy Search"
    },
    "12c150d8843037ccd13f8fc2e07f2816": {
      "source_id": "12c150d8843037ccd13f8fc2e07f2816",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44777,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Off-Policy Deep Reinforcement Learning without Exploration"
    },
    "a444c76549f57bb1172c5b8c9a1dae55": {
      "source_id": "a444c76549f57bb1172c5b8c9a1dae55",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 95715,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Paired Open-Ended Trailblazer (POET): Endlessly Generating Increasingly Complex "
    },
    "5089b9ff46e9fa8a38f1e3a690398b44": {
      "source_id": "5089b9ff46e9fa8a38f1e3a690398b44",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34738,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Risk-Aware Active Inverse Reinforcement Learning"
    },
    "f95f04b04ff7a4b140b3d8687ce52165": {
      "source_id": "f95f04b04ff7a4b140b3d8687ce52165",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73505,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "The Hanabi Challenge: A New Frontier for AI Research"
    },
    "1f18fc5bb4cfac9854827d17db56b89b": {
      "source_id": "1f18fc5bb4cfac9854827d17db56b89b",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37523,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "From Language to Goals: Inverse Reinforcement Learning for Vision-Based Instruct"
    },
    "7aa7add91c4d9bde714f10971f2937c3": {
      "source_id": "7aa7add91c4d9bde714f10971f2937c3",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 76293,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Diagnosing Bottlenecks in Deep Q-learning Algorithms"
    },
    "fc1f4ca4b9f0f52f0aa4ef8a5f020dda": {
      "source_id": "fc1f4ca4b9f0f52f0aa4ef8a5f020dda",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 80457,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "SLIDE : In Defense of Smart Algorithms over Hardware Acceleration for Large-Scal"
    },
    "1971dfd835458fc825a2c897f3b04a74": {
      "source_id": "1971dfd835458fc825a2c897f3b04a74",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38756,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "A Survey of Reinforcement Learning Informed by Natural Language"
    },
    "29912d5e770917b0e0ab6c5a2649c725": {
      "source_id": "29912d5e770917b0e0ab6c5a2649c725",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37340,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "On Inductive Biases in Deep Reinforcement Learning"
    },
    "9588974df808d2b183e54b38430c5c51": {
      "source_id": "9588974df808d2b183e54b38430c5c51",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40939,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Improving Sample Efficiency in Model-Free Reinforcement Learning from Images"
    },
    "28785e694de9fb37dbd4a8b9b0d92e0c": {
      "source_id": "28785e694de9fb37dbd4a8b9b0d92e0c",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42434,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Integrating Behavior Cloning and Reinforcement Learning for Improved Performance"
    },
    "c1201a83d177fa631e89a6d5fbc36d87": {
      "source_id": "c1201a83d177fa631e89a6d5fbc36d87",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55870,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Stabilizing Transformers for Reinforcement Learning"
    },
    "77f8c55109ae4cb3886681bac6dd6ac8": {
      "source_id": "77f8c55109ae4cb3886681bac6dd6ac8",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57402,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Planning with Goal-Conditioned Policies"
    },
    "aff90061d03fe488dacd3c35f4c365c7": {
      "source_id": "aff90061d03fe488dacd3c35f4c365c7",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34778,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Dream to Control: Learning Behaviors by Latent Imagination"
    },
    "50f785472f9f981759bb03991e5b1643": {
      "source_id": "50f785472f9f981759bb03991e5b1643",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35493,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Deep Bayesian Reward Learning from Preferences"
    },
    "2d5fd096432bd8b9f56ee0826f75f872": {
      "source_id": "2d5fd096432bd8b9f56ee0826f75f872",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57726,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "What Can Learned Intrinsic Rewards Capture?"
    },
    "7010710588ce3649be49076da7782fd4": {
      "source_id": "7010710588ce3649be49076da7782fd4",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 154708,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "A high-precision abundance analysis of the nuclear benchmark star HD 20"
    },
    "e918941f9bdc21408c0d04fd0b22f31e": {
      "source_id": "e918941f9bdc21408c0d04fd0b22f31e",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45798,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "State-only Imitation with Transition Dynamics Mismatch"
    },
    "f3b2634f69a529a49c8d5560d8ecd2d2": {
      "source_id": "f3b2634f69a529a49c8d5560d8ecd2d2",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43667,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "On Catastrophic Interference in Atari 2600 Games"
    },
    "67acbfb8e5ef736598192ed5586d9eec": {
      "source_id": "67acbfb8e5ef736598192ed5586d9eec",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45264,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "\"Other-Play\" for Zero-Shot Coordination"
    },
    "14ff96fd6948a4bf59798c37b18010fb": {
      "source_id": "14ff96fd6948a4bf59798c37b18010fb",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 142726,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Curriculum Learning for Reinforcement Learning Domains: A Framework and Survey"
    },
    "17f6f61338a0d2b08005d3b077bdb349": {
      "source_id": "17f6f61338a0d2b08005d3b077bdb349",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 178460,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Constrained Policy Optimization"
    },
    "0f2df22712848c03edc4e6eed0d6ef3a": {
      "source_id": "0f2df22712848c03edc4e6eed0d6ef3a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41600,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Verification of Non-Linear Specifications for Neural Networks"
    },
    "f18e14f67088d23c5a8275e213727bc3": {
      "source_id": "f18e14f67088d23c5a8275e213727bc3",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35841,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Adversarial Robustness through Local Linearization"
    },
    "0e44e17c3879b66756afe3fa13309399": {
      "source_id": "0e44e17c3879b66756afe3fa13309399",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 70131,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Fine-Tuning Language Models from Human Preferences"
    },
    "20004f3f3339a4fd2d63ed6245d5b4d1": {
      "source_id": "20004f3f3339a4fd2d63ed6245d5b4d1",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27508,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Active Reinforcement Learning: Observing Rewards at a Cost"
    },
    "b29568681c7d32279ac192f2aa579bc2": {
      "source_id": "b29568681c7d32279ac192f2aa579bc2",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 182184,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "An Overview of Catastrophic AI Risks"
    },
    "93539db90a16dfabd0f5c054b1185c78": {
      "source_id": "93539db90a16dfabd0f5c054b1185c78",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59384,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "TASRA: a Taxonomy and Analysis of Societal-Scale Risks from AI"
    },
    "6fecf371e716d4a0bbc3c7436c892934": {
      "source_id": "6fecf371e716d4a0bbc3c7436c892934",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51371,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Interpretability in the Wild: a Circuit for Indirect Object Identification in GP"
    },
    "6b434c3af993d14bb9e0b3474c6b9ba4": {
      "source_id": "6b434c3af993d14bb9e0b3474c6b9ba4",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43609,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Polysemanticity and Capacity in Neural Networks"
    },
    "aed15d8ec6db81a2ddedc674e97fd57a": {
      "source_id": "aed15d8ec6db81a2ddedc674e97fd57a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 64725,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Adversarial Training for High-Stakes Reliability"
    },
    "6252189f483ff7ffa7478e2b3de119f2": {
      "source_id": "6252189f483ff7ffa7478e2b3de119f2",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41554,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "X-Risk Analysis for AI Research."
    },
    "a112033c840b076258ff2dbd262f1ee5": {
      "source_id": "a112033c840b076258ff2dbd262f1ee5",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 152216,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Actionable Guidance for High-Consequence AI Risk Management: Towards Standards A"
    },
    "f1cf4d6f754ad5fe761a277650a4471a": {
      "source_id": "f1cf4d6f754ad5fe761a277650a4471a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45437,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Sociotechnical Specification for the Broader Impacts of Autonomous Vehicles."
    },
    "c0a91469fb17f17e98e77fca82a4af84": {
      "source_id": "c0a91469fb17f17e98e77fca82a4af84",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51188,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Towards more Generalizable One-shot Visual Imitation Learning."
    },
    "39c7fd0f423aa0036d839457e6618279": {
      "source_id": "39c7fd0f423aa0036d839457e6618279",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 230343,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Building Human Values into Recommender Systems: An Interdisciplinary Synthesis."
    },
    "455b444cf51f7bbd0d6bb1fd9d2d1662": {
      "source_id": "455b444cf51f7bbd0d6bb1fd9d2d1662",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 68562,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "How Would The Viewer Feel? Estimating Wellbeing From Video Scenarios."
    },
    "0f2f1b0c49e943459b2b5d1a55c9d2b5": {
      "source_id": "0f2f1b0c49e943459b2b5d1a55c9d2b5",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44005,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Inferring Rewards from Language in Context."
    },
    "9ad41374f53f74d9e1544c663c777e2a": {
      "source_id": "9ad41374f53f74d9e1544c663c777e2a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 78987,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Estimating and Penalizing Induced Preference Shifts in Recommender Systems."
    },
    "4bcb6e5e5420699a0b0dc34ed6e69573": {
      "source_id": "4bcb6e5e5420699a0b0dc34ed6e69573",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53372,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Skill Preferences: Learning to Extract and Execute Robotic Skills from Human Fee"
    },
    "92cde803b8cb2b1dc470ec723ca1c4f3": {
      "source_id": "92cde803b8cb2b1dc470ec723ca1c4f3",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49912,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Optimal Cost Design for Model Predictive Control."
    },
    "5585b20ff1241af9c36663ebfc5f0174": {
      "source_id": "5585b20ff1241af9c36663ebfc5f0174",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 106525,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Cross-Domain Imitation Learning via Optimal Transport."
    },
    "dece29c717e8505489f1ea19cef5111e": {
      "source_id": "dece29c717e8505489f1ea19cef5111e",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54274,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "The MAGICAL Benchmark for Robust Imitation."
    },
    "7b1fcae71ae04aa54b08181819ab1d71": {
      "source_id": "7b1fcae71ae04aa54b08181819ab1d71",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32440,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Interpretable and Pedagogical Examples."
    },
    "5e6dd6e10068aa225fb1418ca71e4605": {
      "source_id": "5e6dd6e10068aa225fb1418ca71e4605",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30281,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Understanding Learned Reward Functions."
    },
    "1e952d5dd2d90cafe7b6f166d1aa785e": {
      "source_id": "1e952d5dd2d90cafe7b6f166d1aa785e",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32534,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "DERAIL: Diagnostic Environments for Reward And Imitation Learning."
    },
    "673f5a66b8253c075b43c350fdf5514f": {
      "source_id": "673f5a66b8253c075b43c350fdf5514f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31407,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Choice Set Misspecification in Reward Inference."
    },
    "1405aec1edf8be7e9d05c85a8fbb24fa": {
      "source_id": "1405aec1edf8be7e9d05c85a8fbb24fa",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 184160,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Quantifying Hypothesis Space Misspecification in Learning from Human-Robot Demon"
    },
    "117d259472867be5546d128c227fecea": {
      "source_id": "117d259472867be5546d128c227fecea",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 63543,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Hierarchically Decoupled Imitation for Morphological Transfer."
    },
    "d5d871f8c38b842379b2abc4ca2280e5": {
      "source_id": "d5d871f8c38b842379b2abc4ca2280e5",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28187,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Using Machine Learning to Guide Cognitive Modeling: A Case Study in Moral Reason"
    },
    "e442648d2f9714c2ca63c57376d0d94c": {
      "source_id": "e442648d2f9714c2ca63c57376d0d94c",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43495,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Social Cohesion in Autonomous Driving."
    },
    "858b9038e0a18fffa0c742d763b09aec": {
      "source_id": "858b9038e0a18fffa0c742d763b09aec",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44208,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Repeated Inverse Reinforcement Learning."
    },
    "f78c7ec5be74c3e3d4048db6d46d80bf": {
      "source_id": "f78c7ec5be74c3e3d4048db6d46d80bf",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50563,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Learning Representations that Enable Generalization in Assistive Tasks."
    },
    "a42af15d067364d3cf40823a78a575c4": {
      "source_id": "a42af15d067364d3cf40823a78a575c4",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44494,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Safety Assurances for Human-Robot Interaction via Confidence-aware Game-theoreti"
    },
    "fda9554f87844fc3f415ef52fa25ef4e": {
      "source_id": "fda9554f87844fc3f415ef52fa25ef4e",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 78975,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Fleet-DAgger: Interactive Robot Fleet Learning with Scalable Human Supervision."
    },
    "dfe8653b4e58290986ad480e1846b2f5": {
      "source_id": "dfe8653b4e58290986ad480e1846b2f5",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38438,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Hierarchical Few-Shot Imitation with Skill Transition Models."
    },
    "4383a47169e01d45b34bbc3cb82c2248": {
      "source_id": "4383a47169e01d45b34bbc3cb82c2248",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41911,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Learning Visuo-Haptic Skewering Strategies for Robot-Assisted Feeding."
    },
    "2645dbafdafd63d5516d352df81a482d": {
      "source_id": "2645dbafdafd63d5516d352df81a482d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56978,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Balancing Efficiency and Comfort in Robot-Assisted Bite Transfer."
    },
    "f9f624688935e74ff0ecb044bab69012": {
      "source_id": "f9f624688935e74ff0ecb044bab69012",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 63797,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Learning from Imperfect Demonstrations via Adversarial Confidence Transfer."
    },
    "ad62fda39f25ed183773e91e608c03e8": {
      "source_id": "ad62fda39f25ed183773e91e608c03e8",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 196993,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Learning Latent Actions to Control Assistive Robots."
    },
    "590c3520e8afde51315697b5e8bfd6d0": {
      "source_id": "590c3520e8afde51315697b5e8bfd6d0",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 64307,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Optimal Behavior Prior: Improving Human-AI Collaboration Through Generalizable H"
    },
    "07c0229080ab239986cce69f8756c5ed": {
      "source_id": "07c0229080ab239986cce69f8756c5ed",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11589,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "JEDAI: A System for Skill-Aligned Explainable Robot Planning."
    },
    "37dde144c26b9e56b323eece60d135e9": {
      "source_id": "37dde144c26b9e56b323eece60d135e9",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 109449,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Joint Communication and Motion Planning for Cobots."
    },
    "7dd0fe90b65c521004bbc3247712b37f": {
      "source_id": "7dd0fe90b65c521004bbc3247712b37f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43155,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Pragmatic Image Compression for Human-in-the-Loop Decision-Making."
    },
    "b208fd79f647fe24573decb2bc265c15": {
      "source_id": "b208fd79f647fe24573decb2bc265c15",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 72494,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "On complementing end-to-end human behavior predictors with planning."
    },
    "e27044932d54ad260c56dfa4d367950d": {
      "source_id": "e27044932d54ad260c56dfa4d367950d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 72703,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Analyzing Human Models that Adapt Online."
    },
    "173c85a03b5009b4ae8420e7e1b70c42": {
      "source_id": "173c85a03b5009b4ae8420e7e1b70c42",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 92995,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Dynamically Switching Human Prediction Models for Efficient Planning."
    },
    "66b00ffd67710860ef809f8f79f738b6": {
      "source_id": "66b00ffd67710860ef809f8f79f738b6",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54466,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Multi-Principal Assistance Games."
    },
    "232f0e18dbb9e72281bc79f8098ff6c7": {
      "source_id": "232f0e18dbb9e72281bc79f8098ff6c7",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 72237,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Courteous Autonomous Cars."
    },
    "7065ba6b881fd64f9b13a53f2347a8c0": {
      "source_id": "7065ba6b881fd64f9b13a53f2347a8c0",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39867,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Do You Want Your Autonomous Car to Drive Like You?."
    },
    "f2ac3447dea6aeca87ec27ef47bc5959": {
      "source_id": "f2ac3447dea6aeca87ec27ef47bc5959",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43883,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Generating Plans that Predict Themselves."
    },
    "c9abd238dd2b341d1ddbf188bbc161f4": {
      "source_id": "c9abd238dd2b341d1ddbf188bbc161f4",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61036,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "It Takes Four to Tango: Multiagent Self Play for Automatic Curriculum Generation"
    },
    "2d9e86d8bb50bdb387be62488d4a0ce5": {
      "source_id": "2d9e86d8bb50bdb387be62488d4a0ce5",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11465,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "PantheonRL: A MARL Library for Dynamic Training Interactions."
    },
    "a11519be70a6561048be6f0efca35b21": {
      "source_id": "a11519be70a6561048be6f0efca35b21",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 67369,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "COLA: Consistent Learning with Opponent-Learning Awareness."
    },
    "030d3ea251808602510afd8f864f4fec": {
      "source_id": "030d3ea251808602510afd8f864f4fec",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 88212,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Similarity-based Cooperation."
    },
    "a24b6a306ac63ccf45187b66d81587ef": {
      "source_id": "a24b6a306ac63ccf45187b66d81587ef",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62022,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "No\u2011regret Learning in Dynamic Stackelberg Games."
    },
    "8b6e99864384b2696f368597979fd9f1": {
      "source_id": "8b6e99864384b2696f368597979fd9f1",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48173,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Generalizing meanings from partners to populations: Hierarchical inference suppo"
    },
    "8606d4d1cec21bda37ddc73d86aebc7f": {
      "source_id": "8606d4d1cec21bda37ddc73d86aebc7f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 276136,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Implementing Mediators with Asynchronous Cheap Talk."
    },
    "21f2bad360e8a7d2095c0303a997d179": {
      "source_id": "21f2bad360e8a7d2095c0303a997d179",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50808,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Self-confirming price-prediction strategies for simultaneous one-shot auctions."
    },
    "0e8afc013c84e4e740d4bcf89b1df551": {
      "source_id": "0e8afc013c84e4e740d4bcf89b1df551",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 176021,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Causality, Responsibility and Blame in Team Plans."
    },
    "9f4e3db3a06a3c145e79b68e853a3a8d": {
      "source_id": "9f4e3db3a06a3c145e79b68e853a3a8d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 148487,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Dynamic Awareness."
    },
    "c6e1d26604cebcd7d181573dfee094ae": {
      "source_id": "c6e1d26604cebcd7d181573dfee094ae",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 86539,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "AMP: Adversarial Motion Priors for Stylized Physics-Based Character Control."
    },
    "21a3c572c561138809f7c04e6d53652a": {
      "source_id": "21a3c572c561138809f7c04e6d53652a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62903,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Perceptual Adversarial Robustness: Defense Against Unseen Threat Models."
    },
    "a5042b5aab956d77d2e18b28ac40b521": {
      "source_id": "a5042b5aab956d77d2e18b28ac40b521",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39592,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Adversarial Training with Voronoi Constraints."
    },
    "0fdf5b2c39518e9d4970baa99364266e": {
      "source_id": "0fdf5b2c39518e9d4970baa99364266e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29518,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Natural Adversarial Examples."
    },
    "810e39a469917c9d5369a7044908f820": {
      "source_id": "810e39a469917c9d5369a7044908f820",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47903,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Pretraining Graph Neural Networks for few-shot Analog Circuit Modeling and Desig"
    },
    "e5379b568f77d362f6dc0d5b1068e2ac": {
      "source_id": "e5379b568f77d362f6dc0d5b1068e2ac",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42913,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Sim-to-Real via Sim-to-Seg: End-to-end Off-road Autonomous Driving Without Real "
    },
    "fae603fcbb9051d84ca0564503cd57c7": {
      "source_id": "fae603fcbb9051d84ca0564503cd57c7",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30709,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "DayDreamer: World Models for Physical Robot Learning."
    },
    "5b8bd5bb5035743d08628ee9fe478a79": {
      "source_id": "5b8bd5bb5035743d08628ee9fe478a79",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39217,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Director: Deep Hierarchical Planning from Pixels."
    },
    "da793a00734aa3aaaf8303cf295d9056": {
      "source_id": "da793a00734aa3aaaf8303cf295d9056",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46845,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Learning Visual Robotic Control Efficiently with Contrastive Pre-training and Da"
    },
    "19783db6de007b65d10f4ddf4c52fa9a": {
      "source_id": "19783db6de007b65d10f4ddf4c52fa9a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48524,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embod"
    },
    "1670e43adbfe4218fd7b37b67941aee1": {
      "source_id": "1670e43adbfe4218fd7b37b67941aee1",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42223,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Zero-Shot Text-Guided Object Generation with Dream Fields,."
    },
    "bde187870c058fb9de22311837aff903": {
      "source_id": "bde187870c058fb9de22311837aff903",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35992,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Weakly Supervised Correspondence Learning."
    },
    "9a865c22fd02cd194c81db733aa6378b": {
      "source_id": "9a865c22fd02cd194c81db733aa6378b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44428,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Automatic Correction of Human Translations."
    },
    "f73ccdf3c4176eb4eead1b5caa8df223": {
      "source_id": "f73ccdf3c4176eb4eead1b5caa8df223",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59147,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Path Independent Equilibrium Models Can Better Exploit Test-Time Computation."
    },
    "75e887cfeec8a3e0b7d582e3ccd3c72a": {
      "source_id": "75e887cfeec8a3e0b7d582e3ccd3c72a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 65876,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Learning Deterministic Finite Automata Decompositions from Examples and Demonstr"
    },
    "1118b36d97a0748c1ebc2e7d85f27ab1": {
      "source_id": "1118b36d97a0748c1ebc2e7d85f27ab1",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39790,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Measuring mathematical problem solving with the math dataset."
    },
    "a262d9743e00d85523b73e9284559b01": {
      "source_id": "a262d9743e00d85523b73e9284559b01",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 69479,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Behavior From the Void: Unsupervised Active Pre-Training."
    },
    "641ff6dee15b77cf2ed27c75d450a762": {
      "source_id": "641ff6dee15b77cf2ed27c75d450a762",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56937,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "State Entropy Maximization with Random Encoders for Efficient Exploration."
    },
    "13e9b257e46a73161a608cbdc1b435c6": {
      "source_id": "13e9b257e46a73161a608cbdc1b435c6",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40070,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Unsupervised Learning of Visual 3D Keypoints for Control."
    },
    "eaf0dda90bdb58bcf5427325b2de713c": {
      "source_id": "eaf0dda90bdb58bcf5427325b2de713c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42016,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Contrastive Code Representation Learning."
    },
    "82d12f25322fcc11c2fa9be90b2dcec4": {
      "source_id": "82d12f25322fcc11c2fa9be90b2dcec4",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42498,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Offline-to-Online Reinforcement Learning via Balanced Replay and Pessimistic Q-E"
    },
    "fe1c58202b218fa622a3d106fc7f9b41": {
      "source_id": "fe1c58202b218fa622a3d106fc7f9b41",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47548,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Improving Computational Efficiency in Visual Reinforcement Learning via Stored E"
    },
    "40981833e4aac1ab5d23165b64a6374f": {
      "source_id": "40981833e4aac1ab5d23165b64a6374f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42697,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "URLB: Unsupervised Reinforcement Learning Benchmark."
    },
    "2ddfc52c8f61abd0d0abe51b2f1874bd": {
      "source_id": "2ddfc52c8f61abd0d0abe51b2f1874bd",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58015,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Learning State Representations from Random Deep Action-Conditional Predictions."
    },
    "686b8ae940e6d7723afd773f604f4057": {
      "source_id": "686b8ae940e6d7723afd773f604f4057",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47769,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Agent-aware state estimation for autonomous vehicles."
    },
    "5c91e99695035a964333ff57768fbb8c": {
      "source_id": "5c91e99695035a964333ff57768fbb8c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32810,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Measuring Massive Multitask Language Understanding."
    },
    "a3b00e2c7467d45bd21bd31a2dc0746a": {
      "source_id": "a3b00e2c7467d45bd21bd31a2dc0746a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50468,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Emergent Complexity and Zero-shot Transfer via Unsupervised Environment Design."
    },
    "a99ca4e2ecd6377ec84b271d6fe50ca6": {
      "source_id": "a99ca4e2ecd6377ec84b271d6fe50ca6",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39676,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Sparse Graphical Memory for Robust Planning."
    },
    "6af2c5740e297388c912560e7914299f": {
      "source_id": "6af2c5740e297388c912560e7914299f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48391,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Using Natural Language and Program Abstractions to Instill Human Inductive Biase"
    },
    "2294e451ea1f1e52bc3fbfefa14f4d0e": {
      "source_id": "2294e451ea1f1e52bc3fbfefa14f4d0e",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 80228,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Disentangling Abstraction from Statistical Pattern Matching in Human and Machine"
    },
    "f60dc3ec42354be607c544ba174b952f": {
      "source_id": "f60dc3ec42354be607c544ba174b952f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 90405,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Reinforcement Learning of Implicit and Explicit Control Flow Instructions."
    },
    "568f000a038e4bfbbfcc6c15ab68b948": {
      "source_id": "568f000a038e4bfbbfcc6c15ab68b948",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49221,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Passive Attention in Artificial Neural Networks Predicts Human Visual Selectivit"
    },
    "c81baef1bf42629d3a5589b13b0260b9": {
      "source_id": "c81baef1bf42629d3a5589b13b0260b9",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 103979,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Scaling up psychology via Scientific Regret Minimization."
    },
    "d633e3343d2a7ddf57976272300d828b": {
      "source_id": "d633e3343d2a7ddf57976272300d828b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55267,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Value-laden Disciplinary Shifts in Machine Learning."
    },
    "56c4bb5d101fa24c150799b4aad96cd0": {
      "source_id": "56c4bb5d101fa24c150799b4aad96cd0",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39920,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Aligning AI With Shared Human Values."
    },
    "2315ba0ad7702ea8a2ce47bc77411cab": {
      "source_id": "2315ba0ad7702ea8a2ce47bc77411cab",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19554,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "A Broader View on Bias in Automated Decision-Making: Reflecting on Epistemology "
    },
    "f4a05e444ea709d5ea0bcf5778064c84": {
      "source_id": "f4a05e444ea709d5ea0bcf5778064c84",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 88626,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Multi-Objective Policy Gradients with Topological Constraints."
    },
    "3df04342ed5b89b25dc3f16272c3244c": {
      "source_id": "3df04342ed5b89b25dc3f16272c3244c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 203177,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "A Unified Survey on Anomaly, Novelty, Open-Set, and Out-of-Distribution Detectio"
    },
    "ab8ad7fbfc76f44a2912cd5d42a82283": {
      "source_id": "ab8ad7fbfc76f44a2912cd5d42a82283",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 78836,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Policy Gradient Bayesian Robust Optimization for Imitation Learning."
    },
    "2715c5be751ae5c0f42ddb691655c46c": {
      "source_id": "2715c5be751ae5c0f42ddb691655c46c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34623,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution General"
    },
    "8cd0e4f9e43b214ea3cf807ff5963a32": {
      "source_id": "8cd0e4f9e43b214ea3cf807ff5963a32",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26584,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Pretrained Transformers Improve Out-of-Distribution Robustness."
    },
    "db5b97196116c8434680b8fc34eac6e3": {
      "source_id": "db5b97196116c8434680b8fc34eac6e3",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35743,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty."
    },
    "1381c91c590639748c5f5f1a9aae4e24": {
      "source_id": "1381c91c590639748c5f5f1a9aae4e24",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 168624,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Bayesian Robustness: A Nonasymptotic Viewpoint."
    },
    "f84b0a1d30cf89ae9236ce82a3e24551": {
      "source_id": "f84b0a1d30cf89ae9236ce82a3e24551",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 135660,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "A Risk-Sensitive Finite-Time Reachability Approach for Safety of Stochastic Dyna"
    },
    "1c1b01ae4d1233f4b49ea050c8fbc0fc": {
      "source_id": "1c1b01ae4d1233f4b49ea050c8fbc0fc",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32688,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty."
    },
    "3d6bfae31f2f8beca77dacf06817bc2e": {
      "source_id": "3d6bfae31f2f8beca77dacf06817bc2e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35874,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations."
    },
    "3f4254f317701007b2a5e1c3253ca325": {
      "source_id": "3f4254f317701007b2a5e1c3253ca325",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36144,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Deep Anomaly Detection with Outlier Exposure."
    },
    "f3749553512e1b6699cae2a8cf8f43d0": {
      "source_id": "f3749553512e1b6699cae2a8cf8f43d0",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36341,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise."
    },
    "7902a1192772be3d4b2622e184c1ddf1": {
      "source_id": "7902a1192772be3d4b2622e184c1ddf1",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 90916,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Differential Assessment of Black-Box AI Agents.."
    },
    "73592b70a3f5a792afd4c896bf5148de": {
      "source_id": "73592b70a3f5a792afd4c896bf5148de",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62489,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Translating Neuralese."
    },
    "838c66e61a6f18fb27673c2ff4daef22": {
      "source_id": "838c66e61a6f18fb27673c2ff4daef22",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 69611,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Towards Deep Learning Models Resistant to Adversarial Attacks"
    },
    "eb789c40c7c9d84c091b2a3bf6cbd920": {
      "source_id": "eb789c40c7c9d84c091b2a3bf6cbd920",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38622,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Adversarial Examples Are a Natural Consequence of Test Error in Noise"
    },
    "81cbec0f7ca3bf7ecaabb78aae5cad75": {
      "source_id": "81cbec0f7ca3bf7ecaabb78aae5cad75",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 89267,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Motivating the Rules of the Game for Adversarial Example Research"
    },
    "b3ec07e1af2d6ccb8c6301bde1a1b9fc": {
      "source_id": "b3ec07e1af2d6ccb8c6301bde1a1b9fc",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46920,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Certified Defenses against Adversarial Examples"
    },
    "8b5c292409e3da5233abebbf0b36200b": {
      "source_id": "8b5c292409e3da5233abebbf0b36200b",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32231,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "ImageNet-trained CNNs are biased towards texture; increasing shape bias improves"
    },
    "f3b63431438b60d2d370268721746c7c": {
      "source_id": "f3b63431438b60d2d370268721746c7c",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52541,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "On Calibration of Modern Neural Networks"
    },
    "c356f4bb1fc1101d2792f15a9195db94": {
      "source_id": "c356f4bb1fc1101d2792f15a9195db94",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45072,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "TruthfulQA: Measuring How Models Mimic Human Falsehoods"
    },
    "dc43714b96ecfc2beed9d3c86b31c971": {
      "source_id": "dc43714b96ecfc2beed9d3c86b31c971",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 232530,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Truthful AI: Developing and governing AI that does not lie"
    },
    "8b4d803b67aaf3b9b730b8d8b0700424": {
      "source_id": "8b4d803b67aaf3b9b730b8d8b0700424",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42237,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Avoiding Side Effects in Complex Environments"
    },
    "bf0ff25d784f63805e9cfaad183042a0": {
      "source_id": "bf0ff25d784f63805e9cfaad183042a0",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 146669,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Open Problems in Cooperative AI"
    },
    "1a828311da6c652ee1982cd7216340d3": {
      "source_id": "1a828311da6c652ee1982cd7216340d3",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59206,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Unsolved Problems in ML Safety."
    },
    "ec060a99eb4e8e9a15cab3718c650549": {
      "source_id": "ec060a99eb4e8e9a15cab3718c650549",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 64714,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Designing Recommender Systems to Depolarize."
    },
    "d515617e558a6b73441a6e275f8849c1": {
      "source_id": "d515617e558a6b73441a6e275f8849c1",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35889,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Feature Expansive Reward Learning: Rethinking Human Input."
    },
    "9c2fbcdfc8dd0ae51c75f68b0d04ece1": {
      "source_id": "9c2fbcdfc8dd0ae51c75f68b0d04ece1",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36997,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Conservative agency via attainable utility preservation.."
    },
    "399d1e79027dcec2e1f7d729035f08de": {
      "source_id": "399d1e79027dcec2e1f7d729035f08de",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56395,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "LESS is More: Rethinking Probabilistic Models of Human Behavior."
    },
    "bea3a247e8e516c2fa7b755856128a59": {
      "source_id": "bea3a247e8e516c2fa7b755856128a59",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55718,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Incomplete Contracting and AI Alignment."
    },
    "a8f634af414f0b09e1531308ef324d1f": {
      "source_id": "a8f634af414f0b09e1531308ef324d1f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35411,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Legible Normativity for AI Alignment: The Value of Silly Rules."
    },
    "44744bf31057f3d2299f555a35ca0463": {
      "source_id": "44744bf31057f3d2299f555a35ca0463",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 75316,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Reward-rational (implicit) choice: A unifying formalism for reward learning."
    },
    "961c51700a43ebc088587388657302ab": {
      "source_id": "961c51700a43ebc088587388657302ab",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39019,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Literal or Pedagogic Human? Analyzing Human Model Misspecification in Objective "
    },
    "c4281a21a93e37ca7fab27eb832aea4f": {
      "source_id": "c4281a21a93e37ca7fab27eb832aea4f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34097,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Active Inverse Reward Design."
    },
    "4b13c4aa7548bc21ee3e7e8f47a87027": {
      "source_id": "4b13c4aa7548bc21ee3e7e8f47a87027",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40702,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Inverse Reward Design."
    },
    "1e1f88201aaae570f63f28606e6cea25": {
      "source_id": "1e1f88201aaae570f63f28606e6cea25",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45260,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "On the Utility of Model Learning in HRI."
    },
    "23e75d98b422f570e1eb7eb45a315730": {
      "source_id": "23e75d98b422f570e1eb7eb45a315730",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32913,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Adversarial Policies: Attacking Deep Reinforcement Learning."
    },
    "5ab3b57cc0401a5d3198d09875b1b3b0": {
      "source_id": "5ab3b57cc0401a5d3198d09875b1b3b0",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 67726,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "On the Geometry of Adversarial Examples."
    },
    "4f277b537530f3d03d70405eaddf0108": {
      "source_id": "4f277b537530f3d03d70405eaddf0108",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43058,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Decision Transformer: Reinforcement Learning via Sequence Modeling."
    },
    "915a21392784fa54b433d2c7c2e7c90a": {
      "source_id": "915a21392784fa54b433d2c7c2e7c90a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39676,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Measuring Coding Challenge Competence With APPS."
    },
    "980dbd86b111912d8d645238b9eaa92f": {
      "source_id": "980dbd86b111912d8d645238b9eaa92f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37208,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Hard Choices in Artificial Intelligence: Addressing Normative Uncertainty throug"
    },
    "fe0dc44c3e878801c884a5dc6765b6d1": {
      "source_id": "fe0dc44c3e878801c884a5dc6765b6d1",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 172595,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Building Machines That Learn and Think Like People"
    },
    "53bbe9ae329b1987abbc8b68e9159e19": {
      "source_id": "53bbe9ae329b1987abbc8b68e9159e19",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40705,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Avoiding Negative Side Effects due to Incomplete Knowledge of AI Systems"
    },
    "4d20560a864f229ffe534516bd8a8096": {
      "source_id": "4d20560a864f229ffe534516bd8a8096",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27318,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Towards A Rigorous Science of Interpretable Machine Learning"
    },
    "846a5ff7a4b4af28bf3e50c603553773": {
      "source_id": "846a5ff7a4b4af28bf3e50c603553773",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42098,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Evaluating Robustness of Neural Networks with Mixed Integer Programming"
    },
    "12e5756a832c2c9c847282dce8c817e7": {
      "source_id": "12e5756a832c2c9c847282dce8c817e7",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 90295,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "First-order Adversarial Vulnerability of Neural Networks and Input Dimension"
    },
    "82e11ba0203ce145e86dd1dca5f59a5e": {
      "source_id": "82e11ba0203ce145e86dd1dca5f59a5e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40582,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Manipulating and Measuring Model Interpretability"
    },
    "fa2dc7d0bf954de3a265c16121ddf115": {
      "source_id": "fa2dc7d0bf954de3a265c16121ddf115",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 261751,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Autonomous Intelligent Cyber-defense Agent (AICA) Reference Architecture. Releas"
    },
    "125feae2ca4bf463f35c9295c88ef1d4": {
      "source_id": "125feae2ca4bf463f35c9295c88ef1d4",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52176,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Adversarial Attacks and Defences Competition"
    },
    "54c4066155dbf604844db8635a54fa85": {
      "source_id": "54c4066155dbf604844db8635a54fa85",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59953,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Universal Planning Networks"
    },
    "8712b809a4aca35ea5df2f0544b59b83": {
      "source_id": "8712b809a4aca35ea5df2f0544b59b83",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38054,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "No Metrics Are Perfect: Adversarial Reward Learning for Visual Storytelling"
    },
    "57723e6c17d3c7a55ec74830949724f3": {
      "source_id": "57723e6c17d3c7a55ec74830949724f3",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38136,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Reward Learning from Narrated Demonstrations"
    },
    "1dd6134f73afc29059fd3ce600396f8a": {
      "source_id": "1dd6134f73afc29059fd3ce600396f8a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33626,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Imitating Latent Policies from Observation"
    },
    "ab9d8313ec8c9ad6f27216a3c7be5aff": {
      "source_id": "ab9d8313ec8c9ad6f27216a3c7be5aff",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17368,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "A Psychopathological Approach to Safety Engineering in AI and AGI"
    },
    "741d13de2d731c54718d8d32f2fcc4e7": {
      "source_id": "741d13de2d731c54718d8d32f2fcc4e7",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48128,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Penalizing side effects using stepwise relative reachability"
    },
    "5a0f56ad4bbd83a58e36718643c07afa": {
      "source_id": "5a0f56ad4bbd83a58e36718643c07afa",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61258,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Learning Existing Social Conventions via Observationally Augmented Self-Play"
    },
    "9e60622ab79fb17bb3d678a848e3d836": {
      "source_id": "9e60622ab79fb17bb3d678a848e3d836",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33820,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Representation Learning with Contrastive Predictive Coding"
    },
    "5b7385484d3a48ca210c6af18446df00": {
      "source_id": "5b7385484d3a48ca210c6af18446df00",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33558,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Model-Based Reinforcement Learning via Meta-Policy Optimization"
    },
    "c67c4f1f99a3acf3a069f3ce526661a8": {
      "source_id": "c67c4f1f99a3acf3a069f3ce526661a8",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42830,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "BabyAI: A Platform to Study the Sample Efficiency of Grounded Language Learning"
    },
    "a836978dfbfc5b75ff3965addddff470": {
      "source_id": "a836978dfbfc5b75ff3965addddff470",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17142,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Integrative Biological Simulation, Neuropsychology, and AI Safety"
    },
    "6f54b171cfee650e8335bd851c5f8522": {
      "source_id": "6f54b171cfee650e8335bd851c5f8522",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38990,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Reward learning from human preferences and demonstrations in Atari"
    },
    "2409da6d09cd430233253d14379b0e01": {
      "source_id": "2409da6d09cd430233253d14379b0e01",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36842,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Robustness via curvature regularization, and vice versa"
    },
    "7bac61f7244aa0e9fc77cef4cae4aeef": {
      "source_id": "7bac61f7244aa0e9fc77cef4cae4aeef",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39615,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failu"
    },
    "a6c16cdd16ab2351d458b6e5466fd022": {
      "source_id": "a6c16cdd16ab2351d458b6e5466fd022",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51628,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Scaling shared model governance via model splitting"
    },
    "0f27b954a6dd747101e314aab2942c90": {
      "source_id": "0f27b954a6dd747101e314aab2942c90",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39795,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Impossibility and Uncertainty Theorems in AI Value Alignment (or why your AGI sh"
    },
    "e8d31791732b0a204e6fc89330d57350": {
      "source_id": "e8d31791732b0a204e6fc89330d57350",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 244505,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Algorithms for Verifying Deep Neural Networks"
    },
    "4fa22ceddc8532fa986de05cd7e53fd9": {
      "source_id": "4fa22ceddc8532fa986de05cd7e53fd9",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47336,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Towards Characterizing Divergence in Deep Q-Learning"
    },
    "693565496a05778fc7eee68217da5e25": {
      "source_id": "693565496a05778fc7eee68217da5e25",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39401,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "The LogBarrier adversarial attack: making effective use of decision boundary inf"
    },
    "499a4638a0e2f313929527a759d887dc": {
      "source_id": "499a4638a0e2f313929527a759d887dc",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44980,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Finding and Visualizing Weaknesses of Deep Reinforcement Learning Agents"
    },
    "3f7138172c9331083d2e33da97787e14": {
      "source_id": "3f7138172c9331083d2e33da97787e14",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44965,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Extrapolating Beyond Suboptimal Demonstrations via Inverse Reinforcement Learnin"
    },
    "f08658e9cc2aba173b0270450a412cee": {
      "source_id": "f08658e9cc2aba173b0270450a412cee",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40915,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "HARK Side of Deep Learning -- From Grad Student Descent to Automated Machine Lea"
    },
    "153bcb3b49c0c5980991b5ddc2228ded": {
      "source_id": "153bcb3b49c0c5980991b5ddc2228ded",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44949,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Challenges of Real-World Reinforcement Learning"
    },
    "e662dd63bdddd44f33a2e99b3f9ac3be": {
      "source_id": "e662dd63bdddd44f33a2e99b3f9ac3be",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46845,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "PRECOG: PREdiction Conditioned On Goals in Visual Multi-Agent Settings"
    },
    "0dbfdba362459a9ed82f9ef4f3ec650e": {
      "source_id": "0dbfdba362459a9ed82f9ef4f3ec650e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 78757,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Meta-learners' learning dynamics are unlike learners'"
    },
    "a8e7867b6a2746011b0ba8fe04b56bed": {
      "source_id": "a8e7867b6a2746011b0ba8fe04b56bed",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 72159,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Meta-learning of Sequential Strategies"
    },
    "21e5965ab022e732472e0cc3deda877b": {
      "source_id": "21e5965ab022e732472e0cc3deda877b",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 81327,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "On Variational Bounds of Mutual Information"
    },
    "30993e4d225c18200c1c4a6cef00e665": {
      "source_id": "30993e4d225c18200c1c4a6cef00e665",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25965,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Cold Case: The Lost MNIST Digits"
    },
    "c4f47b8ec83a65c43d0e159eb7227f2f": {
      "source_id": "c4f47b8ec83a65c43d0e159eb7227f2f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 115371,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "AI-GAs: AI-generating algorithms, an alternate paradigm for producing general ar"
    },
    "598d0f8ff5beacac441b919e5328e493": {
      "source_id": "598d0f8ff5beacac441b919e5328e493",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40353,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Causal Confusion in Imitation Learning"
    },
    "79624763ad62f1602a878554c229b3d0": {
      "source_id": "79624763ad62f1602a878554c229b3d0",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39028,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Learning Representations by Humans, for Humans"
    },
    "89cd3ef79c4ea526deb2899513439fbb": {
      "source_id": "89cd3ef79c4ea526deb2899513439fbb",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 77753,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Imitation Learning as $f$-Divergence Minimization"
    },
    "21e9aed4c6db2398ff3168a1b7f49d46": {
      "source_id": "21e9aed4c6db2398ff3168a1b7f49d46",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36317,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "E-LPIPS: Robust Perceptual Image Similarity via Random Transformation Ensembles"
    },
    "9037f853d10c9ac10bbc0d6b4c7a747a": {
      "source_id": "9037f853d10c9ac10bbc0d6b4c7a747a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45370,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Modeling AGI Safety Frameworks with Causal Influence Diagrams"
    },
    "42153d4c6fb5d1f9e9190ddf4b1f74ad": {
      "source_id": "42153d4c6fb5d1f9e9190ddf4b1f74ad",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33842,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Towards Empathic Deep Q-Learning"
    },
    "0242bd9afee7aace1c8365b0891a40c9": {
      "source_id": "0242bd9afee7aace1c8365b0891a40c9",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58093,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Norms for Beneficial A.I.: A Computational Analysis of the Societal Value Alignm"
    },
    "f86f78b8dda14fded82720f80c05d016": {
      "source_id": "f86f78b8dda14fded82720f80c05d016",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59507,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Better-than-Demonstrator Imitation Learning via Automatically-Ranked Demonstrati"
    },
    "782a1b8a0e048fa7a0557ce27c6d3660": {
      "source_id": "782a1b8a0e048fa7a0557ce27c6d3660",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38792,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Cla"
    },
    "793b9faea6d52dafd594c76a795aecf8": {
      "source_id": "793b9faea6d52dafd594c76a795aecf8",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30859,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Improving Deep Reinforcement Learning in Minecraft with Action Advice"
    },
    "64e368da441409b50a472889d5c1323c": {
      "source_id": "64e368da441409b50a472889d5c1323c",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43807,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Finding Generalizable Evidence by Learning to Convince Q&A Models"
    },
    "7ffcd3b363df9e5be6093fbaa0220f3e": {
      "source_id": "7ffcd3b363df9e5be6093fbaa0220f3e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38997,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Scaling data-driven robotics with reward sketching and batch reinforcement learn"
    },
    "cc87f8208703018219498e01b060e785": {
      "source_id": "cc87f8208703018219498e01b060e785",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 68304,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "A Constructive Prediction of the Generalization Error Across Scales"
    },
    "5b89337caf817fe3bf2498d4cbc62b49": {
      "source_id": "5b89337caf817fe3bf2498d4cbc62b49",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51237,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Positive-Unlabeled Reward Learning"
    },
    "a338ff49276e0aa0c71004d1d1ff15a5": {
      "source_id": "a338ff49276e0aa0c71004d1d1ff15a5",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47996,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Self-training with Noisy Student improves ImageNet classification"
    },
    "9cce57483fe0df92ae65dfe5c3193948": {
      "source_id": "9cce57483fe0df92ae65dfe5c3193948",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61386,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "The Transformative Potential of Artificial Intelligence"
    },
    "584641e15cc07415351b5314971d36e0": {
      "source_id": "584641e15cc07415351b5314971d36e0",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49190,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Exploratory Not Explanatory: Counterfactual Analysis of Saliency Maps for Deep R"
    },
    "1eda22f5f61402faf20c6879ecd0ba35": {
      "source_id": "1eda22f5f61402faf20c6879ecd0ba35",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 101021,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Regulatory Markets for AI Safety"
    },
    "dfe1a69ce0a509449e51cd9ffb176807": {
      "source_id": "dfe1a69ce0a509449e51cd9ffb176807",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36210,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "The Offense-Defense Balance of Scientific Knowledge: Does Publishing AI Research"
    },
    "38b411043c9d563e311ffea3f704bf2c": {
      "source_id": "38b411043c9d563e311ffea3f704bf2c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34050,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Social and Governance Implications of Improved Data Efficiency"
    },
    "30a2c9b450475104184f57f73bb344b7": {
      "source_id": "30a2c9b450475104184f57f73bb344b7",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46938,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Gradient Surgery for Multi-Task Learning"
    },
    "9e8530cde437a62a4ffabca9f953fe25": {
      "source_id": "9e8530cde437a62a4ffabca9f953fe25",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 78355,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Artificial Intelligence, Values and Alignment"
    },
    "7add01516d3cbae17e16e80d51b46a07": {
      "source_id": "7add01516d3cbae17e16e80d51b46a07",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 63669,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Towards a Human-like Open-Domain Chatbot"
    },
    "b26648e7d3c2e4a815769958b50d60fc": {
      "source_id": "b26648e7d3c2e4a815769958b50d60fc",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36558,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Towards Learning Multi-agent Negotiations via Self-Play"
    },
    "085c7909f407e916cec67c09112d9d3d": {
      "source_id": "085c7909f407e916cec67c09112d9d3d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29244,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "AI safety: state of the field through quantitative lens"
    },
    "e346718357f748f71ab6a67053b319ce": {
      "source_id": "e346718357f748f71ab6a67053b319ce",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 176266,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence"
    },
    "1bf0c3e8c1c8c32b13c05faef8d505c1": {
      "source_id": "1bf0c3e8c1c8c32b13c05faef8d505c1",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73197,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Learning to Continually Learn"
    },
    "559978de79b22f4e9cb495b2f1e8fbb9": {
      "source_id": "559978de79b22f4e9cb495b2f1e8fbb9",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48809,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Unsupervised Question Decomposition for Question Answering"
    },
    "aa8dbeb0c06350dec4aa7a3ccd61e107": {
      "source_id": "aa8dbeb0c06350dec4aa7a3ccd61e107",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41695,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Neuron Shapley: Discovering the Responsible Neurons"
    },
    "26a97802b8567bca28a99747a360dd18": {
      "source_id": "26a97802b8567bca28a99747a360dd18",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50196,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Rethinking Bias-Variance Trade-off for Generalization of Neural Networks"
    },
    "0a23eb62707408963a72a990ad63cd09": {
      "source_id": "0a23eb62707408963a72a990ad63cd09",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39988,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "TuringAdvice: A Generative and Dynamic Evaluation of Language Use"
    },
    "bbfdc27ddeb5e3a5034a1537bbdd1eac": {
      "source_id": "bbfdc27ddeb5e3a5034a1537bbdd1eac",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 193069,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Dark, Beyond Deep: A Paradigm Shift to Cognitive AI with Humanlike Common Sense"
    },
    "f0be2e561501caeb262d62b6d68433d9": {
      "source_id": "f0be2e561501caeb262d62b6d68433d9",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42206,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Image Augmentation Is All You Need: Regularizing Deep Reinforcement Learning fro"
    },
    "90c0cd83d6e802b52508179a2d5df310": {
      "source_id": "90c0cd83d6e802b52508179a2d5df310",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54037,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Reinforcement Learning with Augmented Data"
    },
    "9f33f3f44f3ec1447c56410a2abacf30": {
      "source_id": "9f33f3f44f3ec1447c56410a2abacf30",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33293,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Learning to Complement Humans"
    },
    "c2ab3aad4eacb1d85f62658abb675652": {
      "source_id": "c2ab3aad4eacb1d85f62658abb675652",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44617,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Evaluating Explainable AI: Which Algorithmic Explanations Help Users Predict Mod"
    },
    "cf48826b533745eb6ed820b47d2b1c5c": {
      "source_id": "cf48826b533745eb6ed820b47d2b1c5c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62566,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Human Instruction-Following with Deep Reinforcement Learning via Transfer-Learni"
    },
    "c2aad946ccdea78f940f9346ffc84101": {
      "source_id": "c2aad946ccdea78f940f9346ffc84101",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 164384,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Language Models are Few-Shot Learners"
    },
    "aa17774e4a5a101069329c36cb44e0ad": {
      "source_id": "aa17774e4a5a101069329c36cb44e0ad",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61356,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Aligning Superhuman AI with Human Behavior: Chess as a Model System"
    },
    "9b11f2b4d3a6a1115592ca626084d0a5": {
      "source_id": "9b11f2b4d3a6a1115592ca626084d0a5",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45259,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Open Questions in Creating Safe Open-ended AI: Tensions Between Control and Crea"
    },
    "49d0e9c54598d75fa9261f1db5d11740": {
      "source_id": "49d0e9c54598d75fa9261f1db5d11740",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 72357,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Online Bayesian Goal Inference for Boundedly-Rational Planning Agents"
    },
    "dd0b51c92f88f0b89ab01ce455d0cf52": {
      "source_id": "dd0b51c92f88f0b89ab01ce455d0cf52",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53811,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Unsupervised Learning of Visual Features by Contrasting Cluster Assignments"
    },
    "ddb3aebf3b13c64731cf7afd0adb26b1": {
      "source_id": "ddb3aebf3b13c64731cf7afd0adb26b1",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 111630,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Quantifying Differences in Reward Functions"
    },
    "8b3ae15fc7ee249ede4fafa62097e658": {
      "source_id": "8b3ae15fc7ee249ede4fafa62097e658",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34498,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Compositional Explanations of Neurons"
    },
    "2aa314412da90693e49b3d4ec9194793": {
      "source_id": "2aa314412da90693e49b3d4ec9194793",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48608,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "AvE: Assistance via Empowerment"
    },
    "274e0974fa7ce720b9c56b21e0a9abdb": {
      "source_id": "274e0974fa7ce720b9c56b21e0a9abdb",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 115557,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Is SGD a Bayesian sampler? Well, almost"
    },
    "99047282a1efb81b7f85d595ae657426": {
      "source_id": "99047282a1efb81b7f85d595ae657426",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 115032,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"
    },
    "012a30b8a005a12c92dc57c8ae3a413b": {
      "source_id": "012a30b8a005a12c92dc57c8ae3a413b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36477,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Verifiably Safe Exploration for End-to-End Reinforcement Learning"
    },
    "8ab49e34de5d3ecdddd1910bbb27acae": {
      "source_id": "8ab49e34de5d3ecdddd1910bbb27acae",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31291,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reaso"
    },
    "75da108fdfb3106ed5b53068646d7bc4": {
      "source_id": "75da108fdfb3106ed5b53068646d7bc4",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 151729,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Forecasting AI Progress: A Research Agenda"
    },
    "198b1d3db5f95e27c228fdb6ab458dd6": {
      "source_id": "198b1d3db5f95e27c228fdb6ab458dd6",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43469,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Deploying Lifelong Open-Domain Dialogue Learning"
    },
    "033334e7f192c5e2613d97bfdf74e564": {
      "source_id": "033334e7f192c5e2613d97bfdf74e564",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49500,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Estimating the Brittleness of AI: Safety Integrity Levels and the Need for Testi"
    },
    "004aec5c84faaf313f2c417c3ca1f25f": {
      "source_id": "004aec5c84faaf313f2c417c3ca1f25f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 105761,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Measurement in AI Policy: Opportunities and Challenges"
    },
    "e7fd702eb3083e3ef639ef79e64696e3": {
      "source_id": "e7fd702eb3083e3ef639ef79e64696e3",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42612,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Humans learn too: Better Human-AI Interaction using Optimized Human Inputs"
    },
    "9eb0eb98a9c8293993514723d424831f": {
      "source_id": "9eb0eb98a9c8293993514723d424831f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 131655,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "A narrowing of AI research?"
    },
    "cfa07cf755510e08ccc3eb19af34cbd5": {
      "source_id": "cfa07cf755510e08ccc3eb19af34cbd5",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57186,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "The Grey Hoodie Project: Big Tobacco, Big Tech, and the threat on academic integ"
    },
    "4c2ae2dfba07abf80982a32a8dfd775f": {
      "source_id": "4c2ae2dfba07abf80982a32a8dfd775f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44966,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Safety Aware Reinforcement Learning (SARL)"
    },
    "526a6e05602d30c0649c6511b99412c7": {
      "source_id": "526a6e05602d30c0649c6511b99412c7",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48068,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Robust Imitation Learning from Noisy Demonstrations"
    },
    "c42b9740e6b4194dbee7a320a07166d2": {
      "source_id": "c42b9740e6b4194dbee7a320a07166d2",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 94574,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Enabling certification of verification-agnostic networks via memory-efficient se"
    },
    "30ab055e127baef8b3a57ae55c24706b": {
      "source_id": "30ab055e127baef8b3a57ae55c24706b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 103400,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Scaling Laws for Autoregressive Generative Modeling"
    },
    "02949cb93049b82c9d0bc7d2e46c52ac": {
      "source_id": "02949cb93049b82c9d0bc7d2e46c52ac",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 113377,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Underspecification Presents Challenges for Credibility in Modern Machine Learnin"
    },
    "a1e6c86b13e4cc51d58ab9bc2c127bc8": {
      "source_id": "a1e6c86b13e4cc51d58ab9bc2c127bc8",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 103280,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Fooling the primate brain with minimal, targeted image manipulation"
    },
    "8f0ba0c8ecc32b173170d1f631240dd0": {
      "source_id": "8f0ba0c8ecc32b173170d1f631240dd0",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34893,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "I Know What You Meant: Learning Human Objectives by (Under)estimating Their Choi"
    },
    "e00f358687aa7aed6e2cd1818439c005": {
      "source_id": "e00f358687aa7aed6e2cd1818439c005",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 65144,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Avoiding Tampering Incentives in Deep RL via Decoupled Approval"
    },
    "9fccf5af82caf9b8a418f12e506b0992": {
      "source_id": "9fccf5af82caf9b8a418f12e506b0992",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 229406,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Imitating Interactive Intelligence"
    },
    "36050c782f2880a8bd5ba7edffa011d8": {
      "source_id": "36050c782f2880a8bd5ba7edffa011d8",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 76219,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Neurosymbolic AI: The 3rd Wave"
    },
    "7b03a29a7f0a47cbf07d5714d494fd65": {
      "source_id": "7b03a29a7f0a47cbf07d5714d494fd65",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 63171,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "The Challenge of Value Alignment: from Fairer Algorithms to AI Safety"
    },
    "54b50aa3fdacde8fb31743e0f8abd9f4": {
      "source_id": "54b50aa3fdacde8fb31743e0f8abd9f4",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46048,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Challenges for Using Impact Regularizers to Avoid Negative Side Effects"
    },
    "e4afc38afe231b0e95bde9ed0254c7c8": {
      "source_id": "e4afc38afe231b0e95bde9ed0254c7c8",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32761,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Scaling Laws for Transfer"
    },
    "2e8b186e1b754281d64b8ec6021b1b8e": {
      "source_id": "2e8b186e1b754281d64b8ec6021b1b8e",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50368,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Rissanen Data Analysis: Examining Dataset Characteristics via Description Length"
    },
    "f12247aaa7c5a30132472244cd7a26a6": {
      "source_id": "f12247aaa7c5a30132472244cd7a26a6",
      "quality_score": 7.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8134,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Formal Methods for the Informal Engineer: Workshop Recommendations"
    },
    "14e5b7d17976f40024339770e01ada48": {
      "source_id": "14e5b7d17976f40024339770e01ada48",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41587,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Adapting Language Models for Zero-shot Learning by Meta-tuning on Dataset and Pr"
    },
    "b541b11c1418c27e97d4a0e8fc03a2e1": {
      "source_id": "b541b11c1418c27e97d4a0e8fc03a2e1",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47207,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "The Power of Scale for Parameter-Efficient Prompt Tuning"
    },
    "7461e158ad377f9a601ca14b858bb6c4": {
      "source_id": "7461e158ad377f9a601ca14b858bb6c4",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61947,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "True Few-Shot Learning with Language Models"
    },
    "88b89589d5046f885be5bd243a2aa2ca": {
      "source_id": "88b89589d5046f885be5bd243a2aa2ca",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43564,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Interactive Explanations: Diagnosis and Repair of Reinforcement Learning Based A"
    },
    "d4d01f8ca206d12f59ec2f66aa4de1f4": {
      "source_id": "d4d01f8ca206d12f59ec2f66aa4de1f4",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35225,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "IQ-Learn: Inverse soft-Q Learning for Imitation"
    },
    "7a97baccf2d0dfad4798e86392a5fd2c": {
      "source_id": "7a97baccf2d0dfad4798e86392a5fd2c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 75709,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Evaluating Large Language Models Trained on Code"
    },
    "63f483a077d61ed36a0d5d5e8a69dd10": {
      "source_id": "63f483a077d61ed36a0d5d5e8a69dd10",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46362,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Scalable Evaluation of Multi-Agent Reinforcement Learning with Melting Pot"
    },
    "84ae7baf831ae7f9b13289a17aecb996": {
      "source_id": "84ae7baf831ae7f9b13289a17aecb996",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 90695,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "The Benchmark Lottery"
    },
    "80b432979afaa87683ab82ff9fc6914c": {
      "source_id": "80b432979afaa87683ab82ff9fc6914c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 60287,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Human-Level Reinforcement Learning through Theory-Based Modeling, Exploration, a"
    },
    "2e13a5b9014cb67119d45d2e9cca9ed3": {
      "source_id": "2e13a5b9014cb67119d45d2e9cca9ed3",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18539,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Evaluating CLIP: Towards Characterization of Broader Capabilities and Downstream"
    },
    "ea99c17bfb8dff90e61d3a535b430bb3": {
      "source_id": "ea99c17bfb8dff90e61d3a535b430bb3",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39517,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "What Matters in Learning from Offline Human Demonstrations for Robot Manipulatio"
    },
    "2da411f3489c10cb274d7ba7fac229c4": {
      "source_id": "2da411f3489c10cb274d7ba7fac229c4",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 855954,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "On the Opportunities and Risks of Foundation Models"
    },
    "3a5dfe29a457d0e7ce7e32b2ed6e6136": {
      "source_id": "3a5dfe29a457d0e7ce7e32b2ed6e6136",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 90608,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Program Synthesis with Large Language Models"
    },
    "837ba9a1554593f146d6b076605d56d9": {
      "source_id": "837ba9a1554593f146d6b076605d56d9",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36886,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Finetuned Language Models Are Zero-Shot Learners"
    },
    "afea29156eae44db59e5ffb24367772c": {
      "source_id": "afea29156eae44db59e5ffb24367772c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73773,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "User Tampering in Reinforcement Learning Recommender Systems"
    },
    "7c0a2d679a7a5ca50fa500ac44849906": {
      "source_id": "7c0a2d679a7a5ca50fa500ac44849906",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48570,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Collaborating with Humans without Human Data"
    },
    "d14b7eb102a079d04894de72e703caf9": {
      "source_id": "d14b7eb102a079d04894de72e703caf9",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38956,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Programmatically Interpretable Reinforcement Learning"
    },
    "08f395401d44b67d98c8e0b3852a20a3": {
      "source_id": "08f395401d44b67d98c8e0b3852a20a3",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 139093,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Learning from Untrusted Data"
    },
    "c6b7c317d780f22b37b6125efcd7590f": {
      "source_id": "c6b7c317d780f22b37b6125efcd7590f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49239,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "A Learning and Masking Approach to Secure Learning"
    },
    "a045c0d911610f0a2f1d9135ace16df3": {
      "source_id": "a045c0d911610f0a2f1d9135ace16df3",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41527,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Spatially Transformed Adversarial Examples"
    },
    "90af76072fa913d70b1efa4c7df7720a": {
      "source_id": "90af76072fa913d70b1efa4c7df7720a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53383,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "A Dual Approach to Scalable Verification of Deep Networks"
    },
    "21a5d914cfa7094f26eb3fd27543f996": {
      "source_id": "21a5d914cfa7094f26eb3fd27543f996",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43429,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Iterative Learning with Open-set Noisy Labels"
    },
    "96a14c1f19757223183a72e4c629050b": {
      "source_id": "96a14c1f19757223183a72e4c629050b",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39493,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks"
    },
    "82a90bff040c2d54b56fba6248003156": {
      "source_id": "82a90bff040c2d54b56fba6248003156",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 91198,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Revi"
    },
    "16f65dedc5d5f097b5dc1886cc44f1bc": {
      "source_id": "16f65dedc5d5f097b5dc1886cc44f1bc",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38112,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Constructing Unrestricted Adversarial Examples with Generative Models"
    },
    "235c01722602231561a5e9f1b7b82f38": {
      "source_id": "235c01722602231561a5e9f1b7b82f38",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45010,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Robustness May Be at Odds with Accuracy"
    },
    "02273093eda16115251a2b894460e8d6": {
      "source_id": "02273093eda16115251a2b894460e8d6",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34051,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "A Benchmark for Interpretability Methods in Deep Neural Networks"
    },
    "2d7eb828d04a7c931a2fabf74bd2a4d4": {
      "source_id": "2d7eb828d04a7c931a2fabf74bd2a4d4",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41682,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Troubling Trends in Machine Learning Scholarship"
    },
    "7de0fab79d9a9abbd2551ee2adb587e8": {
      "source_id": "7de0fab79d9a9abbd2551ee2adb587e8",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46659,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Is Robustness the Cost of Accuracy? -- A Comprehensive Study on the Robustness o"
    },
    "95d1b51c0ecc668428902cf693dede4f": {
      "source_id": "95d1b51c0ecc668428902cf693dede4f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37943,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Characterizing Adversarial Examples Based on Spatial Consistency Information for"
    },
    "55d2ee5a90362dccfab9fdfcf32a0508": {
      "source_id": "55d2ee5a90362dccfab9fdfcf32a0508",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 74149,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "A Closer Look at Deep Policy Gradients"
    },
    "7e8d35b265d75290b3909df69b378adc": {
      "source_id": "7e8d35b265d75290b3909df69b378adc",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19490,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Explicability? Legibility? Predictability? Transparency? Privacy? Security? The "
    },
    "e61c2ca786a879c2a80ec840a55090a2": {
      "source_id": "e61c2ca786a879c2a80ec840a55090a2",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42318,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Feature Denoising for Improving Adversarial Robustness"
    },
    "a7a43764ffb482b60a4176ef6520054d": {
      "source_id": "a7a43764ffb482b60a4176ef6520054d",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40971,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Robust Change Captioning"
    },
    "0701f434e0267fd460a2eb6a766c5710": {
      "source_id": "0701f434e0267fd460a2eb6a766c5710",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16822,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Improving Robustness of Machine Translation with Synthetic Noise"
    },
    "1d30ff2c0b8a1b22074752038d18399e": {
      "source_id": "1d30ff2c0b8a1b22074752038d18399e",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39057,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Toybox: A Suite of Environments for Experimental Evaluation of Deep Reinforcemen"
    },
    "80f6a648f25568e26d778a80296ddeca": {
      "source_id": "80f6a648f25568e26d778a80296ddeca",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19845,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "The Principle of Unchanged Optimality in Reinforcement Learning Generalization"
    },
    "eae2467f1f42e1149c7c35b8cde33bfd": {
      "source_id": "eae2467f1f42e1149c7c35b8cde33bfd",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29732,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Goal-conditioned Imitation Learning"
    },
    "d6d4f93f29f8c1e55edf7becc7ff8a53": {
      "source_id": "d6d4f93f29f8c1e55edf7becc7ff8a53",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59047,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Behaviour Suite for Reinforcement Learning"
    },
    "b941110f24a934df99263071691453ad": {
      "source_id": "b941110f24a934df99263071691453ad",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 74602,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "LCA: Loss Change Allocation for Neural Network Training"
    },
    "0cf68bfe04a22e301801931fd6a76b99": {
      "source_id": "0cf68bfe04a22e301801931fd6a76b99",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38595,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentatio"
    },
    "c5965d6b11fab9ce379fd91572c35543": {
      "source_id": "c5965d6b11fab9ce379fd91572c35543",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40488,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Ask Your Humans: Using Human Instructions to Improve Generalization in Reinforce"
    },
    "abfd963c7afe75892dc401c0d1b26215": {
      "source_id": "abfd963c7afe75892dc401c0d1b26215",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51964,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Navigation Turing Test (NTT): Learning to Evaluate Human-Like Navigation"
    },
    "393a7a93bd7a4f3365f15f1072e40213": {
      "source_id": "393a7a93bd7a4f3365f15f1072e40213",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 349277,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "Studying Large Language Model Generalization with Influence Functions"
    },
    "8c46e9a4bb322ee97d1486e6dff512ae": {
      "source_id": "8c46e9a4bb322ee97d1486e6dff512ae",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 60738,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "A Model of Pathways to Artificial Superintelligence Catastrophe for Risk and Dec"
    },
    "5cec28567850124715e607607e593a7c": {
      "source_id": "5cec28567850124715e607607e593a7c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 90901,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Training language models to follow instructions with human feedback"
    },
    "3625591de24ea61694a0bfd620623349": {
      "source_id": "3625591de24ea61694a0bfd620623349",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 121890,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Risks from Learned Optimization  in Advanced Machine Learning Systems"
    },
    "9daa7dac3bcd0dbceb42f15efdb2835f": {
      "source_id": "9daa7dac3bcd0dbceb42f15efdb2835f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 169481,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Training a Helpful and Harmless Assistant with Reinforcement Learning from Human"
    },
    "e30130fcf4ab2d1649701de9666e2e47": {
      "source_id": "e30130fcf4ab2d1649701de9666e2e47",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62114,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "Finding Neurons in a Haystack:  Case Studies with Sparse Probing"
    },
    "5bb7ca04067a7d2f5404dff7607932f0": {
      "source_id": "5bb7ca04067a7d2f5404dff7607932f0",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42277,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Emergent world representations: Exploring a sequence model trained on a syntheti"
    },
    "8bea59ce4526278233f0bfa854c2aea2": {
      "source_id": "8bea59ce4526278233f0bfa854c2aea2",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58118,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "Towards Automated Circuit Discovery\nfor Mechanistic Interpretability"
    },
    "436ef00c5c5fad81706d3da1c133e8a3": {
      "source_id": "436ef00c5c5fad81706d3da1c133e8a3",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56812,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "A Toy Model of Universality:\nReverse Engineering How Networks Learn Group Operat"
    },
    "5388c16b3140305d5543cab810d3f5a1": {
      "source_id": "5388c16b3140305d5543cab810d3f5a1",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44146,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Causal Mediation Analysis for Interpreting Neural NLP:  The Case of Gender Bias"
    },
    "cef47b8e28f2ee300a1ad3d5a352bd8e": {
      "source_id": "cef47b8e28f2ee300a1ad3d5a352bd8e",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44774,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Discovering Latent Knowledge in Language Models Without Supervision"
    },
    "04ec3ee050cc951838ba9c9b29c1f48f": {
      "source_id": "04ec3ee050cc951838ba9c9b29c1f48f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42784,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a p"
    },
    "6ffccb173ea283dc97f2cdd3d66cbe44": {
      "source_id": "6ffccb173ea283dc97f2cdd3d66cbe44",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42565,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "An Interpretability Illusion for BERT"
    },
    "8030d671c8dc7618b4843fd6a48492cb": {
      "source_id": "8030d671c8dc7618b4843fd6a48492cb",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 141846,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Acquisition of Chess Knowledge in AlphaZero"
    },
    "96bb7a101a3081a55bd02f8f9af72afa": {
      "source_id": "96bb7a101a3081a55bd02f8f9af72afa",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61497,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Toward Transparent AI: A Survey on Interpreting\nthe Inner Structures of Deep Neu"
    },
    "267f825a372778dc9a7b49aaabc411ab": {
      "source_id": "267f825a372778dc9a7b49aaabc411ab",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46437,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Fixing Weight Decay Regularization in Adam"
    },
    "4a6c4493fd0d879ff4856f38bb851f7c": {
      "source_id": "4a6c4493fd0d879ff4856f38bb851f7c",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40531,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Obfuscated Gradients Give a False Sense of Security:\nCircumventing Defenses to A"
    },
    "22c9d63fe77ad41859beca6a341f1d36": {
      "source_id": "22c9d63fe77ad41859beca6a341f1d36",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38139,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Adversarial Examples for Evaluating Reading Comprehension Systems"
    },
    "df26702cd0a432a510db455b29f0ce1a": {
      "source_id": "df26702cd0a432a510db455b29f0ce1a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38136,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Smooth Adversarial Training"
    },
    "c73d1d24858a5a5824f3f53ecf51ec6b": {
      "source_id": "c73d1d24858a5a5824f3f53ecf51ec6b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41335,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Reliable evaluation of adversarial robustness with an ensemble of diverse parame"
    },
    "dfe4f6e3d2c81f5f75ee666f07400054": {
      "source_id": "dfe4f6e3d2c81f5f75ee666f07400054",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36851,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Using Pre-Training Can Improve Model Robustness and Uncertainty"
    },
    "613fb830395808b0b266bcd0b16ff870": {
      "source_id": "613fb830395808b0b266bcd0b16ff870",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 79789,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Towards Evaluating the Robustness \nof Neural Networks"
    },
    "d17f296dd337d166eef3b39f38b283af": {
      "source_id": "d17f296dd337d166eef3b39f38b283af",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47728,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Adversarial NLI: A New Benchmark \nfor Natural Language Understanding"
    },
    "b8666a1c7c7a0192a345abc96c9efc8c": {
      "source_id": "b8666a1c7c7a0192a345abc96c9efc8c",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38118,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "A Baseline for Detecting Misclassified and Out-of-Distribution Examples\nin Neura"
    },
    "7ddf442b31f9baa67bd40831bb9bd289": {
      "source_id": "7ddf442b31f9baa67bd40831bb9bd289",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42411,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "ViM: Out-Of-Distribution with Virtual-logit Matching"
    },
    "a40668486fbcb879a3f83199cd0121be": {
      "source_id": "a40668486fbcb879a3f83199cd0121be",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45370,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversa"
    },
    "545c495f3af5bccccba7d1dd38cb8fa7": {
      "source_id": "545c495f3af5bccccba7d1dd38cb8fa7",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36854,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "The Mythos of Model Interpretability"
    },
    "784d797528d0ab874992d1190123c1a8": {
      "source_id": "784d797528d0ab874992d1190123c1a8",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42660,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Interpretable Explanations of Black Boxes by Meaningful Perturbation"
    },
    "8a978f212608a0259e0978afd6ca1af3": {
      "source_id": "8a978f212608a0259e0978afd6ca1af3",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45808,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Exemplary natural images explain CNN activations better than feature visualizati"
    },
    "be90c7a8998cd326115556a0993409e4": {
      "source_id": "be90c7a8998cd326115556a0993409e4",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45927,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Network Dissection: \nQuantifying Interpretability of Deep Visual Representations"
    },
    "9afb76ce70b2f78e188d1d207932044b": {
      "source_id": "9afb76ce70b2f78e188d1d207932044b",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55112,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Please Stop Explaining Black Box Models for High-Stakes Decisions"
    },
    "2e751e13428ed9ea208eddd4192a138d": {
      "source_id": "2e751e13428ed9ea208eddd4192a138d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44931,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Poisoning and Backdooring Contrastive Learning"
    },
    "ec61370a4d0d45f75e622218893ae746": {
      "source_id": "ec61370a4d0d45f75e622218893ae746",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 98073,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Detecting AI Trojans Using Meta Neural Analysis"
    },
    "4891c64c19a1494cb57fb7c38a4914bd": {
      "source_id": "4891c64c19a1494cb57fb7c38a4914bd",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 81200,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "STRIP: A Defence Against Trojan Attacks on Deep Neural Networks"
    },
    "681635096b39624d8c2cb8df45778133": {
      "source_id": "681635096b39624d8c2cb8df45778133",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59557,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain"
    },
    "231c1c7eb2d2254414931a02742325c5": {
      "source_id": "231c1c7eb2d2254414931a02742325c5",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31907,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Forecasting Future World Events \nwith Neural Networks"
    },
    "28dfb02c5189ee73bb02f80a540a6acf": {
      "source_id": "28dfb02c5189ee73bb02f80a540a6acf",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 144037,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "Natural Selection Favors AIs over Humans"
    },
    "bd5055688c17e7010cb5c3c50b7b9731": {
      "source_id": "bd5055688c17e7010cb5c3c50b7b9731",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41906,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "Towards Measuring the Representation of Subjective Global Opinions in Language M"
    },
    "fb06d2ea0e12476bcabb14f6eb57f310": {
      "source_id": "fb06d2ea0e12476bcabb14f6eb57f310",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 96196,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Discovering Language Model Behaviors with Model-Written Evaluations"
    },
    "4debba2925275e6339727785ba27f02e": {
      "source_id": "4debba2925275e6339727785ba27f02e",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 72864,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Constitutional AI: Harmlessness from AI Feedback"
    },
    "d33fcb4bef6132b8b32997a047b488ac": {
      "source_id": "d33fcb4bef6132b8b32997a047b488ac",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51214,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Measuring Progress on Scalable Oversight for Large Language Models"
    },
    "a1abb2d6195be076e8925c3286b6f681": {
      "source_id": "a1abb2d6195be076e8925c3286b6f681",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 70456,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Les"
    },
    "ec04d5adde44eb5444b9963eb2fef624": {
      "source_id": "ec04d5adde44eb5444b9963eb2fef624",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 84322,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Language Models (Mostly) Know What They Know"
    },
    "60f689dd4baaa68b2819f17b579fdae6": {
      "source_id": "60f689dd4baaa68b2819f17b579fdae6",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59976,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Scaling Laws and Interpretability of Learning from Repeated Data"
    },
    "4efe878bf48a28f377071b10b6587eef": {
      "source_id": "4efe878bf48a28f377071b10b6587eef",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44167,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "Do the Rewards Justify the Means? Measuring Trade-Offs Between \nRewards and Ethi"
    },
    "d88381ef1676ad6ad7c7e94ad753313c": {
      "source_id": "d88381ef1676ad6ad7c7e94ad753313c",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44621,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "Improving Code Generation by Training with Natural Language Feedback"
    },
    "dfb9b33fc00b483ff506c4b172ed95bd": {
      "source_id": "dfb9b33fc00b483ff506c4b172ed95bd",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 70456,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "Eliciting Latent Predictions from Transformers with the Tuned Lens"
    },
    "c61fe8a59ccfaa311d231acaf9fc16c0": {
      "source_id": "c61fe8a59ccfaa311d231acaf9fc16c0",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62416,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "Pretraining Language Models with Human Preferences"
    },
    "8160fe2c96d6932f1c10491050bc4d8d": {
      "source_id": "8160fe2c96d6932f1c10491050bc4d8d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42014,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Adversarial Policies Beat Professional-Level Go AIs"
    },
    "fc3ac5affbf4fcc3ecbce60a9bbea8df": {
      "source_id": "fc3ac5affbf4fcc3ecbce60a9bbea8df",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29301,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "RL with KL penalties is better viewed as Bayesian inference"
    },
    "168f4b8a7feb0cd70efa51b60482b8ca": {
      "source_id": "168f4b8a7feb0cd70efa51b60482b8ca",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49678,
        "year": "2022",
        "has_tags": false
      },
      "title_preview": "Reward Reports for Reinforcement Learning"
    },
    "028a9baaa9a77d42694d3a19d33a0321": {
      "source_id": "028a9baaa9a77d42694d3a19d33a0321",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 85704,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "A New Formalism, Method and Open Issues for Zero-Shot Coordination"
    },
    "468ea22f2d5cf35eefbf8b727985b25e": {
      "source_id": "468ea22f2d5cf35eefbf8b727985b25e",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61138,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Learning to Play Against Any Mixture of Opponents"
    },
    "71661b9ac1ac2caed1d0a125a6672a3f": {
      "source_id": "71661b9ac1ac2caed1d0a125a6672a3f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51703,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "MultiXNet: Multiclass Multistage Multimodal Motion Prediction"
    },
    "8526802e51962e60e9273040e4fdc8b1": {
      "source_id": "8526802e51962e60e9273040e4fdc8b1",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 79704,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Subjectifying Objectivity: Delineating Tastes in Theoretical Quantum Gravity Res"
    },
    "42fe28637dfe77307c08d568cd608ada": {
      "source_id": "42fe28637dfe77307c08d568cd608ada",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25465,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "The AGI Containment Problem"
    },
    "ad8cc8c5ccb611d2311f2496a329b541": {
      "source_id": "ad8cc8c5ccb611d2311f2496a329b541",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33200,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Universal adversarial perturbations"
    },
    "3b0031dba3084f2ec86955f75357ed5a": {
      "source_id": "3b0031dba3084f2ec86955f75357ed5a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40923,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Learning to Protect Communications\nwith Adversarial Neural Cryptography"
    },
    "066ad11bb2ff28fa427ea8b7e8eb3d8b": {
      "source_id": "066ad11bb2ff28fa427ea8b7e8eb3d8b",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26202,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Towards Verified Artificial Intelligence"
    },
    "9957f33fc4faa8359d3bf67a9292fcf9": {
      "source_id": "9957f33fc4faa8359d3bf67a9292fcf9",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40562,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Learning Language Games through Interaction"
    },
    "a1cdc1892cbdbd73d54630e5957a9a06": {
      "source_id": "a1cdc1892cbdbd73d54630e5957a9a06",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43824,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "The Quantization Model of Neural Scaling"
    },
    "17ef6ec21f8407a5ff3f77b505baa10f": {
      "source_id": "17ef6ec21f8407a5ff3f77b505baa10f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": false,
        "is_newsletter": false,
        "text_length": 53203,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Universal Adversarial Triggers for Attacking and Analyzing NLP  WARNING: This pa"
    },
    "5ab982619e6ba5b082367c2a580a8701": {
      "source_id": "5ab982619e6ba5b082367c2a580a8701",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 422178,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Wilds: A Benchmark of in-the-Wild Distribution Shifts"
    },
    "ecbf833c92b33a47f8652b466a012c5a": {
      "source_id": "ecbf833c92b33a47f8652b466a012c5a",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41111,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "On Single Point Forecasts for Fat-Tailed Variables"
    },
    "faac12c9336f2e64da814b9a48b7bbe6": {
      "source_id": "faac12c9336f2e64da814b9a48b7bbe6",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54972,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "Evaluating the Moral Beliefs Encoded in LLMs  Warning: This paper contains moral"
    },
    "c27c6f2ef9ae28b18c0a4f30f2a1b2aa": {
      "source_id": "c27c6f2ef9ae28b18c0a4f30f2a1b2aa",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 98755,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "Inverse Scaling: When Bigger Isn\u2019t Better"
    },
    "162b2e1f034993c7d80bbcb1f823103a": {
      "source_id": "162b2e1f034993c7d80bbcb1f823103a",
      "quality_score": 7.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": false,
        "is_newsletter": false,
        "text_length": 47817,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "Localizing Model Behavior With Path Patching"
    },
    "3d78f1acd91ad10a7f7d68e7658ea5fa": {
      "source_id": "3d78f1acd91ad10a7f7d68e7658ea5fa",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59137,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "The Capacity for Moral Self-Correction in Large Language Models"
    },
    "4f5142e5b00a441fb2b3babdf663e5c8": {
      "source_id": "4f5142e5b00a441fb2b3babdf663e5c8",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30827,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "RobustBench: a standardized adversarial robustness benchmark"
    },
    "d604aa57800a22e1b1fd8fc3b9bdd8b1": {
      "source_id": "d604aa57800a22e1b1fd8fc3b9bdd8b1",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": false,
        "is_newsletter": false,
        "text_length": 16263,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Visualizing Dynamics: from t-SNE to SEMI-MDPs"
    },
    "6d63b24af76850e7d94ffe092fba5d5b": {
      "source_id": "6d63b24af76850e7d94ffe092fba5d5b",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": false,
        "is_newsletter": false,
        "text_length": 15399,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Increasing the Interpretability of Recurrent Neural Networks Using Hidden Markov"
    },
    "709c102c9237b620491e013c3f8f5a4c": {
      "source_id": "709c102c9237b620491e013c3f8f5a4c",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42829,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Unsupervised Risk Estimation Using Only Conditional Independence Structure"
    },
    "5488031cfaa2b302fc2e2e284893395b": {
      "source_id": "5488031cfaa2b302fc2e2e284893395b",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 64583,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Synthesizing the preferred inputs for neurons in neural networks via deep genera"
    },
    "7fe6d29db39a82b35b6d63c8bc8b9bcb": {
      "source_id": "7fe6d29db39a82b35b6d63c8bc8b9bcb",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56092,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Bayesian Optimization with Safety Constraints: Safe and Automatic Parameter Tuni"
    },
    "c3043a62c41391abff177cc994f03598": {
      "source_id": "c3043a62c41391abff177cc994f03598",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": false,
        "is_newsletter": false,
        "text_length": 86488,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Practical Black-Box Attacks against Deep Learning Systems  using Adversarial Exa"
    },
    "c10b9456b03fcc59a381887333da0e3a": {
      "source_id": "c10b9456b03fcc59a381887333da0e3a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 74380,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Graying the black box: Understanding DQNs"
    },
    "78174b74c718cad835330a9b7aaa043a": {
      "source_id": "78174b74c718cad835330a9b7aaa043a",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36108,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "The Off-Switch Game"
    },
    "8c9b4b4fa66e855a3a67e1068e2e74bd": {
      "source_id": "8c9b4b4fa66e855a3a67e1068e2e74bd",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54423,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Cooperative Inverse Reinforcement Learning"
    },
    "e48e7429c48c2e394659644af92814fe": {
      "source_id": "e48e7429c48c2e394659644af92814fe",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40066,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Generative Adversarial Imitation Learning"
    },
    "0b9103d6dc8b3c04d62a406082e800e2": {
      "source_id": "0b9103d6dc8b3c04d62a406082e800e2",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 98165,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "Specific versus General Principles for Constitutional AI"
    },
    "2a755dc71d8b939c0ba58ba4eb68b837": {
      "source_id": "2a755dc71d8b939c0ba58ba4eb68b837",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57563,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "Towards Understanding  Sycophancy in Language Models"
    },
    "1051dda54eaf8c38f429413cd3a13d44": {
      "source_id": "1051dda54eaf8c38f429413cd3a13d44",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 108617,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "Representation Engineering: A Top-Down Approach to AI Transparency"
    },
    "b08e5f64b6d25f472e6ab9280b84c153": {
      "source_id": "b08e5f64b6d25f472e6ab9280b84c153",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 86586,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "AI Deception: A Survey of Examples, Risks, and Potential Solutions"
    },
    "c67778b1627c19d8b7d8cd73cc31b9e0": {
      "source_id": "c67778b1627c19d8b7d8cd73cc31b9e0",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 100031,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "Codebook Features: Sparse and Discrete Interpretability for Neural Networks"
    },
    "ca4359c33a477287b56491cb81ac1e0d": {
      "source_id": "ca4359c33a477287b56491cb81ac1e0d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "arxiv",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40463,
        "year": "2023",
        "has_tags": false
      },
      "title_preview": "Vision-Language Models are Zero-Shot  Reward Models for Reinforcement Learning"
    },
    "dd6a446845d57fed72059ee8bdb37857": {
      "source_id": "dd6a446845d57fed72059ee8bdb37857",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58003,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "A Gentle Introduction to Graph Neural Networks"
    },
    "a15bd5a2f0b26e2015a03fdc5a2319a9": {
      "source_id": "a15bd5a2f0b26e2015a03fdc5a2319a9",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33810,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Adversarial Reprogramming of Neural Cellular Automata"
    },
    "46959ccf83a5e89dbf4fc4aee11b4af9": {
      "source_id": "46959ccf83a5e89dbf4fc4aee11b4af9",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13642,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Weight Banding"
    },
    "d2af05099a4301be3320f05c220b8489": {
      "source_id": "d2af05099a4301be3320f05c220b8489",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23310,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Branch Specialization"
    },
    "8ca56371f32f6a2e55c8306b5fe94e7d": {
      "source_id": "8ca56371f32f6a2e55c8306b5fe94e7d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42343,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Self-Organising Textures"
    },
    "e0055470e63b5b83359c358c17b108f9": {
      "source_id": "e0055470e63b5b83359c358c17b108f9",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30230,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "Visualizing Weights"
    },
    "63e78aeacd5b314498232de7a27d4381": {
      "source_id": "63e78aeacd5b314498232de7a27d4381",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54519,
        "year": "2021",
        "has_tags": false
      },
      "title_preview": "High-Low Frequency Detectors"
    },
    "e3fcaaea154f7c22f0e1e2cc814837d5": {
      "source_id": "e3fcaaea154f7c22f0e1e2cc814837d5",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33870,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Naturally Occurring Equivariance in Neural Networks"
    },
    "9025e9a91810edf582669aac3764b350": {
      "source_id": "9025e9a91810edf582669aac3764b350",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43762,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Understanding RL Vision"
    },
    "dcf03df9a5ecaa60883a9e6fcf18ac7f": {
      "source_id": "dcf03df9a5ecaa60883a9e6fcf18ac7f",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49228,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Communicating with Interactive Articles"
    },
    "14ddb6790290338e5f5f48ae464dfb20": {
      "source_id": "14ddb6790290338e5f5f48ae464dfb20",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27947,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Self-classifying MNIST Digits"
    },
    "c5dbee2ef12d51ed75670e597b7a1ab7": {
      "source_id": "c5dbee2ef12d51ed75670e597b7a1ab7",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 510571,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Curve Detectors"
    },
    "db677f11f115381340bcd9afbaa95af3": {
      "source_id": "db677f11f115381340bcd9afbaa95af3",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35342,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Exploring Bayesian Optimization"
    },
    "957e47782c32e397de3f788737eefba8": {
      "source_id": "957e47782c32e397de3f788737eefba8",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 186827,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "An Overview of Early Vision in InceptionV1"
    },
    "16bba51135fb54b50506160f8e521ab3": {
      "source_id": "16bba51135fb54b50506160f8e521ab3",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50910,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Visualizing Neural Networks with the Grand Tour"
    },
    "ed5ab808068ad61f2b5d9b519a94db3d": {
      "source_id": "ed5ab808068ad61f2b5d9b519a94db3d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47079,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Zoom In: An Introduction to Circuits"
    },
    "fe09c2226ea403295828fbc9d50304ed": {
      "source_id": "fe09c2226ea403295828fbc9d50304ed",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34518,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Growing Neural Cellular Automata"
    },
    "67e0be00bc03466d6c890df4511e3a4d": {
      "source_id": "67e0be00bc03466d6c890df4511e3a4d",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47806,
        "year": "2020",
        "has_tags": false
      },
      "title_preview": "Visualizing the Impact of Feature Attribution Baselines"
    },
    "8ef6f034b4508a82d3da36f052345ec6": {
      "source_id": "8ef6f034b4508a82d3da36f052345ec6",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32279,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Computing Receptive Fields of Convolutional Neural Networks"
    },
    "4dab2fb3c6b0867cd11d51b1de9f1ecf": {
      "source_id": "4dab2fb3c6b0867cd11d51b1de9f1ecf",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11664,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "A Discussion of 'Adversarial Examples Are Not Bugs, They Are Features'"
    },
    "9af84a92d724245f276f38cfe61d7b12": {
      "source_id": "9af84a92d724245f276f38cfe61d7b12",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9996,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "A Discussion of 'Adversarial Examples Are Not Bugs, They Are Features': Adversar"
    },
    "109a9ad019ae9b2c07d878ac8650f88e": {
      "source_id": "109a9ad019ae9b2c07d878ac8650f88e",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8037,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "A Discussion of 'Adversarial Examples Are Not Bugs, They Are Features': Robust F"
    },
    "90edb4745db80192530bcfcdb853ebb3": {
      "source_id": "90edb4745db80192530bcfcdb853ebb3",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7715,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "A Discussion of 'Adversarial Examples Are Not Bugs, They Are Features': Two Exam"
    },
    "929bb52cf50e0b8d42c3547eb0bb34e0": {
      "source_id": "929bb52cf50e0b8d42c3547eb0bb34e0",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16539,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "A Discussion of 'Adversarial Examples Are Not Bugs, They Are Features': Adversar"
    },
    "6e90076e03f74714d63d7b09c7ad8e59": {
      "source_id": "6e90076e03f74714d63d7b09c7ad8e59",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17916,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "A Discussion of 'Adversarial Examples Are Not Bugs, They Are Features': Adversar"
    },
    "bda18cad07b62a0dff8e37b69a396da0": {
      "source_id": "bda18cad07b62a0dff8e37b69a396da0",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28945,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "A Discussion of 'Adversarial Examples Are Not Bugs, They Are Features': Discussi"
    },
    "a9e837be3cded3d2c70b5d5864747eb6": {
      "source_id": "a9e837be3cded3d2c70b5d5864747eb6",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23666,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Open Questions about Generative Adversarial Networks"
    },
    "3a645443102ffa1eb6428f582ff73b62": {
      "source_id": "3a645443102ffa1eb6428f582ff73b62",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37551,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "Activation Atlas"
    },
    "eb5c12bc89464f38db9f304e78f2c702": {
      "source_id": "eb5c12bc89464f38db9f304e78f2c702",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61958,
        "year": "2019",
        "has_tags": false
      },
      "title_preview": "AI Safety Needs Social Scientists"
    },
    "f2c26f7be5a4bf71c811540aa79a57f3": {
      "source_id": "f2c26f7be5a4bf71c811540aa79a57f3",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33807,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Differentiable Image Parameterizations"
    },
    "60c80cf91136c14dd9381b0cec55967f": {
      "source_id": "60c80cf91136c14dd9381b0cec55967f",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44660,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "Feature-wise transformations"
    },
    "16581d92f7140bdd597b913e7ae78c38": {
      "source_id": "16581d92f7140bdd597b913e7ae78c38",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34525,
        "year": "2018",
        "has_tags": false
      },
      "title_preview": "The Building Blocks of Interpretability"
    },
    "5445aad20630afcd10626117b6df4dcc": {
      "source_id": "5445aad20630afcd10626117b6df4dcc",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32034,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Sequence Modeling with CTC"
    },
    "467d4af00cf674a3225b371b2652faa6": {
      "source_id": "467d4af00cf674a3225b371b2652faa6",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32075,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Feature Visualization"
    },
    "4c8e11a1925e403bf42b0b3a19850332": {
      "source_id": "4c8e11a1925e403bf42b0b3a19850332",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 81009,
        "year": "2017",
        "has_tags": false
      },
      "title_preview": "Why Momentum Really Works"
    },
    "790f8af19327d10549fc189402d764f6": {
      "source_id": "790f8af19327d10549fc189402d764f6",
      "quality_score": 8.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9619,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Experiments in Handwriting with a Neural Network"
    },
    "31099860fa969445fcceef8ad17f5754": {
      "source_id": "31099860fa969445fcceef8ad17f5754",
      "quality_score": 9.0,
      "quality_tier": "A",
      "signals": {
        "source": "distill",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 63551,
        "year": "2016",
        "has_tags": false
      },
      "title_preview": "Attention and Augmented Recurrent Neural Networks"
    },
    "ff067b339fb6ed39115588c30d2e9aec": {
      "source_id": "ff067b339fb6ed39115588c30d2e9aec",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52597,
        "year": "2016",
        "has_tags": true
      },
      "title_preview": "Potential Risks from Advanced Artificial Intelligence: The Philanthropic Opportu"
    },
    "f62fed0e74f52c24163527297a98e1f5": {
      "source_id": "f62fed0e74f52c24163527297a98e1f5",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21560,
        "year": "2016",
        "has_tags": true
      },
      "title_preview": "Quantifying the Far Future Effects of Interventions"
    },
    "638733857db42573b62d2d32542dabd9": {
      "source_id": "638733857db42573b62d2d32542dabd9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 739,
        "year": "2016",
        "has_tags": true
      },
      "title_preview": "Andrew Critch: Logical induction \u2014 progress in AI alignment"
    },
    "eae7088a06c4afc7f85169c723addaff": {
      "source_id": "eae7088a06c4afc7f85169c723addaff",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61916,
        "year": "2016",
        "has_tags": true
      },
      "title_preview": "2016 AI Risk Literature Review and Charity Comparison"
    },
    "09ffa97edcbfa3bf5ea06cc3808769a9": {
      "source_id": "09ffa97edcbfa3bf5ea06cc3808769a9",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14154,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "Changes in funding in the AI safety field"
    },
    "2335e89f48a722cd04b43f8fcf27aed2": {
      "source_id": "2335e89f48a722cd04b43f8fcf27aed2",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12593,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "What Should the Average EA Do About AI Alignment?"
    },
    "a003637ca86566778a0e7ce60123038e": {
      "source_id": "a003637ca86566778a0e7ce60123038e",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49250,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "Intro to caring about AI alignment as an EA cause"
    },
    "1623f819cf8b7eedcee097f5ffa34752": {
      "source_id": "1623f819cf8b7eedcee097f5ffa34752",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4956,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "Informatica: Special Issue on Superintelligence"
    },
    "02f83070642bcb0831e197b4f4daa821": {
      "source_id": "02f83070642bcb0831e197b4f4daa821",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35022,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "The AI revolution and international politics (Allan Dafoe)"
    },
    "99e38afc38b8f5bf6037219ed6fbf24a": {
      "source_id": "99e38afc38b8f5bf6037219ed6fbf24a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8502,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "Cognitive Science/Psychology As a Neglected Approach to AI Safety"
    },
    "0d867127e81aeb8521a36f20f9a74f74": {
      "source_id": "0d867127e81aeb8521a36f20f9a74f74",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36758,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "My current thoughts on MIRI's \"highly reliable agent design\" work"
    },
    "6983dd119afe39340bd203ade0221505": {
      "source_id": "6983dd119afe39340bd203ade0221505",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21327,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "Owen Cotton-Barratt: What does (and doesn't) AI mean for effective altruism?"
    },
    "cf510eb0c9c0b1f0aec05932039b92e5": {
      "source_id": "cf510eb0c9c0b1f0aec05932039b92e5",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 287,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "Katja Grace: AI safety"
    },
    "bc4d1dd6ad53b2628082869c64c0a6b8": {
      "source_id": "bc4d1dd6ad53b2628082869c64c0a6b8",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31528,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "Daniel Dewey: The Open Philanthropy Project's work on potential risks from advan"
    },
    "b327c2e8c650302e4a77116a93a4c379": {
      "source_id": "b327c2e8c650302e4a77116a93a4c379",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21303,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "What does (and doesn't) AI mean for effective altruism?"
    },
    "e72fe04f83d28da0b5b93b8394ee50a4": {
      "source_id": "e72fe04f83d28da0b5b93b8394ee50a4",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31440,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "Potential Risks from Advanced AI"
    },
    "582ad0addcdbef7c75b4c83d6a8690c8": {
      "source_id": "582ad0addcdbef7c75b4c83d6a8690c8",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23346,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "An intervention to shape policy dialogue, communication, and AI research norms f"
    },
    "cae60aa6db9e1cfff663676255245002": {
      "source_id": "cae60aa6db9e1cfff663676255245002",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47323,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "There's No Fire Alarm for Artificial General Intelligence"
    },
    "8fe06993698bd019267007bdbe3a2067": {
      "source_id": "8fe06993698bd019267007bdbe3a2067",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 756,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "AI alignment prize winners and next round [link]"
    },
    "a17dca4afa486fd041d2051530a7b3e8": {
      "source_id": "a17dca4afa486fd041d2051530a7b3e8",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 71833,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Why I prioritize moral circle expansion over reducing extinction risk through ar"
    },
    "b2b116503c3218fbfbc66959a03c39eb": {
      "source_id": "b2b116503c3218fbfbc66959a03c39eb",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21816,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Opportunities for individual donors in AI safety"
    },
    "4dbfc0795861f1a7f3cc39106f81a715": {
      "source_id": "4dbfc0795861f1a7f3cc39106f81a715",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49891,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Jade Leung and Seth Baum: The role of existing institutions in AI strategy"
    },
    "ffc119fb9af6ef83ee40818098b99cf5": {
      "source_id": "ffc119fb9af6ef83ee40818098b99cf5",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 321316,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Paul Christiano on how OpenAI is developing real solutions to the 'AI alignment "
    },
    "e26c0c4b6b723b52acea95a896399c20": {
      "source_id": "e26c0c4b6b723b52acea95a896399c20",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 456,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "\"Taking AI Risk Seriously\" \u2013\u00a0Thoughts by Andrew Critch"
    },
    "b8d802abb820d4e4ead6ee15cb703573": {
      "source_id": "b8d802abb820d4e4ead6ee15cb703573",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22611,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Some cruxes on impactful alternatives to AI policy work"
    },
    "beea5aec13e43e4ccb151051043e16d2": {
      "source_id": "beea5aec13e43e4ccb151051043e16d2",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16275,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Critique of Superintelligence Part 1"
    },
    "e4a2720ddf7704a3c7c4640f04cbda4f": {
      "source_id": "e4a2720ddf7704a3c7c4640f04cbda4f",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14576,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Critique of Superintelligence Part 2"
    },
    "95ab23fedd3e52ab7e61b2e027c175cb": {
      "source_id": "95ab23fedd3e52ab7e61b2e027c175cb",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14375,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Critique of Superintelligence Part 3"
    },
    "94d8100d0b3d13414a95dbbd56d2a496": {
      "source_id": "94d8100d0b3d13414a95dbbd56d2a496",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7517,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Critique of Superintelligence Part 4"
    },
    "e0569e6380a6c53a01aab9343a9ccd11": {
      "source_id": "e0569e6380a6c53a01aab9343a9ccd11",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11402,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Critique of Superintelligence Part 5"
    },
    "5141fb0f94d655e041f5859c6e377f23": {
      "source_id": "5141fb0f94d655e041f5859c6e377f23",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1220,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Why I expect successful (narrow) alignment"
    },
    "494a84c920e005a94c7b27ed88f88352": {
      "source_id": "494a84c920e005a94c7b27ed88f88352",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15833,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Disentangling arguments for the importance of AI safety"
    },
    "978b0cb289e6da604105ef7a804f616a": {
      "source_id": "978b0cb289e6da604105ef7a804f616a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3603,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "The case for building expertise to work on US AI policy, and how to do it"
    },
    "1b59078a61c054cf53a4ddb61a96557f": {
      "source_id": "1b59078a61c054cf53a4ddb61a96557f",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34253,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Ben Garfinkel: How sure are we about this AI stuff?"
    },
    "71048d61765d97163c9c195fa68dd32b": {
      "source_id": "71048d61765d97163c9c195fa68dd32b",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23825,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Three Biases That Made Me Believe in AI Risk"
    },
    "e480b746d9d5db6cfdeff672b4da9663": {
      "source_id": "e480b746d9d5db6cfdeff672b4da9663",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1118,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Confused about AI research as a means of addressing AI risk"
    },
    "c9fd01478cfe63e46a12236a93f45242": {
      "source_id": "c9fd01478cfe63e46a12236a93f45242",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32851,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Amanda Askell: AI safety needs social scientists"
    },
    "2abd33758182b18ee78abb339b42f722": {
      "source_id": "2abd33758182b18ee78abb339b42f722",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13998,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "CSER and FHI advice to UN High-level Panel on Digital Cooperation "
    },
    "d20d5749e71aad82fee1891e5fe44d8b": {
      "source_id": "d20d5749e71aad82fee1891e5fe44d8b",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11562,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "CSER Advice to EU High-Level Expert Group on AI"
    },
    "c977bebaec07b8782285aa447b4864c1": {
      "source_id": "c977bebaec07b8782285aa447b4864c1",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20183,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Eric Drexler: Paretotopian goal alignment"
    },
    "0f65ce0fb6d9cef1d32629872768b1cb": {
      "source_id": "0f65ce0fb6d9cef1d32629872768b1cb",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 39636,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": " Alignment Newsletter One Year Retrospective"
    },
    "b0c16b75b54e82f1e00a084d6ea93fd4": {
      "source_id": "b0c16b75b54e82f1e00a084d6ea93fd4",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2594,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Supporting global coordination in AI development: Why and how to contribute to i"
    },
    "211ed195cc27b2834ab496fc4dfae0f9": {
      "source_id": "211ed195cc27b2834ab496fc4dfae0f9",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 90858,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Long-Term Future Fund: April 2019 grant recommendations"
    },
    "93c6342321deb392ba18b7fa5b5f3474": {
      "source_id": "93c6342321deb392ba18b7fa5b5f3474",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29322,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Aligning Recommender Systems as Cause Area"
    },
    "8b29d3fdb1fd70fa38f4ea7f54c46430": {
      "source_id": "8b29d3fdb1fd70fa38f4ea7f54c46430",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33708,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Jade Leung: Why companies should be leading on AI governance"
    },
    "9a2773b2a91ee2e0e38d8973b289a9da": {
      "source_id": "9a2773b2a91ee2e0e38d8973b289a9da",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17995,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Information security careers for GCR reduction"
    },
    "48ab960511ed30a1ab5c2f57073f66db": {
      "source_id": "48ab960511ed30a1ab5c2f57073f66db",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16930,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "How Europe might matter for AI  governance"
    },
    "ec44aef2953ae8961234868d03a7c851": {
      "source_id": "ec44aef2953ae8961234868d03a7c851",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 850,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[Link] Thiel on GCRs"
    },
    "b803ae955e268d46f4fcb8bf5f05fdfe": {
      "source_id": "b803ae955e268d46f4fcb8bf5f05fdfe",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9725,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Ought: why it matters and ways to help"
    },
    "ad49dad74b72d4c11c66a1e474fef966": {
      "source_id": "ad49dad74b72d4c11c66a1e474fef966",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25507,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "An overview of arguments for concern about automation"
    },
    "b09dd286950fcef2e8c0cd49ff50878f": {
      "source_id": "b09dd286950fcef2e8c0cd49ff50878f",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20421,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "AI & Policy 1/3: On knowing the effect of today\u2019s policies on Transformative AI "
    },
    "df114bd21fceb22c6a1555f864abae26": {
      "source_id": "df114bd21fceb22c6a1555f864abae26",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9735,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "AI Forecasting Question Database (Forecasting infrastructure, part 3)"
    },
    "2f50ed7c8b7414a3eac3f99ccc8c6773": {
      "source_id": "2f50ed7c8b7414a3eac3f99ccc8c6773",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3671,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Implications of Quantum Computing for Artificial Intelligence alignment research"
    },
    "9ba8563923781ba900c102fb275f14ba": {
      "source_id": "9ba8563923781ba900c102fb275f14ba",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5278,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "How much EA analysis of AI safety as a cause area exists?"
    },
    "b14b546e21c42c87f06732f319434f7a": {
      "source_id": "b14b546e21c42c87f06732f319434f7a",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17010,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "UK policy and politics careers"
    },
    "c5322779f3bca4dd7fd446dddc295b55": {
      "source_id": "c5322779f3bca4dd7fd446dddc295b55",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8121,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Technical AGI safety research outside AI"
    },
    "a62cf0de6d7ec0a560014cd18ca5ebf2": {
      "source_id": "a62cf0de6d7ec0a560014cd18ca5ebf2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 30286,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Summary of Stuart Russell's new book, \"Human Compatible\""
    },
    "69ba8b76200d6056b259f041ad31b314": {
      "source_id": "69ba8b76200d6056b259f041ad31b314",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31781,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Assessing the state of AI R&D in the US, China, and Europe \u2013 Part 1: Output indi"
    },
    "3293861fc456bd230c5a36e68107e4bb": {
      "source_id": "3293861fc456bd230c5a36e68107e4bb",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22850,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "AI policy careers in the EU"
    },
    "e050f996a3983bbd8233275222929937": {
      "source_id": "e050f996a3983bbd8233275222929937",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56406,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "A conversation with Rohin Shah"
    },
    "f8af4f7fe626407597f7a6224b9df176": {
      "source_id": "f8af4f7fe626407597f7a6224b9df176",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62645,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "On AI Weapons"
    },
    "5175be0c660c7371003ebae0c10edbab": {
      "source_id": "5175be0c660c7371003ebae0c10edbab",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3323,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "I'm Buck Shlegeris, I do research and outreach at MIRI, AMA"
    },
    "1233044df2e3efc18d9aa366f887271d": {
      "source_id": "1233044df2e3efc18d9aa366f887271d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4268,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "AI safety scholarships look worth-funding (if other funding is sane)"
    },
    "4bc91544e4f9f977abe3fc1b7b5ee9b0": {
      "source_id": "4bc91544e4f9f977abe3fc1b7b5ee9b0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7421,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Are Humans 'Human Compatible'? "
    },
    "9b87acf98f80757d34cb65fdd30c4b67": {
      "source_id": "9b87acf98f80757d34cb65fdd30c4b67",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5884,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "But exactly how complex and fragile?"
    },
    "02b8bed2a4a5027f69e078ed8fa3a819": {
      "source_id": "02b8bed2a4a5027f69e078ed8fa3a819",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5214,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Conversation on AI risk with Adam Gleave"
    },
    "87c2007ca20d4e6e80989d4abe181c60": {
      "source_id": "87c2007ca20d4e6e80989d4abe181c60",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1534,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[Link] EAF Research agenda: \"Cooperation, Conflict, and Transformative Artificia"
    },
    "5bfd96d38a59e91081d0cec6d12978bb": {
      "source_id": "5bfd96d38a59e91081d0cec6d12978bb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13008,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AI Alignment 2018-2019 Review"
    },
    "e227d093697eec753a6ecbe6d93b67e9": {
      "source_id": "e227d093697eec753a6ecbe6d93b67e9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30475,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Brian Tse: Sino-Western cooperation in AI safety"
    },
    "6558514f051616c726c57571780185b1": {
      "source_id": "6558514f051616c726c57571780185b1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4507,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "FHI Report: The Windfall Clause: Distributing the Benefits of AI for the Common "
    },
    "650a317b63d4bc60da8c9b78f2bb4e4b": {
      "source_id": "650a317b63d4bc60da8c9b78f2bb4e4b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34628,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What can the principal-agent literature tell us about AI risk?"
    },
    "b1c365ccb1b1adca976dcf91c4384f59": {
      "source_id": "b1c365ccb1b1adca976dcf91c4384f59",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17035,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Short-Term AI Alignment as a Priority Cause"
    },
    "744c14012435abf0b887ebd1e8052934": {
      "source_id": "744c14012435abf0b887ebd1e8052934",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73863,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "My personal cruxes for working on AI safety"
    },
    "aaa4b121e2925039f5cbe4133a89f520": {
      "source_id": "aaa4b121e2925039f5cbe4133a89f520",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20921,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Cort\u00e9s, Pizarro, and Afonso as Precedents for Takeover"
    },
    "1b3aa0f9e748f9bb0b755174eea165aa": {
      "source_id": "1b3aa0f9e748f9bb0b755174eea165aa",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13528,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[Link and commentary] Beyond Near- and Long-Term: Towards a Clearer Account of R"
    },
    "2513e985312d785da5499502e5cff2f9": {
      "source_id": "2513e985312d785da5499502e5cff2f9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2678,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AGI in a vulnerable world"
    },
    "728f45f5ab0ad863075aad0da97eb75f": {
      "source_id": "728f45f5ab0ad863075aad0da97eb75f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10953,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Three kinds of competitiveness"
    },
    "b0eb04f3b3c476a522539ac71b3e7661": {
      "source_id": "b0eb04f3b3c476a522539ac71b3e7661",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42403,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Paul Christiano: Current work in AI alignment"
    },
    "9c722cf3b29ea7722b7113ada592004a": {
      "source_id": "9c722cf3b29ea7722b7113ada592004a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24294,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Takeaways from safety by default interviews"
    },
    "b63df0d8f4e6a9e7ba25c991aa832ac3": {
      "source_id": "b63df0d8f4e6a9e7ba25c991aa832ac3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12473,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Database of existential risk estimates"
    },
    "e90add5a189ae49b63cee15a0cfe193f": {
      "source_id": "e90add5a189ae49b63cee15a0cfe193f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62898,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Discontinuous progress in history: an update"
    },
    "1887b39dfff746fae43de741a766a4ac": {
      "source_id": "1887b39dfff746fae43de741a766a4ac",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 514,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "How do you talk about AI safety?"
    },
    "297d0ebc67427433cec7b390a4745a39": {
      "source_id": "297d0ebc67427433cec7b390a4745a39",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50493,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Critical Review of 'The Precipice': A Reassessment of the Risks of AI and Pandem"
    },
    "877895bc5bbb279c6a30d9bb9e6ea622": {
      "source_id": "877895bc5bbb279c6a30d9bb9e6ea622",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27161,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AI Governance Career Paths for Europeans"
    },
    "280a4c55eee8aaa978628b526f0506ce": {
      "source_id": "280a4c55eee8aaa978628b526f0506ce",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5723,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AI Research Considerations for Human Existential Safety (ARCHES)"
    },
    "f59d806c1a398b07f47958b3e02c0660": {
      "source_id": "f59d806c1a398b07f47958b3e02c0660",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1084,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Relevant pre-AGI possibilities"
    },
    "4142c4365b442493b5bfe764a665b597": {
      "source_id": "4142c4365b442493b5bfe764a665b597",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 151461,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "The flaws that make today's AI architecture unsafe and a new approach that could"
    },
    "f3201a441841894f12d0109094160b6e": {
      "source_id": "f3201a441841894f12d0109094160b6e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5772,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AI Governance Reading Group Guide"
    },
    "d631b3e934f93c961ff1150ce81f543b": {
      "source_id": "d631b3e934f93c961ff1150ce81f543b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35224,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Some promising career ideas beyond 80,000 Hours' priority paths"
    },
    "12a33366c0c640e25062a34b63db24ed": {
      "source_id": "12a33366c0c640e25062a34b63db24ed",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 550,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "FLI AI Alignment podcast: Evan Hubinger on Inner Alignment, Outer Alignment, and"
    },
    "e2ab8d7296b7662d00cc5cb1a6b79787": {
      "source_id": "e2ab8d7296b7662d00cc5cb1a6b79787",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35647,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Mahendra Prasad: Rational group decision-making"
    },
    "63689d25b069288864779724522c81aa": {
      "source_id": "63689d25b069288864779724522c81aa",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2977,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AMA or discuss my 80K podcast episode: Ben Garfinkel, FHI researcher"
    },
    "6af5feb95ccd1905152a0690e30fed8f": {
      "source_id": "6af5feb95ccd1905152a0690e30fed8f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4751,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "A list of good heuristics that the case for AI X-risk fails"
    },
    "0ccba3c8ec1dc55f520cff49b5503c21": {
      "source_id": "0ccba3c8ec1dc55f520cff49b5503c21",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1763,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "How strong is the evidence of unaligned AI systems causing harm?"
    },
    "fc6dce16c6b7ef9a312d715d78d67fd2": {
      "source_id": "fc6dce16c6b7ef9a312d715d78d67fd2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5435,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Intellectual Diversity in AI Safety"
    },
    "e3adae9db5997bfe0282c75291f4b610": {
      "source_id": "e3adae9db5997bfe0282c75291f4b610",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6198,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Why the Orthogonality Thesis's veracity is not the point:"
    },
    "9f84b3b381987f7b6bbd24eb8f7bc05f": {
      "source_id": "9f84b3b381987f7b6bbd24eb8f7bc05f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6149,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Scrutinizing AI Risk (80K, #81) - v. quick summary"
    },
    "9bdbfc3a5b5a7a94c373dc5c99218f69": {
      "source_id": "9bdbfc3a5b5a7a94c373dc5c99218f69",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27134,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Markus Anderljung and Ben Garfinkel: Fireside chat on AI governance"
    },
    "142810b0de8287f78ac8037d44aa6ac2": {
      "source_id": "142810b0de8287f78ac8037d44aa6ac2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25224,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Rohin Shah: What\u2019s been happening in AI alignment?"
    },
    "869993be9876cacd26d8b580882777b6": {
      "source_id": "869993be9876cacd26d8b580882777b6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24780,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "The academic contribution to AI safety seems large"
    },
    "acca0a3382a7a6a2b031a11e6fe91560": {
      "source_id": "acca0a3382a7a6a2b031a11e6fe91560",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1872,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What do we do if AI doesn't take over the world, but still causes a significant "
    },
    "50db0039ad76f68a172313943f091449": {
      "source_id": "50db0039ad76f68a172313943f091449",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2491,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Is GPT-3 the death of the paperclip maximizer?"
    },
    "0cfdc33a14b474c0f2a0653fdd6369c3": {
      "source_id": "0cfdc33a14b474c0f2a0653fdd6369c3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1171,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AI Risk: Increasing Persuasion Power"
    },
    "59d6dbcedca8388419814864b563d72e": {
      "source_id": "59d6dbcedca8388419814864b563d72e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 79556,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "My Understanding of Paul Christiano's Iterated Amplification AI Safety Research "
    },
    "e22a8051aff57e667c957320db427566": {
      "source_id": "e22a8051aff57e667c957320db427566",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6481,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Animal Rights, The Singularity, and Astronomical Suffering"
    },
    "e873fa4106349dcea6199aab48c4ecae": {
      "source_id": "e873fa4106349dcea6199aab48c4ecae",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17867,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Singapore\u2019s Technical AI Alignment Research Career Guide"
    },
    "b5c52070eb3c0595d6beb6bb340f5cf4": {
      "source_id": "b5c52070eb3c0595d6beb6bb340f5cf4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32331,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Asya Bergal: Reasons you might think human-level AI is unlikely to happen soon"
    },
    "9beaa95299d013c12664397124e8a57a": {
      "source_id": "9beaa95299d013c12664397124e8a57a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44798,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "New report on how much computational power it takes to match the human brain (Op"
    },
    "ef32bf7ffb15adc5f45aab1df6300604": {
      "source_id": "ef32bf7ffb15adc5f45aab1df6300604",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1460,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Are social media algorithms an existential risk?"
    },
    "75e31b93ae94eaa204f59d0fdb0bfbfc": {
      "source_id": "75e31b93ae94eaa204f59d0fdb0bfbfc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28623,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AI Governance: Opportunity and Theory of Impact"
    },
    "b2011754fd7d2ee2a213f5c77df92d12": {
      "source_id": "b2011754fd7d2ee2a213f5c77df92d12",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5656,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Hiring engineers and researchers to help align GPT-3"
    },
    "0d3d4be3db2264a762d7d35779f47dcf": {
      "source_id": "0d3d4be3db2264a762d7d35779f47dcf",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6999,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Feedback Request on EA Philippines' Career Advice Research for Technical AI Safe"
    },
    "a5f0746dda78822a3c353bb95c8cb05f": {
      "source_id": "a5f0746dda78822a3c353bb95c8cb05f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5648,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "[Link] How understanding valence could help make future AIs safer"
    },
    "14b54d769440375279c89362a0d33391": {
      "source_id": "14b54d769440375279c89362a0d33391",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53308,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "TIO: A mental health chatbot"
    },
    "e3572c0305dfad45cb4f59ecbf5ec31b": {
      "source_id": "e3572c0305dfad45cb4f59ecbf5ec31b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3665,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Longtermist reasons to work for innovative governments"
    },
    "8eda692ab8e39b17de6cb807f7eb1a11": {
      "source_id": "8eda692ab8e39b17de6cb807f7eb1a11",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2048,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "The case for taking AI seriously as a threat to humanity (Kelsey Piper)"
    },
    "cb882166491a886da132be8acc88ef2f": {
      "source_id": "cb882166491a886da132be8acc88ef2f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5389,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AGI safety from first principles"
    },
    "21da9cd5767e53789279611dc9b0123e": {
      "source_id": "21da9cd5767e53789279611dc9b0123e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 473,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Buck Shlegeris: How I think students should orient to AI safety"
    },
    "505ed5b86ac79ea440390c66f6f70d35": {
      "source_id": "505ed5b86ac79ea440390c66f6f70d35",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 501,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "How to build a safe advanced AI (Evan Hubinger) | What's up in AI safety? (Asya "
    },
    "5d83b479f36367f096e26bd1bbeb4045": {
      "source_id": "5d83b479f36367f096e26bd1bbeb4045",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20204,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "4 Years Later: President Trump and Global Catastrophic Risk"
    },
    "1a951570d027d9a8bdad926f0d84f15f": {
      "source_id": "1a951570d027d9a8bdad926f0d84f15f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8257,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AI risk hub in Singapore?"
    },
    "73466dfce17230ea3b30601701bc8318": {
      "source_id": "73466dfce17230ea3b30601701bc8318",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4205,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Consider paying me to do AI safety research work"
    },
    "cf3425078b7e84ef7fc85e8972effd24": {
      "source_id": "cf3425078b7e84ef7fc85e8972effd24",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 657,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What considerations influence whether I have more influence over short or long t"
    },
    "b1273e2497513488efc3672042d45521": {
      "source_id": "b1273e2497513488efc3672042d45521",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2708,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "How can I bet on short timelines?"
    },
    "75cb3ced44e74b024b660bfa91c6177d": {
      "source_id": "75cb3ced44e74b024b660bfa91c6177d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1357,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Donating against Short Term AI risks"
    },
    "ec918a61cfcddccb1f01e7e1e3709ff7": {
      "source_id": "ec918a61cfcddccb1f01e7e1e3709ff7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8784,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Announcing AI Safety Support"
    },
    "4b2c1557076426e66075495f27528cb0": {
      "source_id": "4b2c1557076426e66075495f27528cb0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20559,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Persuasion Tools: AI takeover without AGI or agency?"
    },
    "cc347121d41982610c1643184d25004f": {
      "source_id": "cc347121d41982610c1643184d25004f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 925,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Jaan Tallinn: Fireside chat (2020)"
    },
    "6c3d2e7e9647ffd17dd1d130b37c88cf": {
      "source_id": "6c3d2e7e9647ffd17dd1d130b37c88cf",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 814,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Tan Zhi Xuan: AI alignment, philosophical pluralism, and the relevance of non-We"
    },
    "1d636de97b91b886d82777610730561c": {
      "source_id": "1d636de97b91b886d82777610730561c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 248,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AGI Predictions"
    },
    "ed9bde06f3ed5b705e2ff4f40907c2d9": {
      "source_id": "ed9bde06f3ed5b705e2ff4f40907c2d9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3005,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Can we convince people to work on AI safety without convincing them about AGI ha"
    },
    "6a8bf2ffe6d33299a15e3d2c055e7311": {
      "source_id": "6a8bf2ffe6d33299a15e3d2c055e7311",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8285,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Delegated agents in practice:  How companies might end up selling AI services th"
    },
    "34ca4e78ec8ba71d78cde92e6a86f3fa": {
      "source_id": "34ca4e78ec8ba71d78cde92e6a86f3fa",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41304,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Centre for the Study of Existential Risk Four Month Report June - September 2020"
    },
    "ce9c14135a9c662d2b3d6e374ce4bbf4": {
      "source_id": "ce9c14135a9c662d2b3d6e374ce4bbf4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12466,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "LessWrong is now a book, available for pre-order!"
    },
    "63f337b8fcc5bf13394841efcf4f9272": {
      "source_id": "63f337b8fcc5bf13394841efcf4f9272",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2819,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Idea: an AI governance group colocated with every AI research group!"
    },
    "8ff12f4a6cdbd53e2e2c1aa406b3d1d1": {
      "source_id": "8ff12f4a6cdbd53e2e2c1aa406b3d1d1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2003,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Draft report on AI timelines"
    },
    "78fb671fe7d388c5aa2c60afb34e280f": {
      "source_id": "78fb671fe7d388c5aa2c60afb34e280f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 98241,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Some AI research areas and their relevance to existential safety"
    },
    "6c6de7d153f78f68691e70676a9bc7e3": {
      "source_id": "6c6de7d153f78f68691e70676a9bc7e3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16726,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Open Philanthropy's AI governance grantmaking (so far)"
    },
    "c1564585aaa9ecf8a4c5e1f8be6a0721": {
      "source_id": "c1564585aaa9ecf8a4c5e1f8be6a0721",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28179,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Mitigating x-risk through modularity"
    },
    "1d36f235c82fd5c285a30aff334ce8b7": {
      "source_id": "1d36f235c82fd5c285a30aff334ce8b7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37756,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "TAI Safety Bibliographic Database"
    },
    "aa5b9a9929f4fd4bcbb1edd241ca8c4d": {
      "source_id": "aa5b9a9929f4fd4bcbb1edd241ca8c4d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3452,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "CFP for the Largest Annual Meeting of Political Science: Get Help With Your Rese"
    },
    "d60bf56f18b3ee61b5b67bf55a79bf33": {
      "source_id": "d60bf56f18b3ee61b5b67bf55a79bf33",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27802,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Against GDP as a metric for timelines and takeoff speeds"
    },
    "d7069b8522e7d186e372df3abd3c84f7": {
      "source_id": "d7069b8522e7d186e372df3abd3c84f7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4559,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Emerging Technologies: More to explore"
    },
    "24eed08ff654c80acad50bc8cc7bd8ce": {
      "source_id": "24eed08ff654c80acad50bc8cc7bd8ce",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23033,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What does it mean to become an expert in AI Hardware?"
    },
    "2dbff511b0cbfcb6216f4dbd23edc694": {
      "source_id": "2dbff511b0cbfcb6216f4dbd23edc694",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1482,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Birds, Brains, Planes, and AI: Against Appeals to the Complexity/Mysteriousness/"
    },
    "2cb081190ced9748a22ddf244440e2bb": {
      "source_id": "2cb081190ced9748a22ddf244440e2bb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16168,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Some thoughts on risks from narrow, non-agentic AI"
    },
    "80051aff18f088ca33b1ea4a31c0b98e": {
      "source_id": "80051aff18f088ca33b1ea4a31c0b98e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11840,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Singapore AI Policy Career Guide"
    },
    "d0813609e6f836be2bdb5b774f065e1c": {
      "source_id": "d0813609e6f836be2bdb5b774f065e1c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32520,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Baobao Zhang: How social science research can inform AI governance"
    },
    "4ac9b72ebbe5cc049c89aa760512d92b": {
      "source_id": "4ac9b72ebbe5cc049c89aa760512d92b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1700,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AMA: Ajeya Cotra, researcher at Open Phil"
    },
    "d1519efec9682ddd3d913146bfecc887": {
      "source_id": "d1519efec9682ddd3d913146bfecc887",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22955,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "13 Recent Publications on Existential Risk (Jan 2021 update)"
    },
    "6ff3d22cb79f312b9c33e67f21de7108": {
      "source_id": "6ff3d22cb79f312b9c33e67f21de7108",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12905,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Interview with Tom Chivers: \u201cAI is a plausible existential risk, but it feels as"
    },
    "33e67dd5d5e5ddd873bb4750568d92e7": {
      "source_id": "33e67dd5d5e5ddd873bb4750568d92e7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3049,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Google's ethics is alarming"
    },
    "35486af118fc2a5a568d0d801e7a8178": {
      "source_id": "35486af118fc2a5a568d0d801e7a8178",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37402,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The Importance of Artificial Sentience"
    },
    "7e03fd4216c27fb8e80046c513426133": {
      "source_id": "7e03fd4216c27fb8e80046c513426133",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 1528,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[Link post] Coordination challenges for preventing AI conflict"
    },
    "d8292c13c6d590a43b46d15c80431cf2": {
      "source_id": "d8292c13c6d590a43b46d15c80431cf2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36160,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Is Democracy a Fad?"
    },
    "2c19520ee8d2a2421083132f1bdf0032": {
      "source_id": "2c19520ee8d2a2421083132f1bdf0032",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9460,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Introducing The Nonlinear Fund: AI Safety research, incubation, and funding"
    },
    "2580ee8ab4532840ac53d5c55a15d2ad": {
      "source_id": "2580ee8ab4532840ac53d5c55a15d2ad",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19384,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AGI risk: analogies & arguments"
    },
    "6d18457efc695a14ded35f684e4fa897": {
      "source_id": "6d18457efc695a14ded35f684e4fa897",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4588,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Report on Semi-informative Priors for AI timelines (Open Philanthropy)"
    },
    "d76cff128b81162a27ee6fc27c75d645": {
      "source_id": "d76cff128b81162a27ee6fc27c75d645",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16355,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Case studies of self-governance to reduce technology risk"
    },
    "aa9db7d031ed31a1bdece12e593d34b0": {
      "source_id": "aa9db7d031ed31a1bdece12e593d34b0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73423,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Working in Congress (Part #1): Background and some EA cause area analysis"
    },
    "cdd23ec703718d8b1fcf0c2cfb18e0fe": {
      "source_id": "cdd23ec703718d8b1fcf0c2cfb18e0fe",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59709,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "International cooperation as a tool to reduce two existential risks."
    },
    "2fb00b2083c207b9860c9e94c262d15c": {
      "source_id": "2fb00b2083c207b9860c9e94c262d15c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1363,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A new proposal for regulating AI in the EU"
    },
    "1b5270bd2fce212eeaa5795b77a7eb6b": {
      "source_id": "1b5270bd2fce212eeaa5795b77a7eb6b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4377,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Why AI is Harder Than We Think - Melanie Mitchell"
    },
    "07d210df71a427b21372a6d5b352fed8": {
      "source_id": "07d210df71a427b21372a6d5b352fed8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1137,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Draft report on existential risk from power-seeking AI"
    },
    "26330f509eedb89049af64d045f3ecc3": {
      "source_id": "26330f509eedb89049af64d045f3ecc3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1787,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What harm could AI safety do?"
    },
    "3944390cb1cee4faaf51742eb1cff6b2": {
      "source_id": "3944390cb1cee4faaf51742eb1cff6b2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 618,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Why should we *not* put effort into AI safety research?"
    },
    "bb5e98aa80f3540ad9b6643feb2ef4b2": {
      "source_id": "bb5e98aa80f3540ad9b6643feb2ef4b2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 116814,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Long-Term Future Fund: May 2021 grant recommendations"
    },
    "04546121e9fcaea3387ce3e622db2055": {
      "source_id": "04546121e9fcaea3387ce3e622db2055",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5104,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Predict responses to the \"existential risk from AI\" survey"
    },
    "c768519deab63417446eb895edeee7be": {
      "source_id": "c768519deab63417446eb895edeee7be",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11662,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AI Safety Career Bottlenecks Survey Responses Responses"
    },
    "25634187897ac76be2c8838a46d3b4a7": {
      "source_id": "25634187897ac76be2c8838a46d3b4a7",
      "quality_score": 2.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 7959,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Final Report of the National Security Commission on Artificial Intelligence (NSC"
    },
    "6973faefbdb51a08c88d3d066e29727b": {
      "source_id": "6973faefbdb51a08c88d3d066e29727b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37876,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "\"Existential risk from AI\" survey results"
    },
    "6657abc65d7c228106495975cb54d910": {
      "source_id": "6657abc65d7c228106495975cb54d910",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3841,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Some AI Governance Research Ideas"
    },
    "4fdebef52ed2fcab93983ff6587b9b04": {
      "source_id": "4fdebef52ed2fcab93983ff6587b9b04",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10227,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A Viral License for AI Safety"
    },
    "5f8d321d48ad1262a02bddd4d2ceb403": {
      "source_id": "5f8d321d48ad1262a02bddd4d2ceb403",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34041,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "High Impact Careers in Formal Verification: Artificial Intelligence"
    },
    "2374cfe6c1f49103b30c576140411b63": {
      "source_id": "2374cfe6c1f49103b30c576140411b63",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17505,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Survey on AI existential risk scenarios"
    },
    "12956e466dfbd24952ed0ed936c05a73": {
      "source_id": "12956e466dfbd24952ed0ed936c05a73",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38779,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Humanities Research Ideas for Longtermists"
    },
    "f07e44723311c2698ff47dc3c912b507": {
      "source_id": "f07e44723311c2698ff47dc3c912b507",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 825,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What is an example of recent, tangible progress in AI safety research?"
    },
    "52e7fbadbc377089fa65b83de088b62b": {
      "source_id": "52e7fbadbc377089fa65b83de088b62b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 80923,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Shallow evaluations of longtermist organizations"
    },
    "8df2e4dfa3338e222785e30dd91e7ac8": {
      "source_id": "8df2e4dfa3338e222785e30dd91e7ac8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2811,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The positive case for a focus on achieving safe AI?"
    },
    "b13ade2d4ade29affff6e6de8fde2933": {
      "source_id": "b13ade2d4ade29affff6e6de8fde2933",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4467,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Getting started independently in AI Safety"
    },
    "9f9f3f2d60d4d125f6cebee928b7311a": {
      "source_id": "9f9f3f2d60d4d125f6cebee928b7311a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26185,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A Simple Model of AGI Deployment Risk"
    },
    "2c54f7f27790b747f1ded570d4084017": {
      "source_id": "2c54f7f27790b747f1ded570d4084017",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32657,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A personal take on longtermist AI governance"
    },
    "e140803539a35f7e98df69774a59fb06": {
      "source_id": "e140803539a35f7e98df69774a59fb06",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2880,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Books and lecture series relevant to AI governance?"
    },
    "5eb6587456e33311c7264c402820da53": {
      "source_id": "5eb6587456e33311c7264c402820da53",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11090,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Apply to the new Open Philanthropy Technology Policy Fellowship!"
    },
    "34538a902ecb481a48cb37366ade491c": {
      "source_id": "34538a902ecb481a48cb37366ade491c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14165,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "How Do AI Timelines Affect Giving Now vs. Later?"
    },
    "d4753acc6e64cd4b46b7439004f109b4": {
      "source_id": "d4753acc6e64cd4b46b7439004f109b4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 243953,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Chris Olah on what the hell is going on inside neural networks"
    },
    "b2d2e16172c27fdfc61ec2dc10a5cc75": {
      "source_id": "b2d2e16172c27fdfc61ec2dc10a5cc75",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21527,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Forecasting Transformative AI: What Kind of AI?"
    },
    "28a9031124d0a9bbcf98a904dae01cfe": {
      "source_id": "28a9031124d0a9bbcf98a904dae01cfe",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 902,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "1h-volunteers needed for a small AI Safety-related research project "
    },
    "832f9f4258dc6f447fdc42a03706cd15": {
      "source_id": "832f9f4258dc6f447fdc42a03706cd15",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2435,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What are the top priorities in a slow-takeoff, multipolar world?"
    },
    "d24150b93a61a996de5a91aa8d2aeaf1": {
      "source_id": "d24150b93a61a996de5a91aa8d2aeaf1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2113,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Making of #IAN"
    },
    "cfd3bf2d7e2894f5fc6391fba60f3824": {
      "source_id": "cfd3bf2d7e2894f5fc6391fba60f3824",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9994,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "\"Epistemic maps\" for AI Debates? (or for other issues)"
    },
    "3bb43fc45b5b788fdd9b1b372599e1db": {
      "source_id": "3bb43fc45b5b788fdd9b1b372599e1db",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2013,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Crazy ideas sometimes do work"
    },
    "a7beb181892e26ecb650675333907901": {
      "source_id": "a7beb181892e26ecb650675333907901",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2030,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "How to get more academics enthusiastic about doing AI Safety research?"
    },
    "76bb78ee4d3a81c3782d82e179cd8184": {
      "source_id": "76bb78ee4d3a81c3782d82e179cd8184",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2039,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "List of AI safety courses and resources"
    },
    "4aaf2df3680335af113f604bfe031c8a": {
      "source_id": "4aaf2df3680335af113f604bfe031c8a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25204,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AI Timelines: Where the Arguments, and the \"Experts,\" Stand"
    },
    "b93178051295c974769faaa5642b2008": {
      "source_id": "b93178051295c974769faaa5642b2008",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43684,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A mesa-optimization perspective on AI valence and moral patienthood"
    },
    "781e33473918ffb1405486dee27df60a": {
      "source_id": "781e33473918ffb1405486dee27df60a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14398,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What is the EU AI Act and why should you care about it?"
    },
    "89890991c52e5f424bf9f7b4f9077e37": {
      "source_id": "89890991c52e5f424bf9f7b4f9077e37",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 133586,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Chris Olah on working at top AI labs without an undergrad degree"
    },
    "92386d8cd1ce5fd634c2edaddc7a7c69": {
      "source_id": "92386d8cd1ce5fd634c2edaddc7a7c69",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34099,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "How to make the best of the most important century?"
    },
    "3f0a0e4679b8e8d79cd873091e34457f": {
      "source_id": "3f0a0e4679b8e8d79cd873091e34457f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16130,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The Metaethics and Normative Ethics of AGI Value Alignment: Many Questions, Some"
    },
    "a3abfddd8e3206e48b3eedf4679a5956": {
      "source_id": "a3abfddd8e3206e48b3eedf4679a5956",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2235,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What kind of event, targeted to undergraduate CS majors, would be most effective"
    },
    "a77d1f67d07bac87903fd8e501bf6496": {
      "source_id": "a77d1f67d07bac87903fd8e501bf6496",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31901,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "On Scaling Academia"
    },
    "eeda48074a23045aed02451e58d43311": {
      "source_id": "eeda48074a23045aed02451e58d43311",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1331,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Is working on AI safety as dangerous as ignoring it?"
    },
    "7bab43b68581d16f65a292788ecb31c4": {
      "source_id": "7bab43b68581d16f65a292788ecb31c4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30000,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Why AI alignment could be hard with modern deep learning"
    },
    "753cf32d82aef95db9832d0e54420f2d": {
      "source_id": "753cf32d82aef95db9832d0e54420f2d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11224,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Fanaticism in AI: SERI Project"
    },
    "5784ee0c8a79e9fd77924bd2407554ec": {
      "source_id": "5784ee0c8a79e9fd77924bd2407554ec",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20243,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The problem of artificial suffering"
    },
    "422d3f5d822903a6d5a5b2611a8e0506": {
      "source_id": "422d3f5d822903a6d5a5b2611a8e0506",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7473,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Seeking social science students / collaborators interested in AI existential ris"
    },
    "a99334f3f152d07df59391d25204899c": {
      "source_id": "a99334f3f152d07df59391d25204899c",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 4585,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[Link post] How plausible are AI Takeover scenarios?"
    },
    "e9a5527bbf29e6ea708548932af718a2": {
      "source_id": "e9a5527bbf29e6ea708548932af718a2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1152,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Why does (any particular) AI safety work reduce s-risks more than it increases t"
    },
    "c6f254a127d19c396c6c860f4ddf32d3": {
      "source_id": "c6f254a127d19c396c6c860f4ddf32d3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54310,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "  Nuclear Espionage and AI Governance"
    },
    "1a28ac5ef75b24190d31474395509030": {
      "source_id": "1a28ac5ef75b24190d31474395509030",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4765,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Why aren't you freaking out about OpenAI? At what point would you start?"
    },
    "570ebfbda4befeab8d89dd7361489d6d": {
      "source_id": "570ebfbda4befeab8d89dd7361489d6d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21770,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AI Risk in Africa"
    },
    "a89e7d105507c8db32e9a2f5310fca22": {
      "source_id": "a89e7d105507c8db32e9a2f5310fca22",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 798,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Is it crunch time yet? If so, who can help?"
    },
    "ef6e43011bbde3983259c475016fdb2b": {
      "source_id": "ef6e43011bbde3983259c475016fdb2b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11562,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[Creative Writing Contest] The Puppy Problem"
    },
    "e9b3b4a2d3642147ada0536286ad0806": {
      "source_id": "e9b3b4a2d3642147ada0536286ad0806",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5506,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "General vs specific arguments for the longtermist importance of shaping AI devel"
    },
    "49361b7a13b2c0d261823e365b28ff1a": {
      "source_id": "49361b7a13b2c0d261823e365b28ff1a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2203,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "An ML safety insurance company - shower thoughts"
    },
    "e49aed44d1604721d1fc0ff9705ac340": {
      "source_id": "e49aed44d1604721d1fc0ff9705ac340",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21288,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "New Working Paper Series of the Legal Priorities Project"
    },
    "ac93410857e0fefcbc29def53de3ecf5": {
      "source_id": "ac93410857e0fefcbc29def53de3ecf5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 161,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[Creative Writing Contest] An AI Safety Limerick"
    },
    "4e6fae4a3d88eec532f8a64c29d81fea": {
      "source_id": "4e6fae4a3d88eec532f8a64c29d81fea",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21081,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Truthful AI"
    },
    "ffc384bea1818441ee293a83c4b1729f": {
      "source_id": "ffc384bea1818441ee293a83c4b1729f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18946,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AGI Safety Fundamentals curriculum and application"
    },
    "0ba7777b873af8b9a65901ab2248f4d0": {
      "source_id": "0ba7777b873af8b9a65901ab2248f4d0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 868,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Podcast: Krister Bykvist on moral uncertainty, rationality, metaethics, AI and f"
    },
    "4730b729bf4d9d0b57913f3043087a8b": {
      "source_id": "4730b729bf4d9d0b57913f3043087a8b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2168,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Apply to be a Stanford HAI Junior Fellow (Assistant Professor- Research) by Nov."
    },
    "ce498b36e25d070c43698e9b4f440379": {
      "source_id": "ce498b36e25d070c43698e9b4f440379",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19600,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The case for long-term corporate governance of AI"
    },
    "fb13f936a1256d136ae7269a76188c6e": {
      "source_id": "fb13f936a1256d136ae7269a76188c6e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3202,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Apply to the ML for Alignment Bootcamp (MLAB) in Berkeley [Jan 3 - Jan 22]"
    },
    "c4ca19668e0a7f7d85a4ddc8145b0c38": {
      "source_id": "c4ca19668e0a7f7d85a4ddc8145b0c38",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2504,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[Discussion] Best intuition pumps for AI safety"
    },
    "6aceab42997dd94a068a98fc2bb6267d": {
      "source_id": "6aceab42997dd94a068a98fc2bb6267d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15487,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Long-term AI policy strategy research and implementation"
    },
    "70bfa4db8b594316ac3471b740a3ec40": {
      "source_id": "70bfa4db8b594316ac3471b740a3ec40",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 963,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "BERI is hiring an ML Software Engineer"
    },
    "990efab9f0eaf901bf8eccb08253086d": {
      "source_id": "990efab9f0eaf901bf8eccb08253086d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 63115,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Discussion with Eliezer Yudkowsky on AGI interventions"
    },
    "e799ca6cc64f799352c37d70e87ad752": {
      "source_id": "e799ca6cc64f799352c37d70e87ad752",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 732,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What would you do if you had a lot of money/power/influence and you thought that"
    },
    "463d7460f54c40386385908689d362c0": {
      "source_id": "463d7460f54c40386385908689d362c0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10679,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "\"Slower tech development\" can be about ordering, gradualness, or distance from n"
    },
    "54a2c953a1c18502f14fe969611b0832": {
      "source_id": "54a2c953a1c18502f14fe969611b0832",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 176657,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Ngo and Yudkowsky on alignment difficulty"
    },
    "0175da550866789221636beb438d5c21": {
      "source_id": "0175da550866789221636beb438d5c21",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 72366,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Ngo and Yudkowsky on AI capability gains"
    },
    "346ec3b09b53a4da9b8f12dd0c83d363": {
      "source_id": "346ec3b09b53a4da9b8f12dd0c83d363",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 110307,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Yudkowsky and Christiano discuss \"Takeoff Speeds\""
    },
    "3aadb8d859a82b9be4a9667c22c97c83": {
      "source_id": "3aadb8d859a82b9be4a9667c22c97c83",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15602,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AI Safety researcher career review"
    },
    "8f2d53a8a6389f4d9de7a0f576abe599": {
      "source_id": "8f2d53a8a6389f4d9de7a0f576abe599",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 782,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What is most confusing to you about AI stuff?"
    },
    "c2271184acc62af1153bafe25d2b3631": {
      "source_id": "c2271184acc62af1153bafe25d2b3631",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3531,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "HIRING: Inform and shape a new project on AI safety at Partnership on AI  "
    },
    "c7698c48a121c142421f38bb11a5528f": {
      "source_id": "c7698c48a121c142421f38bb11a5528f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 125175,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Christiano, Cotra, and Yudkowsky on AI progress"
    },
    "7013a589f5c02e24bce0fe532902ba29": {
      "source_id": "7013a589f5c02e24bce0fe532902ba29",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2195,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Redwood Research is hiring for several roles"
    },
    "c9f4d91caf3e7bced128f2ceb2ad6f93": {
      "source_id": "c9f4d91caf3e7bced128f2ceb2ad6f93",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 956,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AI Governance Course - Curriculum and Application"
    },
    "4675304f389cea1044a9bf2d09293b65": {
      "source_id": "4675304f389cea1044a9bf2d09293b65",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 74704,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Soares, Tallinn, and Yudkowsky discuss AGI cognition"
    },
    "3dbdb8726847c6abcd6d7fba7f867ae4": {
      "source_id": "3dbdb8726847c6abcd6d7fba7f867ae4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3017,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Sydney AI Safety Fellowship"
    },
    "a8dd4bb0a872fbb68ff66487cece1dbf": {
      "source_id": "a8dd4bb0a872fbb68ff66487cece1dbf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16976,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "EA megaprojects continued"
    },
    "6a835cf7c85f3d0eccb81ce709ee0edb": {
      "source_id": "6a835cf7c85f3d0eccb81ce709ee0edb",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3025,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What \u201cdefense layers\u201d should governments, AI labs, and businesses use to prevent"
    },
    "a0ff446c17843334d21009ba766f7bfc": {
      "source_id": "a0ff446c17843334d21009ba766f7bfc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37564,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Shulman and Yudkowsky on AI progress"
    },
    "5e83c3b4c9dcbd4386abec1fa3df9976": {
      "source_id": "5e83c3b4c9dcbd4386abec1fa3df9976",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4026,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Contribute by facilitating the AGI Safety Fundamentals Programme"
    },
    "963f227c808ed8cf9be51191aa984fac": {
      "source_id": "963f227c808ed8cf9be51191aa984fac",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 64440,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Retrospective on the Summer 2021 AGI Safety Fundamentals"
    },
    "1343ff94861d9b58b592879b9f84d98a": {
      "source_id": "1343ff94861d9b58b592879b9f84d98a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5341,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Enabling more feedback"
    },
    "c64c31a73dc526896a3998e37baf3186": {
      "source_id": "c64c31a73dc526896a3998e37baf3186",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 111581,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What role should evolutionary analogies play in understanding AI takeoff speeds?"
    },
    "f6d8e962911f45d7618a2fcc87c6c097": {
      "source_id": "f6d8e962911f45d7618a2fcc87c6c097",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17960,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Stackelberg Games and Cooperative Commitment: My Thoughts and Reflections on a 2"
    },
    "a2cba7793d07242ee4e9dc6337f4227f": {
      "source_id": "a2cba7793d07242ee4e9dc6337f4227f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20965,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AI Safety: Applying to Graduate Studies"
    },
    "6385e62be3855354d4fbb1a17def1df5": {
      "source_id": "6385e62be3855354d4fbb1a17def1df5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30842,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "My Overview of the AI Alignment Landscape: A Bird\u2019s Eye View"
    },
    "84b4ba281839ab60568966055f6ed0da": {
      "source_id": "84b4ba281839ab60568966055f6ed0da",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2485,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Reviews of \"Is power-seeking AI an existential risk?\""
    },
    "3aab24edba6ebc2494834ffda04fd851": {
      "source_id": "3aab24edba6ebc2494834ffda04fd851",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1868,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[Extended Deadline: Jan 23rd] Announcing the PIBBSS Summer Research Fellowship"
    },
    "87d76101f5e42e94e95e3feaef0981a0": {
      "source_id": "87d76101f5e42e94e95e3feaef0981a0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4231,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Why don't governments seem to mind that companies are explicitly trying to make "
    },
    "96ae41e12710cbbfda44c1ab8395677d": {
      "source_id": "96ae41e12710cbbfda44c1ab8395677d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3413,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Free Guy, a rom-com on the moral patienthood of digital sentience"
    },
    "f42c1c55c1518c8d8028368f62819023": {
      "source_id": "f42c1c55c1518c8d8028368f62819023",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1178,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Should the EA community have a DL engineering fellowship?"
    },
    "c181696ff9ea1de7770df30e8a44891d": {
      "source_id": "c181696ff9ea1de7770df30e8a44891d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12156,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AGI alignment results from a series of aligned actions "
    },
    "9577bff1835670647da0889f52c27a62": {
      "source_id": "9577bff1835670647da0889f52c27a62",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7098,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "13 Very Different Stances on AGI"
    },
    "441f14b38de7330fbe0d46ca5475b3dc": {
      "source_id": "441f14b38de7330fbe0d46ca5475b3dc",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5450,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Increased Availability and Willingness for Deployment of Resources for Effective"
    },
    "6556fa67c975c1e41f6e8bb2f257d39f": {
      "source_id": "6556fa67c975c1e41f6e8bb2f257d39f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9225,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Will the EU regulations on AI matter to the rest of the world?"
    },
    "0eb1c62dff63ea457e43e22111014cfa": {
      "source_id": "0eb1c62dff63ea457e43e22111014cfa",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25284,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "GovAI Annual Report 2021"
    },
    "f2bebc8716a642f61b2149ae641942bb": {
      "source_id": "f2bebc8716a642f61b2149ae641942bb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32276,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Consider trying the ELK contest (I am)"
    },
    "7e34eaddb0b5781da51fb80b7405dfe2": {
      "source_id": "7e34eaddb0b5781da51fb80b7405dfe2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12943,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI alignment research links"
    },
    "0b7879487d77a9479d6d3ed65d2dee7f": {
      "source_id": "0b7879487d77a9479d6d3ed65d2dee7f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4762,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What is the role of Bayesian ML for AI alignment/safety?"
    },
    "5a555073cb49c478d91c5c250bde9d9f": {
      "source_id": "5a555073cb49c478d91c5c250bde9d9f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10935,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "FLI launches Worldbuilding Contest with $100,000 in prizes"
    },
    "2b6d29a9953d47f239c92c15ce48a245": {
      "source_id": "2b6d29a9953d47f239c92c15ce48a245",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2551,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "PIBBSS Fellowship: Bounty for Referrals & Deadline Extension"
    },
    "0d3b8897beb1240adfddc4286b8bc679": {
      "source_id": "0d3b8897beb1240adfddc4286b8bc679",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12320,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Clarifications about structural risk from AI"
    },
    "eaf2912720bab68deba1f0d8fe5624bf": {
      "source_id": "eaf2912720bab68deba1f0d8fe5624bf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23288,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The longtermist AI governance landscape: a basic overview"
    },
    "83f1ecea4da5ea62bea9a1922c0e0fca": {
      "source_id": "83f1ecea4da5ea62bea9a1922c0e0fca",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4240,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "My plan for a \u201cMost Important Century\u201d reading group"
    },
    "20023b34d2f998717e754eaef00e7bfd": {
      "source_id": "20023b34d2f998717e754eaef00e7bfd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18880,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI acceleration from a safety perspective: Trade-offs and considerations "
    },
    "299cbccd4be0540db50bf64472f892fa": {
      "source_id": "299cbccd4be0540db50bf64472f892fa",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9266,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "European Union AI Development and Governance Partnerships "
    },
    "ac23c63f887ae137350ae8cde3354170": {
      "source_id": "ac23c63f887ae137350ae8cde3354170",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6411,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Action: Help expand funding for AI Safety by coordinating on NSF response"
    },
    "24ae7d44751bda78f0720202f6e07fd8": {
      "source_id": "24ae7d44751bda78f0720202f6e07fd8",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 535,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[linkpost] Sharing powerful AI models: the emerging paradigm of structured acces"
    },
    "2f71aa8adf7dab703d90c8449ab743fb": {
      "source_id": "2f71aa8adf7dab703d90c8449ab743fb",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7932,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Argument Against Impact: EU Is Not an AI Superpower "
    },
    "7e8c8b918469a1743aa04338e0a71620": {
      "source_id": "7e8c8b918469a1743aa04338e0a71620",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33160,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Should you work in the European Union to do AGI governance?"
    },
    "e6509cfb39f56da616c06a736916c748": {
      "source_id": "e6509cfb39f56da616c06a736916c748",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5712,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AMA: Future of Life Institute's EU Team"
    },
    "5d2ff4d1c45b6c5b01c84802a3a9ac62": {
      "source_id": "5d2ff4d1c45b6c5b01c84802a3a9ac62",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20234,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Software engineering - Career review"
    },
    "593c20c38e5c070eaab3428eedb742a1": {
      "source_id": "593c20c38e5c070eaab3428eedb742a1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47840,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Defending against Adversarial Policies in Reinforcement Learning with Alternatin"
    },
    "f428b830062868cb824af8243769db87": {
      "source_id": "f428b830062868cb824af8243769db87",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1219,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is a career in making AI systems more secure a meaningful way to mitigate the X-"
    },
    "5c116f1967207edf9d2ea1129f424fe3": {
      "source_id": "5c116f1967207edf9d2ea1129f424fe3",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 3092,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Linkpost] How To Get Into Independent Research On Alignment/Agency"
    },
    "8cf0fab14359eaa28773365459ed364e": {
      "source_id": "8cf0fab14359eaa28773365459ed364e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59604,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Map to Navigate AI Governance"
    },
    "a6dbedc3b51015f9d4d292b4023872e4": {
      "source_id": "a6dbedc3b51015f9d4d292b4023872e4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1370,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Analogy of AI Alignment as Raising a Child?"
    },
    "37e9cbd3e92fe4685fedff78e5b83816": {
      "source_id": "37e9cbd3e92fe4685fedff78e5b83816",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 64358,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Ngo and Yudkowsky on scientific reasoning and pivotal acts"
    },
    "56a93afadfb89acfb1f7ca0be27ccb7f": {
      "source_id": "56a93afadfb89acfb1f7ca0be27ccb7f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37808,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Important, actionable research questions for the most important century"
    },
    "53386313443454949a40970875e09d48": {
      "source_id": "53386313443454949a40970875e09d48",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14494,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Re: Some thoughts on vegetarianism and veganism"
    },
    "0b5d521d8da132120ce63893b6fb832a": {
      "source_id": "0b5d521d8da132120ce63893b6fb832a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3799,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "University community building seems like the wrong model for AI safety"
    },
    "faeeac705be66972eab9675dffd3e73d": {
      "source_id": "faeeac705be66972eab9675dffd3e73d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1754,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "New Speaker Series on AI Alignment Starting March 3"
    },
    "9c8ce06aba37bd28b9ff53b7e2729c8d": {
      "source_id": "9c8ce06aba37bd28b9ff53b7e2729c8d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4492,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Being an individual alignment grantmaker"
    },
    "941241ba801daf81c53938e1412c672f": {
      "source_id": "941241ba801daf81c53938e1412c672f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 168229,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Shah and Yudkowsky on alignment failures"
    },
    "7ef73ab62b72b86fb59070538ee3ac28": {
      "source_id": "7ef73ab62b72b86fb59070538ee3ac28",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1137,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI views and disagreements AMA: Christiano, Ngo, Shah, Soares, Yudkowsky"
    },
    "144bde86d3c7a40e0572e146ee05d62f": {
      "source_id": "144bde86d3c7a40e0572e146ee05d62f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2843,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Value Alignment Speaker Series Presented By EA Berkeley"
    },
    "d62afb9eae079cb387080b627743ddb8": {
      "source_id": "d62afb9eae079cb387080b627743ddb8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4652,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AGI x-risk timelines: 10% chance (by year X) estimates should be the headline, n"
    },
    "f42ec52a78acd06ebc040b0e84d7800b": {
      "source_id": "f42ec52a78acd06ebc040b0e84d7800b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1727,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Ethical Committee"
    },
    "2c81b91f3b9dc7f25bae6fa41415b7c0": {
      "source_id": "2c81b91f3b9dc7f25bae6fa41415b7c0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9067,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Credo AI is hiring!"
    },
    "857cc23f0d4f1d361420ab1c2495d584": {
      "source_id": "857cc23f0d4f1d361420ab1c2495d584",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1106,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is transformative AI the biggest existential risk? Why or why not?"
    },
    "4c70c57d0e2735292b7517e5521e4ab8": {
      "source_id": "4c70c57d0e2735292b7517e5521e4ab8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18167,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Risk is like Terminator; Stop Saying it's Not"
    },
    "e5d5c9d01979735e90db77933d92eefe": {
      "source_id": "e5d5c9d01979735e90db77933d92eefe",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4559,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "\u201cIntro to brain-like-AGI safety\u201d series\u2014halfway point!"
    },
    "a929932a5b04c882b658a7960372f0bd": {
      "source_id": "a929932a5b04c882b658a7960372f0bd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19884,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Followup on Terminator"
    },
    "f0a2681cec2f5dfadaac158c1e58c7fc": {
      "source_id": "f0a2681cec2f5dfadaac158c1e58c7fc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18102,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "New GPT3 Impressive Capabilities - InstructGPT3 [1/2] "
    },
    "e20b5d01ebed60ae34be36bcf28ac709": {
      "source_id": "e20b5d01ebed60ae34be36bcf28ac709",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2530,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "There should be an AI safety project board"
    },
    "066ba353d3e17ac61a96b5a0d4c8c0de": {
      "source_id": "066ba353d3e17ac61a96b5a0d4c8c0de",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23007,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Early-warning Forecasting Center: What it is, and why it'd be cool"
    },
    "571a74f6cfeb15db25c13904513556a5": {
      "source_id": "571a74f6cfeb15db25c13904513556a5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33719,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Twitter-length responses to 24 AI alignment arguments"
    },
    "c8839409716e121428d4b5a49f0bf6c4": {
      "source_id": "c8839409716e121428d4b5a49f0bf6c4",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7563,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Mediocre AI safety as existential risk"
    },
    "970331ebf0491707f6484ce5fbbaaf28": {
      "source_id": "970331ebf0491707f6484ce5fbbaaf28",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3355,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Career Advice: Philosophy + Programming -> AI Safety"
    },
    "778e627368875c53bbb48e213683b6e7": {
      "source_id": "778e627368875c53bbb48e213683b6e7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7375,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "E.A. Megaproject Ideas"
    },
    "7f962653d2d050bec16103fcf622853a": {
      "source_id": "7f962653d2d050bec16103fcf622853a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4542,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Desirable? AI qualities"
    },
    "dd2ac2547fe17c3d03baeb6c39dab7a7": {
      "source_id": "dd2ac2547fe17c3d03baeb6c39dab7a7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4006,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Meditations on careers in AI Safety"
    },
    "ffe0d9265fa79ab48c2e47719bef6736": {
      "source_id": "ffe0d9265fa79ab48c2e47719bef6736",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5094,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Safety Overview: CERI Summer Research Fellowship"
    },
    "f46beb37a868d23f4d3ba0d0dc07e9f0": {
      "source_id": "f46beb37a868d23f4d3ba0d0dc07e9f0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 784,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "I'm interviewing Nova Das Sarma about AI safety and information security. What s"
    },
    "326d068caab037486809e894fc792345": {
      "source_id": "326d068caab037486809e894fc792345",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11553,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Scenario Mapping Advanced AI Risk: Request for Participation with Data Collectio"
    },
    "becf7379c446200d8536ec73810c206e": {
      "source_id": "becf7379c446200d8536ec73810c206e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5734,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The role of academia in AI Safety."
    },
    "cf5e8aa1a9d020f14714189b91f464b0": {
      "source_id": "cf5e8aa1a9d020f14714189b91f464b0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12994,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI safety starter pack"
    },
    "a48ad27840aee84282ee97b58f9333ff": {
      "source_id": "a48ad27840aee84282ee97b58f9333ff",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2755,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Seeking Survey Responses - Attitudes Towards AI risks"
    },
    "b2d835d25d75478dbf28b6fc12c72478": {
      "source_id": "b2d835d25d75478dbf28b6fc12c72478",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13666,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Can we simulate human evolution to create a somewhat aligned AGI? "
    },
    "ceceb4c8ffb6c7a1cb60706e7e55bdc9": {
      "source_id": "ceceb4c8ffb6c7a1cb60706e7e55bdc9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30444,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "8 possible high-level goals for work on nuclear risk"
    },
    "733ec65e5454c1e8309f1e67e54717bb": {
      "source_id": "733ec65e5454c1e8309f1e67e54717bb",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1883,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A dataset for AI/superintelligence stories and other media?"
    },
    "2054425abb21242f2c3250f2f7efee80": {
      "source_id": "2054425abb21242f2c3250f2f7efee80",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9976,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing the EU Tech Policy Fellowship"
    },
    "216f4edb2a8924ebf38ccb931438caa7": {
      "source_id": "216f4edb2a8924ebf38ccb931438caa7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 650,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is AI safety still neglected?"
    },
    "8832c1e5a53de27b3a1eb00f1d822acf": {
      "source_id": "8832c1e5a53de27b3a1eb00f1d822acf",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 877,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Pitching AI Safety in 3 sentences"
    },
    "2f195701b66f6be9fd20d0a58b631a8d": {
      "source_id": "2f195701b66f6be9fd20d0a58b631a8d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 745,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What are the best ideas of how to regulate AI from the US executive branch?"
    },
    "2660e06a0ca5d6e56b3a6fb7a0f602f6": {
      "source_id": "2660e06a0ca5d6e56b3a6fb7a0f602f6",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1765,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is it valuable to the field of AI Safety to have a neuroscience background?"
    },
    "b6bf8f7220ee665ddd7258914444dd89": {
      "source_id": "b6bf8f7220ee665ddd7258914444dd89",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 20329,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Yudkowsky and Christiano on AI Takeoff Speeds [LINKPOST]"
    },
    "ca50203ce657e764bae59b668c93235e": {
      "source_id": "ca50203ce657e764bae59b668c93235e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13298,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Cross-post] Change my mind: we should define and measure the effectiveness of a"
    },
    "0b4014959a473992c1c2ff8643ea38cd": {
      "source_id": "0b4014959a473992c1c2ff8643ea38cd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26694,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What Should We Optimize - A Conversation"
    },
    "9492603080e9b61352b6e9e2fdccf6bf": {
      "source_id": "9492603080e9b61352b6e9e2fdccf6bf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29887,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Ideal governance (for companies, countries and more)"
    },
    "2722bba67f299fe9e236794e7f184a27": {
      "source_id": "2722bba67f299fe9e236794e7f184a27",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8091,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A tough career decision"
    },
    "59f75ccb022ac608a934d978cd17c31d": {
      "source_id": "59f75ccb022ac608a934d978cd17c31d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13720,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The right to protection from catastrophic AI risk"
    },
    "d429f33846e4b29dfbb749982678f0f2": {
      "source_id": "d429f33846e4b29dfbb749982678f0f2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1259,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A visualization of some orgs in the AI Safety Pipeline"
    },
    "d7f71653bdc3628d949d78f7319494aa": {
      "source_id": "d7f71653bdc3628d949d78f7319494aa",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6845,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Crucial considerations in the field of Wild Animal Welfare (WAW)"
    },
    "1444d7f2691942f033642bb6a593e987": {
      "source_id": "1444d7f2691942f033642bb6a593e987",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8269,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Ought's theory of change"
    },
    "78e99edf02a73319a000825edbb04c21": {
      "source_id": "78e99edf02a73319a000825edbb04c21",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1318,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "6 Year Decrease of Metaculus AGI Prediction"
    },
    "2851977868059f29905f6dba315e8d9b": {
      "source_id": "2851977868059f29905f6dba315e8d9b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27461,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How to become an AI safety researcher"
    },
    "2a3905b50c09ac9a2f2e94b8f926c571": {
      "source_id": "2a3905b50c09ac9a2f2e94b8f926c571",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28620,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A primer & some reflections on recent CSER work (EAB talk) "
    },
    "17bf224b8bdb89a79b39e1e9fc4369f4": {
      "source_id": "17bf224b8bdb89a79b39e1e9fc4369f4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17400,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Help us find pain points in AI safety"
    },
    "0e29098bb3465a609de56f93e6f0cfd1": {
      "source_id": "0e29098bb3465a609de56f93e6f0cfd1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9519,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Tips for conducting worldview investigations"
    },
    "30e0b4fcc761f4ec50336a8af9262576": {
      "source_id": "30e0b4fcc761f4ec50336a8af9262576",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10680,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How dath ilan coordinates around solving AI alignment"
    },
    "eacc77b6f5b0335a607d4807444a7aac": {
      "source_id": "eacc77b6f5b0335a607d4807444a7aac",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2285,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Redwood Research is hiring for several roles (Operations and Technical)"
    },
    "55d595f693f6f947d62e8b9d6f1c4a5b": {
      "source_id": "55d595f693f6f947d62e8b9d6f1c4a5b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8850,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A grand strategy to recruit AI capabilities researchers into AI safety research"
    },
    "fdb7ae1f1ba2ebe9bfd4b2ffdafe3178": {
      "source_id": "fdb7ae1f1ba2ebe9bfd4b2ffdafe3178",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4363,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Begging, Pleading AI Orgs to Comment on NIST AI Risk Management Framework"
    },
    "cf0d5112a64cf1b6843b9fec0a1c2bec": {
      "source_id": "cf0d5112a64cf1b6843b9fec0a1c2bec",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 68243,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How I failed to form views on AI safety"
    },
    "11bcefcf60c12ba8cff61dcaf2413acc": {
      "source_id": "11bcefcf60c12ba8cff61dcaf2413acc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 770,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why not offer a multi-million / billion dollar prize for solving the Alignment P"
    },
    "1f76304b255abb8abf77e2727e6d7ecf": {
      "source_id": "1f76304b255abb8abf77e2727e6d7ecf",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1115,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How will the world respond to \"AI x-risk warning shots\" according to reference c"
    },
    "d0f8ea4f2f801afe882eb3e8207f2087": {
      "source_id": "d0f8ea4f2f801afe882eb3e8207f2087",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6476,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Closed] Hiring a mathematician to work on the learning-theoretic AI alignment a"
    },
    "e55c12ac71ff56e17f86fd5cd2b6a3ae": {
      "source_id": "e55c12ac71ff56e17f86fd5cd2b6a3ae",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34249,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Chaining Retroactive Funders to Borrow Against Unlikely Utopias"
    },
    "8673a2c371e951f43048386cca4b9ecd": {
      "source_id": "8673a2c371e951f43048386cca4b9ecd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13149,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "\u201cPivotal Act\u201d Intentions: Negative Consequences and Fallacious Arguments"
    },
    "763b1c1b5c5865e036287882f15354d5": {
      "source_id": "763b1c1b5c5865e036287882f15354d5",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8300,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Calling for Student Submissions: AI Safety Distillation Contest"
    },
    "80a719659fff92bb03b1a3fc9160ab1f": {
      "source_id": "80a719659fff92bb03b1a3fc9160ab1f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2618,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Skilling-up in ML Engineering for Alignment: request for comments"
    },
    "982e7ac3990a6d599cd7744b2271e41e": {
      "source_id": "982e7ac3990a6d599cd7744b2271e41e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3801,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Which Post Idea Is Most Effective?"
    },
    "ed4a0fdfed581e8e5b589fd11e8ce5d3": {
      "source_id": "ed4a0fdfed581e8e5b589fd11e8ce5d3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44257,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Key questions about artificial sentience: an opinionated guide"
    },
    "6d1090039876be341c8ec0e2a1b414f2": {
      "source_id": "6d1090039876be341c8ec0e2a1b414f2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8235,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Make a neural network in ~10 minutes"
    },
    "156b734a71748aae357920f4f4058933": {
      "source_id": "156b734a71748aae357920f4f4058933",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2498,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How to engage with AI 4 Social Justice actors "
    },
    "ea61a3961e095eca2f07cdb57af0a00a": {
      "source_id": "ea61a3961e095eca2f07cdb57af0a00a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6909,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[$20K In Prizes] AI Safety Arguments Competition"
    },
    "30d1c947bad4ab1ae6f2f6b2fd1ab7a5": {
      "source_id": "30d1c947bad4ab1ae6f2f6b2fd1ab7a5",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5401,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "SERI ML Alignment Theory Scholars Program 2022"
    },
    "71ed6718479570b68d4150266dc97720": {
      "source_id": "71ed6718479570b68d4150266dc97720",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13737,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Law-Following AI 2: Intent Alignment + Superintelligence \u2192 Lawless AI (By Defaul"
    },
    "1891e808898bd2687191d853b41868d8": {
      "source_id": "1891e808898bd2687191d853b41868d8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6468,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Law-Following AI 3: Lawless AI Agents Undermine Stabilizing Agreements"
    },
    "786aa527560cf2341f488209382f24b3": {
      "source_id": "786aa527560cf2341f488209382f24b3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30787,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A tale of 2.5 orthogonality theses"
    },
    "2b27350ddcacd9167876a04edac48cd9": {
      "source_id": "2b27350ddcacd9167876a04edac48cd9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 107038,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "My thoughts on nanotechnology strategy research as an EA cause area"
    },
    "42d7c0b15679dfaba6a8aaad5ae73db9": {
      "source_id": "42d7c0b15679dfaba6a8aaad5ae73db9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26285,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Information security considerations for AI and the long term future"
    },
    "2613861ceabb37b8715c8d3958288649": {
      "source_id": "2613861ceabb37b8715c8d3958288649",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6310,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Introducing the ML Safety Scholars Program"
    },
    "c23b3864c9d0747df0400692aafaead9": {
      "source_id": "c23b3864c9d0747df0400692aafaead9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2586,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The AI Messiah "
    },
    "976f6b5789d0373e6af497cfbc07675c": {
      "source_id": "976f6b5789d0373e6af497cfbc07675c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3971,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Messy personal stuff that affected my cause prioritization (or: how I started to"
    },
    "7c51060397aa3f1d125daca16b1b9bb0": {
      "source_id": "7c51060397aa3f1d125daca16b1b9bb0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10701,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Apply to the second ML for Alignment Bootcamp (MLAB 2) in Berkeley [Aug 15 - Fri"
    },
    "b8dfc00fb14a5180bb1a2ef20c62dc06": {
      "source_id": "b8dfc00fb14a5180bb1a2ef20c62dc06",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 810,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What are the coolest topics in AI safety, to a hopelessly pure mathematician?"
    },
    "41ecf41dcdc5c9315b98c088940912d5": {
      "source_id": "41ecf41dcdc5c9315b98c088940912d5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53325,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Video and Transcript of Presentation on Existential Risk from Power-Seeking AI"
    },
    "76dc710d62b26f167f599e54682b6ba3": {
      "source_id": "76dc710d62b26f167f599e54682b6ba3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15988,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "When is AI safety research harmful?"
    },
    "dbd8995d3146fdbbadcf65745c57098a": {
      "source_id": "dbd8995d3146fdbbadcf65745c57098a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2458,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Student project for engaging with AI alignment"
    },
    "d69bb081eedaa9aff28212b245ce9088": {
      "source_id": "d69bb081eedaa9aff28212b245ce9088",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12618,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Introduction to Pragmatic AI Safety [Pragmatic AI Safety #1]"
    },
    "55e582c0a71e59af7ea963daa9210d89": {
      "source_id": "55e582c0a71e59af7ea963daa9210d89",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 77100,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Bird's Eye View of the ML Field [Pragmatic AI Safety #2]"
    },
    "fc8c198008f48b1296b1bad4e767ae79": {
      "source_id": "fc8c198008f48b1296b1bad4e767ae79",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 22043,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Alternative Futures: Exploratory Scenario Mapping for Artificial Intelligence"
    },
    "ee5884c0f74544477d10a599d6c59be4": {
      "source_id": "ee5884c0f74544477d10a599d6c59be4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1274,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Alignment YouTube Playlists"
    },
    "68e53725abb9085ac70e1cee5b6cd4a0": {
      "source_id": "68e53725abb9085ac70e1cee5b6cd4a0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30312,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Rabbits, robots and resurrection"
    },
    "18b1ddf33b4528dfcab5ea4db501d967": {
      "source_id": "18b1ddf33b4528dfcab5ea4db501d967",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1283,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "New series of posts answering one of Holden's \"Important, actionable research qu"
    },
    "e255425c03d634df2ef2497704df4591": {
      "source_id": "e255425c03d634df2ef2497704df4591",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6523,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A tentative dialogue with a Friendly-boxed-super-AGI on brain uploads"
    },
    "4318455f866f646d00ce4d7cbd049b3f": {
      "source_id": "4318455f866f646d00ce4d7cbd049b3f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 922,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Fermi estimation of the impact you might have working on AI safety"
    },
    "810326a9501ce0a25cca93636430417f": {
      "source_id": "810326a9501ce0a25cca93636430417f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 283,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "I'm interviewing Max Tegmark about AI safety and more. What shouId I ask him?"
    },
    "de22976130f1a12b0fef75073f3a8255": {
      "source_id": "de22976130f1a12b0fef75073f3a8255",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7537,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "\"Tech company singularities\", and steering them to reduce x-risk"
    },
    "528e29535e956211505de3ebf0d01c64": {
      "source_id": "528e29535e956211505de3ebf0d01c64",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 775,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What does the Project Management role look like in AI safety?"
    },
    "f13353d0962c049cd9800142a7ad01d2": {
      "source_id": "f13353d0962c049cd9800142a7ad01d2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17161,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AGI Risk: How to internationally regulate industries in non-democracies"
    },
    "fc8ee91453efc2ecf1454c6070cd6a59": {
      "source_id": "fc8ee91453efc2ecf1454c6070cd6a59",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6031,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "We Ran an AI Timelines Retreat"
    },
    "dfc478f1b547586439b5a21a6bc76fb2": {
      "source_id": "dfc478f1b547586439b5a21a6bc76fb2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5732,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Actionable-guidance and roadmap recommendations for the NIST AI Risk Management "
    },
    "107383b87ff699ff950e7f57c6adc38c": {
      "source_id": "107383b87ff699ff950e7f57c6adc38c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5615,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "\u201cIntro to brain-like-AGI safety\u201d series\u2014just finished!"
    },
    "49633f5394f40e44a0047cad26e71af8": {
      "source_id": "49633f5394f40e44a0047cad26e71af8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26173,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Fiction] Improved Governance on the Critical Path to AI Alignment by 2045."
    },
    "97fb01b3c9ed30073719f9c8ff0bc900": {
      "source_id": "97fb01b3c9ed30073719f9c8ff0bc900",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33378,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Are you really in a race? The Cautionary Tales of Szil\u00e1rd and Ellsberg"
    },
    "2f4186ecfed0d470c9854a06a9876117": {
      "source_id": "2f4186ecfed0d470c9854a06a9876117",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61578,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Windfall Clause has a remedies problem"
    },
    "834e50eba3ef38b0b4d3a1af4ad24441": {
      "source_id": "834e50eba3ef38b0b4d3a1af4ad24441",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43458,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Complex Systems for AI Safety [Pragmatic AI Safety #3]"
    },
    "c770d1b2970bc785fd18311f7ba1da12": {
      "source_id": "c770d1b2970bc785fd18311f7ba1da12",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36684,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How Could AI Governance Go Wrong?"
    },
    "056b28cd54c10324d89b774039ff8159": {
      "source_id": "056b28cd54c10324d89b774039ff8159",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15333,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "EA, Psychology & AI Safety Research"
    },
    "9192c4215b81ec0f71ff1e3eacc37029": {
      "source_id": "9192c4215b81ec0f71ff1e3eacc37029",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22074,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Introducing spirit hazards"
    },
    "71ed1acb648ee4003f26f0a6e14754b8": {
      "source_id": "71ed1acb648ee4003f26f0a6e14754b8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7064,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "We should expect to worry more about speculative risks"
    },
    "cdc30cb9a616d063ee17c34d40855f3b": {
      "source_id": "cdc30cb9a616d063ee17c34d40855f3b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 70299,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Perform Tractable Research While Avoiding Capabilities Externalities [Pragmatic "
    },
    "66983d44fbb822d53faa4724298d9f59": {
      "source_id": "66983d44fbb822d53faa4724298d9f59",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1796,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Which possible AI impacts should receive the most additional attention?"
    },
    "de9968f2c2456296c6bb23d2dfd61147": {
      "source_id": "de9968f2c2456296c6bb23d2dfd61147",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9422,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Advice on Pursuing Technical AI Safety Research"
    },
    "e4c92c038b14a214e142b5f6a5d636bd": {
      "source_id": "e4c92c038b14a214e142b5f6a5d636bd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51773,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Appendix to Bridging Demonstration"
    },
    "18906967b10d800bfe7717827caa3775": {
      "source_id": "18906967b10d800bfe7717827caa3775",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11252,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Data collection for AI alignment - Career review"
    },
    "06796535599ce53821fcc2abe8fd592b": {
      "source_id": "06796535599ce53821fcc2abe8fd592b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6421,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Intergenerational trauma impeding cooperative existential safety efforts"
    },
    "fd0b98ceb50aa8d60398d779ddee3420": {
      "source_id": "fd0b98ceb50aa8d60398d779ddee3420",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1805,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Training a GPT model on EA texts: what data?"
    },
    "9a00ad9a002c0a0e3a87e867a26bfeaf": {
      "source_id": "9a00ad9a002c0a0e3a87e867a26bfeaf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 93992,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How to pursue a career in technical AI alignment"
    },
    "4cc4e6f9acae3efcae7cbe88551e21ff": {
      "source_id": "4cc4e6f9acae3efcae7cbe88551e21ff",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28605,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "New cooperation mechanism - quadratic funding without a matching pool"
    },
    "e13fcb28cf26d9a2cf43e5a47370dd5a": {
      "source_id": "e13fcb28cf26d9a2cf43e5a47370dd5a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5079,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Here are the finalists from FLI\u2019s $100K Worldbuilding Contest"
    },
    "c865f9eb158817c5556ddce1c13e177a": {
      "source_id": "c865f9eb158817c5556ddce1c13e177a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29573,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Grokking \u201cForecasting TAI with biological anchors\u201d"
    },
    "03fac606063c69f86e7375518d83d069": {
      "source_id": "03fac606063c69f86e7375518d83d069",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56742,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AGI Ruin: A List of Lethalities"
    },
    "609c85321c99e2bfba42a9d6f9989edb": {
      "source_id": "609c85321c99e2bfba42a9d6f9989edb",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4549,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is the time crunch for AI Safety Movement Building now?"
    },
    "11149fca4e6f38cce288b0c405e5d6bf": {
      "source_id": "11149fca4e6f38cce288b0c405e5d6bf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 78969,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Open Problems in AI X-Risk [PAIS #5]"
    },
    "8bf33b2560cc965ecc5b73fd81ce12bb": {
      "source_id": "8bf33b2560cc965ecc5b73fd81ce12bb",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7849,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Digital people could make AI safer"
    },
    "adca3cc99bcbdb467d235266e70f699b": {
      "source_id": "adca3cc99bcbdb467d235266e70f699b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32759,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Could Defeat All Of Us Combined"
    },
    "ee648ad801e1e06da4919f9634d938de": {
      "source_id": "ee648ad801e1e06da4919f9634d938de",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1861,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AGI Safety Communications Initiative"
    },
    "64e0427f6c02c934c27476cef25b97ae": {
      "source_id": "64e0427f6c02c934c27476cef25b97ae",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48977,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Grokking \u201cSemi-informative priors over AI timelines\u201d"
    },
    "25a311ca3c2d8f7f99a51fa68f1e6e9a": {
      "source_id": "25a311ca3c2d8f7f99a51fa68f1e6e9a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2990,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "EA AI/Emerging Tech Orgs Should Be Involved with Patent Office Partnership"
    },
    "68b4c09a63da6d56e603f8e20dd0f2d7": {
      "source_id": "68b4c09a63da6d56e603f8e20dd0f2d7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2880,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What are current smaller problems related to top EA cause areas (eg deepfake pol"
    },
    "670650e28f4fba5f7ba383b8872cb7b3": {
      "source_id": "670650e28f4fba5f7ba383b8872cb7b3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 63082,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Vael Gates: Risks from Advanced AI (June 2022)"
    },
    "de1102ea0930d2722b0fef9c86474e4b": {
      "source_id": "de1102ea0930d2722b0fef9c86474e4b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2078,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Steering AI to care for animals, and soon"
    },
    "e33b0d777a0bb96cb967f4e24f1225d0": {
      "source_id": "e33b0d777a0bb96cb967f4e24f1225d0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23740,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Expected impact of a career in AI safety under different opinions"
    },
    "c815e3ff1a1889541a1718f012c26954": {
      "source_id": "c815e3ff1a1889541a1718f012c26954",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1640,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Catholic theologians and priests on artificial intelligence"
    },
    "03c2ca92ede7c116490c496305a2d351": {
      "source_id": "03c2ca92ede7c116490c496305a2d351",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8451,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Blake Richards on Why he is Skeptical of Existential Risk from AI"
    },
    "ba35ab559a42e772d427388755fb6724": {
      "source_id": "ba35ab559a42e772d427388755fb6724",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5117,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Refer the Cooperative AI Foundation\u2019s New COO, Receive $5000"
    },
    "e1aa56407694d2ac0db3fffb104dbb25": {
      "source_id": "e1aa56407694d2ac0db3fffb104dbb25",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1052,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Apply to the Machine Learning For Good bootcamp in France"
    },
    "264d0262bfc8e1a1396e763d5fc3583a": {
      "source_id": "264d0262bfc8e1a1396e763d5fc3583a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8699,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Pivotal outcomes and pivotal processes"
    },
    "81f154de654d2e67e3776b4d2e9ee6a8": {
      "source_id": "81f154de654d2e67e3776b4d2e9ee6a8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10570,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "\u2018Force multipliers\u2019 for EA research"
    },
    "1c8c250c2c8d712c896c24a5ad53cd3b": {
      "source_id": "1c8c250c2c8d712c896c24a5ad53cd3b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35579,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "On Deference and Yudkowsky's AI Risk Estimates"
    },
    "a9f8f502d2ea3068e93e47bf1183fe7f": {
      "source_id": "a9f8f502d2ea3068e93e47bf1183fe7f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51580,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Key Papers in Language Model Safety"
    },
    "f4c4fe61176310ca01766294538a8903": {
      "source_id": "f4c4fe61176310ca01766294538a8903",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23146,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Technical AI safety in the United Arab Emirates"
    },
    "8acf33d2380790fff8f69ac31b9c3484": {
      "source_id": "8acf33d2380790fff8f69ac31b9c3484",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2673,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "20 Critiques of AI Safety That I Found on Twitter"
    },
    "1f5f381cd6ceecd713fd226c9c533694": {
      "source_id": "1f5f381cd6ceecd713fd226c9c533694",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2294,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Half-baked ideas thread (EA / AI Safety)"
    },
    "fe3d1e0d3e4a4d881c0a07497202144e": {
      "source_id": "fe3d1e0d3e4a4d881c0a07497202144e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3981,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "7 essays on Building a Better Future"
    },
    "a6987d065130ddcaa94af85c184794f7": {
      "source_id": "a6987d065130ddcaa94af85c184794f7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8029,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Rapha\u00ebl Milli\u00e8re on the Limits of Deep Learning and AI x-risk skepticism"
    },
    "f4c80a8765e157fa8a1668826e79c654": {
      "source_id": "f4c80a8765e157fa8a1668826e79c654",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 115321,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Military Artificial Intelligence as Contributor to Global Catastrophic Risk"
    },
    "1e4f32e5e4297cc7b670cf035b5f3d6b": {
      "source_id": "1e4f32e5e4297cc7b670cf035b5f3d6b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24490,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing Epoch: A research organization investigating the road to Transformati"
    },
    "f9bd11fa79a39d686d2e98f34aea95ef": {
      "source_id": "f9bd11fa79a39d686d2e98f34aea95ef",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7758,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Four reasons I find AI safety emotionally compelling"
    },
    "bd3ddff6d46efc47deb69978cdaf68f6": {
      "source_id": "bd3ddff6d46efc47deb69978cdaf68f6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38362,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What success looks like"
    },
    "fdd62b92ae97bb25b8a8f6dcc23ebe1e": {
      "source_id": "fdd62b92ae97bb25b8a8f6dcc23ebe1e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19443,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The inordinately slow spread of good AGI conversations in ML"
    },
    "2bb7258dd0b25bf934089f5c2285c5db": {
      "source_id": "2bb7258dd0b25bf934089f5c2285c5db",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3991,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "$500 bounty for alignment contest ideas"
    },
    "8258e0d7f2f61f06b965e270b2fa383d": {
      "source_id": "8258e0d7f2f61f06b965e270b2fa383d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10369,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing the Harvard AI Safety Team"
    },
    "0b3e077c607ad0fb76edfae37f649579": {
      "source_id": "0b3e077c607ad0fb76edfae37f649579",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1411,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Quick survey on AI alignment resources"
    },
    "f9f33528342c10ce4a73ce862e6607dc": {
      "source_id": "f9f33528342c10ce4a73ce862e6607dc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28214,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "(Even) More Early-Career EAs Should Try AI Safety Technical Research"
    },
    "931c77709278fbe723d01476ea632720": {
      "source_id": "931c77709278fbe723d01476ea632720",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8445,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Strategic Perspectives on Transformative AI Governance: Introduction"
    },
    "ccda90deae347f1671f0b4fd082fe200": {
      "source_id": "ccda90deae347f1671f0b4fd082fe200",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11612,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Components of Strategic Clarity [Strategic Perspectives on Long-term AI Governan"
    },
    "07010ada4c17de288c453de6fb620736": {
      "source_id": "07010ada4c17de288c453de6fb620736",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14759,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "When 2/3rds of the world goes against you"
    },
    "dc7859538f722834d1b5a534235d761c": {
      "source_id": "dc7859538f722834d1b5a534235d761c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16672,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Research + Reality Graphing to Support AI Policy (and more): Summary of a Frozen"
    },
    "f9ca884ec421de3fbae61f86ffe50200": {
      "source_id": "f9ca884ec421de3fbae61f86ffe50200",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19156,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why AGI Timeline Research/Discourse Might Be Overrated"
    },
    "0f1489f114ba4a89f316a745e0b73bb2": {
      "source_id": "0f1489f114ba4a89f316a745e0b73bb2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42574,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Future Matters #3: digital sentience, AGI ruin, and forecasting track records"
    },
    "cabddcc53d08fd574a7cf77ddfa6db41": {
      "source_id": "cabddcc53d08fd574a7cf77ddfa6db41",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1230,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Facilitator Help Wanted for Columbia EA AI Safety Groups"
    },
    "acee38f93e88c5810ba36bfe450ad57c": {
      "source_id": "acee38f93e88c5810ba36bfe450ad57c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8937,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Introducing the Fund for Alignment Research (We're Hiring!)"
    },
    "bdecc17885f91dfb0a9934eb6510f44b": {
      "source_id": "bdecc17885f91dfb0a9934eb6510f44b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15101,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Forecasting Through Fiction"
    },
    "27d19ae1dae52b52d5a44c8c5a8973c8": {
      "source_id": "27d19ae1dae52b52d5a44c8c5a8973c8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 794,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI ethics: the case for including animals (my first published paper, Peter Singe"
    },
    "a295f81e63646898ceddc416c446948e": {
      "source_id": "a295f81e63646898ceddc416c446948e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2201,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Recommendations for non-technical books on AI?"
    },
    "87e9314514e1292a42f58fcf33511364": {
      "source_id": "87e9314514e1292a42f58fcf33511364",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5769,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Pile of Law and Law-Following AI"
    },
    "c09f1f5840eae066924dc47e1cd69a78": {
      "source_id": "c09f1f5840eae066924dc47e1cd69a78",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4902,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Slowing down AI progress is an underexplored alignment strategy"
    },
    "43870b9fef1c8060f1e0c36f145c1d67": {
      "source_id": "43870b9fef1c8060f1e0c36f145c1d67",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2178,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why policymakers should beware claims of new \"arms races\" (Bulletin of the Atomi"
    },
    "4cabaaf83cb43847bfd154c8e7147699": {
      "source_id": "4cabaaf83cb43847bfd154c8e7147699",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11513,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Resilience Via Fragmented Power"
    },
    "5ceeed5e8bd85e1c099e860d5f207354": {
      "source_id": "5ceeed5e8bd85e1c099e860d5f207354",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7145,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What if we don't need a \"Hard Left Turn\" to reach AGI?"
    },
    "3f7e950b54d90bc7274b68e918ba07cf": {
      "source_id": "3f7e950b54d90bc7274b68e918ba07cf",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5152,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "More to explore on 'Risks from Artificial Intelligence'"
    },
    "1d1e3a4216636ea7c33201c62a06d2de": {
      "source_id": "1d1e3a4216636ea7c33201c62a06d2de",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 246,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Does the idea of AGI that benevolently control us appeal to EA folks?"
    },
    "5885a784fa688622232a2472e123dc2a": {
      "source_id": "5885a784fa688622232a2472e123dc2a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 271,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Do EA folks think that a path to zero AGI development is feasible or worthwhile "
    },
    "0a1d8fa4fa38118893f8d8e3fcd9d16b": {
      "source_id": "0a1d8fa4fa38118893f8d8e3fcd9d16b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1991,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Four questions I ask AI safety researchers"
    },
    "67c542a04c49e06577cdee77e07b62f5": {
      "source_id": "67c542a04c49e06577cdee77e07b62f5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4891,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Explore Risks from Emerging Technology with Peers Outside of (or New to) the AI "
    },
    "7d6e3b5269bcc1990f31fc12aaa7bb29": {
      "source_id": "7d6e3b5269bcc1990f31fc12aaa7bb29",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 75260,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Survey of the Potential Long-term Impacts of AI"
    },
    "dc203c1373b50dc362f577b81a9a0a04": {
      "source_id": "dc203c1373b50dc362f577b81a9a0a04",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20990,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What\u2019s so dangerous about AI anyway? \u2013 Or: What it means to be a superintelligen"
    },
    "868ec4305d55e36f0b9dae763dccf176": {
      "source_id": "868ec4305d55e36f0b9dae763dccf176",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52822,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why EAs are skeptical about AI Safety"
    },
    "330ed458dbfc2f03f079ffa6b5408af6": {
      "source_id": "330ed458dbfc2f03f079ffa6b5408af6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 181052,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Without specific countermeasures, the easiest path to transformative AI likely l"
    },
    "705fb7084ee3824e40176ab952964ee1": {
      "source_id": "705fb7084ee3824e40176ab952964ee1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7575,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What I'm doing"
    },
    "430c117a6b46980108c42012817b28cc": {
      "source_id": "430c117a6b46980108c42012817b28cc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17533,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How to Diversify Conceptual AI Alignment: the Model Behind Refine"
    },
    "c30d4e8efb176f210513dfa233fa3f61": {
      "source_id": "c30d4e8efb176f210513dfa233fa3f61",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40133,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Social scientists interested in AI safety should consider doing direct technical"
    },
    "43cb7b5e57f06a5a3a3808031914d3a8": {
      "source_id": "43cb7b5e57f06a5a3a3808031914d3a8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11607,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A \"Solipsistic\" Repugnant Conclusion"
    },
    "b3a01b4f76296624221b39dbcb219a8f": {
      "source_id": "b3a01b4f76296624221b39dbcb219a8f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16152,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "UK AI Policy Report: Content, Summary, and its Impact on EA Cause Areas"
    },
    "3786dbe596c624bba7e6d6189a3c3054": {
      "source_id": "3786dbe596c624bba7e6d6189a3c3054",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15570,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Reasons I\u2019ve been hesitant about high levels of near-ish AI risk"
    },
    "3cb2cbca261eacb782975d4f4476ee9d": {
      "source_id": "3cb2cbca261eacb782975d4f4476ee9d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11878,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Maybe AI risk shouldn't affect your life plan all that much"
    },
    "46da390b3d6613ca1884e0ea547ee473": {
      "source_id": "46da390b3d6613ca1884e0ea547ee473",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17838,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Connor Leahy on Conjecture and Dying with Dignity"
    },
    "f3e2ffe19024336817c1726d94cffb28": {
      "source_id": "f3e2ffe19024336817c1726d94cffb28",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11022,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "We Did AGISF\u2019s 8-week Course in 3 Days. Here\u2019s How it Went"
    },
    "f51f0c77ae2afd21782eca0743a82b05": {
      "source_id": "f51f0c77ae2afd21782eca0743a82b05",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4043,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AGI Safety Needs People With All Skillsets!"
    },
    "0d580fae05cf134279aba9da22c08999": {
      "source_id": "0d580fae05cf134279aba9da22c08999",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10603,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Humanity\u2019s vast future and its implications for cause prioritization"
    },
    "969e7a7e469896dc7bc60d5f91b5da48": {
      "source_id": "969e7a7e469896dc7bc60d5f91b5da48",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 618,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Slowing down AI progress? "
    },
    "4a47ca5804c822433dd93077178de76d": {
      "source_id": "4a47ca5804c822433dd93077178de76d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2055,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How much should you optimize for the short-timelines scenario?"
    },
    "53952860f627fdc6fa4807dd7d2dd263": {
      "source_id": "53952860f627fdc6fa4807dd7d2dd263",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26416,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Neartermists should consider AGI timelines in their spending decisions"
    },
    "fae2ce37bac957aee967d98c2123c052": {
      "source_id": "fae2ce37bac957aee967d98c2123c052",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2732,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "FLI is hiring a new Director of US Policy"
    },
    "0e7733eace7e56beb3ec5ca2042539e9": {
      "source_id": "0e7733eace7e56beb3ec5ca2042539e9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 806,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How long does it take to undersrand AI X-Risk from scratch so that I have a conf"
    },
    "a4fbed6dfaf1a9608f1e560411d6804e": {
      "source_id": "a4fbed6dfaf1a9608f1e560411d6804e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13946,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Safety without oppression: an AI governance problem"
    },
    "5cd3d2485efdacdfe2ad632c56062e93": {
      "source_id": "5cd3d2485efdacdfe2ad632c56062e93",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1233,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Alignment is intractable (and we humans should stop working on it)"
    },
    "717a2f0b8d9200b7573d2462b05ad188": {
      "source_id": "717a2f0b8d9200b7573d2462b05ad188",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 412,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Closing the Feedback Loop on AI Safety Research."
    },
    "60330e367bcb842ffcaab787847bba93": {
      "source_id": "60330e367bcb842ffcaab787847bba93",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6881,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI timelines by bio anchors: the debate in one place"
    },
    "1c183adf44604e0b170728485569cf9c": {
      "source_id": "1c183adf44604e0b170728485569cf9c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3985,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing the GovAI Policy Team"
    },
    "d6a3cd8808c02b910e44e0187ce456db": {
      "source_id": "d6a3cd8808c02b910e44e0187ce456db",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6234,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Information in risky technology races"
    },
    "65fb57766a62923660e20faa27a066ec": {
      "source_id": "65fb57766a62923660e20faa27a066ec",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27430,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What if AI development goes well?"
    },
    "e1e5c83cf3be73e953c80bdc9c2fb06a": {
      "source_id": "e1e5c83cf3be73e953c80bdc9c2fb06a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1836,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AMA: Ought"
    },
    "4d71b3fe27bf0c29a48e8817da18d122": {
      "source_id": "4d71b3fe27bf0c29a48e8817da18d122",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22473,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Three pillars for avoiding AGI catastrophe: Technical alignment, deployment deci"
    },
    "6ea88fc617219be4b8b0678b70616db7": {
      "source_id": "6ea88fc617219be4b8b0678b70616db7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9938,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing the SPT Model Web App for AI Governance"
    },
    "2b0a4cd24eccb8c353a158690ab59ccc": {
      "source_id": "2b0a4cd24eccb8c353a158690ab59ccc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1930,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why we need a new agency to regulate advanced artificial intelligence"
    },
    "6d77db37509c7c4194b4801adbcc0d39": {
      "source_id": "6d77db37509c7c4194b4801adbcc0d39",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5050,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "2022 AI expert survey results"
    },
    "4ca7f87b6b006d223f3b01b52ec69456": {
      "source_id": "4ca7f87b6b006d223f3b01b52ec69456",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1584,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Does China have AI alignment resources/institutions? How can we prioritize creat"
    },
    "e42ded40acff4641222a271621484c74": {
      "source_id": "e42ded40acff4641222a271621484c74",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11801,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "$20K in Bounties for AI Safety Public Materials"
    },
    "def2d5e22fcee981c9d6026cf31e0d9e": {
      "source_id": "def2d5e22fcee981c9d6026cf31e0d9e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17806,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing the Introduction to ML Safety Course"
    },
    "f04be84afff6c3e84fdff6fc642a607b": {
      "source_id": "f04be84afff6c3e84fdff6fc642a607b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3572,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Collection of work on 'Should you focus on the EU if you're interested in AI gov"
    },
    "f485a514a52a2b3f2ee39931a3184329": {
      "source_id": "f485a514a52a2b3f2ee39931a3184329",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 723,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI risks: the most convincing argument "
    },
    "f23f6b7d0e5abdbbb7c61da8a2fc1bb2": {
      "source_id": "f23f6b7d0e5abdbbb7c61da8a2fc1bb2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37732,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How I Came To Longtermism On My Own & An Outsider Perspective On EA Longtermism"
    },
    "2db6a310d98a14a7ef057bae48229b6b": {
      "source_id": "2db6a310d98a14a7ef057bae48229b6b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12357,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Longtermists Should Work on AI - There is No \"AI Neutral\" Scenario "
    },
    "e9248e7f9aa1bdebdc8f2a6eefa8f43d": {
      "source_id": "e9248e7f9aa1bdebdc8f2a6eefa8f43d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2193,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why does no one care about AI?"
    },
    "4d32441fb6dfa48ff988e643d5cef771": {
      "source_id": "4d32441fb6dfa48ff988e643d5cef771",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37689,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Future Matters #4: AI timelines, AGI risk, and existential risk from climate cha"
    },
    "69615dc6cb44302171bdc266120234df": {
      "source_id": "69615dc6cb44302171bdc266120234df",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24127,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How technical safety standards could promote TAI safety"
    },
    "33e430111fd8e072f96063a5a62886e1": {
      "source_id": "33e430111fd8e072f96063a5a62886e1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7581,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Classifying sources of AI x-risk"
    },
    "839f8f9343502e084029834ad62985eb": {
      "source_id": "839f8f9343502e084029834ad62985eb",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 294,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "\"Normal accidents\" and AI systems "
    },
    "738f1689e10bf8ad1573465e71911c8b": {
      "source_id": "738f1689e10bf8ad1573465e71911c8b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32014,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Disagreements about Alignment: Why, and how, we should try to solve them"
    },
    "dc08b9374b0f01de443fa6f942f37a69": {
      "source_id": "dc08b9374b0f01de443fa6f942f37a69",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11956,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Encultured AI, Part 1: Enabling New Benchmarks"
    },
    "57e61a9786c4e69c8de7293788f55279": {
      "source_id": "57e61a9786c4e69c8de7293788f55279",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2140,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How/When Should One Introduce AI Risk Arguments to People Unfamiliar With the Id"
    },
    "5cbc983af2fb083c7bf991d15c39dd99": {
      "source_id": "5cbc983af2fb083c7bf991d15c39dd99",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 596,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Which of these arguments for x-risk do you think we should test? "
    },
    "de534cbbfaa377ad798c16c3da81acac": {
      "source_id": "de534cbbfaa377ad798c16c3da81acac",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5253,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Spicy takes about AI policy (Clark, 2022)"
    },
    "15d631162ed18087863d55d8bec65297": {
      "source_id": "15d631162ed18087863d55d8bec65297",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7782,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Effective Persuasion For AI Alignment Risk"
    },
    "70aab86715e0e9990369a15f4eb7fc99": {
      "source_id": "70aab86715e0e9990369a15f4eb7fc99",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 92689,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Cause Area: Differential Neurotechnology Development"
    },
    "240e719622beff6546d31db898a6900e": {
      "source_id": "240e719622beff6546d31db898a6900e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1989,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "By how much should Meta's BlenderBot being really bad cause me to update on how "
    },
    "5c3a1cd19cd80b306bb56a825f634455": {
      "source_id": "5c3a1cd19cd80b306bb56a825f634455",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7060,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Possible directions in AI ideal governance research"
    },
    "cd684638bdd2ac3417337405e1c99b74": {
      "source_id": "cd684638bdd2ac3417337405e1c99b74",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22117,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The History, Epistemology and Strategy of Technological Restraint, and lessons f"
    },
    "dab9fcb7b82f896b1a336807806d51eb": {
      "source_id": "dab9fcb7b82f896b1a336807806d51eb",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8187,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "There are two factions working to prevent AI dangers. Here\u2019s why they\u2019re deeply "
    },
    "2c65e5f1c22f6d367b67d1e8569cca5b": {
      "source_id": "2c65e5f1c22f6d367b67d1e8569cca5b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6791,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A pseudo mathematical formulation of direct work choice between two x-risks"
    },
    "21ed6ded60399d9547ddfca1d982fbdd": {
      "source_id": "21ed6ded60399d9547ddfca1d982fbdd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57486,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The alignment problem from a deep learning perspective"
    },
    "6503a9da7dc738ad5c8cb0751c7ded43": {
      "source_id": "6503a9da7dc738ad5c8cb0751c7ded43",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5861,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Encultured AI, Part 2:  Providing a Service"
    },
    "d2abd48af7ff921dd54935a8cd467702": {
      "source_id": "d2abd48af7ff921dd54935a8cd467702",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 653,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is there any research or forecasts of how likely AI Alignment is going to be a h"
    },
    "0f18f42ec55d3e31e35bf7971928a792": {
      "source_id": "0f18f42ec55d3e31e35bf7971928a792",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10464,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Deception as the optimal: mesa-optimizers and inner alignment  "
    },
    "98b1ed2af189c47bf0cb25ce4c962613": {
      "source_id": "98b1ed2af189c47bf0cb25ce4c962613",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11025,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A concern about the \u201cevolutionary anchor\u201d of Ajeya Cotra\u2019s report on AI timeline"
    },
    "0c0ec3de55f13a1cd00ddf86ca851603": {
      "source_id": "0c0ec3de55f13a1cd00ddf86ca851603",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33309,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Credibility of Apocalyptic Claims: A Critique of Techno-Futurism within Exis"
    },
    "affafc22d4fd01052d67d68599826bb2": {
      "source_id": "affafc22d4fd01052d67d68599826bb2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15400,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Supplement to \"The Brussels Effect and AI: How EU AI regulation will impact the "
    },
    "a3d9041dee7dc876faaf0b25503007c7": {
      "source_id": "a3d9041dee7dc876faaf0b25503007c7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21945,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "An Exercise in Speed-Reading: The National Security Commission on AI (NSCAI) Fin"
    },
    "a2e6a73f0dbbe4531966318d30af4bb7": {
      "source_id": "a2e6a73f0dbbe4531966318d30af4bb7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3920,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Could realistic depictions of catastrophic AI risks effectively reduce said risk"
    },
    "fa87c35a1c7d773960e82257fc3d1014": {
      "source_id": "fa87c35a1c7d773960e82257fc3d1014",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3384,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Alignment's phlogiston "
    },
    "203a3f7a38c64e5b2405dde168ff46bf": {
      "source_id": "203a3f7a38c64e5b2405dde168ff46bf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12942,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Effective Enforceability of EU Competition Law Under Different AI Development Sc"
    },
    "3065d365e231dcdbec68f1e98c1c0129": {
      "source_id": "3065d365e231dcdbec68f1e98c1c0129",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1762,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "BERI, Epoch, and FAR will explain their work & current job openings online this "
    },
    "1fc5dfa2ba9d85883debaa49fc277cfc": {
      "source_id": "1fc5dfa2ba9d85883debaa49fc277cfc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1741,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "First call for EA Data Science/ML/AI"
    },
    "79a865a6b05d2e550631e62adfc87839": {
      "source_id": "79a865a6b05d2e550631e62adfc87839",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 106780,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Philanthropists Probably Shouldn't Mission-Hedge AI Progress"
    },
    "e963bddb4976e0693af656a12fd3b2c1": {
      "source_id": "e963bddb4976e0693af656a12fd3b2c1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1192,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Should I force myself to work on AGI alignment?"
    },
    "91a33055c40414c3639eee85e628543d": {
      "source_id": "91a33055c40414c3639eee85e628543d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 63954,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Safety For Dummies (Like Me)"
    },
    "aedccf3c4639e56322416b3e69081193": {
      "source_id": "aedccf3c4639e56322416b3e69081193",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 135,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Who would you have on your dream team for solving AGI Alignment?"
    },
    "eddf146484b1aa41b6357d28eeab45d3": {
      "source_id": "eddf146484b1aa41b6357d28eeab45d3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4885,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Seeking Student Submissions: Edit Your Source Code Contest"
    },
    "dc92583ee0fd9f762fa0d4e24bfc813e": {
      "source_id": "dc92583ee0fd9f762fa0d4e24bfc813e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10632,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AGI Safety Fundamentals programme is contracting a low-code engineer"
    },
    "398ee0be156600dd7fa544d4c6215d66": {
      "source_id": "398ee0be156600dd7fa544d4c6215d66",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20057,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI strategy nearcasting"
    },
    "7b2783288ee94744902a35baeb1eec66": {
      "source_id": "7b2783288ee94744902a35baeb1eec66",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 579,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "ARIA is looking for topics for roundtables"
    },
    "31a7ee83c8cb277a65d3e43663f33d2d": {
      "source_id": "31a7ee83c8cb277a65d3e43663f33d2d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3864,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Annual AGI Benchmarking Event"
    },
    "870ec80571d0cb1e1434224951ebee52": {
      "source_id": "870ec80571d0cb1e1434224951ebee52",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28964,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The History of AI Rights Research"
    },
    "549132de510c62e6f05f7c39b10d408d": {
      "source_id": "549132de510c62e6f05f7c39b10d408d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6272,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Who ordered alignment's apple? "
    },
    "ce90f625c40b9a90e7af693cda997dde": {
      "source_id": "ce90f625c40b9a90e7af693cda997dde",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 105220,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How might we align transformative AI if it\u2019s developed very soon?"
    },
    "acb5f76a253fa9fecefea455949651c7": {
      "source_id": "acb5f76a253fa9fecefea455949651c7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15097,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Preventing an AI-related catastrophe - Problem profile"
    },
    "5c17d06ac5324582466f069656add0e9": {
      "source_id": "5c17d06ac5324582466f069656add0e9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58881,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Happiness Maximizer: Why EA is an x-risk"
    },
    "a3e627dfedf8889338dbd637102ab286": {
      "source_id": "a3e627dfedf8889338dbd637102ab286",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17738,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Chaining the evil genie: why \"outer\" AI safety is probably easy"
    },
    "d64767b3205bc413d88492464fbfdc75": {
      "source_id": "d64767b3205bc413d88492464fbfdc75",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23531,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Critique of AI Takeover Scenarios"
    },
    "0e0968df90a7e3339ebf038191d8fa22": {
      "source_id": "0e0968df90a7e3339ebf038191d8fa22",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24311,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The great energy descent (short version) - An important thing EA might have miss"
    },
    "fca0f2d3db4f305a68e7f01e972b8f70": {
      "source_id": "fca0f2d3db4f305a68e7f01e972b8f70",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53273,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The great energy descent - Part 2: Limits to growth and why we probably won\u2019t re"
    },
    "8cacfb1578e20fc0b58c5849519da54b": {
      "source_id": "8cacfb1578e20fc0b58c5849519da54b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8262,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Reasons for my negative feelings towards the AI risk discussion"
    },
    "3d0c9a5b5c7ea62a96ed93dc76eadf81": {
      "source_id": "3d0c9a5b5c7ea62a96ed93dc76eadf81",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7011,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Alignment is hard. Communicating that, might be harder "
    },
    "8c1ef4486a1d160f77ff940b19796dd4": {
      "source_id": "8c1ef4486a1d160f77ff940b19796dd4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 66574,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "My take on What We Owe the Future"
    },
    "2d041f030a8fca5846917566712b71e7": {
      "source_id": "2d041f030a8fca5846917566712b71e7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26953,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Values lock-in is already happening (without AGI)"
    },
    "7cf3b09fcb51d77652a776a0ec9e6029": {
      "source_id": "7cf3b09fcb51d77652a776a0ec9e6029",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5402,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Replacement for PONR concept"
    },
    "d2c931780c3fd0429ee099924faffbd8": {
      "source_id": "d2c931780c3fd0429ee099924faffbd8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45556,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Systemic Cascading Risks: Relevance in Longtermism & Value Lock-In"
    },
    "22571416f23326cce6b7552eaec21834": {
      "source_id": "22571416f23326cce6b7552eaec21834",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22150,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "We Can\u2019t Do Long Term Utilitarian Calculations Until We Know if AIs Can Be Consc"
    },
    "783937354dd690e38bd4e63749f4bde4": {
      "source_id": "783937354dd690e38bd4e63749f4bde4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4309,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Peter Eckersley (1979-2022)"
    },
    "b52863ed9172d200b3d6515f4ccc8b0f": {
      "source_id": "b52863ed9172d200b3d6515f4ccc8b0f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 337,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Do AI companies make their safety researchers sign a non-disparagement clause?"
    },
    "a3643d17cf2a8bb3f32f11a6ecf42649": {
      "source_id": "a3643d17cf2a8bb3f32f11a6ecf42649",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17290,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "An entire category of risks is undervalued by EA [Summary of previous forum post"
    },
    "3fecaee86a59324a00004fe0bf19bb5d": {
      "source_id": "3fecaee86a59324a00004fe0bf19bb5d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6054,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Three scenarios of pseudo-alignment "
    },
    "7deabd3ce5c47e9f47002e07ddf7e0e8": {
      "source_id": "7deabd3ce5c47e9f47002e07ddf7e0e8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 260,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A New York Times article on AI risk "
    },
    "d6c4d1271a25ce2163f1fea7e007b710": {
      "source_id": "d6c4d1271a25ce2163f1fea7e007b710",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9897,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Safety Executive Summary"
    },
    "37a717e71e33fc779534d2c7eda0acee": {
      "source_id": "37a717e71e33fc779534d2c7eda0acee",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5617,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "13 background claims about EA"
    },
    "67d2e3da05a831ec8fa89805c67ae442": {
      "source_id": "67d2e3da05a831ec8fa89805c67ae442",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3911,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": " It's (not) how you use it "
    },
    "716542cebb63c1b617ab3accc4dfd8e3": {
      "source_id": "716542cebb63c1b617ab3accc4dfd8e3",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5812,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI alignment with humans... but with which humans?"
    },
    "180ec0706dd7056f6945d299a813d233": {
      "source_id": "180ec0706dd7056f6945d299a813d233",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11320,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Samotsvety's AI risk forecasts"
    },
    "cc4469b50e7ba83b83d154fd7ee83289": {
      "source_id": "cc4469b50e7ba83b83d154fd7ee83289",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8765,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A California Effect for Artificial Intelligence"
    },
    "8131128b0082f7e80da8dce293d5a4ff": {
      "source_id": "8131128b0082f7e80da8dce293d5a4ff",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4429,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Markus Anderljung On The AI Policy Landscape"
    },
    "5cf1163eb34ba1ffbbb976d02a88d431": {
      "source_id": "5cf1163eb34ba1ffbbb976d02a88d431",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6208,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Join ASAP (AI Safety Accountability Programme) \ud83d\ude80"
    },
    "9ee6de1477286516ae7299cbf78cc7ef": {
      "source_id": "9ee6de1477286516ae7299cbf78cc7ef",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 60732,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Risk Intro 1: Advanced AI Might Be Very Bad"
    },
    "49958a54fe065a14cb06966fb0a588fe": {
      "source_id": "49958a54fe065a14cb06966fb0a588fe",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30539,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "An experiment eliciting relative estimates for Open Philanthropy\u2019s 2018 AI safet"
    },
    "b3c4d4a1446027b193c596b37a3df629": {
      "source_id": "b3c4d4a1446027b193c596b37a3df629",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5376,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Differential technology development: preprint on the concept"
    },
    "2504369d674bf51b3644d48b4e52e547": {
      "source_id": "2504369d674bf51b3644d48b4e52e547",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20273,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What could an AI-caused existential catastrophe actually look like? "
    },
    "352c49abd23442de28bf72ef23ebfa63": {
      "source_id": "352c49abd23442de28bf72ef23ebfa63",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34751,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "EA & LW Forums Weekly Summary (5 - 11 Sep 22\u2019)"
    },
    "f0708a1a5b581ab4dad3d488dbffe47f": {
      "source_id": "f0708a1a5b581ab4dad3d488dbffe47f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4348,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing an Empirical AI Safety Program"
    },
    "eb41b3fd2ca5e7473ff92585400f662c": {
      "source_id": "eb41b3fd2ca5e7473ff92585400f662c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3255,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Roodman's Thoughts on Biological Anchors"
    },
    "99f7a8a4514f1e510faff21da9f334e2": {
      "source_id": "99f7a8a4514f1e510faff21da9f334e2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41170,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Future Matters #5: supervolcanoes, AI takeover, and What We Owe the Future"
    },
    "18e822ceaf2f7d19ce722a8e46c38a04": {
      "source_id": "18e822ceaf2f7d19ce722a8e46c38a04",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5164,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Black Box Investigations Research Hackathon"
    },
    "97e240f31f3a76feb112d1400a84add5": {
      "source_id": "97e240f31f3a76feb112d1400a84add5",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5678,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "'Artificial Intelligence Governance under Change' (PhD dissertation)"
    },
    "8261d076cb4567f5a7bbc091cfe3b0fb": {
      "source_id": "8261d076cb4567f5a7bbc091cfe3b0fb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23822,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The religion problem in AI alignment"
    },
    "0491a8fcab4c2b7e081906b67406d454": {
      "source_id": "0491a8fcab4c2b7e081906b67406d454",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54394,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Pugwash Conferences and the Anti-Ballistic Missile Treaty as a case study of"
    },
    "4ee2e6481e222aab0c4ac505b83a2a9a": {
      "source_id": "4ee2e6481e222aab0c4ac505b83a2a9a",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 634,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[linkpost] When does technical work to reduce AGI conflict make a difference?: I"
    },
    "1f50486f5c3b45e53709df1532a13309": {
      "source_id": "1f50486f5c3b45e53709df1532a13309",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7105,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Katja Grace on Slowing Down AI, AI Expert Surveys And Estimating AI Risk"
    },
    "c5dbc3876b8432556f9cdf07292f0762": {
      "source_id": "c5dbc3876b8432556f9cdf07292f0762",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20634,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The heterogeneity of human value types: Implications for AI alignment"
    },
    "edc495dfdd05bfe560be6bd9864a2526": {
      "source_id": "edc495dfdd05bfe560be6bd9864a2526",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7330,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Aligning AI with Humans by Leveraging Legal Informatics"
    },
    "7521936728a1e841c6e9c18ace804adc": {
      "source_id": "7521936728a1e841c6e9c18ace804adc",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7935,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Prize and fast track to alignment research at ALTER"
    },
    "56fb181d99a24bca57b1ed81c16aa4b6": {
      "source_id": "56fb181d99a24bca57b1ed81c16aa4b6",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3435,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Updates on FLI'S Value Alignment Map?"
    },
    "3d82641d9640d2a655509bf83b8d943e": {
      "source_id": "3d82641d9640d2a655509bf83b8d943e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36567,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Safety timelines: How long will it take to solve alignment?"
    },
    "a87f9e94f128703befccf693e14b7dc3": {
      "source_id": "a87f9e94f128703befccf693e14b7dc3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1789,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Summaries: Alignment Fundamentals Curriculum"
    },
    "63a98472df5ed544319cddb89c940a78": {
      "source_id": "63a98472df5ed544319cddb89c940a78",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1009,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why AGIs utility can't outweigh humans' utility?"
    },
    "4963f8f40345fa96a23b1661d827be81": {
      "source_id": "4963f8f40345fa96a23b1661d827be81",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1605,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "I'm Interviewing Kat Woods, EA Powerhouse. What Should I Ask?"
    },
    "0c7c867a12f3876e97ee045e91332aa0": {
      "source_id": "0c7c867a12f3876e97ee045e91332aa0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1230,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What Do AI Safety Pitches Not Get About Your Field?"
    },
    "1caa328e127fd9b97e6372353377aa7b": {
      "source_id": "1caa328e127fd9b97e6372353377aa7b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3803,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Establishing Oxford\u2019s AI Safety Student Group: Lessons Learnt and Our Model"
    },
    "9115a32c2d7422b9407a7bb6f7f6d90a": {
      "source_id": "9115a32c2d7422b9407a7bb6f7f6d90a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51077,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "EA\u2019s brain-over-body bias, and the embodied value problem in AI alignment "
    },
    "4647e014fff570a24a7c64428b539a40": {
      "source_id": "4647e014fff570a24a7c64428b539a40",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3950,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Mathematical Circuits in Neural Networks"
    },
    "28a4edb5e9096be11d20b4d797bd77fd": {
      "source_id": "28a4edb5e9096be11d20b4d797bd77fd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22325,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Cause Exploration Prizes] Expanding communication about AGI risks"
    },
    "2978b7375cc451190a898b9adabe352e": {
      "source_id": "2978b7375cc451190a898b9adabe352e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44967,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AGI Battle Royale: Why \u201cslow takeover\u201d scenarios devolve into a chaotic multi-AG"
    },
    "237dd3588ebef7e3e369ff8950d11c21": {
      "source_id": "237dd3588ebef7e3e369ff8950d11c21",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18702,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "(My suggestions) On Beginner Steps in AI Alignment"
    },
    "0c3053e546573e9645dd192cc05e0293": {
      "source_id": "0c3053e546573e9645dd192cc05e0293",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1485,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Crypto 'oracle protocols' for AI alignment with real-world data?"
    },
    "8b0a43b95ce79cbfc3a20ef1ee93db61": {
      "source_id": "8b0a43b95ce79cbfc3a20ef1ee93db61",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19047,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "7 Learnings and a Detailed Description of an AI Safety Reading Group"
    },
    "0c1de57647203964716c86a97ee5567f": {
      "source_id": "0c1de57647203964716c86a97ee5567f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26432,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Rival AI Deployment Problem: a Pre-deployment Agreement as the least-bad res"
    },
    "a651337c946ffbfa6913a8d660456b3b": {
      "source_id": "a651337c946ffbfa6913a8d660456b3b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9093,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Shahar Avin on How to Strategically Regulate Advanced AI Systems"
    },
    "1e1349f3b03b5bd49fa1f0799b354c4f": {
      "source_id": "1e1349f3b03b5bd49fa1f0799b354c4f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28862,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing the Future Fund's AI Worldview Prize"
    },
    "80342dc861c99993af3890901241a786": {
      "source_id": "80342dc861c99993af3890901241a786",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59125,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Risk Intro 2: Solving The Problem"
    },
    "33f9d7c88476796159720057fa7f02d6": {
      "source_id": "33f9d7c88476796159720057fa7f02d6",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8810,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Two reasons we might be closer to solving alignment than it seems"
    },
    "15d7baca30af2dfceda5662fc0f3add4": {
      "source_id": "15d7baca30af2dfceda5662fc0f3add4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28818,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Lessons from Three Mile Island for AI Warning Shots"
    },
    "a5ac8adae471d5abecf9173be8950a1f": {
      "source_id": "a5ac8adae471d5abecf9173be8950a1f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4410,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Project Idea: The cost of Coccidiosis on Chicken farming and if AI can help"
    },
    "0954595c8564204dc6e9858d7601314f": {
      "source_id": "0954595c8564204dc6e9858d7601314f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3985,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Stress Externalities More in AI Safety Pitches"
    },
    "bbd247b4c795b3e6f6f94b540211f109": {
      "source_id": "bbd247b4c795b3e6f6f94b540211f109",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58012,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why we're not founding a human-data-for-alignment org"
    },
    "cf9f0b8154033bfa19ce3a779216c6a4": {
      "source_id": "cf9f0b8154033bfa19ce3a779216c6a4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2594,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Likelihood of an anti-AI backlash: Results from a preliminary Twitter poll"
    },
    "070a4b22eb81e6e5e1791281e86ccf6b": {
      "source_id": "070a4b22eb81e6e5e1791281e86ccf6b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14829,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Optimism, AI risk, and EA blind spots"
    },
    "95e182c52e2949f48e80a97378071661": {
      "source_id": "95e182c52e2949f48e80a97378071661",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31332,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How Open Source Machine Learning Software Shapes AI"
    },
    "9c11856e396b783036c9a595de85ad16": {
      "source_id": "9c11856e396b783036c9a595de85ad16",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36871,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Estimating the Current and Future Number of AI Safety Researchers"
    },
    "bad44676d0cb4c870127cd28568336ac": {
      "source_id": "bad44676d0cb4c870127cd28568336ac",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1582,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "I'm interviewing prolific AI safety researcher Richard Ngo (now at OpenAI and pr"
    },
    "68c5cd9eded9086e1e0a8b71699a7ec8": {
      "source_id": "68c5cd9eded9086e1e0a8b71699a7ec8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59562,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "We all teach: here's how to do it better"
    },
    "d14bb2327f077c4c621b53494ed09f7f": {
      "source_id": "d14bb2327f077c4c621b53494ed09f7f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13477,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "EAG DC: Meta-Bottlenecks in Preventing AI Doom"
    },
    "0efe640cf5669b334fe98202942a2ebc": {
      "source_id": "0efe640cf5669b334fe98202942a2ebc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4595,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing the AI Safety Nudge Competition to Help Beat Procrastination"
    },
    "3190703f3e32ea5cc965d23078c7864f": {
      "source_id": "3190703f3e32ea5cc965d23078c7864f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2867,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Questions on databases of AI Risk estimates"
    },
    "ee44202da3f9e5ace99a5893e586155f": {
      "source_id": "ee44202da3f9e5ace99a5893e586155f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 683,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What are the risks of an oracle AI?"
    },
    "fe35ed04c493458968307a1227f14de6": {
      "source_id": "fe35ed04c493458968307a1227f14de6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26318,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The probability that Artificial General Intelligence will be developed by 2043 i"
    },
    "81ec69959a01bc32894b860b2ae78a35": {
      "source_id": "81ec69959a01bc32894b860b2ae78a35",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28583,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Public Explainer on AI as an Existential Risk"
    },
    "7b481694edb2deac5635fda49b0fb93d": {
      "source_id": "7b481694edb2deac5635fda49b0fb93d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1776,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Georgetown EA Fall 2022\"Intro to AI\" Reading Group"
    },
    "fcf74381a6f0cac08248239ef35b9a0c": {
      "source_id": "fcf74381a6f0cac08248239ef35b9a0c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6526,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "\u201cTechnological unemployment\u201d AI vs. \u201cmost important century\u201d AI: how far apart?"
    },
    "1c6a42614271e66892cb11e7756f1b6b": {
      "source_id": "1c6a42614271e66892cb11e7756f1b6b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1416,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "BenevolentAI - an effectively impactful company?"
    },
    "215a5bbdf4add281dcd2e95c8d701824": {
      "source_id": "215a5bbdf4add281dcd2e95c8d701824",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3230,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Which AI Safety Org to Join?"
    },
    "0bcdff7b3e2b096ba0a16d706ab8cb3d": {
      "source_id": "0bcdff7b3e2b096ba0a16d706ab8cb3d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5192,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "My argument against AGI"
    },
    "d0bc45f2c5549937875ec5c39b99d414": {
      "source_id": "d0bc45f2c5549937875ec5c39b99d414",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3527,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Vitalik Buterin Fellowship in AI Existential Safety is open for applications"
    },
    "475b709e7e49911c63f00c290f82c431": {
      "source_id": "475b709e7e49911c63f00c290f82c431",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8727,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The US expands restrictions on AI exports to China. What are the x-risk effects?"
    },
    "feab6f05f5500d33bc95a24510e2ea5e": {
      "source_id": "feab6f05f5500d33bc95a24510e2ea5e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 64801,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Counterarguments to the basic AI risk case"
    },
    "dcfad2dd52e49887a63bf14f2da0c249": {
      "source_id": "dcfad2dd52e49887a63bf14f2da0c249",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1062,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is interest in alignment worth mentioning for grad school applications?"
    },
    "d2f1bc17d3ad7b611ce9fc6c21dcb7f1": {
      "source_id": "d2f1bc17d3ad7b611ce9fc6c21dcb7f1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1537,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Assistant-professor-ranked AI ethics philosopher job opportunity at Canterbury U"
    },
    "749e3cc98ca5cd8d75e7e3eb4b703225": {
      "source_id": "749e3cc98ca5cd8d75e7e3eb4b703225",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2346,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why not to solve alignment by making superintelligent humans?"
    },
    "e15e8ea49201de13e65bcd3eee7e1167": {
      "source_id": "e15e8ea49201de13e65bcd3eee7e1167",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1951,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A modest case for hope"
    },
    "28c75d597fae234a7c1fae63999196ef": {
      "source_id": "28c75d597fae234a7c1fae63999196ef",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8250,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Safety Ideas: A collaborative AI safety research platform"
    },
    "c88f382b6d35413b5e6993ebc833b294": {
      "source_id": "c88f382b6d35413b5e6993ebc833b294",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1751,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Metaculus is building a team dedicated to AI forecasting"
    },
    "04c610dce068e5013a1e19b864a1752c": {
      "source_id": "04c610dce068e5013a1e19b864a1752c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 78603,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "\u2018Dissolving\u2019 AI Risk \u2013 Parameter Uncertainty in AI Future Forecasting"
    },
    "3122d393f487f07e50c2fcf02b3d7989": {
      "source_id": "3122d393f487f07e50c2fcf02b3d7989",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3153,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Governments pose larger risks than corporations: a brief response to Grace"
    },
    "0afc70f89a55bc118b99875fe30b5c40": {
      "source_id": "0afc70f89a55bc118b99875fe30b5c40",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51569,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The heritability of human values: A behavior genetic critique of Shard Theory"
    },
    "39ee64a4685bc803aef153b5b5cf8f33": {
      "source_id": "39ee64a4685bc803aef153b5b5cf8f33",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2207,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Introducing Generally Intelligent: an AI research lab focused on improved theore"
    },
    "4e116f76debe8b19c683ab310960499a": {
      "source_id": "4e116f76debe8b19c683ab310960499a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 16300,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Newsletter for Alignment Research: The ML Safety Updates"
    },
    "0f505ba6e61301f6cf8b4ae89409fe9b": {
      "source_id": "0f505ba6e61301f6cf8b4ae89409fe9b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1068,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Call to action: Read + Share AI Safety / Reinforcement Learning Featured in Conv"
    },
    "9016c950a34bb4edfca0db346b79f1dc": {
      "source_id": "9016c950a34bb4edfca0db346b79f1dc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52589,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "My (Lazy) Longtermism FAQ"
    },
    "fe0b8529bfed67596ee74f395cbd87af": {
      "source_id": "fe0b8529bfed67596ee74f395cbd87af",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 96393,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The optimal timing of spending on AGI safety work; why we should probably be spe"
    },
    "f9304b1ba7217ae5445f63b3b1879727": {
      "source_id": "f9304b1ba7217ae5445f63b3b1879727",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6988,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Mechanism Design for AI Safety - Reading Group Curriculum"
    },
    "a1b23ea29254c5280b177ef5e732f680": {
      "source_id": "a1b23ea29254c5280b177ef5e732f680",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10045,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Brief Summary Of The Most Important Century"
    },
    "506ae101758b3dd4e076f595f7c119d8": {
      "source_id": "506ae101758b3dd4e076f595f7c119d8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6827,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why some people believe in AGI, but I don't."
    },
    "5ff14f8e9e8c4acccaa43d93acba039e": {
      "source_id": "5ff14f8e9e8c4acccaa43d93acba039e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27319,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Apply to the Redwood Research Mechanistic Interpretability Experiment (REMIX), a"
    },
    "9572367e0dafadcc915bdb6381ca0bc8": {
      "source_id": "9572367e0dafadcc915bdb6381ca0bc8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2768,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Prizes for ML Safety Benchmark Ideas"
    },
    "85d775329177e93ee2057094eaafebb4": {
      "source_id": "85d775329177e93ee2057094eaafebb4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1298,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What should I ask Ajeya Cotra \u2014 senior researcher at Open Philanthropy, and expe"
    },
    "baa84368483af7063278846993456912": {
      "source_id": "baa84368483af7063278846993456912",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 69099,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Using artificial intelligence (machine vision) to increase the effectiveness of "
    },
    "808cb4745b81df86042ee5e76fba4cea": {
      "source_id": "808cb4745b81df86042ee5e76fba4cea",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11800,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Join the interpretability research hackathon"
    },
    "161b75b1a6e5b38884bc72f38c48ab99": {
      "source_id": "161b75b1a6e5b38884bc72f38c48ab99",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22037,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AGI and Lock-In"
    },
    "8095de47025a4a8ac0722b77ba04d478": {
      "source_id": "8095de47025a4a8ac0722b77ba04d478",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42416,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "ML Safety Scholars Summer 2022 Retrospective"
    },
    "8572ec1cbbe4c3e80f69c99b42fac10b": {
      "source_id": "8572ec1cbbe4c3e80f69c99b42fac10b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11259,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "On the correspondence between AI-misalignment and cognitive dissonance using a b"
    },
    "296bb68c16f9549ff035f81f73f05237": {
      "source_id": "296bb68c16f9549ff035f81f73f05237",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1776,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Should AI focus on problem-solving or strategic planning? Why not both?"
    },
    "cd76372f4a5781842d1b2ee0f0e5256b": {
      "source_id": "cd76372f4a5781842d1b2ee0f0e5256b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 109945,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI X-Risk: Integrating on the Shoulders of Giants"
    },
    "6c9b6c1b80a9ed71c092c38b10a839b6": {
      "source_id": "6c9b6c1b80a9ed71c092c38b10a839b6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28865,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "WFW?: Opportunity and Theory of Impact"
    },
    "71e618cb9383b6550538670b8e61b1da": {
      "source_id": "71e618cb9383b6550538670b8e61b1da",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13062,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Safety Needs Great Product Builders"
    },
    "99088461ef1b8f0dce9872a753388b5f": {
      "source_id": "99088461ef1b8f0dce9872a753388b5f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21235,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Theologian's Response to Anthropogenic Existential Risk"
    },
    "c19ab122fc3ad300f8644d0a278147d4": {
      "source_id": "c19ab122fc3ad300f8644d0a278147d4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4308,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A new place to discuss cognitive science, ethics and human alignment"
    },
    "e4457ce032ef2e20ae366952e903980e": {
      "source_id": "e4457ce032ef2e20ae366952e903980e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5171,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Applications are now open for Intro to ML Safety Spring 2023"
    },
    "470841a477671edf998afc77d1b89cb4": {
      "source_id": "470841a477671edf998afc77d1b89cb4",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6970,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is AI forecasting a waste of effort on the margin?"
    },
    "73cb9fb54b923dbf4587694f320b14af": {
      "source_id": "73cb9fb54b923dbf4587694f320b14af",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39484,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Slippery Slope from DALLE-2 to Deepfake Anarchy"
    },
    "7f4a654b3817d51698a87883319414aa": {
      "source_id": "7f4a654b3817d51698a87883319414aa",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8977,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "My summary of \u201cPragmatic AI Safety\u201d "
    },
    "ea2bb1ace11aacdd5ae527b6e31c0dc3": {
      "source_id": "ea2bb1ace11aacdd5ae527b6e31c0dc3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23633,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "\"AGI timelines: ignore the social factor at their peril\" (Future Fund AI Worldvi"
    },
    "1b131d904134ea98db2f8a57559867d7": {
      "source_id": "1b131d904134ea98db2f8a57559867d7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6330,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "\"AI predictions\" (Future Fund AI Worldview Prize submission)"
    },
    "eebf5119323587aa502933b7334729e8": {
      "source_id": "eebf5119323587aa502933b7334729e8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13201,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "\"Develop Anthropomorphic AGI to Save Humanity from Itself\" (Future Fund AI World"
    },
    "94c3a02c603eb8c470ae0fc7256b73e4": {
      "source_id": "94c3a02c603eb8c470ae0fc7256b73e4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17152,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Longevity research as AI X-risk intervention"
    },
    "c100e3ee6ff0a472664c2c7ba49fcdad": {
      "source_id": "c100e3ee6ff0a472664c2c7ba49fcdad",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33060,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What's Happening in Australia"
    },
    "905717bf94f83dc4af07a5d1e786b7ca": {
      "source_id": "905717bf94f83dc4af07a5d1e786b7ca",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3040,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Safety Unconference NeurIPS 2022 "
    },
    "bdba2b35d229af85e84824a8ea58651c": {
      "source_id": "bdba2b35d229af85e84824a8ea58651c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4073,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Safety groups should imitate career development clubs"
    },
    "2c6385f2e68a641dbb5e9151cdd11a77": {
      "source_id": "2c6385f2e68a641dbb5e9151cdd11a77",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1832,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What are some low-cost outside-the-box ways to do/fund alignment research?"
    },
    "38466b03cc3d706ed36df32dec4ab21e": {
      "source_id": "38466b03cc3d706ed36df32dec4ab21e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10469,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Apply now for the EU Tech Policy Fellowship 2023  "
    },
    "a97f1ebf5e22a55a6dc58c19911734a6": {
      "source_id": "a97f1ebf5e22a55a6dc58c19911734a6",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7276,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Poster Session on AI Safety"
    },
    "d071cd3293aee295577fa957229595b5": {
      "source_id": "d071cd3293aee295577fa957229595b5",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5062,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Safety Microgrant Round"
    },
    "f96dda7ccdc9cc5619a9c027e98b6b48": {
      "source_id": "f96dda7ccdc9cc5619a9c027e98b6b48",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1225,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Winners of the AI Safety Nudge Competition"
    },
    "c5a64942a948d45d7c0420ad270edd47": {
      "source_id": "c5a64942a948d45d7c0420ad270edd47",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1584,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "If FTX is liquidated, who ends up controlling Anthropic?"
    },
    "2f72a1a6d5b15193dcc39ecc71fd37df": {
      "source_id": "2f72a1a6d5b15193dcc39ecc71fd37df",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21676,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Training for Good - Update & Plans for 2023"
    },
    "c29bb54c4e6edfb0a04796f7c9ecb22f": {
      "source_id": "c29bb54c4e6edfb0a04796f7c9ecb22f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21910,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The limited upside of interpretability"
    },
    "bed9dc0f930992c0155d43caf73fe6e5": {
      "source_id": "bed9dc0f930992c0155d43caf73fe6e5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 117441,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Artificial Intelligence and Nuclear Command, Control, & Communications: The Risk"
    },
    "7c9917ef9302bc4e6012409f69417bbe": {
      "source_id": "7c9917ef9302bc4e6012409f69417bbe",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40214,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Beyond Simple Existential Risk: Survival in a Complex Interconnected World"
    },
    "0982b5a483c49a827888ecaef17fc8d5": {
      "source_id": "0982b5a483c49a827888ecaef17fc8d5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1369,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Benefits/Risks of Scott Aaronson's Orthodox/Reform Framing for AI Alignment"
    },
    "c413eac88fa5d7b70e0a31ffa88aa939": {
      "source_id": "c413eac88fa5d7b70e0a31ffa88aa939",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 497,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What is the best article to introduce someone to AI safety for the first time?"
    },
    "f8a30b86366011f69b4cb1963b1b6fac": {
      "source_id": "f8a30b86366011f69b4cb1963b1b6fac",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8091,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Epoch is hiring a Research Data Analyst"
    },
    "6c39da06f3c46c55fbdaa8016b03e018": {
      "source_id": "6c39da06f3c46c55fbdaa8016b03e018",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 101954,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Two contrasting models of \u201cintelligence\u201d and future growth"
    },
    "6ddc2bb5333b2d91c33fba01a8e356c8": {
      "source_id": "6ddc2bb5333b2d91c33fba01a8e356c8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15954,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Part 1: The AI Safety community has four main work groups, Strategy, Governance,"
    },
    "35ad7c03b2cd5d0346c68f7b8109dffc": {
      "source_id": "35ad7c03b2cd5d0346c68f7b8109dffc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 103003,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Rethink Priorities\u2019 2022 Impact, 2023 Strategy, and Funding Gaps"
    },
    "87f535e0494ad38b80e390a2efce6943": {
      "source_id": "87f535e0494ad38b80e390a2efce6943",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2558,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "More Academic Diversity in Alignment?"
    },
    "bc160351c82fb74d5d1bd6837c9ebb9d": {
      "source_id": "bc160351c82fb74d5d1bd6837c9ebb9d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7148,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Good Futures Initiative: Winter Project Internship "
    },
    "71e769d19aedaf899bf18723c855743d": {
      "source_id": "71e769d19aedaf899bf18723c855743d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37041,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "When to diversify? Breaking down mission-correlated investing"
    },
    "46a93f6ec4cd25615a634c34b53d06f0": {
      "source_id": "46a93f6ec4cd25615a634c34b53d06f0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15530,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "\"The Physicists\": A play about extinction and the responsibility of scientists"
    },
    "bb838cf03574996c860fcb1757e5b6d1": {
      "source_id": "bb838cf03574996c860fcb1757e5b6d1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 69289,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why Would AI \"Aim\" To Defeat Humanity?"
    },
    "738f4f4edede56ddb858df82dec6ab38": {
      "source_id": "738f4f4edede56ddb858df82dec6ab38",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18495,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Distillation of \"How Likely is Deceptive Alignment?\""
    },
    "1f12d91be33a6ec057a18a6e11c0aa50": {
      "source_id": "1f12d91be33a6ec057a18a6e11c0aa50",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31649,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Concrete actions to improve AI governance: the behaviour science approach"
    },
    "13bb7f33512871f83e8cf2ef3599566c": {
      "source_id": "13bb7f33512871f83e8cf2ef3599566c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2365,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing the Cambridge Boston Alignment Initiative [Hiring!]"
    },
    "c296a08aab49dc239df65b809366ecd8": {
      "source_id": "c296a08aab49dc239df65b809366ecd8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4465,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Apply for the ML Winter Camp in Cambridge, UK [2-10 Jan]"
    },
    "6033a5a574f332cff86e0c14c867247b": {
      "source_id": "6033a5a574f332cff86e0c14c867247b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2516,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI can exploit safety plans posted on the Internet"
    },
    "be9977630d4b376e623b22c29a8aaeb0": {
      "source_id": "be9977630d4b376e623b22c29a8aaeb0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2755,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Race to the Top: Benchmarks for AI Safety"
    },
    "dda5ff81408d153d174113f6d233f4c4": {
      "source_id": "dda5ff81408d153d174113f6d233f4c4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13876,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AGI as a Black Swan Event"
    },
    "6752fa49dbdcc143bb6d09fb4eec8148": {
      "source_id": "6752fa49dbdcc143bb6d09fb4eec8148",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 373,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Safety Pitches post ChatGPT"
    },
    "b04d3c14efd104f74ff0fde1ef0f8555": {
      "source_id": "b04d3c14efd104f74ff0fde1ef0f8555",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 835,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Something to make myself fascinated with computing science and AI."
    },
    "f528626b23e2c89dd0824b40495378e9": {
      "source_id": "f528626b23e2c89dd0824b40495378e9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23758,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Promoting compassionate longtermism"
    },
    "e72754f6f90c52043e8e40aa8e8667be": {
      "source_id": "e72754f6f90c52043e8e40aa8e8667be",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14311,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Thoughts on AGI organizations and capabilities work"
    },
    "19bc19259d57ccc352dd5334a2a991c1": {
      "source_id": "19bc19259d57ccc352dd5334a2a991c1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18783,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Main paths to impact in EU AI Policy"
    },
    "e6738787ab4cd520aae5caaa5ce78374": {
      "source_id": "e6738787ab4cd520aae5caaa5ce78374",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2646,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing BlueDot Impact"
    },
    "369112ecfe845a67ada25a3784a427ee": {
      "source_id": "369112ecfe845a67ada25a3784a427ee",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1535,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "ChatGPT can write code! ?"
    },
    "154fbeb06be4bd69b2b102bd3db8766e": {
      "source_id": "154fbeb06be4bd69b2b102bd3db8766e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34302,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Cooperation, Avoidance, and Indifference: Alternate Futures for Misaligned AGI"
    },
    "90cb028411ec0c1963367671c34a863f": {
      "source_id": "90cb028411ec0c1963367671c34a863f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30867,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Safety Seems Hard to Measure"
    },
    "689d99b305dcfe81bb072435f810c86d": {
      "source_id": "689d99b305dcfe81bb072435f810c86d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1885,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "An appraisal of the Future of Life Institute AI existential risk program"
    },
    "e05d544091d23415dd44f6f3a703dd1d": {
      "source_id": "e05d544091d23415dd44f6f3a703dd1d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40811,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Reflections on the PIBBSS Fellowship 2022"
    },
    "f4241fd16fc158dad81112c764985fe3": {
      "source_id": "f4241fd16fc158dad81112c764985fe3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2746,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Please provide feedback on AI-safety grant proposal, thanks!"
    },
    "bf695e0c5354342158390fb3eb84fc30": {
      "source_id": "bf695e0c5354342158390fb3eb84fc30",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18043,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Join the AI Testing Hackathon this Friday"
    },
    "53cbe781a99c9c3ef9b0f27b9910401d": {
      "source_id": "53cbe781a99c9c3ef9b0f27b9910401d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4763,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Applications open for AGI Safety Fundamentals: Alignment Course"
    },
    "e5aef18925c4edb3241b1f5ed25bd501": {
      "source_id": "e5aef18925c4edb3241b1f5ed25bd501",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1610,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Seeking participants for study of AI safety researchers"
    },
    "af102f43e9b84cfb500fa2c477746332": {
      "source_id": "af102f43e9b84cfb500fa2c477746332",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11913,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Part 2: AI Safety Movement Builders should help the community to optimise three "
    },
    "4bee272ab84b551b1d185e0f6aa109ec": {
      "source_id": "4bee272ab84b551b1d185e0f6aa109ec",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4539,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How would you estimate the value of delaying AGI by 1 day, in marginal donations"
    },
    "bb03a814092ca1212443f1bca50e81b6": {
      "source_id": "bb03a814092ca1212443f1bca50e81b6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33297,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How important are accurate AI timelines for the optimal spending schedule on AI "
    },
    "135e223b49c87b9e132e5daac8fcc34f": {
      "source_id": "135e223b49c87b9e132e5daac8fcc34f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1416,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Who will be in charge once alignment is achieved?"
    },
    "29b9131780fd87d364f65381c7e78da3": {
      "source_id": "29b9131780fd87d364f65381c7e78da3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46520,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Concrete actionable policies relevant to AI safety (written 2019)"
    },
    "a81ab90befbe46619180bc2e12d0b5f3": {
      "source_id": "a81ab90befbe46619180bc2e12d0b5f3",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7056,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "We should say more than \u201cx-risk is high\u201d"
    },
    "fbb3d8afbee0c75455ba0d5a77691968": {
      "source_id": "fbb3d8afbee0c75455ba0d5a77691968",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3521,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "There have been 3 planes (billionaire donors) and 2 have crashed"
    },
    "df816ff0fc5eb333ec86da9816f9b402": {
      "source_id": "df816ff0fc5eb333ec86da9816f9b402",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1588,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What we owe the microbiome"
    },
    "9aaa694dd07d572fbfd3320eba22ce10": {
      "source_id": "9aaa694dd07d572fbfd3320eba22ce10",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30197,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The \u2018Old AI\u2019: Lessons for AI governance from early electricity regulation"
    },
    "9c4d1fca3606525f7854c5a4d714e420": {
      "source_id": "9c4d1fca3606525f7854c5a4d714e420",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4435,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why I think that teaching philosophy is high impact"
    },
    "7644c1bf5066433a205a7a75b98bbdd5": {
      "source_id": "7644c1bf5066433a205a7a75b98bbdd5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42020,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "High-level hopes for AI alignment"
    },
    "f0fc42e9248f19bd75745f8db023734b": {
      "source_id": "f0fc42e9248f19bd75745f8db023734b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 309,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Posit: Most AI safety people should work on alignment/safety challenges for AI t"
    },
    "942264e02fec74ce85df9dd2c54c3d8b": {
      "source_id": "942264e02fec74ce85df9dd2c54c3d8b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 72112,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Understanding the diffusion of large language models: summary"
    },
    "a710ebb211ca6a88f38411833343e741": {
      "source_id": "a710ebb211ca6a88f38411833343e741",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57751,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Background for \"Understanding the diffusion of large language models\""
    },
    "dcefbd390d6d19cdccafad7ad599e101": {
      "source_id": "dcefbd390d6d19cdccafad7ad599e101",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57592,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "GPT-3-like models are now much easier to access and deploy than to develop"
    },
    "742bd4c015fd20fb0507e8dfe9e1e999": {
      "source_id": "742bd4c015fd20fb0507e8dfe9e1e999",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 118020,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The replication and emulation of GPT-3"
    },
    "1545441b90a54973b0b99b210e8743e9": {
      "source_id": "1545441b90a54973b0b99b210e8743e9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 88969,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Drivers of large language model diffusion: incremental research, publicity, and "
    },
    "6ee75932128ae1d478dbb82998e3eba3": {
      "source_id": "6ee75932128ae1d478dbb82998e3eba3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40038,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Publication decisions for large language models, and their impacts"
    },
    "676bd247cf251e725f744060f7dfb2a0": {
      "source_id": "676bd247cf251e725f744060f7dfb2a0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 105925,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Implications of large language model diffusion for AI governance"
    },
    "026795a3ccdf86f55c21d30b7850f016": {
      "source_id": "026795a3ccdf86f55c21d30b7850f016",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27697,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Questions for further investigation of AI diffusion"
    },
    "cf3429d86c619987b6f3e7afe4e7b049": {
      "source_id": "cf3429d86c619987b6f3e7afe4e7b049",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30835,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Conclusion and Bibliography for \"Understanding the diffusion of large language m"
    },
    "6e97a5c038c60906c9abe3496bcec8fe": {
      "source_id": "6e97a5c038c60906c9abe3496bcec8fe",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4944,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Katja Grace: Let's think about slowing down AI"
    },
    "37810c074d4fe8a04e54e7160341852a": {
      "source_id": "37810c074d4fe8a04e54e7160341852a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2576,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why is \"Argument Mapping\" Not More Common in EA/Rationality (And What Objections"
    },
    "a66f3ec541dbb533cb3f05962af6e7f7": {
      "source_id": "a66f3ec541dbb533cb3f05962af6e7f7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4620,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is Eric Schmidt funding AI capabilities research by the US government? "
    },
    "7e53c135bf42718b839799f92742c41d": {
      "source_id": "7e53c135bf42718b839799f92742c41d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10253,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How long till Brussels?: A light investigation into the Brussels Gap"
    },
    "9eafead424e43300984eb7ff3eff686b": {
      "source_id": "9eafead424e43300984eb7ff3eff686b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8185,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Slightly against aligning with neo-luddites"
    },
    "4fae3a465094a6cc0b2160a0670e378f": {
      "source_id": "4fae3a465094a6cc0b2160a0670e378f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3661,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "I have thousands of copies of HPMOR in Russian. How to use them with the most im"
    },
    "ceba7a304bc2a7fde1e7a12a2b942086": {
      "source_id": "ceba7a304bc2a7fde1e7a12a2b942086",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11313,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The AIA and its Brussels Effect"
    },
    "a02ce89caf2fe7417d785a977d61c042": {
      "source_id": "a02ce89caf2fe7417d785a977d61c042",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6811,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How to Catch a ChatGPT Cheat: 7 Practical Tips"
    },
    "ffd1c8689ae3370198d9844d22e5c78c": {
      "source_id": "ffd1c8689ae3370198d9844d22e5c78c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15769,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Reflections on my 5-month AI alignment upskilling grant"
    },
    "fc9b95046e4b08ce4271eb5cc4b7529f": {
      "source_id": "fc9b95046e4b08ce4271eb5cc4b7529f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 256,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Book recommendations for the history of ML? "
    },
    "632c2f71c88e0bae903c5d644152cdcd": {
      "source_id": "632c2f71c88e0bae903c5d644152cdcd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54698,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Future Matters #6: FTX collapse, value lock-in, and counterarguments to AI x-ris"
    },
    "04936444764946db60b4c959e88ed800": {
      "source_id": "04936444764946db60b4c959e88ed800",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2247,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Self-Limiting AI in AI Alignment"
    },
    "47ff7f3c749f6176f8e292d1ad9b8b4e": {
      "source_id": "47ff7f3c749f6176f8e292d1ad9b8b4e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29708,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Racing through a minefield: the AI deployment problem"
    },
    "5f864582fc4e8a4ccbd3ba9e4eed8522": {
      "source_id": "5f864582fc4e8a4ccbd3ba9e4eed8522",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11153,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Results from the AI testing hackathon"
    },
    "6ec92b74eb17517925fe60eb0ec588d1": {
      "source_id": "6ec92b74eb17517925fe60eb0ec588d1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4422,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Doesn't Have to be Weird"
    },
    "a70e945b2a38252ed79979a97acacc7a": {
      "source_id": "a70e945b2a38252ed79979a97acacc7a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 425,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How have shorter AI timelines been affecting you, and how have you been respondi"
    },
    "17f89cfc63d012461e50d96c17c96d92": {
      "source_id": "17f89cfc63d012461e50d96c17c96d92",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2832,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Normalcy bias and Base rate neglect: Bias in Evaluating AGI X-Risks"
    },
    "3eb96459b71b20cd877561b5c39ae8ec": {
      "source_id": "3eb96459b71b20cd877561b5c39ae8ec",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1901,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing Insights for Impact"
    },
    "113d57cdaeba1da4c7428f6258ba942f": {
      "source_id": "113d57cdaeba1da4c7428f6258ba942f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11026,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "ChatGPT understands, but largely does not generate Spanglish (and other code-mix"
    },
    "936eb939563160cc64f669d3b0af072d": {
      "source_id": "936eb939563160cc64f669d3b0af072d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16414,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Large Language Models as Corporate Lobbyists, and Implications for Societal-AI A"
    },
    "93f761ad4c8cd718a904d781d9e66747": {
      "source_id": "93f761ad4c8cd718a904d781d9e66747",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3304,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "When you plan according to your AI timelines, should you put more weight on the "
    },
    "341dd56b02a94c68a9844fc4e201f746": {
      "source_id": "341dd56b02a94c68a9844fc4e201f746",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1310,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Illusion of truth effect and Ambiguity effect: Bias in Evaluating AGI X-Risks"
    },
    "b3b6a0f485bb4711a8a14e05e30b3fb7": {
      "source_id": "b3b6a0f485bb4711a8a14e05e30b3fb7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5403,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Skill up in ML for AI safety with the Intro to ML Safety course (Spring 2023)"
    },
    "e88f0c53b834d93c173a365de0aa5374": {
      "source_id": "e88f0c53b834d93c173a365de0aa5374",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13198,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Metaculus Year in Review: 2022"
    },
    "d20c465873260174c5bd60d6e087cf6e": {
      "source_id": "d20c465873260174c5bd60d6e087cf6e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47811,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Transformative AI issues (not just misalignment): an overview"
    },
    "3158a0348d850f0ba60877ce6f9e9abe": {
      "source_id": "3158a0348d850f0ba60877ce6f9e9abe",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1815,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Machine Learning for Scientific Discovery - AI Safety Camp "
    },
    "004f48e5fa8ddfcbdf5c509bfdf10fd7": {
      "source_id": "004f48e5fa8ddfcbdf5c509bfdf10fd7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24668,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Misha Yagudin and Ozzie Gooen Discuss LLMs and Effective Altruism"
    },
    "a62d6e01e8a4385554fa5674f1d7cff2": {
      "source_id": "a62d6e01e8a4385554fa5674f1d7cff2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1062,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How to create curriculum for self-study towards AI alignment work? "
    },
    "a6c01abd5a66cfa27640d914fa57a190": {
      "source_id": "a6c01abd5a66cfa27640d914fa57a190",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6176,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "David Krueger on AI Alignment in Academia and Coordination"
    },
    "2375d1e9aa7182729cf2e675e4b2ddf3": {
      "source_id": "2375d1e9aa7182729cf2e675e4b2ddf3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13267,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Learning as much Deep Learning math as I could in 24 hours"
    },
    "3782f7c7c4ee2ae138f65f8be99020c7": {
      "source_id": "3782f7c7c4ee2ae138f65f8be99020c7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1492,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is this community over-emphasizing AI alignment?"
    },
    "72eb27e34cb2ccdf23ec78e6d5d16673": {
      "source_id": "72eb27e34cb2ccdf23ec78e6d5d16673",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5700,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is anyone else also getting more worried about hard takeoff AGI scenarios?"
    },
    "3c70d81ad31a469e65cdcbcebcf77a34": {
      "source_id": "3c70d81ad31a469e65cdcbcebcf77a34",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8686,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Nearcast-based \u201cdeployment problem\u201d analysis (Karnofsky, 2022)"
    },
    "19683a8e873cc075111830b9afc841bf": {
      "source_id": "19683a8e873cc075111830b9afc841bf",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 928,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What AI Take-Over Movies or Books Will Scare Me Into Taking AI Seriously?"
    },
    "f5f4d38fcd5f9502ab52730b8c8d0f63": {
      "source_id": "f5f4d38fcd5f9502ab52730b8c8d0f63",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5088,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Against using stock prices to forecast AI timelines"
    },
    "0fabeef9a2586253a77a005f2550766f": {
      "source_id": "0fabeef9a2586253a77a005f2550766f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16035,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "ML Summer Bootcamp Reflection: Aalto EA Finland"
    },
    "3c77cca37a5150522445b0b65cce6606": {
      "source_id": "3c77cca37a5150522445b0b65cce6606",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8125,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "ea.domains - Domains Free to a Good Home"
    },
    "a7ecbf8c8d9d47f2ea9f4e82512f0d92": {
      "source_id": "a7ecbf8c8d9d47f2ea9f4e82512f0d92",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2887,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing the 2023 PIBBSS Summer Research Fellowship"
    },
    "0911e07021755f2e66bfbaab755ea3fd": {
      "source_id": "0911e07021755f2e66bfbaab755ea3fd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13535,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Beware safety-washing"
    },
    "25c3e0ade029707e007271fd0233be75": {
      "source_id": "25c3e0ade029707e007271fd0233be75",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7749,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Concerns about AI safety career change"
    },
    "460100fc0d3d1f0f57a21ed18cd7e0bb": {
      "source_id": "460100fc0d3d1f0f57a21ed18cd7e0bb",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7299,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Aligning the Aligners: Ensuring Aligned AI acts for the common good of all manki"
    },
    "c1eb0b3b113b97505eae938df29c5605": {
      "source_id": "c1eb0b3b113b97505eae938df29c5605",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8289,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "EA relevant Foresight Institute Workshops in 2023: WBE & AI safety, Cryptography"
    },
    "cb26cc382ab02ad01013e3da38a13fdf": {
      "source_id": "cb26cc382ab02ad01013e3da38a13fdf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 65328,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How we could stumble into AI catastrophe"
    },
    "be1dc2c12e7ff54473d4ddc224f84b66": {
      "source_id": "be1dc2c12e7ff54473d4ddc224f84b66",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18935,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Can GPT-3 produce new ideas? Partially automating Robin Hanson and others"
    },
    "6ad79409afa667e7d51272aebc7fbfb3": {
      "source_id": "6ad79409afa667e7d51272aebc7fbfb3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23062,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Preparing for AI-assisted alignment research: we need data!"
    },
    "d59c4c110c90597647c7a255ef526592": {
      "source_id": "d59c4c110c90597647c7a255ef526592",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17603,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Ricerca sulla sicurezza delle IA: panoramica delle carriere"
    },
    "237334b3809a943636406f0f28cabef8": {
      "source_id": "237334b3809a943636406f0f28cabef8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10599,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Prevenire una catastrofe legata all'intelligenza artificiale"
    },
    "8ad5136c78638c17d7fc41ce7e39e15a": {
      "source_id": "8ad5136c78638c17d7fc41ce7e39e15a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9631,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How many people are working (directly) on reducing existential risk from AI?"
    },
    "0a946ab9e09222382b73aed40db9b199": {
      "source_id": "0a946ab9e09222382b73aed40db9b199",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9829,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Lessons learned and review of the AI Safety Nudge Competition"
    },
    "843d5d522fbde0d6adb54fa0d36e2e39": {
      "source_id": "843d5d522fbde0d6adb54fa0d36e2e39",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6297,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AGISF adaptation for in-person groups"
    },
    "c018154eca799da2dd72781165fb9125": {
      "source_id": "c018154eca799da2dd72781165fb9125",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 215,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "L\u2019importanza delle IA come possibile minaccia per l\u2019umanit\u00e0"
    },
    "c1ed804470401797ad00f21bff050273": {
      "source_id": "c1ed804470401797ad00f21bff050273",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34958,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Perch\u00e9 il deep learning moderno potrebbe rendere difficile l\u2019allineamento delle "
    },
    "f684e0f80edd614d46f7f8c2d6d50576": {
      "source_id": "f684e0f80edd614d46f7f8c2d6d50576",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1096,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Any Philosophy PhD recommendations for students interested in Alignment Efforts?"
    },
    "d068fa57a36e701f6eb01b51852f2375": {
      "source_id": "d068fa57a36e701f6eb01b51852f2375",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37064,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Emerging Paradigms: The Case of Artificial Intelligence Safety"
    },
    "f8030d7dd91c1dd00651d26971c5edba": {
      "source_id": "f8030d7dd91c1dd00651d26971c5edba",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1477,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Help me to understand AI alignment!"
    },
    "5fa51de17d24974124201dbf9086b3d3": {
      "source_id": "5fa51de17d24974124201dbf9086b3d3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4657,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Approfondimenti sui rischi dell\u2019IA (materiali in inglese)"
    },
    "e9fb63ab4f21715811bd82f4b58171a2": {
      "source_id": "e9fb63ab4f21715811bd82f4b58171a2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5911,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Vitalik on science, his philanthropy and effective altruism."
    },
    "301fd76fbc87ce1c74fe0c8f45a6c379": {
      "source_id": "301fd76fbc87ce1c74fe0c8f45a6c379",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3685,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing Cavendish Labs"
    },
    "f3f6589c2451c58e9fd8384f6e612d7c": {
      "source_id": "f3f6589c2451c58e9fd8384f6e612d7c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7902,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What\u2019s going on with \u2018crunch time\u2019?"
    },
    "dfa8bfcd59985d13406516692411c1f8": {
      "source_id": "dfa8bfcd59985d13406516692411c1f8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5505,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "We Ran an Alignment Workshop"
    },
    "29219384b1bbf0d46c7a65adc47774c8": {
      "source_id": "29219384b1bbf0d46c7a65adc47774c8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2132,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "NYT: Google will \u2018recalibrate\u2019 the risk of releasing AI due to competition with "
    },
    "04cecd352ed5faa55223b9f966941e42": {
      "source_id": "04cecd352ed5faa55223b9f966941e42",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3786,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "There should be a public adversarial collaboration on AI x-risk"
    },
    "34664f0f895725d7a65130dd50bb9d71": {
      "source_id": "34664f0f895725d7a65130dd50bb9d71",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40483,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What a compute-centric framework says about AI takeoff speeds"
    },
    "d326e10088ed200a0758a51bbbd54a63": {
      "source_id": "d326e10088ed200a0758a51bbbd54a63",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12236,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Has private AGI research made independent safety research ineffective already? W"
    },
    "f64330231d07e9991456a5a5bc70b3dc": {
      "source_id": "f64330231d07e9991456a5a5bc70b3dc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27294,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "My highly personal skepticism braindump on existential risk from artificial inte"
    },
    "67f8ecc9238b574acdfb3b3db17ea8a1": {
      "source_id": "67f8ecc9238b574acdfb3b3db17ea8a1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7027,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Update to Samotsvety AGI timelines"
    },
    "cd67b21ce55f24a9fbec9565ec57a217": {
      "source_id": "cd67b21ce55f24a9fbec9565ec57a217",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31265,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why people want to work on AI safety (but don\u2019t)"
    },
    "b4957581a195fdd83e8ba462663476da": {
      "source_id": "b4957581a195fdd83e8ba462663476da",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17155,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Existential Risk of Misaligned Intelligence Augmentation (Particularly Using Hig"
    },
    "33cfb3644579295385128b38ea32a311": {
      "source_id": "33cfb3644579295385128b38ea32a311",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 78682,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Large Language Models as Fiduciaries to Humans"
    },
    "16ce099d1eba5d6b6a0801ecc561c4c2": {
      "source_id": "16ce099d1eba5d6b6a0801ecc561c4c2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39521,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Spreading messages to help with the most important century"
    },
    "a09db6ae70f919b2d953181b9026f998": {
      "source_id": "a09db6ae70f919b2d953181b9026f998",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15190,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Excerpts from \"Doing EA Better\" on x-risk methodology"
    },
    "67248b7005739be8e86f62839914bf97": {
      "source_id": "67248b7005739be8e86f62839914bf97",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2742,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\"How to Escape from the Simulation\" - Seeds of Science call for reviewers"
    },
    "5b64c782a0ca6a824565c25d6023604b": {
      "source_id": "5b64c782a0ca6a824565c25d6023604b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5658,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Time-stamping: An urgent, neglected AI safety measure"
    },
    "1a2a0e4e978f3a2f808c646fb03fef05": {
      "source_id": "1a2a0e4e978f3a2f808c646fb03fef05",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24691,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How to use AI speech transcription and analysis to accelerate social science res"
    },
    "e61aff2931dfe4c65a332dcda1030165": {
      "source_id": "e61aff2931dfe4c65a332dcda1030165",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3956,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Questions about AI that bother me "
    },
    "e25644b1643c64d756451ad491f79f25": {
      "source_id": "e25644b1643c64d756451ad491f79f25",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 672,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] Human-narrated audio version of \"Is Power-Seeking AI an Existential R"
    },
    "7f82d7444e82a76c1dfbfec37a78ad0f": {
      "source_id": "7f82d7444e82a76c1dfbfec37a78ad0f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30861,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What Are The Biggest Threats To Humanity? (A Happier World video)"
    },
    "2657a0fbb50d940006850d5f111b1b1e": {
      "source_id": "2657a0fbb50d940006850d5f111b1b1e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55069,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Eli Lifland on Navigating the AI Alignment Landscape"
    },
    "571fcd11e953233fa326fbb513a1af33": {
      "source_id": "571fcd11e953233fa326fbb513a1af33",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47237,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Predicting researcher interest in AI alignment"
    },
    "254923a0c4dcc6a7aaa0db614dc52d06": {
      "source_id": "254923a0c4dcc6a7aaa0db614dc52d06",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3448,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\u201cAI Risk Discussions\u201d website: Exploring interviews from 97 AI Researchers"
    },
    "e5d1216bd94f6ee5c48dd279b4a33a99": {
      "source_id": "e5d1216bd94f6ee5c48dd279b4a33a99",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18609,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Retrospective on the AI Safety Field Building Hub"
    },
    "d7c33f8f98f4aca4e7d987d9ebc45cf5": {
      "source_id": "d7c33f8f98f4aca4e7d987d9ebc45cf5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3423,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "40,000 reasons to worry about AI safety"
    },
    "3195b924f6663d6adbb0faaf17eaccd7": {
      "source_id": "3195b924f6663d6adbb0faaf17eaccd7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 411,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An audio version of the alignment problem from a deep learning perspective by Ri"
    },
    "f988123b1e6041751d95986d8dab0ab1": {
      "source_id": "f988123b1e6041751d95986d8dab0ab1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4549,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Criticism Thread: What things should OpenPhil improve on?"
    },
    "ff3ebeb2e6c39ffb1b1c659eb1d92c1a": {
      "source_id": "ff3ebeb2e6c39ffb1b1c659eb1d92c1a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22235,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A discussion with ChatGPT on value-based models vs. large language models, etc.."
    },
    "1cb8e37ad93aec26bcd8f4dea8597422": {
      "source_id": "1cb8e37ad93aec26bcd8f4dea8597422",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3616,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Call for submissions: AI Safety Special Session at the Conference on Artificial "
    },
    "d5a310736ae426e9ad28aed2a45333dc": {
      "source_id": "d5a310736ae426e9ad28aed2a45333dc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4817,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Launching The Collective Intelligence Project: Whitepaper and Pilots"
    },
    "9380211ed195b42ac9123aedda7421ad": {
      "source_id": "9380211ed195b42ac9123aedda7421ad",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 486,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Donation recommendations for xrisk + ai safety"
    },
    "6377f7e7e66b0f3332e3aebbde309ecd": {
      "source_id": "6377f7e7e66b0f3332e3aebbde309ecd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41605,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Speedrun: AI Alignment Prizes"
    },
    "b34e6f0c408c9fa051b6aab9eefdc697": {
      "source_id": "b34e6f0c408c9fa051b6aab9eefdc697",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4318,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Technology is Power: Raising Awareness Of Technological Risks"
    },
    "f29e572547e5ff2efb3eeb3727454c79": {
      "source_id": "f29e572547e5ff2efb3eeb3727454c79",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12082,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Technological developments that could increase risks from nuclear weapons: A sha"
    },
    "3cffc0f5bdf028c5feda8b3a2cb1bc9c": {
      "source_id": "3cffc0f5bdf028c5feda8b3a2cb1bc9c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10722,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Apply to the Cambridge ML for Alignment Bootcamp (CaMLAB) [26 March - 8 April]"
    },
    "d7f2de11cf1666119a034f14d2aeea3e": {
      "source_id": "d7f2de11cf1666119a034f14d2aeea3e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2992,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Mechanism Design for AI Safety - Agenda Creation Retreat"
    },
    "137974180e35b6a26be72a9438a80cc3": {
      "source_id": "137974180e35b6a26be72a9438a80cc3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46549,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Importance of AI Alignment, explained in 5 points"
    },
    "8e76e4cde1e4a693437253cb0a0af527": {
      "source_id": "8e76e4cde1e4a693437253cb0a0af527",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 69975,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Jobs that can help with the most important century"
    },
    "b4f101962b72adf6aa20abde823724db": {
      "source_id": "b4f101962b72adf6aa20abde823724db",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30708,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI alignment researchers may have a comparative advantage in reducing s-risks"
    },
    "1c5bb444cb79146fd721d742544192a9": {
      "source_id": "1c5bb444cb79146fd721d742544192a9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4791,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Should ChatGPT make us downweight our belief in the consciousness of non-human a"
    },
    "23ffe4aea84ae7ddfe085206f45f126b": {
      "source_id": "23ffe4aea84ae7ddfe085206f45f126b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15117,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What to think when a language model tells you it's sentient"
    },
    "1357b611eebdbbc5e277af7b44026173": {
      "source_id": "1357b611eebdbbc5e277af7b44026173",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3383,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Don't Call It AI Alignment"
    },
    "a729cede3ae36a342c9b3746df96698e": {
      "source_id": "a729cede3ae36a342c9b3746df96698e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12198,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[MLSN #8]: Mechanistic interpretability, using law to inform AI alignment, scali"
    },
    "b99b9c8f2e3f8af9471c370b3a8d8649": {
      "source_id": "b99b9c8f2e3f8af9471c370b3a8d8649",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24008,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What AI companies can do today to help with the most important century"
    },
    "d276a632fcb13872876cd08e9a91f482": {
      "source_id": "d276a632fcb13872876cd08e9a91f482",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62059,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "There are no coherence theorems"
    },
    "7ea272bbb6244516a5daa1c63e43a87f": {
      "source_id": "7ea272bbb6244516a5daa1c63e43a87f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9534,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Does most of your impact come from what you do soon?"
    },
    "299246c999dc46c8d92e133d1c200651": {
      "source_id": "299246c999dc46c8d92e133d1c200651",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18292,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What is it like doing AI safety work?"
    },
    "fcee81ed5954c9d933a226425c9449a2": {
      "source_id": "fcee81ed5954c9d933a226425c9449a2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3469,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Taking a leave of absence from Open Philanthropy to work on AI safety"
    },
    "a7123ce783b6d01a699cad25425c837c": {
      "source_id": "a7123ce783b6d01a699cad25425c837c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1414,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "2023 Stanford Existential Risks Conference"
    },
    "56b8fed60a3f5d2bffa624ecacc6a3ee": {
      "source_id": "56b8fed60a3f5d2bffa624ecacc6a3ee",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10597,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How major governments can help with the most important century"
    },
    "2bc28fe516edb6cd60e8d666289da23d": {
      "source_id": "2bc28fe516edb6cd60e8d666289da23d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 581,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Which is more important for reducing s-risks, researching on AI sentience or ani"
    },
    "233ca6a37dcb295c906039acc13eb08f": {
      "source_id": "233ca6a37dcb295c906039acc13eb08f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1225,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How to \u2018troll for good\u2019: Leveraging IP for AI governance"
    },
    "1da70c1b3fd555656bc0dba8fa5f3625": {
      "source_id": "1da70c1b3fd555656bc0dba8fa5f3625",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2631,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Very Briefly: The CHIPS Act"
    },
    "771964246100b1bb26b01e5711f2c80f": {
      "source_id": "771964246100b1bb26b01e5711f2c80f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17908,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why I think it's important to work on AI forecasting"
    },
    "5c6876a2c3ff184e11f8d7adf861ad40": {
      "source_id": "5c6876a2c3ff184e11f8d7adf861ad40",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5070,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Seeking input on a list of AI books for broader audience"
    },
    "ca2c8a18d1325bc87ef92f9187a904bd": {
      "source_id": "ca2c8a18d1325bc87ef92f9187a904bd",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2654,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Do you worry about totalitarian regimes using AI Alignment technology to create "
    },
    "4a250321c618c5c3e4da80ca09921cd7": {
      "source_id": "4a250321c618c5c3e4da80ca09921cd7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4775,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What does Bing Chat tell us about AI risk?"
    },
    "93338bb40c5fefca538e9ae1afdc8ee2": {
      "source_id": "93338bb40c5fefca538e9ae1afdc8ee2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12505,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Some Things I Heard about AI Governance at EAG"
    },
    "d5568ae9b48262bbae1d179c755c85bd": {
      "source_id": "d5568ae9b48262bbae1d179c755c85bd",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6218,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Call for Cruxes by Rhyme, a Longtermist History Consultancy "
    },
    "9bce321396897553008b10a8f6c64833": {
      "source_id": "9bce321396897553008b10a8f6c64833",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17488,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Joscha Bach on Synthetic Intelligence [annotated]"
    },
    "b16c845957671ed449cf484ef37d6f49": {
      "source_id": "b16c845957671ed449cf484ef37d6f49",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 532,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Game theory work on AI alignment with diverse AI systems, human individuals, & h"
    },
    "17bb95471cd6cf1c241995600803d387": {
      "source_id": "17bb95471cd6cf1c241995600803d387",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1942,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Call to demand answers from Anthropic about joining the AI race "
    },
    "80b9fd4aa5906a39aabd5b99f77701f3": {
      "source_id": "80b9fd4aa5906a39aabd5b99f77701f3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3002,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "New Artificial Intelligence quiz: can you beat ChatGPT?"
    },
    "e5db7c6d2f63b098298b2c4caa3fe27c": {
      "source_id": "e5db7c6d2f63b098298b2c4caa3fe27c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13592,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Introducing the new Riesgos Catastr\u00f3ficos Globales team"
    },
    "223b377463ce6d62b21671357a510c56": {
      "source_id": "223b377463ce6d62b21671357a510c56",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14695,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Acausal normalcy"
    },
    "8713de0a69d40197bd1f9a85eff264c1": {
      "source_id": "8713de0a69d40197bd1f9a85eff264c1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2337,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Misalignment Museum opens in San Francisco: \u2018Sorry for killing most of humanity\u2019"
    },
    "be87f096ba4a4df27b498e8187197b9c": {
      "source_id": "be87f096ba4a4df27b498e8187197b9c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9572,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Benefits of Distillation in Research"
    },
    "b784657e5ca971ee0af6006726af9985": {
      "source_id": "b784657e5ca971ee0af6006726af9985",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49829,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Model-Based Policy Analysis under Deep Uncertainty"
    },
    "93e658ae608d3f36547cc4c7a518edde": {
      "source_id": "93e658ae608d3f36547cc4c7a518edde",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 594,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Should people get neuroscience phD to work in AI safety field?"
    },
    "bee1604c2c630bf4e525e8cf5c5cc2b7": {
      "source_id": "bee1604c2c630bf4e525e8cf5c5cc2b7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8622,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Crosspost] Why Uncontrollable AI Looks More Likely Than Ever"
    },
    "228a79d033dbe390e34c9c0a0cb74853": {
      "source_id": "228a79d033dbe390e34c9c0a0cb74853",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10443,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Paper Summary: The Effectiveness of AI Existential Risk Communication to the Ame"
    },
    "b1d6208246ed61eab51dcd379ecb8874": {
      "source_id": "b1d6208246ed61eab51dcd379ecb8874",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9801,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A Roundtable for Safe AI (RSAI)? "
    },
    "79e8d778206975c8427bee27ec169ce8": {
      "source_id": "79e8d778206975c8427bee27ec169ce8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12450,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A Windfall Clause for CEO could worsen AI race dynamics"
    },
    "67f906701f0ab09713c00665c6b27fb7": {
      "source_id": "67f906701f0ab09713c00665c6b27fb7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6364,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Everything's normal until it's not "
    },
    "12e50fbdd29eceaba1b684cd0be5b229": {
      "source_id": "12e50fbdd29eceaba1b684cd0be5b229",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7877,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing the Open Philanthropy AI Worldviews Contest"
    },
    "b25a75dd023f82a57468acbcd64a2f8e": {
      "source_id": "b25a75dd023f82a57468acbcd64a2f8e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24376,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Thoughts on the OpenAI alignment plan: will AI research assistants be net-positi"
    },
    "bbbaab6e4fb2e93c9beb406809b10ccc": {
      "source_id": "bbbaab6e4fb2e93c9beb406809b10ccc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1828,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Japan AI Alignment Conference"
    },
    "00a3081efa71bafbf20227c24ea3169b": {
      "source_id": "00a3081efa71bafbf20227c24ea3169b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 129562,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Yudkowsky on AGI risk on the Bankless podcast"
    },
    "eb554ef034e742f025c2cc96b6caf9fe": {
      "source_id": "eb554ef034e742f025c2cc96b6caf9fe",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1695,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "On taking AI risk seriously  "
    },
    "a816a9138dcd45eb797b5780baabc324": {
      "source_id": "a816a9138dcd45eb797b5780baabc324",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12103,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Foundations for a Longtermist Foreign Policy "
    },
    "e73051d6babe00cae68e9952e0b14103": {
      "source_id": "e73051d6babe00cae68e9952e0b14103",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 90835,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "2023 Open Philanthropy AI Worldviews Contest: Odds of Artificial General Intelli"
    },
    "284646a6c7db5eb58d150e089514bcb6": {
      "source_id": "284646a6c7db5eb58d150e089514bcb6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30115,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Shutting Down the Lightcone Offices"
    },
    "4da8fb77a68e82ed46f38854c64a17f9": {
      "source_id": "4da8fb77a68e82ed46f38854c64a17f9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19751,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI safety and consciousness research: A brainstorm"
    },
    "c6480d8e4d72ead99258698fcba2924e": {
      "source_id": "c6480d8e4d72ead99258698fcba2924e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52504,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety - 7 months of discussion in 17 minutes"
    },
    "624d64a2e298ab5d10569c825c302d61": {
      "source_id": "624d64a2e298ab5d10569c825c302d61",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37456,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "We are fighting a shared battle (a call for a different approach to AI Strategy)"
    },
    "8530462b3f9d7136bc1ca6f6f163c667": {
      "source_id": "8530462b3f9d7136bc1ca6f6f163c667",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4626,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Donation offsets for ChatGPT Plus subscriptions"
    },
    "982a7dcee4386daca91506f8fb6fe2a1": {
      "source_id": "982a7dcee4386daca91506f8fb6fe2a1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1688,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Legal Assistance for Victims of AI"
    },
    "25be3f3cdce513b7bd6b5f7ae069e859": {
      "source_id": "25be3f3cdce513b7bd6b5f7ae069e859",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48744,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Symbiosis, not alignment, as the goal for liberal democracies in the transition "
    },
    "a516834e2188e213ac568ba893b18ff2": {
      "source_id": "a516834e2188e213ac568ba893b18ff2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5268,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Unjournal: Evaluations of \"Artificial Intelligence and Economic Growth\", and new"
    },
    "1acf7e92be4e62d5bad1c0033cc32f0f": {
      "source_id": "1acf7e92be4e62d5bad1c0033cc32f0f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6401,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Would you pursue software engineering as a career today?"
    },
    "2f6de174927b2a2c515d0f1ac2c43313": {
      "source_id": "2f6de174927b2a2c515d0f1ac2c43313",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3242,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Pros and Cons of boycotting paid Chat GPT"
    },
    "cd3be0290e623fd2625c5c7880dad98a": {
      "source_id": "cd3be0290e623fd2625c5c7880dad98a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8749,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Potential employees have a unique lever to influence the behaviors of AI labs"
    },
    "7cdd4f9d7d956c0e6681ef35fbeb89f2": {
      "source_id": "7cdd4f9d7d956c0e6681ef35fbeb89f2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 112830,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How much should governments pay to prevent catastrophes? Longtermism\u2019s limited r"
    },
    "bd9f09420b1b46571054ce83096d3a6a": {
      "source_id": "bd9f09420b1b46571054ce83096d3a6a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12670,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Where I'm at with AI risk: convinced of danger but not (yet) of doom "
    },
    "11685135dee9902b22ce9fc64bbfc57d": {
      "source_id": "11685135dee9902b22ce9fc64bbfc57d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7487,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Capping AGI profits"
    },
    "61e5cf7ca0ca3101baafe1bb9eed8e19": {
      "source_id": "61e5cf7ca0ca3101baafe1bb9eed8e19",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53518,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Future Matters #8: Bing Chat, AI labs on safety, and pausing Future Matters"
    },
    "b4bd1026ac6b5af2f9c4059a1748d0f2": {
      "source_id": "b4bd1026ac6b5af2f9c4059a1748d0f2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4311,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\"Aligned with who?\" Results of surveying 1,000 US participants on AI values"
    },
    "7811326d039ea1a8495e6aa7551b6122": {
      "source_id": "7811326d039ea1a8495e6aa7551b6122",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 67290,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Part 3: A Proposed Approach for AI Safety Movement Building: Projects, Professio"
    },
    "be5e0280701fd579c06e20bc27d0e69c": {
      "source_id": "be5e0280701fd579c06e20bc27d0e69c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7347,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Whether you should do a PhD doesn't depend much on timelines."
    },
    "b056d9dde341dfbe27bb34c3139becc4": {
      "source_id": "b056d9dde341dfbe27bb34c3139becc4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10213,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The space of systems and the space of maps"
    },
    "dd7677e28751230ad199773fc4d81e55": {
      "source_id": "dd7677e28751230ad199773fc4d81e55",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6954,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing the European Network for AI Safety (ENAIS)"
    },
    "9398c3d806bcfb9be465ca7e8bdfd0bd": {
      "source_id": "9398c3d806bcfb9be465ca7e8bdfd0bd",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 1990,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] Shorter version of report on existential risk from power-seeking AI"
    },
    "916127921f898ded1a1eb8039077e994": {
      "source_id": "916127921f898ded1a1eb8039077e994",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10794,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Join the AI governance and interpretability hackathons!"
    },
    "3cfb7a936283b56e6cc4e7fcf75dfb9d": {
      "source_id": "3cfb7a936283b56e6cc4e7fcf75dfb9d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1072,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Can independent researchers get a sponsored visa for the US or UK?"
    },
    "2687bf209370c4061799f774909d3096": {
      "source_id": "2687bf209370c4061799f774909d3096",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38959,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "My attempt at explaining the case for AI risk in a straightforward way"
    },
    "f6269f0bd610e0e2c09f5b865569fcc7": {
      "source_id": "f6269f0bd610e0e2c09f5b865569fcc7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6600,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Mitigating existential risks associated with human nature and AI: Thoughts on se"
    },
    "2525f51ed49f716cb9ee402f5297b769": {
      "source_id": "2525f51ed49f716cb9ee402f5297b769",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7674,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Please help me sense-check my assumptions about the needs of the AI Safety commu"
    },
    "6146add9f9058b02f67ce48f2b008cd3": {
      "source_id": "6146add9f9058b02f67ce48f2b008cd3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 665,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Are there cause priortizations estimates for s-risks supporters?"
    },
    "e7d82cb09d8c05f6329fa81adf940721": {
      "source_id": "e7d82cb09d8c05f6329fa81adf940721",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1645,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "New blog: Planned Obsolescence"
    },
    "b8bcb693d4eb6d558bef7207d17aa07d": {
      "source_id": "b8bcb693d4eb6d558bef7207d17aa07d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1003,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Governing High-Impact AI Systems: Understanding Canada\u2019s Proposed AI Bill. April"
    },
    "66939e6232d5013403251cb01575f8e1": {
      "source_id": "66939e6232d5013403251cb01575f8e1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16350,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "When Will We Spend Enough to Train Transformative AI"
    },
    "db82b303faa2affb5715e0d6f967ae6f": {
      "source_id": "db82b303faa2affb5715e0d6f967ae6f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3829,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Some of My Current Impressions Entering AI Safety"
    },
    "a9de806385698cf097d814b75f55e46c": {
      "source_id": "a9de806385698cf097d814b75f55e46c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1580,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What longtermist projects would you like to see implemented?"
    },
    "1910cc34967d749bb9a7007685b38ab8": {
      "source_id": "1910cc34967d749bb9a7007685b38ab8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13557,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Explorers in a virtual country: Navigating the knowledge landscape of large lang"
    },
    "e1bb5671ee7c1d0eaced9ce6e3835510": {
      "source_id": "e1bb5671ee7c1d0eaced9ce6e3835510",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2487,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Desensitizing Deepfakes"
    },
    "73a31f58e2a65910f67899adf802b956": {
      "source_id": "73a31f58e2a65910f67899adf802b956",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27554,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Nobody\u2019s on the ball on AGI alignment"
    },
    "934ed1b2bca7174441dd8025d905a737": {
      "source_id": "934ed1b2bca7174441dd8025d905a737",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52045,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Recruit the World\u2019s best for AGI Alignment"
    },
    "450dee6c1c250919077d740a694366cf": {
      "source_id": "450dee6c1c250919077d740a694366cf",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8303,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Nuclear brinksmanship is not a good AI x-risk strategy"
    },
    "9f619e35bab97815507272c59cc9b469": {
      "source_id": "9f619e35bab97815507272c59cc9b469",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2754,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Longtermism and shorttermism can disagree on nuclear war to stop advanced AI"
    },
    "343e2a0e62cb717a705a8b6ddc0a074c": {
      "source_id": "343e2a0e62cb717a705a8b6ddc0a074c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47328,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Critiques of prominent AI safety labs: Redwood Research"
    },
    "879642e96f5dbf12036157df90925bff": {
      "source_id": "879642e96f5dbf12036157df90925bff",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16790,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI, Cybersecurity, and Malware: A Shallow Report [General]"
    },
    "fe4a498fdb037199f1296a43b9c47abe": {
      "source_id": "fe4a498fdb037199f1296a43b9c47abe",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19032,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI, Cybersecurity, and Malware: A Shallow Report [Technical]"
    },
    "a20b51a4fc5dcd553cdbf79a863602c6": {
      "source_id": "a20b51a4fc5dcd553cdbf79a863602c6",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 612,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What are the biggest obstacles on AI safety research career?"
    },
    "f04bf64b3fb1b2d7e1d876949b696ae7": {
      "source_id": "f04bf64b3fb1b2d7e1d876949b696ae7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4943,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Manifund x AI Worldviews"
    },
    "41701403ec7660ad2d585d81db453ddc": {
      "source_id": "41701403ec7660ad2d585d81db453ddc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2934,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Keep Making AI Safety News"
    },
    "70537846b0752e38e226ef6f3ea89bf3": {
      "source_id": "70537846b0752e38e226ef6f3ea89bf3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22751,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Human Values and AGI Risk | William James"
    },
    "3d8b9c7442573fdd8fcaa9efa9b78c2a": {
      "source_id": "3d8b9c7442573fdd8fcaa9efa9b78c2a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2431,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Seeking advice on impactful career paths given my unique capabilities and intere"
    },
    "7d3b84207d48afade0dd659dccde7a5c": {
      "source_id": "7d3b84207d48afade0dd659dccde7a5c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7461,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\u0393\u03b1\u03bc\u03b9\u03bd\u03b3\u03ba the Algorithms: Large Language Models as Mirrors"
    },
    "f0d1bddba1701c231825a43b4cae7919": {
      "source_id": "f0d1bddba1701c231825a43b4cae7919",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14204,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Pillars to Convergence"
    },
    "02b6c19513827d14a76d32782403d112": {
      "source_id": "02b6c19513827d14a76d32782403d112",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3222,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Vael Gates: Risks from Highly-Capable AI (March 2023)"
    },
    "8b750ced53b7a31012e50030f767cfcf": {
      "source_id": "8b750ced53b7a31012e50030f767cfcf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 66623,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Pessimism about AI Safety"
    },
    "b59029042f6d457b513c575d1257ec5d": {
      "source_id": "b59029042f6d457b513c575d1257ec5d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15004,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Research Summary: Forecasting with Large Language Models"
    },
    "446a7dfb1bc301dc42970695ef9680e8": {
      "source_id": "446a7dfb1bc301dc42970695ef9680e8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3020,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Platform for Project Spitballing? (e.g., for AI field building)"
    },
    "80042018770d05913b11b8016e14f0f2": {
      "source_id": "80042018770d05913b11b8016e14f0f2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11401,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Reducing profit motivations in AI development"
    },
    "554f66b98dde048abe1de252c16cca4f": {
      "source_id": "554f66b98dde048abe1de252c16cca4f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1092,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Apply to the Cavendish Labs Fellowship (by 4/15)"
    },
    "c0e42fe2029f17703d4419304218687c": {
      "source_id": "c0e42fe2029f17703d4419304218687c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 547,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why might AI be a x-risk? Succinct explanations please"
    },
    "9173ba80f0aeb22a35efbc71d627116d": {
      "source_id": "9173ba80f0aeb22a35efbc71d627116d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9389,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Keep Chasing AI Safety Press Coverage"
    },
    "25f6a930323e0dda6b56f4b3b1368198": {
      "source_id": "25f6a930323e0dda6b56f4b3b1368198",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17119,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Orthogonality Thesis is Not Obviously True "
    },
    "74fd59104ccbc62373244b833bac5870": {
      "source_id": "74fd59104ccbc62373244b833bac5870",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2421,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What to suggest companies & entrepreneurs do to use AI safely?"
    },
    "9a103121a1330127df147bf81375b18f": {
      "source_id": "9a103121a1330127df147bf81375b18f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1364,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Debates on reducing long-term s-risks?"
    },
    "0f2f64e2070a66dc5d9c5577762fab5d": {
      "source_id": "0f2f64e2070a66dc5d9c5577762fab5d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2719,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISafety.world is a map of the AIS ecosystem"
    },
    "a9a9682c550eae8d7e3d5e7f92a2b503": {
      "source_id": "a9a9682c550eae8d7e3d5e7f92a2b503",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9289,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is it time for a pause?"
    },
    "3cbbd0e6b2020a1c2cec8bb5756ee0be": {
      "source_id": "3cbbd0e6b2020a1c2cec8bb5756ee0be",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11521,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Some Preliminary Opinions on AI Safety Problems"
    },
    "9ab87336125155a08677e62d1349df5f": {
      "source_id": "9ab87336125155a08677e62d1349df5f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 586,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Imagine AGI killed us all in three years. What would have been our biggest mista"
    },
    "06470a1138029c048dfc21959ef2ef1e": {
      "source_id": "06470a1138029c048dfc21959ef2ef1e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2972,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How much should states invest in contingency plans for widespread internet outag"
    },
    "7d5a429f7978e5aa6f50e89b8ad620f7": {
      "source_id": "7d5a429f7978e5aa6f50e89b8ad620f7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1372,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An 'AGI Emergency Eject Criteria' consensus could be really useful."
    },
    "996bda9c00c05d10650ba9e31985feb7": {
      "source_id": "996bda9c00c05d10650ba9e31985feb7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 237779,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Podcast/video/transcript: Eliezer Yudkowsky - Why AI Will Kill Us, Aligning LLMs"
    },
    "047223b78aa85d286df8ca7edd7d4789": {
      "source_id": "047223b78aa85d286df8ca7edd7d4789",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10189,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Current UK government levers on AI development"
    },
    "8da68df98b971609f0b5b7d8f03794bc": {
      "source_id": "8da68df98b971609f0b5b7d8f03794bc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35482,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Four mindset disagreements behind existential risk disagreements in ML"
    },
    "41fa465d91e2c6755fb85a714dca9ead": {
      "source_id": "41fa465d91e2c6755fb85a714dca9ead",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1692,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Existential risk x Crypto: An unconference at Zuzalu"
    },
    "ed00047ae4b26a04d87cf03aa9b18b04": {
      "source_id": "ed00047ae4b26a04d87cf03aa9b18b04",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3999,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Paleontological study of extinctions supports AI as a existential threat to huma"
    },
    "47deb9bf8e6f3d3ac958301003e9d082": {
      "source_id": "47deb9bf8e6f3d3ac958301003e9d082",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15629,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[MLSN #9] Verifying large training runs, security risks from LLM access to APIs,"
    },
    "ae3fe0d0d9e031db9a0df24ab292f390": {
      "source_id": "ae3fe0d0d9e031db9a0df24ab292f390",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16883,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Preliminary investigations on if STEM and EA communities could benefit from more"
    },
    "cef1080169e3fd34e1167e6ceff8d18f": {
      "source_id": "cef1080169e3fd34e1167e6ceff8d18f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42882,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Data Taxation: A Proposal for Slowing Down AGI Progress"
    },
    "a6e74b053b7c9b4a823a01c56f8c7cb9": {
      "source_id": "a6e74b053b7c9b4a823a01c56f8c7cb9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 853,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Risk US Presidental Candidate"
    },
    "ebad0d6c9a6cf2f187032d0327fd7366": {
      "source_id": "ebad0d6c9a6cf2f187032d0327fd7366",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30069,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Navigating the Open-Source AI Landscape: Data, Funding, and Safety"
    },
    "96bb1cf09a93ee41d0d7aabe12890efa": {
      "source_id": "96bb1cf09a93ee41d0d7aabe12890efa",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8166,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AIs accelerating AI research"
    },
    "8fc570a2891a344bca47a5f27e931d55": {
      "source_id": "8fc570a2891a344bca47a5f27e931d55",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13761,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Artificial Intelligence as exit strategy from the age of acute existential risk"
    },
    "1fc610bb3ac586c24b19e53bac353faa": {
      "source_id": "1fc610bb3ac586c24b19e53bac353faa",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 3249,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[linkpost] AI NOW Institute's 2023 Annual Report & Roadmap"
    },
    "b92ab9ddea1dec0d72852f78e5a98549": {
      "source_id": "b92ab9ddea1dec0d72852f78e5a98549",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4821,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Apply to >50 AI safety funders in one application with the Nonlinear Network [Ro"
    },
    "bf72c7081e396d658ce24aa2facb0723": {
      "source_id": "bf72c7081e396d658ce24aa2facb0723",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2216,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AGI - alignment - paperclip maximizer - pause - defection - incentives"
    },
    "92cf10f95f846c95cdf1da5fb5fafdef": {
      "source_id": "92cf10f95f846c95cdf1da5fb5fafdef",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2557,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[US] NTIA: AI Accountability Policy Request for Comment"
    },
    "cbde7b6fe343a299b083feb377d38c57": {
      "source_id": "cbde7b6fe343a299b083feb377d38c57",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11743,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A freshman year during the AI midgame: my approach to the next year"
    },
    "50e66097a737fa60ed4be7ae738dc470": {
      "source_id": "50e66097a737fa60ed4be7ae738dc470",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 65679,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] The A.I. Dilemma - March 9, 2023, with Tristan Harris and Aza Raskin"
    },
    "af11f630816094f7b389506cca1f0220": {
      "source_id": "af11f630816094f7b389506cca1f0220",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25451,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\"Risk Awareness Moments\" (Rams): A concept for thinking about AI governance inte"
    },
    "8e944f753f71bedbbdf21a2a0048ec90": {
      "source_id": "8e944f753f71bedbbdf21a2a0048ec90",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 66584,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Prospects for AI safety agreements between countries"
    },
    "962f4128c9e46d612d9ec76b225de0b9": {
      "source_id": "962f4128c9e46d612d9ec76b225de0b9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 612,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Who is testing AI Safety public outreach messaging?"
    },
    "aa951e3041b28a24a6e5db974faf60ff": {
      "source_id": "aa951e3041b28a24a6e5db974faf60ff",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 579,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Brain-computer interfaces and brain organoids in AI alignment?"
    },
    "332844ece471aca6ffeb9435d57af0ce": {
      "source_id": "332844ece471aca6ffeb9435d57af0ce",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7525,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Summary: The Case for Halting AI Development - Max Tegmark on the Lex Fridman Po"
    },
    "13c93201bb3cad43b8a23fa7fbb6667e": {
      "source_id": "13c93201bb3cad43b8a23fa7fbb6667e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7919,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Geoffrey Miller on Cross-Cultural Understanding Between China and Western Countr"
    },
    "8ac41166e253bc717e55785e9c83c2c9": {
      "source_id": "8ac41166e253bc717e55785e9c83c2c9",
      "quality_score": 2.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 8837,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Impacts Quarterly Newsletter, Jan-Mar 2023"
    },
    "f25f951b9b234fa286ea99ddae9845a2": {
      "source_id": "f25f951b9b234fa286ea99ddae9845a2",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 976,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] AI Alignment, Explained in 5 Points (updated)"
    },
    "991b0dbe679808c4e3f4de7ec9e57b18": {
      "source_id": "991b0dbe679808c4e3f4de7ec9e57b18",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4356,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What can we do now to prepare for AI sentience, in order to protect them from th"
    },
    "f834bd27906af35680128b3415d5b1c1": {
      "source_id": "f834bd27906af35680128b3415d5b1c1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5816,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Risk of AI deceleration."
    },
    "87c299795b3d3790b32eab9c42ab8ecb": {
      "source_id": "87c299795b3d3790b32eab9c42ab8ecb",
      "quality_score": 2.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 9118,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Newsletter #2: ChaosGPT, Natural Selection, and AI Safety in the Media"
    },
    "a7d75f8ced35b65e5ae94f917820dd78": {
      "source_id": "a7d75f8ced35b65e5ae94f917820dd78",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8215,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Organizing a debate with experts and MPs to raise AI xrisk awareness: a possible"
    },
    "4a9cf1df3ed684c2c5bf72d2901c6af6": {
      "source_id": "4a9cf1df3ed684c2c5bf72d2901c6af6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14586,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "12 tentative ideas for US AI policy (Luke Muehlhauser)"
    },
    "c89980d56dd74f786ac61588cb6ff2d9": {
      "source_id": "c89980d56dd74f786ac61588cb6ff2d9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 728,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "'AI Emergency Eject Criteria' Survey"
    },
    "b50444cb80a28f5700a738a155a6c375": {
      "source_id": "b50444cb80a28f5700a738a155a6c375",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1635,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Reasons to have hope"
    },
    "b682b03d4cc3f6712b685fa589fdc406": {
      "source_id": "b682b03d4cc3f6712b685fa589fdc406",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 849,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Bio-risk and AI: AI progress might soon lead to much faster research and enginee"
    },
    "59969d3fafca318414900906927d48d1": {
      "source_id": "59969d3fafca318414900906927d48d1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5232,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "OPEC for a slow AGI takeoff"
    },
    "68155fd44f7feb998fd6a4830024612a": {
      "source_id": "68155fd44f7feb998fd6a4830024612a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1809,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "If your AGI x-risk estimates are low, what scenarios make up the bulk of your ex"
    },
    "65b251c269f75b3f8353b754ad68fe79": {
      "source_id": "65b251c269f75b3f8353b754ad68fe79",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3943,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Progress: The Game Show"
    },
    "e2b17706a66aadd790b8e268e2e3ceee": {
      "source_id": "e2b17706a66aadd790b8e268e2e3ceee",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3134,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\"Who Will You Be After ChatGPT Takes Your Job?\""
    },
    "dcfda9f6730a2982691ae667fa2d237e": {
      "source_id": "dcfda9f6730a2982691ae667fa2d237e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2725,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "PhD Position: AI Interpretability in Berlin, Germany"
    },
    "5d3ef7efef1f147879d78575586747b2": {
      "source_id": "5d3ef7efef1f147879d78575586747b2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1457,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A great talk for AI noobs (according to an AI noob)"
    },
    "bad0e354d485456783e34673008049eb": {
      "source_id": "bad0e354d485456783e34673008049eb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43039,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Preventing AI Misuse: State of the Art Research and its Flaws"
    },
    "47a008ee8ffd36402d5ade7b530fec21": {
      "source_id": "47a008ee8ffd36402d5ade7b530fec21",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1972,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "X-Risk Researchers Survey "
    },
    "006df7a0ee5ba617420306ba25272a54": {
      "source_id": "006df7a0ee5ba617420306ba25272a54",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14235,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "No, the EMH does not imply that markets have long AGI timelines"
    },
    "61604b44b2afac7d0a578fce32f1110c": {
      "source_id": "61604b44b2afac7d0a578fce32f1110c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3788,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "FT: We must slow down the race to God-like AI"
    },
    "a01978d301f6f66d46a027007cb23b40": {
      "source_id": "a01978d301f6f66d46a027007cb23b40",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7172,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Case For Civil Disobedience For The AI Movement"
    },
    "bd1e35b8ee6970ab03262bf08d765c22": {
      "source_id": "bd1e35b8ee6970ab03262bf08d765c22",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3310,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Student competition for drafting a treaty on moratorium of large-scale AI capabi"
    },
    "1e56ad4d0de7201aef733cb34340d208": {
      "source_id": "1e56ad4d0de7201aef733cb34340d208",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1031,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "UK Government announces \u00a3100 million in funding for Foundation Model Taskforce."
    },
    "894d68979ecb67f926ea0688832bf629": {
      "source_id": "894d68979ecb67f926ea0688832bf629",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 10976,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Newsletter #3: AI policy proposals and a new challenger approaches"
    },
    "539f24ad9be4c3b200055a561134f0a8": {
      "source_id": "539f24ad9be4c3b200055a561134f0a8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2766,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is China Becoming a Science and Technology Superpower? Jeffrey Ding's Insight on"
    },
    "9fd111c184c5d404d5205223acac2912": {
      "source_id": "9fd111c184c5d404d5205223acac2912",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22500,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Archetypal Transfer Learning: a Proposed Alignment Solution that solves the Inne"
    },
    "1503866b631a1866b8ab1c4022617458": {
      "source_id": "1503866b631a1866b8ab1c4022617458",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1881,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Join a \u2018learning by writing' group"
    },
    "0567a16707aafb49f4c7dfdc545c1196": {
      "source_id": "0567a16707aafb49f4c7dfdc545c1196",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 600,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is there EA discussion on non-x-risk transformative AI?"
    },
    "25e907cba40c4ca9f4bf95c9130ecdea": {
      "source_id": "25e907cba40c4ca9f4bf95c9130ecdea",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1163,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How come there isn't that much focus in EA on research into whether / when AI's "
    },
    "c619ff3ab07b7cf05bd579fd3edc24fc": {
      "source_id": "c619ff3ab07b7cf05bd579fd3edc24fc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28052,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Proposals for the AI Regulatory Sandbox in Spain"
    },
    "693b177d9a49b3baf3203f96ab53cb33": {
      "source_id": "693b177d9a49b3baf3203f96ab53cb33",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56761,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The AI guide I'm sending my grandparents"
    },
    "5c2915e9ae7f3e9ca322c3696f6c3629": {
      "source_id": "5c2915e9ae7f3e9ca322c3696f6c3629",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2955,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI safety logo design contest, due end of May (extended)"
    },
    "6d2ed6e34e20879a769a52aa54c02c8d": {
      "source_id": "6d2ed6e34e20879a769a52aa54c02c8d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6284,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "New open letter on AI \u2014 \"Include Consciousness Research\""
    },
    "553047070d7320ab68d168e08d53fb4d": {
      "source_id": "553047070d7320ab68d168e08d53fb4d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11003,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A Guide to Forecasting AI Science Capabilities"
    },
    "84ab86e7fb59763c5d1739bc272bd054": {
      "source_id": "84ab86e7fb59763c5d1739bc272bd054",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11655,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Discussion about AI Safety funding (FB transcript)"
    },
    "0dc93fe2c71e4e57ea89c24c6c6e1528": {
      "source_id": "0dc93fe2c71e4e57ea89c24c6c6e1528",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6042,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "My current take on existential AI risk [FB post]"
    },
    "28569850cdc23d218a39ceff54aa4bb4": {
      "source_id": "28569850cdc23d218a39ceff54aa4bb4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 11319,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "List of AI safety newsletters and other resources"
    },
    "451b969cde248da685dfe0a4131719ae": {
      "source_id": "451b969cde248da685dfe0a4131719ae",
      "quality_score": 2.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 5382,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] \u2018The Godfather of A.I.\u2019 Leaves Google and Warns of Danger Ahead"
    },
    "2c64003ce7dac5e11e94e5744a74ab81": {
      "source_id": "2c64003ce7dac5e11e94e5744a74ab81",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7279,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The costs of caution"
    },
    "e85293d2afd98e69e243db5b6b6e6a5d": {
      "source_id": "e85293d2afd98e69e243db5b6b6e6a5d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 674,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Call for Pythia-style foundation model suite for alignment research"
    },
    "6b57d9df670de208d7d3db3f6096e01a": {
      "source_id": "6b57d9df670de208d7d3db3f6096e01a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32383,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Exploring Metaculus\u2019s AI Track Record"
    },
    "4ca031244ac960cf3c1ac6122d510211": {
      "source_id": "4ca031244ac960cf3c1ac6122d510211",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2544,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Owain Evans on LLMs, Truthful AI, AI Composition, and More"
    },
    "05e9e643af145373a4453278c557af12": {
      "source_id": "05e9e643af145373a4453278c557af12",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58134,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AGI rising: why we are in a new era of acute risk and increasing public awarenes"
    },
    "8c66a0f98a3f1b1c487d50f71480e191": {
      "source_id": "8c66a0f98a3f1b1c487d50f71480e191",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15338,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "P(doom|AGI) is high: why the default outcome of AGI is doom"
    },
    "d24e8881c3cb642ccee8fdb5ca8685a8": {
      "source_id": "d24e8881c3cb642ccee8fdb5ca8685a8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34901,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Simulating a possible alignment solution in GPT2-medium using Archetypal Transfe"
    },
    "e5570ccd5cb7d672c0d5d7651e6a2042": {
      "source_id": "e5570ccd5cb7d672c0d5d7651e6a2042",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 15123,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Newsletter #4: AI and Cybersecurity, Persuasive AIs, Weaponization, an"
    },
    "88165f9767266cb3f99af112dafff6e2": {
      "source_id": "88165f9767266cb3f99af112dafff6e2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 746,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "My choice of AI misalignment introduction for a general audience"
    },
    "dfb45342f85bbed44db35e13d73d59a9": {
      "source_id": "dfb45342f85bbed44db35e13d73d59a9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34405,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How CISA can Support the Security of Large AI Models Against Theft [Grad School "
    },
    "70fb93d8d6814211cbf88171f025bdd8": {
      "source_id": "70fb93d8d6814211cbf88171f025bdd8",
      "quality_score": 2.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 5349,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Link Post: New York Times] White House Unveils Initiatives to Reduce Risks of A"
    },
    "ee3d14af3f1d67c6d86b1d2e1fdc1d7a": {
      "source_id": "ee3d14af3f1d67c6d86b1d2e1fdc1d7a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20907,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI X-risk in the News: How Effective are Recent Media Items and How is Awareness"
    },
    "8af9342c6651be0b47b7b6b71d4f3b31": {
      "source_id": "8af9342c6651be0b47b7b6b71d4f3b31",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3306,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Most Leading AI Experts Believe That Advanced AI Could Be Extremely Dangerous to"
    },
    "b91a8a9fff0fdce5773d0cb805ae2e3a": {
      "source_id": "b91a8a9fff0fdce5773d0cb805ae2e3a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25571,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI risk/reward: A simple model"
    },
    "c4b0215bf5c455f49c31f361b97a439c": {
      "source_id": "c4b0215bf5c455f49c31f361b97a439c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3465,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An Update On The Campaign For AI Safety Dot Org"
    },
    "454a10fbaf6fb415c4175eae36a52d00": {
      "source_id": "454a10fbaf6fb415c4175eae36a52d00",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5422,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Intro to ML Safety virtual program:  12 June - 14 August"
    },
    "6ff55c4ad9a88e17f6b37d763809b7b2": {
      "source_id": "6ff55c4ad9a88e17f6b37d763809b7b2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17652,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Introducing the AI Objectives Institute's Research: Differential Paths toward Sa"
    },
    "39d0cd1eb9f0a6f78a67b35d1886d9ca": {
      "source_id": "39d0cd1eb9f0a6f78a67b35d1886d9ca",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2326,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Graphical Representations of Paul Christiano's Doom Model"
    },
    "35ab10904f2bf8ae0369889a87f2dfda": {
      "source_id": "35ab10904f2bf8ae0369889a87f2dfda",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15915,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Implications of the Whitehouse meeting with AI CEOs for AI superintelligence ris"
    },
    "aaefcb3b9be635c898edb593de73ff3f": {
      "source_id": "aaefcb3b9be635c898edb593de73ff3f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12870,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Unveiling the American Public Opinion on AI Moratorium and Government Interventi"
    },
    "6c5c6a676fd647c671f8d327a74c2043": {
      "source_id": "6c5c6a676fd647c671f8d327a74c2043",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15214,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How  \"AGI\" could end up being many different specialized AI's stitched together"
    },
    "5c155ca3bd899b83001c59a5a8d373a7": {
      "source_id": "5c155ca3bd899b83001c59a5a8d373a7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28288,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How quickly AI could transform the world (Tom Davidson on The 80,000 Hours Podca"
    },
    "0b76a03944e3ed5e85756a1e3bf8e56a": {
      "source_id": "0b76a03944e3ed5e85756a1e3bf8e56a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 801,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Reminder: AI Worldviews Contest Closes May 31"
    },
    "eaaa70d4eb311a31abf738f28ce72e08": {
      "source_id": "eaaa70d4eb311a31abf738f28ce72e08",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73523,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Predictable updating about AI risk"
    },
    "088cdae61422333453f3d1f69f34ded8": {
      "source_id": "088cdae61422333453f3d1f69f34ded8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12902,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Chilean AIS Hackathon Retrospective"
    },
    "10e4dd3cbafeb2e893331ddf86897e91": {
      "source_id": "10e4dd3cbafeb2e893331ddf86897e91",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3285,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A note of caution on believing things on a gut level"
    },
    "79e13add93fbeff3c4ece9ed902ed17e": {
      "source_id": "79e13add93fbeff3c4ece9ed902ed17e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3081,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Stampy's AI Safety Info - New Distillations #2 [April 2023]"
    },
    "4415a6ce401f8c2fbeec0ccee77be218": {
      "source_id": "4415a6ce401f8c2fbeec0ccee77be218",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 10920,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Newsletter #5: Geoffrey Hinton speaks out on AI risk, the White House "
    },
    "fc961cc39daca8b5ff18639d49e75226": {
      "source_id": "fc961cc39daca8b5ff18639d49e75226",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23660,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why \"just make an agent which cares only about binary rewards\" doesn't work."
    },
    "7faddd0e31fbae77baf0132a2fedb2bb": {
      "source_id": "7faddd0e31fbae77baf0132a2fedb2bb",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4645,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing \u201cKey Phenomena in AI Risk\u201d (facilitated reading group)"
    },
    "aa290acf1a526425023757298c1bd3a4": {
      "source_id": "aa290acf1a526425023757298c1bd3a4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2144,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Crises Reveal Centralisation (Stefan Schubert)"
    },
    "b6e8075fa75509cb378790a0b6a08c7d": {
      "source_id": "b6e8075fa75509cb378790a0b6a08c7d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8791,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Continuous doesn\u2019t mean slow"
    },
    "6c65690a67b0336e538b9138905841e6": {
      "source_id": "6c65690a67b0336e538b9138905841e6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12278,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "You don't need to be a genius to be in AI safety research"
    },
    "2a9624909d5cb6a937cf7f38ee655f84": {
      "source_id": "2a9624909d5cb6a937cf7f38ee655f84",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1678,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A request to keep pessimistic AI posts actionable."
    },
    "66ac23b23207cb3596658ec12cdb89f8": {
      "source_id": "66ac23b23207cb3596658ec12cdb89f8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28604,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Alignment, Goals, & The Gut-Head Gap: A Review of Ngo. et al"
    },
    "4b3909d82c41706c7e751282d46966ef": {
      "source_id": "4b3909d82c41706c7e751282d46966ef",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34951,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "US public opinion of AI policy and risk"
    },
    "039bfd975df920553329400061657127": {
      "source_id": "039bfd975df920553329400061657127",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50829,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A Study of AI Science Models "
    },
    "a7e11e41991dea1d2e8a856b38382902": {
      "source_id": "a7e11e41991dea1d2e8a856b38382902",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7792,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Are there enough opportunities for AI safety specialists?"
    },
    "a32366986cbae665f9e3d6cdddc29ab9": {
      "source_id": "a32366986cbae665f9e3d6cdddc29ab9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4467,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "CEA Should Invest in Helping Altruists Navigate Advanced AI"
    },
    "c7281152ee9bc22d9e15b59a321de55d": {
      "source_id": "c7281152ee9bc22d9e15b59a321de55d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6025,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI policy & governance in Australia: notes from an initial discussion"
    },
    "5a61f93569b878d5ccb9877c8b3afbb8": {
      "source_id": "5a61f93569b878d5ccb9877c8b3afbb8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10037,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "EA and AI Safety Schism: AGI, the last tech humans will (soon*) build"
    },
    "1ea1bb5c42abf4569be1564c8f351954": {
      "source_id": "1ea1bb5c42abf4569be1564c8f351954",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31257,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Accidentally teaching AI models to deceive us (Ajeya Cotra on The 80,000 Hours P"
    },
    "c01e92a9c4a65714e48ca2e3dddbeced": {
      "source_id": "c01e92a9c4a65714e48ca2e3dddbeced",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19586,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Risk & Policy Forecasts from Metaculus & FLI's AI Pathways Workshop"
    },
    "1b63ce0c7e5a524f0fd5ca6b5c462748": {
      "source_id": "1b63ce0c7e5a524f0fd5ca6b5c462748",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 14430,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Newsletter #6: Examples of AI safety progress, Yoshua Bengio proposes "
    },
    "600307d5c3d1eebd42dcb04bc4476040": {
      "source_id": "600307d5c3d1eebd42dcb04bc4476040",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27272,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why AGI systems will not be fanatical maximisers (unless trained by fanatical hu"
    },
    "6ee1afd7440fef8af3ed46cf1d9ba4c3": {
      "source_id": "6ee1afd7440fef8af3ed46cf1d9ba4c3",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7528,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Some quotes from Tuesday's Senate hearing on AI"
    },
    "4df200cd10bb1c17a9fc81cc260d76f3": {
      "source_id": "4df200cd10bb1c17a9fc81cc260d76f3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20479,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Lessons\u00a0on project management from \u201cHow Big Things Get Done\u201d"
    },
    "4e524770f6f4f776fb29cd515278b4a0": {
      "source_id": "4e524770f6f4f776fb29cd515278b4a0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1689,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Alignment in The New Yorker "
    },
    "24aaa1ed6cc583e652b04b307b334805": {
      "source_id": "24aaa1ed6cc583e652b04b307b334805",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50097,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A recent write-up of the case for AI (existential) risk"
    },
    "c63653bdbcfa79dbdf1c963b6b07ec7b": {
      "source_id": "c63653bdbcfa79dbdf1c963b6b07ec7b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 928,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Thread: Reflections on the AGI Safety Fundamentals course?"
    },
    "cde8e9fd356a713100a1fe2b10220fce": {
      "source_id": "cde8e9fd356a713100a1fe2b10220fce",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47409,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\u201cThe Race to the End of Humanity\u201d \u2013 Structural Uncertainty Analysis in AI Risk M"
    },
    "cf13b2b9f2275c1318247ccd85852712": {
      "source_id": "cf13b2b9f2275c1318247ccd85852712",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1894,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Effective Altruism Florida's AI Expert Panel - Recording and Slides Available "
    },
    "58becf231d81cedfd92be1ec453835b8": {
      "source_id": "58becf231d81cedfd92be1ec453835b8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 631,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Former Israeli Prime Minister Speaks About AI X-Risk"
    },
    "2c4a4ef5f8298fb26e1915c925deb01a": {
      "source_id": "2c4a4ef5f8298fb26e1915c925deb01a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1801,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI strategy career pipeline"
    },
    "d3e459c9ddb898600e3fef406cad9fc7": {
      "source_id": "d3e459c9ddb898600e3fef406cad9fc7",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 2987,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] \"Governance of superintelligence\" by OpenAI"
    },
    "724d66c17910d05b52d3dcef2c302e22": {
      "source_id": "724d66c17910d05b52d3dcef2c302e22",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35770,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How I learned to stop worrying and love skill trees"
    },
    "723034e358f3c1899093ab22436191d3": {
      "source_id": "723034e358f3c1899093ab22436191d3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54182,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Some governance research ideas to prevent malevolent control over AGI and why th"
    },
    "b8242f9fb94092d5f10cfe6faae90338": {
      "source_id": "b8242f9fb94092d5f10cfe6faae90338",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17340,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A Different Approach to Community Building: The Spiral Path to Impact "
    },
    "fa2e9759f863a63844ad2dab8005599e": {
      "source_id": "fa2e9759f863a63844ad2dab8005599e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 16883,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Newsletter #7: Disinformation, Governance Recommendations for AI labs,"
    },
    "b33f9c9dcaacfa65fa88060d27dd0aaa": {
      "source_id": "b33f9c9dcaacfa65fa88060d27dd0aaa",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16866,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "October 2022 AI Risk Community Survey Results"
    },
    "ea1b22e5d4ce6a9fd5f7f7bfd71b2dee": {
      "source_id": "ea1b22e5d4ce6a9fd5f7f7bfd71b2dee",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12661,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AGI Catastrophe and Takeover: Some Reference Class-Based Priors"
    },
    "c47f9c87b2dcfc697e38ecb7087454ed": {
      "source_id": "c47f9c87b2dcfc697e38ecb7087454ed",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13858,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Diagram with Commentary for AGI as an X-Risk"
    },
    "acd6029ca8d0d05ed6487eea02bc1521": {
      "source_id": "acd6029ca8d0d05ed6487eea02bc1521",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 1010,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] OpenAI leaders call for regulation of \"superintelligence\" to reduce e"
    },
    "56ddd7970a0506eaa4c26efc63a0dab2": {
      "source_id": "56ddd7970a0506eaa4c26efc63a0dab2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37164,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Will AI end everything? A guide to guessing | EAG Bay Area 23"
    },
    "e583b787083da2ac997c7f25ebd4e6a5": {
      "source_id": "e583b787083da2ac997c7f25ebd4e6a5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15165,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Job Ad] SERI MATS is hiring for our summer program"
    },
    "70f5457975d063d316d36b419af889e1": {
      "source_id": "70f5457975d063d316d36b419af889e1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50056,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Bandgaps, Brains, and Bioweapons: The limitations of computational science and w"
    },
    "1255558dcffce6908b0b4cff2c4b0929": {
      "source_id": "1255558dcffce6908b0b4cff2c4b0929",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36973,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Biomimetic alignment:  Alignment between animal genes and animal brains as a mod"
    },
    "4c210f0db8d6ceb8e57a65b723e5c795": {
      "source_id": "4c210f0db8d6ceb8e57a65b723e5c795",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18084,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "By failing to take serious AI action, the US could be in violation of its intern"
    },
    "eea465a53b3303ad51d8deca3cdfd324": {
      "source_id": "eea465a53b3303ad51d8deca3cdfd324",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 1540,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] Longtermists Are Pushing a New Cold War With China"
    },
    "9887484a5fe0ccd8018f0ee950de0506": {
      "source_id": "9887484a5fe0ccd8018f0ee950de0506",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26071,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Diminishing Returns in Machine Learning Part 1: Hardware Development and the Phy"
    },
    "7ebd7d8ae28cff4d2c157ff00b548c39": {
      "source_id": "7ebd7d8ae28cff4d2c157ff00b548c39",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29842,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Status Quo Engines - AI essay"
    },
    "434f8634ecfad3b1a6c81ac75ed774fc": {
      "source_id": "434f8634ecfad3b1a6c81ac75ed774fc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52335,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Language Agents Reduce the Risk of Existential Catastrophe"
    },
    "34beac39f8daca86244fede8948aca47": {
      "source_id": "34beac39f8daca86244fede8948aca47",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 975,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Statement on AI Extinction - Signed by AGI Labs, Top Academics, and Many Other N"
    },
    "ade7a5555a9bc4dd8b8cdabb194702e8": {
      "source_id": "ade7a5555a9bc4dd8b8cdabb194702e8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 15514,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Newsletter #8: Rogue AIs, how to screen for AI risks, and grants for r"
    },
    "b432074848d0607f47101b12bee515c6": {
      "source_id": "b432074848d0607f47101b12bee515c6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30188,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The bullseye framework: My case against AI doom"
    },
    "27bf40314b5e10ded77c741a5cdbbbfd": {
      "source_id": "27bf40314b5e10ded77c741a5cdbbbfd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13767,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Case for AI Adaptation: The Perils of Living in a World with Aligned and Wel"
    },
    "59ed8c3378467e15ae5395c4488985e7": {
      "source_id": "59ed8c3378467e15ae5395c4488985e7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42211,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Implications of AGI on Subjective Human Experience"
    },
    "90a7357516f251f1790ae4653514717a": {
      "source_id": "90a7357516f251f1790ae4653514717a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24428,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Doom and David Hume: A Defence of Empiricism in AI Safety"
    },
    "6586690f6c4f8a2f579063d0b572b694": {
      "source_id": "6586690f6c4f8a2f579063d0b572b694",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16112,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Exponential AI takeoff is a myth"
    },
    "779c3c53a96dd5d18c17085a6351e1ce": {
      "source_id": "779c3c53a96dd5d18c17085a6351e1ce",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7611,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The EU AI Act needs a definition of high-risk foundation models to avoid regulat"
    },
    "37ad2ed56ea3677dffcc2794bc550f8a": {
      "source_id": "37ad2ed56ea3677dffcc2794bc550f8a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27762,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A moral backlash against AI will probably slow down AGI development"
    },
    "0ddab547b6a30d9bbe096ea070bf0603": {
      "source_id": "0ddab547b6a30d9bbe096ea070bf0603",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 67028,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A compute-based framework for thinking about the future of AI"
    },
    "6cacf7093c9c9cd45af6a93345569c6f": {
      "source_id": "6cacf7093c9c9cd45af6a93345569c6f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25644,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Primitive Global Discourse Framework, Constitutional AI using legal frameworks, "
    },
    "9ffc0375f66dd64358d809685408db3d": {
      "source_id": "9ffc0375f66dd64358d809685408db3d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6278,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Update from Campaign for AI Safety"
    },
    "954503eb969b2c6491b69391b9cbea47": {
      "source_id": "954503eb969b2c6491b69391b9cbea47",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39690,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Safe AI and moral AI"
    },
    "ae9f2095aec5b0ddc4c0e9c3706b112e": {
      "source_id": "ae9f2095aec5b0ddc4c0e9c3706b112e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21049,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Catastrophic Risks from Unsafe AI: Navigating a Tightrope Scenario (Ben Garfinke"
    },
    "fb6442d614ed3fc76f202d107aec8b0d": {
      "source_id": "fb6442d614ed3fc76f202d107aec8b0d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7848,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Some thoughts on \"AI could defeat all of us combined\""
    },
    "2bb443a42caf659a6dfa49658f717af8": {
      "source_id": "2bb443a42caf659a6dfa49658f717af8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4898,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Applications open for AI Safety Fundamentals: Governance Course"
    },
    "61f8ad08e4bab11f5e1c9c8fcc4719ed": {
      "source_id": "61f8ad08e4bab11f5e1c9c8fcc4719ed",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25060,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Intrinsic limitations of GPT-4 and other large language models, and why I'm not "
    },
    "1fb4af16d3f00eb788789a20b1bd879b": {
      "source_id": "1fb4af16d3f00eb788789a20b1bd879b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25530,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "From voluntary to mandatory, are the ESG disclosure frameworks still fertile gro"
    },
    "11ffbe2040c633167bc33aa0771e1b91": {
      "source_id": "11ffbe2040c633167bc33aa0771e1b91",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27158,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Decomposing alignment to take advantage of paradigms"
    },
    "a335a81c14dd81e283a98409f0fec028": {
      "source_id": "a335a81c14dd81e283a98409f0fec028",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1203,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Fundamentals: An Informal Cohort Starting Soon! (cross-posted to lessw"
    },
    "93cd17f8c29da386f4ad450aa3033aaa": {
      "source_id": "93cd17f8c29da386f4ad450aa3033aaa",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4015,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Stampy's AI Safety Info - New Distillations #3 [May 2023]"
    },
    "776b7d7dc2165f4a9952ab1b5edd47bf": {
      "source_id": "776b7d7dc2165f4a9952ab1b5edd47bf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19711,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISN #9: Statement on Extinction Risks, Competitive Pressures, and When Will AI "
    },
    "b804c56a98967cf263cd368bff1ad197": {
      "source_id": "b804c56a98967cf263cd368bff1ad197",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38079,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "US Policy Career Resources"
    },
    "fdb8d87e65318128a9b4647441a0cd77": {
      "source_id": "fdb8d87e65318128a9b4647441a0cd77",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19517,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Rethink Priorities is hiring a Compute Governance Researcher or Research Assista"
    },
    "580e452f7f596c244ffd15c43bde332d": {
      "source_id": "580e452f7f596c244ffd15c43bde332d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2318,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Article Summary: Current and Near-Term AI as a Potential Existential Risk Factor"
    },
    "01d53ce1a0381ebcceae6033ca70d929": {
      "source_id": "01d53ce1a0381ebcceae6033ca70d929",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7852,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A note of caution about recent AI risk coverage"
    },
    "974eee80eb5c2e422946caca9bda47c7": {
      "source_id": "974eee80eb5c2e422946caca9bda47c7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12680,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Understanding how hard alignment is may be the most important research direction"
    },
    "d233b9eb2b651d6159bcc505a981b8ff": {
      "source_id": "d233b9eb2b651d6159bcc505a981b8ff",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58195,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The current alignment plan, and how we might improve it | EAG Bay Area 23"
    },
    "9cc42e6bc56156662ee6ee5bfc9c6e49": {
      "source_id": "9cc42e6bc56156662ee6ee5bfc9c6e49",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16402,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Beware popular discussions of AI \"sentience\""
    },
    "77ea4edd4890c3d088571b3e528c8d44": {
      "source_id": "77ea4edd4890c3d088571b3e528c8d44",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8980,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "UK government to host first global summit on AI Safety"
    },
    "bb770e5a7f08f72e1d61c4c407478755": {
      "source_id": "bb770e5a7f08f72e1d61c4c407478755",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5557,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Wild Animal Welfare Scenarios for AI Doom"
    },
    "238c0d32d335f962905041d9d5508e10": {
      "source_id": "238c0d32d335f962905041d9d5508e10",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16837,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A survey of concrete risks derived from Artificial Intelligence"
    },
    "81f9558c664009f31b623cc14e6b777b": {
      "source_id": "81f9558c664009f31b623cc14e6b777b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2145,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How does AI progress affect other EA cause areas?"
    },
    "cc6324064918370ff90dfb4d6078b491": {
      "source_id": "cc6324064918370ff90dfb4d6078b491",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4239,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcement: You can now listen to the \u201cAI Safety Fundamentals\u201d courses"
    },
    "11969221d5f9169a9fe7ce44f58a6f2a": {
      "source_id": "11969221d5f9169a9fe7ce44f58a6f2a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 87078,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Critiques of prominent AI safety labs: Conjecture"
    },
    "515284dc0036743a482170c489eacdfb": {
      "source_id": "515284dc0036743a482170c489eacdfb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26038,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "On DeepMind and Trying to Fairly Hear Out Both AI Doomers and Doubters (Rohin Sh"
    },
    "bab1581943c0d97f987f9a66be73bc99": {
      "source_id": "bab1581943c0d97f987f9a66be73bc99",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23410,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A Manifold Market \"Leaked\" the AI Extinction Statement and CAIS Wanted it Delete"
    },
    "542e9d747dc509e1f81cf42850dfb29f": {
      "source_id": "542e9d747dc509e1f81cf42850dfb29f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7963,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "ARC is hiring theoretical researchers"
    },
    "ffe5c7355b63abed4436d9510d8b8ac5": {
      "source_id": "ffe5c7355b63abed4436d9510d8b8ac5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10860,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "If you are too stressed, walk away from the front lines"
    },
    "304bd6d5ffeb07f50b0f09bc847bb440": {
      "source_id": "304bd6d5ffeb07f50b0f09bc847bb440",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21179,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "There is only one goal or drive - only self-perpetuation counts"
    },
    "5274bf8eea399fe8c76d45238765159b": {
      "source_id": "5274bf8eea399fe8c76d45238765159b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 628,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "<$750k grants for General Purpose AI Assurance/Safety Research"
    },
    "0fd0f5f492fcd4cacdab82d84a95db02": {
      "source_id": "0fd0f5f492fcd4cacdab82d84a95db02",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11568,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Tony Blair Institute AI Safety Work"
    },
    "14f0741f3b82e515dc553ed43faa7b1c": {
      "source_id": "14f0741f3b82e515dc553ed43faa7b1c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17923,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Some talent needs in AI governance"
    },
    "e609403fcf6a4c809f8a6228f6d6bc26": {
      "source_id": "e609403fcf6a4c809f8a6228f6d6bc26",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17907,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Aptitudes for AI governance work"
    },
    "e093ea8e8099e42a76282f020b546b9d": {
      "source_id": "e093ea8e8099e42a76282f020b546b9d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 563,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What's the exact way you predict probability of AI extinction?"
    },
    "a674d9ee1dbf42284d4eb96f0d146b52": {
      "source_id": "a674d9ee1dbf42284d4eb96f0d146b52",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2958,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Raising the voices that actually count"
    },
    "60e0adeaceefa9d773ee2b2bbdfe55cc": {
      "source_id": "60e0adeaceefa9d773ee2b2bbdfe55cc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4776,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Strategy - A new organization for better timelines"
    },
    "c86c1291030fd5f22d983b213a5e6fe2": {
      "source_id": "c86c1291030fd5f22d983b213a5e6fe2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17296,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Brief thoughts on Data, Reporting, and Response for AI Risk Mitigation"
    },
    "3da2cf3335175cd571ae8f9b64aad8e2": {
      "source_id": "3da2cf3335175cd571ae8f9b64aad8e2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2126,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "EU AI Act passed vote, and x-risk was a main topic "
    },
    "ffa31c0a3b94cc0d0b4ac17fe51717b1": {
      "source_id": "ffa31c0a3b94cc0d0b4ac17fe51717b1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5916,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Report: Artificial Intelligence Risk Management in Spain"
    },
    "0e51be41c777b35d0eb2602022a9dc73": {
      "source_id": "0e51be41c777b35d0eb2602022a9dc73",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1968,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "UN Secretary-General recognises existential threat from AI"
    },
    "290163a0574037fe135f4e8a5707c5d5": {
      "source_id": "290163a0574037fe135f4e8a5707c5d5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1058,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "PhD student and postdoc positions philosophy of AI in Erlangen (Germany)"
    },
    "c206b1deeafe4dca8090b73bcd1ee9bf": {
      "source_id": "c206b1deeafe4dca8090b73bcd1ee9bf",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4863,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Critiques of non-existent AI safety labs: Yours"
    },
    "bf607e27cdec012990801475459d116e": {
      "source_id": "bf607e27cdec012990801475459d116e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4297,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Updates from Campaign for AI Safety"
    },
    "75902a83a14eaf3a73858ec2fe8c7303": {
      "source_id": "75902a83a14eaf3a73858ec2fe8c7303",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31991,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Safety evaluations and standards for AI | Beth Barnes | EAG Bay Area 23"
    },
    "a3c5f63cc49b5adab3b2838ac68da3ab": {
      "source_id": "a3c5f63cc49b5adab3b2838ac68da3ab",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 905,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What would it look like for AIS to no longer be neglected?"
    },
    "8093b3d73a18f361f3d24bedd5575ae7": {
      "source_id": "8093b3d73a18f361f3d24bedd5575ae7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 996,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "UK Foundation Model Task Force - Expression of Interest"
    },
    "3268f4c6609dfc12bd663e29bb844759": {
      "source_id": "3268f4c6609dfc12bd663e29bb844759",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5903,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "My lab's small AI safety agenda"
    },
    "2f84609aefb6b7c5eca09e4cd22266ca": {
      "source_id": "2f84609aefb6b7c5eca09e4cd22266ca",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23148,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Multidisciplinary Approach to Alignment (MATA) and Archetypal Transfer Learn"
    },
    "d2bfa201692bec97b1f2ca286f27c09c": {
      "source_id": "d2bfa201692bec97b1f2ca286f27c09c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25445,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Principles for AI Welfare Research"
    },
    "13e3cd07a87b9e50006614049858fb6e": {
      "source_id": "13e3cd07a87b9e50006614049858fb6e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1419,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "New reference standard on LLM Application security started by OWASP"
    },
    "9c9dd55d6cb920cc17183e6e5c2537de": {
      "source_id": "9c9dd55d6cb920cc17183e6e5c2537de",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15117,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Simulating Shutdown Code Activations in an AI Virus Lab"
    },
    "f23f4aa46524943f88b19038bb7dfb49": {
      "source_id": "f23f4aa46524943f88b19038bb7dfb49",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48613,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Summary of the AI Bill of Rights and Policy Implications"
    },
    "c2e1c697a594738b6f13bb25624d8e81": {
      "source_id": "c2e1c697a594738b6f13bb25624d8e81",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7491,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "LPP Summer Research Fellowship in Law & AI 2023: Applications Open"
    },
    "800b1ce361124d2c9d1e3483f99f6e79": {
      "source_id": "800b1ce361124d2c9d1e3483f99f6e79",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1064,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Join the Virtual AI Safety Unconference (VAISU)!"
    },
    "1d37df6051b16288f3cd05eea15f0218": {
      "source_id": "1d37df6051b16288f3cd05eea15f0218",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51443,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "20 concrete projects for reducing existential risk"
    },
    "3cd5b235dabea65a869fae4546478d8e": {
      "source_id": "3cd5b235dabea65a869fae4546478d8e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 246,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Yip Fai Tse on animal welfare & AI safety and long termism"
    },
    "3446c335887504a814a1b9f8e6408dda": {
      "source_id": "3446c335887504a814a1b9f8e6408dda",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17367,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "RP\u2019s AI Governance & Strategy team - June 2023 interim overview"
    },
    "d5cdd14d96003f80a827a08a75c0d28e": {
      "source_id": "d5cdd14d96003f80a827a08a75c0d28e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21835,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "US public perception of CAIS statement and the risk of extinction"
    },
    "ea9302551a081da061b119f73a769219": {
      "source_id": "ea9302551a081da061b119f73a769219",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3242,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing the EA Project Ideas Database"
    },
    "b8c6962f3ed762686af5408903cf95ab": {
      "source_id": "b8c6962f3ed762686af5408903cf95ab",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5223,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing the AIPolicyIdeas.com Database "
    },
    "95bcf2a1f59975b75e6eb46b23913280": {
      "source_id": "95bcf2a1f59975b75e6eb46b23913280",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31160,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "On the compute governance era and what has to come after (Lennart Heim on The 80"
    },
    "95b63f61ba3ebb6cf08ab03820612c79": {
      "source_id": "95b63f61ba3ebb6cf08ab03820612c79",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24120,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Thoughts about AI safety field-building in LMIC"
    },
    "0cc0c27e41d910d3f079c1927e25a9c5": {
      "source_id": "0cc0c27e41d910d3f079c1927e25a9c5",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7731,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Map of maps of interesting fields"
    },
    "1e46b5912df1eb1f6b56da82e15c0e10": {
      "source_id": "1e46b5912df1eb1f6b56da82e15c0e10",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2382,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Looking for Canadian summer co-op position in AI Governance"
    },
    "1a3505980aa538181d47bd9beb9478b4": {
      "source_id": "1a3505980aa538181d47bd9beb9478b4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16352,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Let\u2019s set new AI safety actors up for success"
    },
    "4a132f34a04c656109a142ada6689254": {
      "source_id": "4a132f34a04c656109a142ada6689254",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12462,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Field Building vs. EA CB "
    },
    "8e464fce2f46bf9b8407c7c326af8ce0": {
      "source_id": "8e464fce2f46bf9b8407c7c326af8ce0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11894,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Where on the continuum of pure EA to pure AIS should you be? (Uni Group Organize"
    },
    "aa96b56f67c7575c667bb3c1868a9a4e": {
      "source_id": "aa96b56f67c7575c667bb3c1868a9a4e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17238,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISN #12: Policy Proposals from NTIA\u2019s Request for Comment and Reconsidering Ins"
    },
    "bab9a6b0bc6156f79d2235c500f20d15": {
      "source_id": "bab9a6b0bc6156f79d2235c500f20d15",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2247,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "ML4G Germany - AI Alignment Camp"
    },
    "4d2b5f9cbe20f23ebb838b97df1b305c": {
      "source_id": "4d2b5f9cbe20f23ebb838b97df1b305c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10970,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Incident Sharing - Best practices from other fields and a comprehensive list "
    },
    "fe16cd9b08f98be5560b23fb23b1b74e": {
      "source_id": "fe16cd9b08f98be5560b23fb23b1b74e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 40982,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Link Post] Interesting shallow round-up of reasons to be skeptical that transfo"
    },
    "ba35dfaab9b5108c47d3ac040b7be789": {
      "source_id": "ba35dfaab9b5108c47d3ac040b7be789",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2646,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Updates from Campaign for AI Safety"
    },
    "96954992dfa590e2cd0ae8d8950af4a9": {
      "source_id": "96954992dfa590e2cd0ae8d8950af4a9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9032,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Biosafety Regulations (BMBL) and their relevance for AI"
    },
    "b992e41eb8e67dac39a1b30e5c5dd39f": {
      "source_id": "b992e41eb8e67dac39a1b30e5c5dd39f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7339,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Three camps in AI x-risk discussions: My personal very oversimplified overview"
    },
    "50b84032120bcd6c91f6fcbd64539965": {
      "source_id": "50b84032120bcd6c91f6fcbd64539965",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3532,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "(Intro/1) - My Understandings of Mechanistic Interpretability Notebook "
    },
    "763b1d38c4e48afafa6b3ce1258c98b9": {
      "source_id": "763b1d38c4e48afafa6b3ce1258c98b9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2947,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Douglas Hoftstadter concerned about AI xrisk"
    },
    "0886d1723e35d02efd008f166df3d040": {
      "source_id": "0886d1723e35d02efd008f166df3d040",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1789,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Job] Managing Director at the Cooperative AI Foundation ($5000 Referral Bonus)"
    },
    "69370f2d7e19b5697985e459bd3c384c": {
      "source_id": "69370f2d7e19b5697985e459bd3c384c",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 1309,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[linkpost] Ten Levels of AI Alignment Difficulty"
    },
    "9cd7c2e54e9468e70a41b4b265ebb817": {
      "source_id": "9cd7c2e54e9468e70a41b4b265ebb817",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1321,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Know a grad student studying AI's economic impacts?"
    },
    "712128cae60dd9279fe1bada1c210a96": {
      "source_id": "712128cae60dd9279fe1bada1c210a96",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2678,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Washington Post article about EA university groups"
    },
    "1409fea5e2d0cd7c409b6e33c9e060ea": {
      "source_id": "1409fea5e2d0cd7c409b6e33c9e060ea",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21753,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISN #13: An interdisciplinary perspective on AI proxy failures, new competitors"
    },
    "892d3aa69a1a78df717478752f4f5352": {
      "source_id": "892d3aa69a1a78df717478752f4f5352",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1635,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What did AI Safety\u2019s specific funding of AGI R&D labs lead to?"
    },
    "fd72c63656c0845f9633718b767eb1cf": {
      "source_id": "fd72c63656c0845f9633718b767eb1cf",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3359,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "OpenAI is starting a new \"Superintelligence alignment\" team and they're hiring"
    },
    "02969eed91239d70607d9a74325994ba": {
      "source_id": "02969eed91239d70607d9a74325994ba",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8360,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing Manifund Regrants"
    },
    "523160b5c1b5eaf41e9b3c70389f6e98": {
      "source_id": "523160b5c1b5eaf41e9b3c70389f6e98",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52073,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Concrete open problems in mechanistic interpretability: a technical overview"
    },
    "982ebe3b7347b324ab6848df5bf90620": {
      "source_id": "982ebe3b7347b324ab6848df5bf90620",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5135,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A Defense of Work on Mathematical AI Safety"
    },
    "37a2ce86e6acd4272a175e0989fff6b1": {
      "source_id": "37a2ce86e6acd4272a175e0989fff6b1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3304,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing the Existential InfoSec Forum"
    },
    "2c551a2e29e9f5f807bae28a528e2109": {
      "source_id": "2c551a2e29e9f5f807bae28a528e2109",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13088,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Constructive Discussion and Thinking Methodology for Severe Situations including"
    },
    "91f2a34c7c33ba166ecc6b5c6c648573": {
      "source_id": "91f2a34c7c33ba166ecc6b5c6c648573",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1379,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing AI Alignment workshop at the ALIFE 2023 conference"
    },
    "14563dee193d73e4d58855a3b630287c": {
      "source_id": "14563dee193d73e4d58855a3b630287c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18032,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Modeling the impact of AI safety field-building programs"
    },
    "44a0b4f29c38056d2aff734539ef0410": {
      "source_id": "44a0b4f29c38056d2aff734539ef0410",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38251,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Cost-effectiveness of student programs for AI safety research"
    },
    "86e5f652e50d38155e4ad3ba3623ac30": {
      "source_id": "86e5f652e50d38155e4ad3ba3623ac30",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44335,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Cost-effectiveness of professional field-building programs for AI safety researc"
    },
    "184e0fbce9709825326a23b65fee4f64": {
      "source_id": "184e0fbce9709825326a23b65fee4f64",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1128,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Urgent Need for Refinancing"
    },
    "c27de57137ebb94cb430aec4dc6bea4b": {
      "source_id": "c27de57137ebb94cb430aec4dc6bea4b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19058,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Wellbeing"
    },
    "a2478c78ec0620b2ddf8b756d8bc5ab4": {
      "source_id": "a2478c78ec0620b2ddf8b756d8bc5ab4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 857,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "(How) Is technical AI Safety research being evaluated?"
    },
    "2177d023e6602e3c4a41ebd933c9d585": {
      "source_id": "2177d023e6602e3c4a41ebd933c9d585",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23435,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How to regulate cutting-edge AI models (Markus Anderljung on The 80,000 Hours Po"
    },
    "2fc0cf29aad0d9be0ed89aed6054fb4e": {
      "source_id": "2fc0cf29aad0d9be0ed89aed6054fb4e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 138,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What is the most convincing article, video, etc. making the case that AI is an X"
    },
    "39445fdbf6faa3eb461382c1e619f37d": {
      "source_id": "39445fdbf6faa3eb461382c1e619f37d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6756,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing the AI Fables Writing Contest! "
    },
    "b606ef0ba3ef6b105a916f280bedc712": {
      "source_id": "b606ef0ba3ef6b105a916f280bedc712",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2016,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Could unions be an underrated driver for AI safety policy?"
    },
    "863022e8427aed96d8a9c24ad7f01bda": {
      "source_id": "863022e8427aed96d8a9c24ad7f01bda",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33065,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An Overview of the AI Safety Funding Situation"
    },
    "2acec6639eb0d0a989238aabab904d4f": {
      "source_id": "2acec6639eb0d0a989238aabab904d4f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10911,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISN#14: OpenAI\u2019s \u2018Superalignment\u2019 team, Musk\u2019s xAI launches, and developments i"
    },
    "d9cdde45ba014f8fa19525f7194921cf": {
      "source_id": "d9cdde45ba014f8fa19525f7194921cf",
      "quality_score": 2.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 8325,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] NY Times Feature on Anthropic"
    },
    "17851443f1f465f3d61eadd8eb6efa18": {
      "source_id": "17851443f1f465f3d61eadd8eb6efa18",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52670,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Book Review: Oryx and Crake"
    },
    "f54b1ebffb09499b3298fa5c1c7552f0": {
      "source_id": "f54b1ebffb09499b3298fa5c1c7552f0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 391,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What new psychology research could best promote AI safety & alignment research?"
    },
    "89db94b47904ee6979bd23b2731c4844": {
      "source_id": "89db94b47904ee6979bd23b2731c4844",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11903,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Risk and Survivorship Bias - How Andreessen and LeCun got it wrong "
    },
    "6c703486d31795be26ca639984e34da0": {
      "source_id": "6c703486d31795be26ca639984e34da0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2526,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Cambridge AI Safety Hub is looking for full- or part-time organisers"
    },
    "707726bdc003f67d62caa3a2f3b42419": {
      "source_id": "707726bdc003f67d62caa3a2f3b42419",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14249,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI-Relevant Regulation: IAEA"
    },
    "f3f3209850a9f4fd8363b9fb02b0ac63": {
      "source_id": "f3f3209850a9f4fd8363b9fb02b0ac63",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14589,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI-Relevant Regulation: CERN"
    },
    "a1b2452cbbdfeda8bd9d0bb22d5ed61e": {
      "source_id": "a1b2452cbbdfeda8bd9d0bb22d5ed61e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4531,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A fictional AI law laced w/ alignment theory"
    },
    "2e5f028384bef9826665976fa19af579": {
      "source_id": "2e5f028384bef9826665976fa19af579",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 71343,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "New career review: AI safety technical research"
    },
    "f849660c259548e1eef069519a9c01d0": {
      "source_id": "f849660c259548e1eef069519a9c01d0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53073,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What we can learn from stress testing for AI regulation"
    },
    "1236d048bf5300d98ee6fe05d3b8e9b5": {
      "source_id": "1236d048bf5300d98ee6fe05d3b8e9b5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 855,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Eliciting responses to Marc Andreessen's \"Why AI Will Save the World\""
    },
    "1826117f6c3b836d9875b36fa1dabe67": {
      "source_id": "1826117f6c3b836d9875b36fa1dabe67",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3832,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Train for incorrigibility, then reverse it (Shutdown Problem Contest Submission)"
    },
    "0e63179417ed1e01a63f1abd92604c73": {
      "source_id": "0e63179417ed1e01a63f1abd92604c73",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36009,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Five Years of Rethink Priorities: Impact, Future Plans, Funding Needs (July 2023"
    },
    "46f6d102c2a7e1722439babc712c132a": {
      "source_id": "46f6d102c2a7e1722439babc712c132a",
      "quality_score": 2.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 7819,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Impacts Quarterly Newsletter, Apr-Jun 2023"
    },
    "b32d1589892a36848a503c17daad580a": {
      "source_id": "b32d1589892a36848a503c17daad580a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 776,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "I'm interviewing Jan Leike, co-lead of OpenAI's new Superalignment project. What"
    },
    "351365b9ee45277e0f5f6b4fb1d92924": {
      "source_id": "351365b9ee45277e0f5f6b4fb1d92924",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16256,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISN#15: China and the US take action to regulate AI, results from a tournament "
    },
    "dfc04084796ab1d7f6e7b3895c266e3f": {
      "source_id": "dfc04084796ab1d7f6e7b3895c266e3f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12248,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An Introduction to Critiques of prominent AI safety organizations"
    },
    "17b8e05f1b4deb05f24a4683455707ad": {
      "source_id": "17b8e05f1b4deb05f24a4683455707ad",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62863,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What do XPT forecasts tell us about AI risk?"
    },
    "d15d1952402004d9af62c9a4a76d4bb2": {
      "source_id": "d15d1952402004d9af62c9a4a76d4bb2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4631,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Updates from Campaign for AI Safety"
    },
    "4bca413193e3321caceb0311f52874be": {
      "source_id": "4bca413193e3321caceb0311f52874be",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3517,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Thoughts on yesterday\u2019s UN Security Council meeting on AI"
    },
    "556b1d3be828189fa3e8cf856ccf774a": {
      "source_id": "556b1d3be828189fa3e8cf856ccf774a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50697,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Incident reporting for AI safety"
    },
    "05d136e3f0900d21e221d75d3d83192b": {
      "source_id": "05d136e3f0900d21e221d75d3d83192b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5424,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "All AGI Safety questions welcome (especially basic ones) [July 2023]"
    },
    "2e608f86771e18da9adcfa5f3003be95": {
      "source_id": "2e608f86771e18da9adcfa5f3003be95",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1436,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Should we nationalize AI development?"
    },
    "359fb797e49378273ebd5715934daf3a": {
      "source_id": "359fb797e49378273ebd5715934daf3a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2908,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Australians call for AI safety to be taken seriously"
    },
    "0722886aefb2ca336d7cb3cd0e68c551": {
      "source_id": "0722886aefb2ca336d7cb3cd0e68c551",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56824,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What do XPT forecasts tell us about AI timelines?"
    },
    "f21202deae896a9ff5f55f15123c8567": {
      "source_id": "f21202deae896a9ff5f55f15123c8567",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 1923,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Linkpost: 7 A.I. Companies Agree to Safeguards After Pressure From the White Hou"
    },
    "348b8e60f1aae6ce75aafe0290a0958b": {
      "source_id": "348b8e60f1aae6ce75aafe0290a0958b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2250,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Excerpts from \"Majority Leader Schumer Delivers Remarks To Launch SAFE Innovatio"
    },
    "fa8aee9cb6a0b596f6eedfb2baba3b23": {
      "source_id": "fa8aee9cb6a0b596f6eedfb2baba3b23",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1196,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Could someone help me understand why it's so difficult to solve the alignment pr"
    },
    "e14b2dcfc68b802c8b81db566e908c17": {
      "source_id": "e14b2dcfc68b802c8b81db566e908c17",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12642,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI-Relevant Regulation: Insurance in Safety-Critical Industries"
    },
    "15f0685959864766fd53c99423285a66": {
      "source_id": "15f0685959864766fd53c99423285a66",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13682,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Crosspost] An AI Pause Is Humanity's Best Bet For Preventing Extinction (TIME)"
    },
    "62ade9a418e78918519c829fd5933aef": {
      "source_id": "62ade9a418e78918519c829fd5933aef",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 100122,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "XPT forecasts on (some) biological anchors inputs"
    },
    "930b9d7bf806616706064b2841d0da38": {
      "source_id": "930b9d7bf806616706064b2841d0da38",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2263,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Asterisk Magazine Issue 03: AI"
    },
    "e7d62ed981d981790dc9f980c6fa3403": {
      "source_id": "e7d62ed981d981790dc9f980c6fa3403",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3810,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Towards evidence gap-maps for AI safety"
    },
    "5888fd1ff1da9e4f7ee57525ab4e486a": {
      "source_id": "5888fd1ff1da9e4f7ee57525ab4e486a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12321,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Summary of posts on XPT forecasts on AI risk and timelines"
    },
    "d01abc5ab7529f46bacfe74296030d85": {
      "source_id": "d01abc5ab7529f46bacfe74296030d85",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 578,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] My attempt at trying to summarize 'Intro to ML Safety'"
    },
    "9435ee618a1527a6f2be377f9289fa9a": {
      "source_id": "9435ee618a1527a6f2be377f9289fa9a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28326,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Should you work at a leading AI lab? (including in non-safety roles)"
    },
    "7e1fc21b7ac2bcf0a4a952be566354a4": {
      "source_id": "7e1fc21b7ac2bcf0a4a952be566354a4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16130,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISN #16: White House Secures Voluntary Commitments from Leading AI Labs and Les"
    },
    "b6fa171d4dd88144592cd6bc10ab69d9": {
      "source_id": "b6fa171d4dd88144592cd6bc10ab69d9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9144,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Carl Shulman on AI takeover mechanisms (& more): Part II of Dwarkesh Patel inter"
    },
    "10254d838cfad83fda3ebb888e0b1098": {
      "source_id": "10254d838cfad83fda3ebb888e0b1098",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6292,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Hub Serbia Soft Launch"
    },
    "4a3e35fa16eacddebd271ca63b28e9fa": {
      "source_id": "4a3e35fa16eacddebd271ca63b28e9fa",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3724,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AGI Takeoff dynamics - Intelligence vs Quantity explosion "
    },
    "f06a6c0071e18a92f5b6c9deea2cd911": {
      "source_id": "f06a6c0071e18a92f5b6c9deea2cd911",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24140,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Existential risk from AI and what DC could do about it (Ezra Klein on the 80,000"
    },
    "79850f2d62e85955713f966eb1dd9aee": {
      "source_id": "79850f2d62e85955713f966eb1dd9aee",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3528,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Apply to CEEALAR to do AGI moratorium work"
    },
    "00aab6ab0ce3350ca739d2c736776777": {
      "source_id": "00aab6ab0ce3350ca739d2c736776777",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2476,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Discussing AI-Human Collaboration Through Fiction: The Story of Laika and GPT-\u221e"
    },
    "561d02ca8e392de4db576576e8f4c0fd": {
      "source_id": "561d02ca8e392de4db576576e8f4c0fd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14166,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Animal Advocacy in the Age of AI"
    },
    "d47987cdf8267e13b9035b70628222e8": {
      "source_id": "d47987cdf8267e13b9035b70628222e8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40048,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Partial Transcript of Recent Senate Hearing Discussing AI\u00a0X-Risk"
    },
    "9ce248f9475de4ac01fa561c0f564a2e": {
      "source_id": "9ce248f9475de4ac01fa561c0f564a2e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5159,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing the ITAM AI Futures Fellowship "
    },
    "15ab887a1a43fab83d37b123ff8775e5": {
      "source_id": "15ab887a1a43fab83d37b123ff8775e5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3825,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Visit Mexico City in January & February to interact with the AI Futures Fellowsh"
    },
    "6bf8f4c8384183287272790f38105cd3": {
      "source_id": "6bf8f4c8384183287272790f38105cd3",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8123,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Fundamentals of Fatal Risks"
    },
    "deb6898a59c8ad40d2baa730043f1f7f": {
      "source_id": "deb6898a59c8ad40d2baa730043f1f7f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 967,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Shutting down AI Safety Support"
    },
    "a0fd7ed0f374b93054542a9d69479f3d": {
      "source_id": "a0fd7ed0f374b93054542a9d69479f3d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3360,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "If AIs had subcortical brain simulation, would that solve the alignment problem?"
    },
    "a6e1286564f4e356a6ce27fddc2661a2": {
      "source_id": "a6e1286564f4e356a6ce27fddc2661a2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25707,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The \u201cno sandbagging on checkable tasks\u201d hypothesis"
    },
    "e2fcf2ba23a5b21df30a15bdbfce1434": {
      "source_id": "e2fcf2ba23a5b21df30a15bdbfce1434",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19804,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISN #17: Automatically Circumventing LLM Guardrails, the Frontier Model Forum, "
    },
    "90937adfcccc787b276930687da9bae3": {
      "source_id": "90937adfcccc787b276930687da9bae3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31811,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Four part playbook for dealing with AI (Holden Karnofsky on the 80,000 Hours Pod"
    },
    "7f7043777c40fa4bae8a09c31ffc6939": {
      "source_id": "7f7043777c40fa4bae8a09c31ffc6939",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14117,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "3 levels of threat obfuscation"
    },
    "65f7194d98697eb2283e155331105691": {
      "source_id": "65f7194d98697eb2283e155331105691",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2599,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Alignment Grantmaking is Funding-Limited Right Now [crosspost]"
    },
    "9075f8ee5d3cda83f73ed553e2f5abed": {
      "source_id": "9075f8ee5d3cda83f73ed553e2f5abed",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14507,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Training for Good is hiring (and why you should join us): AI Programme Lead and "
    },
    "aab2957f5007ec1f261325dc1411320f": {
      "source_id": "aab2957f5007ec1f261325dc1411320f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5189,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Apollo Research is hiring evals and interpretability engineers & scientists"
    },
    "106c2d29937f68b3b7900e77f373b0b1": {
      "source_id": "106c2d29937f68b3b7900e77f373b0b1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3506,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Join AISafety.info's Writing & Editing Hackathon (Aug 25-28) (Prizes to be won!)"
    },
    "2d777f47dcbc2bb8504f45f54351c591": {
      "source_id": "2d777f47dcbc2bb8504f45f54351c591",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5860,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An appeal to people who are smarter than me: please help me clarify my thinking "
    },
    "a062a59bc3bd965e5a6959526d7271e7": {
      "source_id": "a062a59bc3bd965e5a6959526d7271e7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25113,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Safety-First Agents/Architectures Are a Promising Path to Safe AGI"
    },
    "d5bd8b928c9904054a4cdac408c99916": {
      "source_id": "d5bd8b928c9904054a4cdac408c99916",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4165,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Updates from Campaign for AI Safety"
    },
    "e95986c14db43d74789d5a6bc5e9507e": {
      "source_id": "e95986c14db43d74789d5a6bc5e9507e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1311,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Ben Horowitz and others are spreading a \"regulation is bad\" view. Would it be us"
    },
    "d565128e801e46d7f8079108c98c5ada": {
      "source_id": "d565128e801e46d7f8079108c98c5ada",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20382,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Fundamentals of Global Priorities Research in Economics Syllabus"
    },
    "871689580c879693f367ea95efd08ec2": {
      "source_id": "871689580c879693f367ea95efd08ec2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14018,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISN #18: Challenges of Reinforcement Learning from Human Feedback, Microsoft\u2019s "
    },
    "a758493c1ba468b141f2a0c63b4c6b02": {
      "source_id": "a758493c1ba468b141f2a0c63b4c6b02",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33420,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "OpenAI\u2019s massive push to make superintelligence safe in 4 years or less (Jan Lei"
    },
    "1a238c8a1240ab5437440b7c52d9d431": {
      "source_id": "1a238c8a1240ab5437440b7c52d9d431",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40252,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Podcast (+transcript): Nathan Barnard on how US financial regulation can inform "
    },
    "e77893fd72a9d29fd7e9349363339ce4": {
      "source_id": "e77893fd72a9d29fd7e9349363339ce4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12221,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "4 types of AGI selection, and how to constrain them"
    },
    "fead16c8d23bb6c59e0a3a97f6fb87c2": {
      "source_id": "fead16c8d23bb6c59e0a3a97f6fb87c2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9768,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Update on cause area focus working group"
    },
    "ce34b5d40945b52f60677c57641961df": {
      "source_id": "ce34b5d40945b52f60677c57641961df",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1099,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "UN Public Call for Nominations For High-level Advisory Body on Artificial Intell"
    },
    "cc356c34ae4b80ba01513ebf46e51ffd": {
      "source_id": "cc356c34ae4b80ba01513ebf46e51ffd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58280,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A selection of some writings and considerations on the cause of artificial senti"
    },
    "fd93089c7e05d1e7c17be3dfdfb417db": {
      "source_id": "fd93089c7e05d1e7c17be3dfdfb417db",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19301,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What Does a Marginal Grant at LTFF Look Like? Funding Priorities and Grantmaking"
    },
    "1bf6771c006dfcc568a5936e57eec0ca": {
      "source_id": "1bf6771c006dfcc568a5936e57eec0ca",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12533,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Concepts Writeup: WebGPT"
    },
    "ceaafc557c88fbd2754f0b2f709397c9": {
      "source_id": "ceaafc557c88fbd2754f0b2f709397c9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12509,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI-Relevant Regulation: CPSC"
    },
    "00d6692a20b13eb5d78d401735a51c30": {
      "source_id": "00d6692a20b13eb5d78d401735a51c30",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 321,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What do we know about Mustafa Suleyman's position on AI Safety?"
    },
    "419da6b6a9ebba63c11f1df0a6295a7a": {
      "source_id": "419da6b6a9ebba63c11f1df0a6295a7a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21580,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Summary of \u201cThe Precipice\u201d (2 of 4): We are a danger to ourselves"
    },
    "a54598a4e3d58064f2bb0cf2a687cc70": {
      "source_id": "a54598a4e3d58064f2bb0cf2a687cc70",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1490,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A bill to prevent AI from hiring people instead of human enployers in NY"
    },
    "44e413ecd2e739eebe686a0c2633652e": {
      "source_id": "44e413ecd2e739eebe686a0c2633652e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32603,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why some people disagree with the CAIS statement on AI"
    },
    "4667038b99154551fb908f8d21472d29": {
      "source_id": "4667038b99154551fb908f8d21472d29",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6245,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Credo AI is hiring for AI Gov Researcher & more!"
    },
    "f8015a8dba558e78a3a816c316177a9f": {
      "source_id": "f8015a8dba558e78a3a816c316177a9f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29910,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An Overview of Catastrophic AI Risks"
    },
    "63a440062094a7041e30f5b4ff043677": {
      "source_id": "63a440062094a7041e30f5b4ff043677",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 451,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Am I taking crazy pills? Why aren't EAs advocating for a pause on AI capabilitie"
    },
    "30c87ea9b522092ea2b72195cea6f3ce": {
      "source_id": "30c87ea9b522092ea2b72195cea6f3ce",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5505,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An argument for accelerating international AI governance research (part 1)"
    },
    "a10f8d9e1ddf5fb0cee6d72604dda01a": {
      "source_id": "a10f8d9e1ddf5fb0cee6d72604dda01a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2360,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Stampy's AI Safety Info - New Distillations #4 [July 2023]"
    },
    "51d0da7b4085b0bfed06afcfda781048": {
      "source_id": "51d0da7b4085b0bfed06afcfda781048",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3896,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Launching Foresight Institute\u2019s AI Grant for Underexplored Approaches to AI Safe"
    },
    "ea11f81d1e6f72706b69b6cf44cd32f8": {
      "source_id": "ea11f81d1e6f72706b69b6cf44cd32f8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12481,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The State of AI Governance in Africa: Musings from the Global South "
    },
    "50715d721308e9f2b1ecd73c6dff49ef": {
      "source_id": "50715d721308e9f2b1ecd73c6dff49ef",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11377,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Making EA more inclusive, representative, and impactful in Africa"
    },
    "23ce8f52182633810f3b4d19e0b10231": {
      "source_id": "23ce8f52182633810f3b4d19e0b10231",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20551,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Corporate campaigns work: a key learning for AI Safety"
    },
    "bffbd96373a58cc55d6cfeca7d723f5e": {
      "source_id": "bffbd96373a58cc55d6cfeca7d723f5e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6461,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "6 non-obvious mental health issues specific to AI safety"
    },
    "ec17f54f37994f5e56e3afee03ccca70": {
      "source_id": "ec17f54f37994f5e56e3afee03ccca70",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 4113,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] Eric Schwitzgebel: AI systems must not confuse users about their sent"
    },
    "f30e458ab82d538c77d231481e6b9522": {
      "source_id": "f30e458ab82d538c77d231481e6b9522",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12185,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Supervised Program for Alignment Research (SPAR) at UC Berkeley: Spring 2023 sum"
    },
    "e375a575f2b33ef6bebdff1532fd03e1": {
      "source_id": "e375a575f2b33ef6bebdff1532fd03e1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1617,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI labs' requests for input"
    },
    "87d01f80de1a0a0b42b494f99025a175": {
      "source_id": "87d01f80de1a0a0b42b494f99025a175",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4216,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Will AI kill everyone? Here's what the godfathers of AI have to say [RA video]"
    },
    "b323fbde6e72c4bb282245087753e3a8": {
      "source_id": "b323fbde6e72c4bb282245087753e3a8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13175,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Longtermism Fund: August 2023 Grants Report"
    },
    "fbb9120b26c3c3e06d391b0512fed94e": {
      "source_id": "fbb9120b26c3c3e06d391b0512fed94e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39511,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "XPT forecasts on (some) Direct Approach model inputs"
    },
    "1539d5362b425e34b80197745b32ce2c": {
      "source_id": "1539d5362b425e34b80197745b32ce2c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1583,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why does an AI have to have specified goals?"
    },
    "1cf2ce9c8091ba48452cd97b11269709": {
      "source_id": "1cf2ce9c8091ba48452cd97b11269709",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20969,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An argument for accelerating international AI governance research (part 2)"
    },
    "f634a5cc6c5106298b5626f8f6ea7210": {
      "source_id": "f634a5cc6c5106298b5626f8f6ea7210",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6686,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why Is No One Trying To Align Profit Incentives With Alignment Research?"
    },
    "c67f055887bab863038d210a1ceecf86": {
      "source_id": "c67f055887bab863038d210a1ceecf86",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55598,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Health, morality, and goal alignment of systems, agents, and organs"
    },
    "37a1794717ef75d659507c197f40116c": {
      "source_id": "37a1794717ef75d659507c197f40116c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15994,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Bounties"
    },
    "13b6fcb1791b52b2bb2fdf8ef4b6e565": {
      "source_id": "13b6fcb1791b52b2bb2fdf8ef4b6e565",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9700,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Crosspost] AI Regulation May Be More Important Than AI Alignment For Existentia"
    },
    "a213898c18c61bc00ab5c44ac9ff7993": {
      "source_id": "a213898c18c61bc00ab5c44ac9ff7993",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 396,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What AI Posts Do You Want Distilled?"
    },
    "9e6fe0b2b0c6ea84e16cc27d9b043285": {
      "source_id": "9e6fe0b2b0c6ea84e16cc27d9b043285",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1330,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A model-based approach to AI Existential Risk"
    },
    "c24ccb259f17a8df3710d72821b5bb1c": {
      "source_id": "c24ccb259f17a8df3710d72821b5bb1c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32167,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "On whether AI will soon cause job loss, lower incomes, and higher inequality \u2014 o"
    },
    "fe4ce78b24a5bfb642b555d801087593": {
      "source_id": "fe4ce78b24a5bfb642b555d801087593",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21585,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "EA is underestimating intelligence agencies and this is dangerous"
    },
    "66591591fdce3bab4e95b2ec7b96ab00": {
      "source_id": "66591591fdce3bab4e95b2ec7b96ab00",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3724,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Navigating the Future: A Guide on How to Stay Safe with AI | Emmanuel Katto Ugan"
    },
    "6adc5d25f5d4a5810253c6ec1ef0074e": {
      "source_id": "6adc5d25f5d4a5810253c6ec1ef0074e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14135,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Rethink Priorities is looking for a (Co-)Founder for a New Project: Field Buildi"
    },
    "6ff534383d1dc9e395f5f9d1c299a093": {
      "source_id": "6ff534383d1dc9e395f5f9d1c299a093",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19130,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISN #20: LLM Proliferation, AI Deception, and Continuing Drivers of AI Capabili"
    },
    "c1548568d3dbc805cc6fe64112a8c187": {
      "source_id": "c1548568d3dbc805cc6fe64112a8c187",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2202,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Apply to a small iteration of MLAB to be run in Oxford"
    },
    "a9484043c33319fd714bc26bea597b30": {
      "source_id": "a9484043c33319fd714bc26bea597b30",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14627,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Language models surprised us"
    },
    "d6b293527882c0af902505c903db1c28": {
      "source_id": "d6b293527882c0af902505c903db1c28",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4364,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Updates from Campaign for AI Safety"
    },
    "280e05c4d1e82921c0cb331d2e6a903b": {
      "source_id": "280e05c4d1e82921c0cb331d2e6a903b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10204,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Agency Foundations Challenge: September 8th-24th, $10k Prizes"
    },
    "b672e9083f449f3f05f2771b44da9039": {
      "source_id": "b672e9083f449f3f05f2771b44da9039",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 4376,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] Michael Nielsen remarks on 'Oppenheimer'"
    },
    "692ba07c36bf5f0f8c88e6b54d7ec0e4": {
      "source_id": "692ba07c36bf5f0f8c88e6b54d7ec0e4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1437,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Alignment & Capabilities: What's the difference?"
    },
    "277a3aa1ce05134aae9bedab04b2b7f1": {
      "source_id": "277a3aa1ce05134aae9bedab04b2b7f1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14803,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI pause/governance advocacy might be net-negative, especially without focus on "
    },
    "bff61eb38b1ff19838a2dac6d2cb14bd": {
      "source_id": "bff61eb38b1ff19838a2dac6d2cb14bd",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1965,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is AI like disk drives?"
    },
    "78a0abf6d07fa1a5533ae373765ffc98": {
      "source_id": "78a0abf6d07fa1a5533ae373765ffc98",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 3464,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] Beware the Squirrel by Verity Harding"
    },
    "990ff1a99e0d139d92145c5896bc1d52": {
      "source_id": "990ff1a99e0d139d92145c5896bc1d52",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7958,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[CFP] NeurIPS workshop:  AI meets Moral Philosophy and Moral Psychology"
    },
    "8d2cb7be260bdb19c9ba1ef7bac9f6ba": {
      "source_id": "8d2cb7be260bdb19c9ba1ef7bac9f6ba",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1532,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Transformative AI and Compute - Reading List"
    },
    "8b79805d5871b105178872dc29fbe812": {
      "source_id": "8b79805d5871b105178872dc29fbe812",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17715,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Getting Washington and Silicon Valley to tame AI (Mustafa Suleyman on the 80,000"
    },
    "2d4f6eec1440c99bd940bb5324e8d135": {
      "source_id": "2d4f6eec1440c99bd940bb5324e8d135",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8907,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "No. Impending AGI doesn't make everything else unimportant."
    },
    "773d1e149e733c1e9a38243a55b4ea2a": {
      "source_id": "773d1e149e733c1e9a38243a55b4ea2a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12924,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Against the Open Source / Closed Source Dichotomy: Regulated Source as a Model f"
    },
    "0ecaad06136077804191febec259ce55": {
      "source_id": "0ecaad06136077804191febec259ce55",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7332,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Data Poisoning for Dummies (No Code, No Math)"
    },
    "63ee0fdeb256f323504aa08921d1b78b": {
      "source_id": "63ee0fdeb256f323504aa08921d1b78b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11606,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISN #21: Google DeepMind\u2019s GPT-4 Competitor, Military Investments in Autonomous"
    },
    "af9bc7f23310738542520599559d1f9e": {
      "source_id": "af9bc7f23310738542520599559d1f9e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2256,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Strongest real-world examples supporting AI risk claims?"
    },
    "683fc4377b12261ffcfb992b419129f3": {
      "source_id": "683fc4377b12261ffcfb992b419129f3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28380,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What I would do if I wasn\u2019t at ARC Evals"
    },
    "0e41b47560f80bd676151f61b2e35ea2": {
      "source_id": "0e41b47560f80bd676151f61b2e35ea2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26065,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What term to use for AI in different policy contexts?"
    },
    "2ffc74b379614e0e6fa95a87471fa790": {
      "source_id": "2ffc74b379614e0e6fa95a87471fa790",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50046,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How long will reaching a Risk Awareness Moment and CHARTS agreement take?"
    },
    "1c8aece7423cffa4161397674349fb2f": {
      "source_id": "1c8aece7423cffa4161397674349fb2f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3186,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Explained Simply: Quantilizers"
    },
    "7ff0fbb3f2ba1f5bc929b42bca6c972b": {
      "source_id": "7ff0fbb3f2ba1f5bc929b42bca6c972b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3229,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Debate series: should we push for a pause on the development of AI?"
    },
    "efee37b0452631890dfcefcce01063fe": {
      "source_id": "efee37b0452631890dfcefcce01063fe",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 90952,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A case study of regulation done well? Canadian biorisk regulations"
    },
    "5f42e0ef3a3469be45aee7654d1f9c7e": {
      "source_id": "5f42e0ef3a3469be45aee7654d1f9c7e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2834,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Possible Divergence in AGI Risk Tolerance between Selfish and Altruistic agents"
    },
    "a33a1ca0cc88a65bc1ad84d277ac698e": {
      "source_id": "a33a1ca0cc88a65bc1ad84d277ac698e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 75416,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Panel discussion on AI consciousness with Rob Long and Jeff Sebo"
    },
    "2f2ebf8d58e919750cb46d674e098c9c": {
      "source_id": "2f2ebf8d58e919750cb46d674e098c9c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2804,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How should technical AI researchers best transition into AI governance and polic"
    },
    "888244ccf86a6128bd51fcf7be8ac003": {
      "source_id": "888244ccf86a6128bd51fcf7be8ac003",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40412,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Theory: \u201cWAW might be of higher impact than x-risk prevention based on utilitari"
    },
    "8f2250dc033385959c471b4fc635626f": {
      "source_id": "8f2250dc033385959c471b4fc635626f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4731,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI-Risk in the State of the European Union Address"
    },
    "3acc08d1d511b8149fe5f373904f78b1": {
      "source_id": "3acc08d1d511b8149fe5f373904f78b1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12334,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "MLSN: #10 Adversarial Attacks Against Language and Vision Models, Improving LLM "
    },
    "04cbdb1929c2470aa5860a691319c458": {
      "source_id": "04cbdb1929c2470aa5860a691319c458",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41240,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The state of AI in different countries \u2014 an overview"
    },
    "a304a3303527a3d86c94677d3ce8a3dd": {
      "source_id": "a304a3303527a3d86c94677d3ce8a3dd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19650,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What's in a Pause?"
    },
    "2be57e39027c5e221bb5ae4fadbc650d": {
      "source_id": "2be57e39027c5e221bb5ae4fadbc650d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29699,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Pause Will Likely Backfire"
    },
    "6fe51ab0784ab48491e864711bff5fe7": {
      "source_id": "6fe51ab0784ab48491e864711bff5fe7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20389,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Policy ideas for mitigating AI risk"
    },
    "c40b4eca7830a724f3aad35da3fe7bee": {
      "source_id": "c40b4eca7830a724f3aad35da3fe7bee",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11362,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How to think about slowing AI"
    },
    "ddd1e5da75c78b72fe442bb0a1bb7349": {
      "source_id": "ddd1e5da75c78b72fe442bb0a1bb7349",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6283,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Microdooms averted by working on AI Safety"
    },
    "8d75a3395ed99084f76e61588b68d431": {
      "source_id": "8d75a3395ed99084f76e61588b68d431",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12142,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Comments on Manheim's \"What's in a Pause?\""
    },
    "18e5575b5f997bc029c5f60bb20f7c4c": {
      "source_id": "18e5575b5f997bc029c5f60bb20f7c4c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 709,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Stuart J. Russell on \"should we press pause on AI?\" "
    },
    "59228d9ddcd0dd30543a7cbbbb1f1449": {
      "source_id": "59228d9ddcd0dd30543a7cbbbb1f1449",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2074,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Relationship between EA Community and AI safety"
    },
    "057850068f4dcb9b50261a83a31bf6fd": {
      "source_id": "057850068f4dcb9b50261a83a31bf6fd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31237,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The possibility of an indefinite AI pause "
    },
    "cbf72ce8cc1fd4a71f6d997385eaeac8": {
      "source_id": "cbf72ce8cc1fd4a71f6d997385eaeac8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 11754,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Link post] Michael Nielsen's \"Notes on Existential Risk from Artificial Superin"
    },
    "76f80cf46a05bd74ac8c6d2b0e5ef5d8": {
      "source_id": "76f80cf46a05bd74ac8c6d2b0e5ef5d8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13948,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISN #22: The Landscape of US AI Legislation -  Hearings, Frameworks, Bills, and"
    },
    "b48598098b92a22a5c38cdae5541c3a9": {
      "source_id": "b48598098b92a22a5c38cdae5541c3a9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20024,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Anthropic's Responsible Scaling Policy & Long-Term Benefit Trust"
    },
    "a9c593a27ff2b2450e43719f45f1d447": {
      "source_id": "a9c593a27ff2b2450e43719f45f1d447",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1726,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Protest against Meta's irreversible proliferation (Sept 29, San Francisco)"
    },
    "e166629b21929182c28099ed8a599593": {
      "source_id": "e166629b21929182c28099ed8a599593",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24958,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Existential Cybersecurity Risks & AI (A Research Agenda)"
    },
    "bba6783a7b8c1abdcaa1d35bb522ebd3": {
      "source_id": "bba6783a7b8c1abdcaa1d35bb522ebd3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28763,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Case for AI Safety Advocacy to the Public "
    },
    "36f1b7c3f78b6d8ab6de5cf31a0dc032": {
      "source_id": "36f1b7c3f78b6d8ab6de5cf31a0dc032",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9396,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The \u201ctechnology\" bucket error"
    },
    "e7a64fb73ab3a34d9baf4bcd95e3b5ac": {
      "source_id": "e7a64fb73ab3a34d9baf4bcd95e3b5ac",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31308,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI is centralizing by default; let's not make it worse"
    },
    "0c387ed6c508c7d2a89a667e3b5f7459": {
      "source_id": "0c387ed6c508c7d2a89a667e3b5f7459",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1016,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is there much need for frontend engineers in AI alignment?"
    },
    "9f0de6a591a57fad4d10e142df0c83e4": {
      "source_id": "9f0de6a591a57fad4d10e142df0c83e4",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5777,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Let's talk about Impostor syndrome in AI safety"
    },
    "c51adfb4a406f593ac118b78ad29d417": {
      "source_id": "c51adfb4a406f593ac118b78ad29d417",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17366,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How could a moratorium fail?"
    },
    "5c205f14e5b36233bf86d3e67e3c027f": {
      "source_id": "5c205f14e5b36233bf86d3e67e3c027f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9612,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "We are not alone: many communities want to stop Big Tech from scaling unsafe AI"
    },
    "22f54a242bd0fef0de2b180dcfad3872": {
      "source_id": "22f54a242bd0fef0de2b180dcfad3872",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2303,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Intro to AI risk for AI grad students?"
    },
    "28d937402d909b418b6cc6b1a48abbe5": {
      "source_id": "28d937402d909b418b6cc6b1a48abbe5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31156,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "It\u2019s not obvious that getting dangerous AI later is better"
    },
    "33a7a80c70a33634077842e4b95010f5": {
      "source_id": "33a7a80c70a33634077842e4b95010f5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2184,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\"We can Prevent AI Disaster Like We Prevented Nuclear Catastrophe\" "
    },
    "938cfbde2b845f765cef5d3db5c5c166": {
      "source_id": "938cfbde2b845f765cef5d3db5c5c166",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5664,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "I designed an AI safety course (for a philosophy department) "
    },
    "9c3392fad7497c19a67ed6229b8d0ef2": {
      "source_id": "9c3392fad7497c19a67ed6229b8d0ef2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3952,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Unions for AI safety?"
    },
    "9d0e362d9aba7d074f788754ea46d27c": {
      "source_id": "9d0e362d9aba7d074f788754ea46d27c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18947,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Five neglected work areas that could reduce AI risk"
    },
    "15eaacd0552196409dd9891b098111f0": {
      "source_id": "15eaacd0552196409dd9891b098111f0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34100,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Aim for conditional pauses"
    },
    "99027ac85a782ff95eb45d3bfde0e29e": {
      "source_id": "99027ac85a782ff95eb45d3bfde0e29e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61336,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How to pursue a career in AI governance and coordination"
    },
    "d0ede5acdd933acdcff491e60ec17036": {
      "source_id": "d0ede5acdd933acdcff491e60ec17036",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18518,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\u201cX distracts from Y\u201d as a thinly-disguised fight over group status / politics"
    },
    "653e4bbf6229713df86a2057caa11d72": {
      "source_id": "653e4bbf6229713df86a2057caa11d72",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4121,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Welcome to Apply: The 2024 Vitalik Buterin Fellowships in AI Existential Safety "
    },
    "0dd831d1022055be5cde72c0a661c860": {
      "source_id": "0dd831d1022055be5cde72c0a661c860",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5882,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Public Opinion on AI Safety: AIMS 2023 and 2021 Summary"
    },
    "6bc172d0abb20b023102d5a7f9661c78": {
      "source_id": "6bc172d0abb20b023102d5a7f9661c78",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38218,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Inside the Mind of an Aspiring Charity Entrepreneur [Follow Along] #1 - From Lay"
    },
    "a533ca4274de351440aa0361dcab61ff": {
      "source_id": "a533ca4274de351440aa0361dcab61ff",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5245,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "International AI Institutions: a literature review of models, examples, and prop"
    },
    "22c3fbd7a37918ee140033aaf1029698": {
      "source_id": "22c3fbd7a37918ee140033aaf1029698",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30515,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "ARENA 2.0 - Impact Report"
    },
    "4a18d2b5d31cf4f6ef95891fc4a17af3": {
      "source_id": "4a18d2b5d31cf4f6ef95891fc4a17af3",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 194,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] Prospect Magazine - How to save humanity from extinction"
    },
    "f9bc1301dd425fc71a5282410ffb43c2": {
      "source_id": "f9bc1301dd425fc71a5282410ffb43c2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7053,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Tarbell Fellowship 2024 - Applications Open (AI Journalism)"
    },
    "6b8f3e19715c75369ca94d0faeab960f": {
      "source_id": "6b8f3e19715c75369ca94d0faeab960f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25774,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Culture and Programming Retrospective: ERA Fellowship 2023"
    },
    "27adb0fcca071e71bbb230ee42b5fac9": {
      "source_id": "27adb0fcca071e71bbb230ee42b5fac9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42991,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\"Diamondoid bacteria\" nanobots: deadly threat or dead-end? A nanotech investigat"
    },
    "1af5288c3a580d476443698bf81a702c": {
      "source_id": "1af5288c3a580d476443698bf81a702c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41685,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Retroactive Funding Landscape: Innovations for Donors and Grantmakers"
    },
    "9f078f378a54f1ac82a5c2c99938ada4": {
      "source_id": "9f078f378a54f1ac82a5c2c99938ada4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2296,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Anki deck for learning the main AI safety orgs, projects, and programs"
    },
    "f1f208aa465a91cfc5190ca93ee0e947": {
      "source_id": "f1f208aa465a91cfc5190ca93ee0e947",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11709,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Introducing Future Matters \u2013 a strategy consultancy"
    },
    "7d3a9a4af4e6fdfc33431327b792f1bd": {
      "source_id": "7d3a9a4af4e6fdfc33431327b792f1bd",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4709,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing the Winners of the 2023 Open Philanthropy AI Worldviews Contest"
    },
    "bad252c032b41bbd485b66740dc2e2f8": {
      "source_id": "bad252c032b41bbd485b66740dc2e2f8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15933,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Impact Markets: Your Charity Evaluator for AI Safety"
    },
    "d0e814c152b826879d42743d94c1f5d9": {
      "source_id": "d0e814c152b826879d42743d94c1f5d9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3779,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Join AISafety.info's Distillation Hackathon (Oct 6-9th)"
    },
    "558066b694c456d04095e1426a006b99": {
      "source_id": "558066b694c456d04095e1426a006b99",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44648,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Observations on the funding landscape of EA and AI safety"
    },
    "173e33da3a08ce34087ab94657d98328": {
      "source_id": "173e33da3a08ce34087ab94657d98328",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 70269,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Automated Parliaments \u2014 A Solution to Decision Uncertainty and Misalignment in L"
    },
    "b2f4ce494d5f43239208ac197516c04f": {
      "source_id": "b2f4ce494d5f43239208ac197516c04f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 85799,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Modelling large-scale cyber attacks from advanced AI systems with Advanced Persi"
    },
    "9bb3c04f09ecb0ede0f31685fafeb3e6": {
      "source_id": "9bb3c04f09ecb0ede0f31685fafeb3e6",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3222,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing FAR Labs, an AI safety coworking space"
    },
    "93e3c1eafae9a518b809612d352bb317": {
      "source_id": "93e3c1eafae9a518b809612d352bb317",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17416,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "De Dicto and De Se Reference Matters for Alignment"
    },
    "f2188dd31950f3bf4f2aedde83b8f949": {
      "source_id": "f2188dd31950f3bf4f2aedde83b8f949",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 469,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why isn't there a Charity Entrepreneurship program for AI Safety?"
    },
    "41259c1d615565494413f796c7dbf97c": {
      "source_id": "41259c1d615565494413f796c7dbf97c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13153,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISN #23: New OpenAI Models, News from Anthropic, and Representation Engineering"
    },
    "3d29c15428c37d8cdaca65b03008a019": {
      "source_id": "3d29c15428c37d8cdaca65b03008a019",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8781,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How Rethink Priorities\u2019 Research could inform your grantmaking"
    },
    "dad30abb263c6dd886db332a13b871e2": {
      "source_id": "dad30abb263c6dd886db332a13b871e2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2718,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Fiscal sponsorship, ops support, or incubation?"
    },
    "c26a72f989c80bf35943109db323c792": {
      "source_id": "c26a72f989c80bf35943109db323c792",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4783,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Stampy's AI Safety Info soft launch"
    },
    "bd910bb22c35ca32eb519ec37cbe54ca": {
      "source_id": "bd910bb22c35ca32eb519ec37cbe54ca",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44581,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What AI could mean for animals"
    },
    "0db7bcfd79f6e89f1c724c28908a5073": {
      "source_id": "0db7bcfd79f6e89f1c724c28908a5073",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31286,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Risk-averse Batch Active Inverse Reward Design"
    },
    "77816c90b041841a1bac54815988ac24": {
      "source_id": "77816c90b041841a1bac54815988ac24",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14315,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Fixing Insider Threats in the AI Supply Chain"
    },
    "b196e48f6dee0058a8571bd23a772b6b": {
      "source_id": "b196e48f6dee0058a8571bd23a772b6b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21638,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Silicon Valley\u2019s Rabbit Hole Problem"
    },
    "6f59771d7d4477ff7b313f0d89a4a90a": {
      "source_id": "6f59771d7d4477ff7b313f0d89a4a90a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3771,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI+bio cannot be half of AI catastrophe risk, right?"
    },
    "55f69b22a10bcb4998fa0574cf41aa3d": {
      "source_id": "55f69b22a10bcb4998fa0574cf41aa3d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35402,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Pause For Thought: The AI Pause Debate"
    },
    "6954c556d83e49be73a578aaebd63920": {
      "source_id": "6954c556d83e49be73a578aaebd63920",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17393,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Scale, schlep, and systems"
    },
    "a05b5021e5a97051902533d520b308cc": {
      "source_id": "a05b5021e5a97051902533d520b308cc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37844,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Timelines are short, p(doom) is high: a global stop to frontier AI development u"
    },
    "99d9468bce0ee225862f8237ec32c7ab": {
      "source_id": "99d9468bce0ee225862f8237ec32c7ab",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7462,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Resources & opportunities for careers in European AI Policy"
    },
    "25d09d758376c1e830a1ec1f2c37c85e": {
      "source_id": "25d09d758376c1e830a1ec1f2c37c85e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11182,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Opportunities for Impact Beyond the EU AI Act "
    },
    "a4d6399e465922f977f0810de7744698": {
      "source_id": "a4d6399e465922f977f0810de7744698",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9716,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The International PauseAI Protest: Activism under uncertainty"
    },
    "2e236753f5acb4629cd31c3a28e00316": {
      "source_id": "2e236753f5acb4629cd31c3a28e00316",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27449,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What he\u2019s learned as an AI policy insider (Tantum Collins on the 80,000 Hours Po"
    },
    "cbb75231cdd477155c17183585c18d62": {
      "source_id": "cbb75231cdd477155c17183585c18d62",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59008,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "If Contractualism, Then AMF"
    },
    "2927644fe3c0b4b54559e3fef0835603": {
      "source_id": "2927644fe3c0b4b54559e3fef0835603",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22325,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Assessing the Dangerousness of Malevolent Actors in AGI Governance: A Preliminar"
    },
    "16d648936412b994531bac7cfc9d83e0": {
      "source_id": "16d648936412b994531bac7cfc9d83e0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7159,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Neuronpedia - AI Safety Game"
    },
    "ebf5a8176617cf6452141e0e1c4ab3dc": {
      "source_id": "ebf5a8176617cf6452141e0e1c4ab3dc",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5117,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Beginner\u2019s guide to reducing s-risks [link-post]"
    },
    "845dbe848ebd9781b6eb13a747f3fdaf": {
      "source_id": "845dbe848ebd9781b6eb13a747f3fdaf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16174,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISN #24: Kissinger Urges US-China Cooperation on AI, China's New AI Law, US Exp"
    },
    "8e28a119d2130d40f30f0b34fdc9d782": {
      "source_id": "8e28a119d2130d40f30f0b34fdc9d782",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8783,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "New roles on my team: come build Open Phil's technical AI safety program with me"
    },
    "6395437aeff806c52fda3b70dd50fb13": {
      "source_id": "6395437aeff806c52fda3b70dd50fb13",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4330,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "TOMORROW: the largest AI Safety protest ever!"
    },
    "52b06092b5de4a02b8d58f265586a540": {
      "source_id": "52b06092b5de4a02b8d58f265586a540",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13965,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Apply for MATS Winter 2023-24!"
    },
    "e908d44bf91409d39d5d848a85bd39b8": {
      "source_id": "e908d44bf91409d39d5d848a85bd39b8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13890,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing Timaeus"
    },
    "d8deeb65888654e0b801fa674cd8254d": {
      "source_id": "d8deeb65888654e0b801fa674cd8254d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13815,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Fundamental Challenges in AI Governance"
    },
    "e9d1e1004d46fab3cba6202c94619a0b": {
      "source_id": "e9d1e1004d46fab3cba6202c94619a0b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4728,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Pausing AI might be good policy, but it's bad politics"
    },
    "b42a4319932c9ee45c54b3109e2ada59": {
      "source_id": "b42a4319932c9ee45c54b3109e2ada59",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 98295,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Shutdown Problem: Three Theorems"
    },
    "d76ac7f95e5fbf309e1e86db724f11ae": {
      "source_id": "d76ac7f95e5fbf309e1e86db724f11ae",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 969,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Help us design the interface for aisafety.com"
    },
    "f2725b4ca58d146e6c8e2b3bff2f758f": {
      "source_id": "f2725b4ca58d146e6c8e2b3bff2f758f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3208,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing #AISummitTalks featuring Professor Stuart Russell and many others"
    },
    "69d4a615a55b946e804307368c0b3ecc": {
      "source_id": "69d4a615a55b946e804307368c0b3ecc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 77586,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Go Mobilize? Lessons from GM Protests for Pausing AI"
    },
    "a387eaf2431142f13aee52d3d86ce9f7": {
      "source_id": "a387eaf2431142f13aee52d3d86ce9f7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11845,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Thoughts on responsible scaling policies and regulation"
    },
    "01e0e77602d19cbc023c8f78971ba3a2": {
      "source_id": "01e0e77602d19cbc023c8f78971ba3a2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9012,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Successif: Join our AI program to help mitigate the catastrophic risks of AI"
    },
    "9d1b14245216c8562fc2800b3bf956f6": {
      "source_id": "9d1b14245216c8562fc2800b3bf956f6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11053,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What we learned from running an Australian AI Safety Unconference"
    },
    "39d07df0ebb0b88b3b7f7e6450c18831": {
      "source_id": "39d07df0ebb0b88b3b7f7e6450c18831",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5524,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "CHAI internship applications are open (due Nov 13)"
    },
    "7f98e5321fac38a737130f5d8f402e49": {
      "source_id": "7f98e5321fac38a737130f5d8f402e49",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3109,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Apply to the Constellation Visiting Researcher Program and Astra Fellowship, in "
    },
    "d74e5e6053c708011bec6075ac46ab76": {
      "source_id": "d74e5e6053c708011bec6075ac46ab76",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13632,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "UK Prime Minister Rishi Sunak's Speech on AI"
    },
    "3b4a7975dd15d215e707a061737e3403": {
      "source_id": "3b4a7975dd15d215e707a061737e3403",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54838,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Efficacy of AI Activism: Have We Ever Said No?"
    },
    "dc99fc66ea54e48d95cd02941456363e": {
      "source_id": "dc99fc66ea54e48d95cd02941456363e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6767,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "New report on the state of AI safety in China"
    },
    "3db589f626d33c28254cf53615627a17": {
      "source_id": "3db589f626d33c28254cf53615627a17",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18927,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI safety field-building survey: Talent needs, infrastructure needs, and relatio"
    },
    "993d0900937e941c3d975916291a48ee": {
      "source_id": "993d0900937e941c3d975916291a48ee",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15502,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Summary: Existential risk from power-seeking AI by Joseph Carlsmith"
    },
    "da53a21ccaa3a5e693de5bbf6427aac9": {
      "source_id": "da53a21ccaa3a5e693de5bbf6427aac9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5829,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Regrant up to $600,000 to AI safety projects with GiveWiki"
    },
    "4699575251f30fab091df7b685f5a588": {
      "source_id": "4699575251f30fab091df7b685f5a588",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6736,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "President Biden Issues Executive Order on Safe, Secure, and Trustworthy Artifici"
    },
    "7eb1d3f2b0d4fc7869bcf440cef5a700": {
      "source_id": "7eb1d3f2b0d4fc7869bcf440cef5a700",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5302,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The UK AI Safety Summit tomorrow"
    },
    "4ce6bd1e2c947b5b0e46452ceae67a6d": {
      "source_id": "4ce6bd1e2c947b5b0e46452ceae67a6d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15429,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISN #25: White House Executive Order on AI, UK AI Safety Summit, and Progress o"
    },
    "75a8eb5bc13fde13ba8c2694748fbc4f": {
      "source_id": "75a8eb5bc13fde13ba8c2694748fbc4f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8933,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Bletchley Declaration on AI Safety"
    },
    "7e73a763c023a7b2b5842e07707591b6": {
      "source_id": "7e73a763c023a7b2b5842e07707591b6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13128,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Congressional Hearing] Oversight of A.I.: Legislating on Artificial Intelligenc"
    },
    "de060d84d2a1c6c8b830f82e634e18a8": {
      "source_id": "de060d84d2a1c6c8b830f82e634e18a8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 682,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Still no strong evidence that LLMs increase bioterrorism risk"
    },
    "32c40b4574c09f8d32c38f6fbf5c5261": {
      "source_id": "32c40b4574c09f8d32c38f6fbf5c5261",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2754,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Sam Altman: \"safety and capabilities are not these two separate things\""
    },
    "be1e2f23caaa40da742dfd93aba30c81": {
      "source_id": "be1e2f23caaa40da742dfd93aba30c81",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 689,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why is learning economics, psychology, sociology important for preventing AI ris"
    },
    "c6a6806e17191b7667b01a2c234fede8": {
      "source_id": "c6a6806e17191b7667b01a2c234fede8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2831,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Navigation Fund launched + is hiring a program officer to lead the distribut"
    },
    "3cd07715ec3928e5165108d5ccc6e81c": {
      "source_id": "3cd07715ec3928e5165108d5ccc6e81c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7048,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why building ventures in AI Safety is particularly challenging"
    },
    "858dd72fa2a4611307e3ec81a8b4ae83": {
      "source_id": "858dd72fa2a4611307e3ec81a8b4ae83",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6320,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Governance of AI, Breakfast Cereal, Car Factories, Etc."
    },
    "9147cbd78cb48ca7fd94ed9670cf0fc2": {
      "source_id": "9147cbd78cb48ca7fd94ed9670cf0fc2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4369,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Fables Writing Contest Winners!"
    },
    "2d06c484bb0cf191ee01f898a446563b": {
      "source_id": "2d06c484bb0cf191ee01f898a446563b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19159,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "20+ tips, tricks, lessons and thoughts on hosting hackathons"
    },
    "98d03704c554a5a531c1f344384e7a8e": {
      "source_id": "98d03704c554a5a531c1f344384e7a8e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3072,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Please, someone make a dataset of supposed cases of \"tech panic\""
    },
    "e939b8434e587046aa3408afc11cbf85": {
      "source_id": "e939b8434e587046aa3408afc11cbf85",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14531,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Alignment Research Engineer Accelerator (ARENA): call for applicants"
    },
    "6318ea7a7678638660328eb86f7bfdb7": {
      "source_id": "6318ea7a7678638660328eb86f7bfdb7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4349,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Scalable And Transferable Black-Box Jailbreaks For Language Models Via Persona M"
    },
    "e8dc4802a5ad4b30d12e07d68073cb69": {
      "source_id": "e8dc4802a5ad4b30d12e07d68073cb69",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29587,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What we're missing: the case for structural risks from AI"
    },
    "c9038c7cc075f2d08f5d9f714debb8d0": {
      "source_id": "c9038c7cc075f2d08f5d9f714debb8d0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20478,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "EA Poland is facing an existential risk"
    },
    "ccee152bb78427c07442c35560cfcaa7": {
      "source_id": "ccee152bb78427c07442c35560cfcaa7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6798,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Existential Risk of Speciesist Bias in AI"
    },
    "5f6b574c10a068e9a2d3c6c549fa0971": {
      "source_id": "5f6b574c10a068e9a2d3c6c549fa0971",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "eaforum",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17470,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Top AI Safety Bets for 2023: GiveWiki\u2019s Latest Recommendations"
    },
    "605898c7c25efc4af8c634fd621a468e": {
      "source_id": "605898c7c25efc4af8c634fd621a468e",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12863,
        "year": "2016",
        "has_tags": true
      },
      "title_preview": "A toy model of the treacherous turn"
    },
    "4afa6286ac5703e42edb58bbb7e73d48": {
      "source_id": "4afa6286ac5703e42edb58bbb7e73d48",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 237,
        "year": "2016",
        "has_tags": true
      },
      "title_preview": "[LINK] OpenAI doing an AMA today"
    },
    "edef9350314a68eb7236ffb54ce74b4f": {
      "source_id": "edef9350314a68eb7236ffb54ce74b4f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3928,
        "year": "2016",
        "has_tags": true
      },
      "title_preview": "To contribute to AI safety, consider doing AI research"
    },
    "893e9aa86222546c1a619a282026a5e1": {
      "source_id": "893e9aa86222546c1a619a282026a5e1",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53801,
        "year": "2016",
        "has_tags": true
      },
      "title_preview": "Book Review: Age of Em"
    },
    "22a7534e4c57dd07dfa945bc009f75ec": {
      "source_id": "22a7534e4c57dd07dfa945bc009f75ec",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6024,
        "year": "2016",
        "has_tags": true
      },
      "title_preview": "Superintelligence via whole brain emulation"
    },
    "baf72ac4aa7069e8e7a0289f5de017f8": {
      "source_id": "baf72ac4aa7069e8e7a0289f5de017f8",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49150,
        "year": "2016",
        "has_tags": true
      },
      "title_preview": "Superintelligence FAQ"
    },
    "d456fef6e0adee78a448cb02be43facd": {
      "source_id": "d456fef6e0adee78a448cb02be43facd",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22631,
        "year": "2016",
        "has_tags": true
      },
      "title_preview": "Is Global Reinforcement Learning (RL) a Fantasy?"
    },
    "9736b7ecfc0d3ad9022bb9ad5f998ec7": {
      "source_id": "9736b7ecfc0d3ad9022bb9ad5f998ec7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4505,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "Corrigibility thoughts II: the robot operator"
    },
    "f1e6e4c9e7ae1f248508c9d76134cda7": {
      "source_id": "f1e6e4c9e7ae1f248508c9d76134cda7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2908,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "Corrigibility thoughts III: manipulating versus deceiving"
    },
    "5f81d5794d85efe6ca3a0cc2d9d0f781": {
      "source_id": "5f81d5794d85efe6ca3a0cc2d9d0f781",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6069,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "Allegory On AI Risk, Game Theory, and Mithril"
    },
    "eee842a61f998a7bacbbc562c6dffedb": {
      "source_id": "eee842a61f998a7bacbbc562c6dffedb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8188,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "Could utility functions be for narrow AI only, and downright antithetical to AGI"
    },
    "de93ac97202c3ebe4f0ac54d1c49e512": {
      "source_id": "de93ac97202c3ebe4f0ac54d1c49e512",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12668,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "G.K. Chesterton On AI Risk"
    },
    "b8a42ad99b5bf3b456a1e62b29b4c7e0": {
      "source_id": "b8a42ad99b5bf3b456a1e62b29b4c7e0",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12392,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "OpenAI makes humanity less safe"
    },
    "3103f2978b7c8cd06f234086f3322ec2": {
      "source_id": "3103f2978b7c8cd06f234086f3322ec2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1446,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "An OpenAI board seat is surprisingly expensive"
    },
    "71bc2a3616fb2328ffa60da356d67c4f": {
      "source_id": "71bc2a3616fb2328ffa60da356d67c4f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6452,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "Existential risk from AI without an intelligence explosion"
    },
    "1982663b3dbf6cfef37042028667dc0d": {
      "source_id": "1982663b3dbf6cfef37042028667dc0d",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14100,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "SSC Journal Club: AI Timelines"
    },
    "d8ac7a3181edd93be56ac3ee33fcccbe": {
      "source_id": "d8ac7a3181edd93be56ac3ee33fcccbe",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46807,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "There's No Fire Alarm for Artificial General Intelligence"
    },
    "9014526621bdb9b4fe34f6f07bae2739": {
      "source_id": "9014526621bdb9b4fe34f6f07bae2739",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5009,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "Yudkowsky on AGI ethics"
    },
    "676e626b0cd7a0f4abbcd4eb7276911e": {
      "source_id": "676e626b0cd7a0f4abbcd4eb7276911e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5675,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "AlphaGo Zero and the Foom Debate"
    },
    "fd6085b08275369b0e0fb62edd62e8a6": {
      "source_id": "fd6085b08275369b0e0fb62edd62e8a6",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17210,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "\tMixed-Strategy Ratifiability Implies CDT=EDT"
    },
    "2619a51959800efa42c6be7532abf3e2": {
      "source_id": "2619a51959800efa42c6be7532abf3e2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1668,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "Military AI as a Convergent Goal of Self-Improving AI"
    },
    "095ea866a8335d572c9a700684a0f7d0": {
      "source_id": "095ea866a8335d572c9a700684a0f7d0",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11428,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "I Vouch For MIRI"
    },
    "c2867f043186cad4b47a06a28cdbb277": {
      "source_id": "c2867f043186cad4b47a06a28cdbb277",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51883,
        "year": "2017",
        "has_tags": true
      },
      "title_preview": "2017 AI Safety Literature Review and Charity Comparison "
    },
    "971db6c2f6daa04eced6fe29d553963a": {
      "source_id": "971db6c2f6daa04eced6fe29d553963a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4004,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Papers for 2017"
    },
    "c6cf28e9ec325fe4f6715526c61d812d": {
      "source_id": "c6cf28e9ec325fe4f6715526c61d812d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2506,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Global online debate on the governance of AI"
    },
    "c8658e34a775192166673c137f98493e": {
      "source_id": "c8658e34a775192166673c137f98493e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3264,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Neural program synthesis is a dangerous technology"
    },
    "b217692e7e22c2796aa36f1976494bac": {
      "source_id": "b217692e7e22c2796aa36f1976494bac",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7432,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Field-Building and Deep Models"
    },
    "a2625c5d643b60455a232eb968b79428": {
      "source_id": "a2625c5d643b60455a232eb968b79428",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3900,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Announcement: AI alignment prize winners and next round"
    },
    "4e05f41c2d1b2b7b4e164422a7d0d0dd": {
      "source_id": "4e05f41c2d1b2b7b4e164422a7d0d0dd",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11692,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "A model I use when making plans to reduce AI x-risk"
    },
    "87a0ccc56ab9c36b811c04301c0a6680": {
      "source_id": "87a0ccc56ab9c36b811c04301c0a6680",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24682,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "\"Taking AI Risk Seriously\" (thoughts by Critch)"
    },
    "ee0b9bbd24cd7ae47cfa90cf37a68ec4": {
      "source_id": "ee0b9bbd24cd7ae47cfa90cf37a68ec4",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4281,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Epiphenomenal Oracles Ignore Holes in the Box"
    },
    "fc5e1fb3ae6310f3a9f6d17f898a40b6": {
      "source_id": "fc5e1fb3ae6310f3a9f6d17f898a40b6",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18993,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "AI Safety Research Camp - Project Proposal"
    },
    "b271f43c19ef8ec635fc865284f1a917": {
      "source_id": "b271f43c19ef8ec635fc865284f1a917",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5158,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The Utility of Human Atoms for the Paperclip Maximizer"
    },
    "91d20c9909785879a7b437dd3c6545b0": {
      "source_id": "91d20c9909785879a7b437dd3c6545b0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7412,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Factorio, Accelerando, Empathizing with Empires and Moderate Takeoffs"
    },
    "d66f44c3a191588b784655a3f93d074f": {
      "source_id": "d66f44c3a191588b784655a3f93d074f",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 92110,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "A Safer Oracle Setup?"
    },
    "710994b93521e09bde5cc99c0db206e0": {
      "source_id": "710994b93521e09bde5cc99c0db206e0",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12331,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Some conceptual highlights from \u201cDisjunctive Scenarios of Catastrophic AI Risk\u201d"
    },
    "0be10ae4986ba6b82609ed6dd1c5e6bf": {
      "source_id": "0be10ae4986ba6b82609ed6dd1c5e6bf",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1871,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Will AI See Sudden Progress?"
    },
    "ba13dd24721047291bbfb581a5353197": {
      "source_id": "ba13dd24721047291bbfb581a5353197",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2226327,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Walkthrough of 'Formalizing Convergent Instrumental Goals'"
    },
    "08b88320f901e2f313eb269022e39912": {
      "source_id": "08b88320f901e2f313eb269022e39912",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 496201,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Takeoff Speed: Simple Asymptotics in a Toy Model."
    },
    "81add4ef947b871fe296499218c4e8b8": {
      "source_id": "81add4ef947b871fe296499218c4e8b8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7148,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "AI Alignment Prize: Round 2 due March 31, 2018"
    },
    "09e842ff71baba803c8dc7968c036349": {
      "source_id": "09e842ff71baba803c8dc7968c036349",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 182919,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "AI Alignment Prize: Super-Boxing "
    },
    "b75c539a011239db2ee62780b4a579e1": {
      "source_id": "b75c539a011239db2ee62780b4a579e1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1161,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Deciphering China's AI Dream"
    },
    "f184a7a5b838c23752eb9dd82640d339": {
      "source_id": "f184a7a5b838c23752eb9dd82640d339",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4189,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Is the Star Trek Federation really incapable of building AI?"
    },
    "08cf93b279cc96f72ff6192dd925e7a7": {
      "source_id": "08cf93b279cc96f72ff6192dd925e7a7",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12346,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "My Thoughts on Takeoff Speeds"
    },
    "5f79fdb797cfd199286b270d2585668e": {
      "source_id": "5f79fdb797cfd199286b270d2585668e",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20975,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Opportunities for individual donors in AI safety"
    },
    "752f1887cceaaad1bcc88374fb82f315": {
      "source_id": "752f1887cceaaad1bcc88374fb82f315",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3086,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Reframing misaligned AGI's: well-intentioned non-neurotypical assistants"
    },
    "f9748eb7d337cb7571ac8040cfe90d34": {
      "source_id": "f9748eb7d337cb7571ac8040cfe90d34",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11497,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Corrigible but misaligned:   a superintelligent messiah"
    },
    "e677e54b1f00ad8467bc3da9f91bcd41": {
      "source_id": "e677e54b1f00ad8467bc3da9f91bcd41",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7613,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Critique my Model: The EV of AGI to Selfish Individuals"
    },
    "ee65345c4be4ae44de36b0fe655f9757": {
      "source_id": "ee65345c4be4ae44de36b0fe655f9757",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9650,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The limits of corrigibility"
    },
    "da6f6800a7c8be7b55c3d5e2ed6fd087": {
      "source_id": "da6f6800a7c8be7b55c3d5e2ed6fd087",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28668,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Utility versus Reward function: partial equivalence"
    },
    "21bd3550a7b72b5d5385547c8e07f9c5": {
      "source_id": "21bd3550a7b72b5d5385547c8e07f9c5",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11994,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Implicit extortion"
    },
    "fd44cace91c1246822515ff1c1a4f08e": {
      "source_id": "fd44cace91c1246822515ff1c1a4f08e",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34020,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Reward function learning: the learning process"
    },
    "acaff5b55e2240a10d719a48d93fe0bd": {
      "source_id": "acaff5b55e2240a10d719a48d93fe0bd",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21267,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Double Cruxing the AI Foom debate"
    },
    "1ae555a95043b8a5f394886236d0f991": {
      "source_id": "1ae555a95043b8a5f394886236d0f991",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 78764,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": " Levels of AI Self-Improvement "
    },
    "8efcc97a5b2d43183e4e0e1b9f747b15": {
      "source_id": "8efcc97a5b2d43183e4e0e1b9f747b15",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2806,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Soon: a weekly AI Safety prerequisites module on LessWrong"
    },
    "7b05e3ade0b5e48b3ed4c4b7404790bc": {
      "source_id": "7b05e3ade0b5e48b3ed4c4b7404790bc",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11458,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Everything I ever needed to know, I learned from World of Warcraft: Goodhart\u2019s l"
    },
    "dbb452690b9beafa3cf599bc95d4c09d": {
      "source_id": "dbb452690b9beafa3cf599bc95d4c09d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 696,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "AGI Safety Literature Review (Everitt, Lea & Hutter 2018)"
    },
    "de6aa1b79cfea70ec38fded53c07d744": {
      "source_id": "de6aa1b79cfea70ec38fded53c07d744",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11705,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Thoughts on AI Safety via Debate"
    },
    "d80d4927412069a994304cf3a9e94e67": {
      "source_id": "d80d4927412069a994304cf3a9e94e67",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8145,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Lotuses and Loot Boxes"
    },
    "0e95c1daaf786a063b32940adfef2580": {
      "source_id": "0e95c1daaf786a063b32940adfef2580",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18053,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "When is unaligned AI morally valuable?"
    },
    "6d09d5c4605d1733a9974e1a1428590e": {
      "source_id": "6d09d5c4605d1733a9974e1a1428590e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3587,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The simple picture on AI safety"
    },
    "e59aac9cf333fd6bb1f79483f71b8093": {
      "source_id": "e59aac9cf333fd6bb1f79483f71b8093",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16430,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Swimming Upstream: A Case Study in Instrumental Rationality"
    },
    "0765dd929e7f4da1d35cedc7581ef4f5": {
      "source_id": "0765dd929e7f4da1d35cedc7581ef4f5",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16083,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The first AI Safety Camp & onwards"
    },
    "e20d4d72d32240109520045ebb3296ab": {
      "source_id": "e20d4d72d32240109520045ebb3296ab",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1774,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Announcing the second AI Safety Camp"
    },
    "2594d92e0ea1a63ef356ca07ae9bdbb8": {
      "source_id": "2594d92e0ea1a63ef356ca07ae9bdbb8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5387,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "How many philosophers accept the orthogonality thesis ? Evidence from the PhilPa"
    },
    "b802c8f04c242659a5b0da35554564a4": {
      "source_id": "b802c8f04c242659a5b0da35554564a4",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12350,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Goodhart Taxonomy: Agreement"
    },
    "056dc68b0208dba3a50dd1fadb4ab25f": {
      "source_id": "056dc68b0208dba3a50dd1fadb4ab25f",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1233647,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Making a Difference Tempore: Insights from 'Reinforcement Learning: An Introduct"
    },
    "9ff245754c263358adc1683afb904fa8": {
      "source_id": "9ff245754c263358adc1683afb904fa8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4413,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Study on what makes people approve or condemn mind upload technology; references"
    },
    "c3b9ca8933f45a1092c61f31103bc623": {
      "source_id": "c3b9ca8933f45a1092c61f31103bc623",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6670,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Are pre-specified utility functions about the real world possible in principle?"
    },
    "10e2828a08bd7ce657d6970f1b4b7de7": {
      "source_id": "10e2828a08bd7ce657d6970f1b4b7de7",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11635,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Can few-shot learning teach AI right from wrong?"
    },
    "0b2fd9658b9e0881b75705e9b6a82d0a": {
      "source_id": "0b2fd9658b9e0881b75705e9b6a82d0a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5039,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Computational efficiency reasons not to model VNM-rational preference relations "
    },
    "27dac03db75a05637e6b864369e58f4b": {
      "source_id": "27dac03db75a05637e6b864369e58f4b",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46212,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Narrow AI Nanny:  Reaching Strategic Advantage via Narrow AI to Prevent Creation"
    },
    "21fd52480b0070e5a110b5560340e6f9": {
      "source_id": "21fd52480b0070e5a110b5560340e6f9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2619,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Algo trading is a central example of AI risk"
    },
    "fc951a8be14d891399401b9daafbe723": {
      "source_id": "fc951a8be14d891399401b9daafbe723",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26901,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Book Review: AI Safety and Security"
    },
    "ac3ff783b577caf7cdf2cfade3c1bd80": {
      "source_id": "ac3ff783b577caf7cdf2cfade3c1bd80",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8933,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "HLAI 2018 Field Report"
    },
    "d42af680785114009538d927fcd00490": {
      "source_id": "d42af680785114009538d927fcd00490",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9566,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "(Some?) Possible Multi-Agent Goodhart Interactions"
    },
    "80aca7419e8bcfc0dd74cbec3c78b562": {
      "source_id": "80aca7419e8bcfc0dd74cbec3c78b562",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8594,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Deep learning - deeper flaws?"
    },
    "b930f039e56f33dd02eff7374f13b011": {
      "source_id": "b930f039e56f33dd02eff7374f13b011",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27503,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Leto among the Machines "
    },
    "e3b99f118449b2ab784a77ec37b0ac24": {
      "source_id": "e3b99f118449b2ab784a77ec37b0ac24",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22418,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Some cruxes on impactful alternatives to AI policy work"
    },
    "bc50bd58a9f6e358d8e9a00b993124c9": {
      "source_id": "bc50bd58a9f6e358d8e9a00b993124c9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8430,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Current AI Safety Roles for Software Engineers"
    },
    "5ab1811343d97c508e1ce3bf2be2efac": {
      "source_id": "5ab1811343d97c508e1ce3bf2be2efac",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3225,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Values Weren't Complex, Once."
    },
    "89001808a30fc219c06aedc463872a74": {
      "source_id": "89001808a30fc219c06aedc463872a74",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17627,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "Should ethicists be inside or outside a profession?"
    },
    "a01f92794618eb42f18cdd5402b7ce4f": {
      "source_id": "a01f92794618eb42f18cdd5402b7ce4f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1821,
        "year": "2018",
        "has_tags": true
      },
      "title_preview": "The E-Coli Test for AI Alignment"
    },
    "41cd51c772fe26ef982aecabec69275c": {
      "source_id": "41cd51c772fe26ef982aecabec69275c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1631,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Why is so much discussion happening in private Google Docs?"
    },
    "18398ccbc3cdb139901a73dec7ee4801": {
      "source_id": "18398ccbc3cdb139901a73dec7ee4801",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32261,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "What AI Safety Researchers Have Written About the Nature of Human Values"
    },
    "af31eaa25254c8fc8077c2e65e5aed8e": {
      "source_id": "af31eaa25254c8fc8077c2e65e5aed8e",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14494,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "The reward engineering problem "
    },
    "ba703344c068a2bd6421710bde01414e": {
      "source_id": "ba703344c068a2bd6421710bde01414e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4432,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Debate AI and the Decision to Release an AI"
    },
    "f0b764f9304b46f5dfe56e184cc856bc": {
      "source_id": "f0b764f9304b46f5dfe56e184cc856bc",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21362,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Thoughts on reward engineering "
    },
    "304bc337a44fc2826a8582ada8b4507c": {
      "source_id": "304bc337a44fc2826a8582ada8b4507c",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20639,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Drexler on AI Risk"
    },
    "344d48304ec5f747a1c9cc4d828518f3": {
      "source_id": "344d48304ec5f747a1c9cc4d828518f3",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33023,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "(notes on) Policy Desiderata for Superintelligent AI: A Vector Field Approach"
    },
    "b72910cfa7934d3c8f0772879418f433": {
      "source_id": "b72910cfa7934d3c8f0772879418f433",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2444,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Some disjunctive reasons for urgency on AI risk"
    },
    "4030ff99d63288a56e6b946f6ae6c462": {
      "source_id": "4030ff99d63288a56e6b946f6ae6c462",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2490,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Limiting an AGI's Context Temporally"
    },
    "c70257d7377a94e03fbd22eb3c8be14a": {
      "source_id": "c70257d7377a94e03fbd22eb3c8be14a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4739,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Robin Hanson on Lumpiness of AI Services"
    },
    "4c67af67ca0086fcf1bc8ea5e5942fa6": {
      "source_id": "4c67af67ca0086fcf1bc8ea5e5942fa6",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 908,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[Link] OpenAI on why we need social scientists"
    },
    "e42290ee8b41b5a764a744d85c464ab9": {
      "source_id": "e42290ee8b41b5a764a744d85c464ab9",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11451,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Humans Who Are Not Concentrating Are Not General Intelligences"
    },
    "2d0e06761da4a0ff5b679c8b2abfcc72": {
      "source_id": "2d0e06761da4a0ff5b679c8b2abfcc72",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2142,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "RAISE is launching their MVP"
    },
    "0b919e797e461ab6c9f47a0e93d6d209": {
      "source_id": "0b919e797e461ab6c9f47a0e93d6d209",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2329,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "What are CAIS' boldest near/medium-term predictions?"
    },
    "85250a94199df06483b2e3d7fddf346f": {
      "source_id": "85250a94199df06483b2e3d7fddf346f",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15937,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "On AI and Compute"
    },
    "1af8de69cb699dd359397b377b19f0f8": {
      "source_id": "1af8de69cb699dd359397b377b19f0f8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1148,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Any rebuttals of Christiano and AI Impacts on takeoff speeds?"
    },
    "971dd00421a7fa8564353f78fa733d04": {
      "source_id": "971dd00421a7fa8564353f78fa733d04",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 86443,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": " AI Alignment Problem:  \u201cHuman Values\u201d don\u2019t Actually Exist"
    },
    "3747d42c6b571f434b264577572cc128": {
      "source_id": "3747d42c6b571f434b264577572cc128",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5146,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Value learning for moral essentialists"
    },
    "c96fc8b3e8ad09c14ca8d9023b65d27a": {
      "source_id": "c96fc8b3e8ad09c14ca8d9023b65d27a",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 65823,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Coherent decisions imply consistent utilities"
    },
    "7f066b54f43625ef5a7473c61bc68ef6": {
      "source_id": "7f066b54f43625ef5a7473c61bc68ef6",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1937,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Where are people thinking and talking about global coordination for AI safety?"
    },
    "47d61de573e153662aced0c88804e1c5": {
      "source_id": "47d61de573e153662aced0c88804e1c5",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42662,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Risks from Learned Optimization: Introduction"
    },
    "ec78dc9d1b3f26b159e2a0d366b5d790": {
      "source_id": "ec78dc9d1b3f26b159e2a0d366b5d790",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41830,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Conditions for Mesa-Optimization"
    },
    "d00fc9b7bbbe0e90e3e415cf40c0251f": {
      "source_id": "d00fc9b7bbbe0e90e3e415cf40c0251f",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43961,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "The Inner Alignment Problem"
    },
    "ca500ccf8bc1069aab47bc47aa060a2a": {
      "source_id": "ca500ccf8bc1069aab47bc47aa060a2a",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 52542,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Deceptive Alignment"
    },
    "410eec991a7556adaa251ec6fc1289b8": {
      "source_id": "410eec991a7556adaa251ec6fc1289b8",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30758,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Risks from Learned Optimization: Conclusion and Related Work"
    },
    "0b0bd29b8fa95912677e6466742881bf": {
      "source_id": "0b0bd29b8fa95912677e6466742881bf",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16741,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "The Hacker Learns to Trust"
    },
    "cd380e89035a1176184639cb57b7e296": {
      "source_id": "cd380e89035a1176184639cb57b7e296",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 948,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Is AlphaZero any good without the tree search?"
    },
    "41eb08da174e3fdb96c0943cef26a7b2": {
      "source_id": "41eb08da174e3fdb96c0943cef26a7b2",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15539,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "The AI Timelines Scam"
    },
    "bedd75d7c3813048053e1234529a7798": {
      "source_id": "bedd75d7c3813048053e1234529a7798",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40377,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Jeff Hawkins on neuromorphic AGI within 20 years"
    },
    "472726f27a30e82e809a5e0840345805": {
      "source_id": "472726f27a30e82e809a5e0840345805",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16641,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "The Self-Unaware AI Oracle"
    },
    "2754a507e8c6db30eb67bb956eec7672": {
      "source_id": "2754a507e8c6db30eb67bb956eec7672",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5567,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Does it become easier, or harder, for the world to coordinate around not buildin"
    },
    "c33d5403fa17459f01871667547a1a03": {
      "source_id": "c33d5403fa17459f01871667547a1a03",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 19718,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[AN #61]\u00a0AI policy and governance, from two people in the field"
    },
    "ff4337e8c79d6b7b97761a90896d86ad": {
      "source_id": "ff4337e8c79d6b7b97761a90896d86ad",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7771,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "In defense of Oracle (\"Tool\") AI research"
    },
    "f90e690629b13cbe4e334a2cb647aa56": {
      "source_id": "f90e690629b13cbe4e334a2cb647aa56",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 829,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Which of these five AI alignment research projects ideas are no good?"
    },
    "e9a080a28989e28696e33deac5df2f82": {
      "source_id": "e9a080a28989e28696e33deac5df2f82",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3239,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "2-D Robustness"
    },
    "b7986c97cc58691be0eb7cd3bafe57a2": {
      "source_id": "b7986c97cc58691be0eb7cd3bafe57a2",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23790,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Utility \u2260 Reward"
    },
    "e9e5107e11fa4559d983258bf773aaa7": {
      "source_id": "e9e5107e11fa4559d983258bf773aaa7",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11942,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Three Stories for How AGI Comes Before FAI"
    },
    "dc1a6743affea826d6eb038e43e6d186": {
      "source_id": "dc1a6743affea826d6eb038e43e6d186",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4614,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "The problem/solution matrix: Calculating the probability of AI safety \"on the ba"
    },
    "936c1bf9a151bd379e4392878626e890": {
      "source_id": "936c1bf9a151bd379e4392878626e890",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3989,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "The new dot com bubble is here: it\u2019s called online advertising"
    },
    "7f096fa4981cbb3ca0a3845c7961fd09": {
      "source_id": "7f096fa4981cbb3ca0a3845c7961fd09",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8770,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Thinking of tool AIs"
    },
    "743cc4354e1fc8dacfec1f9268cef168": {
      "source_id": "743cc4354e1fc8dacfec1f9268cef168",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14113,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Thoughts on Robin Hanson's AI Impacts interview"
    },
    "89a2ac5d9f41161bee374877b41f7bc1": {
      "source_id": "89a2ac5d9f41161bee374877b41f7bc1",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33067,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": " Oracles: reject all deals - break superrationality, with superrationality"
    },
    "6e898e636155162c524bd8ecf30d6ffe": {
      "source_id": "6e898e636155162c524bd8ecf30d6ffe",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5579,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Preface to CLR's Research Agenda on Cooperation, Conflict, and TAI "
    },
    "67b988ec13a157ccb51f5622e897db63": {
      "source_id": "67b988ec13a157ccb51f5622e897db63",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42313,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Sections 3 & 4: Credibility, Peaceful Bargaining Mechanisms "
    },
    "38277108322d5f08d4a1c36edc6f02c7": {
      "source_id": "38277108322d5f08d4a1c36edc6f02c7",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30578,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[Part 2] Amplifying generalist research via forecasting \u2013 results from a prelimi"
    },
    "8d23f7ea1f5e30ab5e254e8da0537ef2": {
      "source_id": "8d23f7ea1f5e30ab5e254e8da0537ef2",
      "quality_score": 6.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37601,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "[Part 1] Amplifying generalist research via forecasting \u2013 Models of impact and c"
    },
    "621613c8a149cf8bd43876c33814f7a0": {
      "source_id": "621613c8a149cf8bd43876c33814f7a0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6139,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Might humans not be the most intelligent animals?"
    },
    "f7e6f294e257e137821c58f39c7b3813": {
      "source_id": "f7e6f294e257e137821c58f39c7b3813",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7932,
        "year": "2019",
        "has_tags": true
      },
      "title_preview": "Another AI Winter?"
    },
    "c98f16b102ca107cd0331a51cec89fe3": {
      "source_id": "c98f16b102ca107cd0331a51cec89fe3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 963,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Since figuring out human values is hard, what about, say, monkey values?"
    },
    "54390cbca24f8197af9660573e750608": {
      "source_id": "54390cbca24f8197af9660573e750608",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18814,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Dissolving Confusion around Functional Decision Theory"
    },
    "c77564ab142335822e81307f2ee9079b": {
      "source_id": "c77564ab142335822e81307f2ee9079b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1283,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What is the relationship between Preference Learning and Value Learning?"
    },
    "adf985536f31f25396df8b605604cdcf": {
      "source_id": "adf985536f31f25396df8b605604cdcf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10605,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "A rant against robots"
    },
    "2fbb9ebc90a1401e2a038543f000e11a": {
      "source_id": "2fbb9ebc90a1401e2a038543f000e11a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5473,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "In Defense of the Arms Races\u2026 that End Arms Races"
    },
    "0b069d4a1bf1101c8bb5e340e75630cd": {
      "source_id": "0b069d4a1bf1101c8bb5e340e75630cd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11715,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Book review: Human Compatible"
    },
    "e115b9b0b03fb582b00479addc7f4d2c": {
      "source_id": "e115b9b0b03fb582b00479addc7f4d2c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 616,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Slide deck: Introduction to AI Safety"
    },
    "aca71dfdfdc0efadfe0999b53b93f9ab": {
      "source_id": "aca71dfdfdc0efadfe0999b53b93f9ab",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31097,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Value uncertainty"
    },
    "c8f9ac14b6a80969773eb20767acb1d7": {
      "source_id": "c8f9ac14b6a80969773eb20767acb1d7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30925,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Book Review: Human Compatible"
    },
    "d6b329bf48328944e36018001fce9098": {
      "source_id": "d6b329bf48328944e36018001fce9098",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2265,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What do you make of AGI:unaligned::spaceships:not enough food?"
    },
    "aa26fc5151810de13f92e77bd45fdcc6": {
      "source_id": "aa26fc5151810de13f92e77bd45fdcc6",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3360,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "New article from Oren Etzioni"
    },
    "16ae21eacdd08e6e3c9457a24a7ab472": {
      "source_id": "16ae21eacdd08e6e3c9457a24a7ab472",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11614,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "If I were a well-intentioned AI... I: Image classifier"
    },
    "5ac7331067baeb6668bee1cc9a69f772": {
      "source_id": "5ac7331067baeb6668bee1cc9a69f772",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23120,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "If I were a well-intentioned AI... II: Acting in a world"
    },
    "b57ed0c361834a48f52f6667ae935b68": {
      "source_id": "b57ed0c361834a48f52f6667ae935b68",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15133,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Response to Oren Etzioni's \"How to know if artificial intelligence is about to d"
    },
    "7d32de3f8ddfb84f7803affd9196e67e": {
      "source_id": "7d32de3f8ddfb84f7803affd9196e67e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17841,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "My Updating Thoughts on AI policy"
    },
    "de1e4ff798014116df5bf2e7908e67fe": {
      "source_id": "de1e4ff798014116df5bf2e7908e67fe",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28798,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "If I were a well-intentioned AI... IV: Mesa-optimising"
    },
    "ff3686f013c296c77f38c835c2f33374": {
      "source_id": "ff3686f013c296c77f38c835c2f33374",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19628,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "A Proof Against Oracle AI"
    },
    "a8fbe677133900870a68424995821a1a": {
      "source_id": "a8fbe677133900870a68424995821a1a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7714,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Why don't singularitarians bet on the creation of AGI by buying stocks?"
    },
    "835b6948ccad7d4b4da69f8396213eb1": {
      "source_id": "835b6948ccad7d4b4da69f8396213eb1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15938,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "How special are human brains among animal brains? "
    },
    "930e3f050e539b366b1dc225c03cb22b": {
      "source_id": "930e3f050e539b366b1dc225c03cb22b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 519,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What achievements have people claimed will be warning signs for AGI?"
    },
    "390e61349d41b696a816004a13c8f43f": {
      "source_id": "390e61349d41b696a816004a13c8f43f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19855,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": " Equilibrium and prior selection problems in multipolar deployment"
    },
    "834ab66fbe8add353775090c1c5f1015": {
      "source_id": "834ab66fbe8add353775090c1c5f1015",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25837,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Takeaways from safety by default interviews"
    },
    "38eee92692564095522521791b132796": {
      "source_id": "38eee92692564095522521791b132796",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 78336,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Discontinuous progress in history: an update"
    },
    "6e28e943db9e2d2c8258c02310ffe4ab": {
      "source_id": "6e28e943db9e2d2c8258c02310ffe4ab",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 483,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What are the relative speeds of AI capabilities and AI safety?"
    },
    "7c07e20057ddb0200bcbeebfd46294cc": {
      "source_id": "7c07e20057ddb0200bcbeebfd46294cc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3848,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Fast Takeoff in Biological Intelligence"
    },
    "3d196947b12e2c57c9301610500166b4": {
      "source_id": "3d196947b12e2c57c9301610500166b4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 106315,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Optimising Society to Constrain Risk of War from an Artificial Superintelligence"
    },
    "01ff79a25c413a1cc11d64d4b6993b37": {
      "source_id": "01ff79a25c413a1cc11d64d4b6993b37",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12955,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Stanford Encyclopedia of Philosophy on AI ethics and superintelligence"
    },
    "b8196edc1988ee6347d91b6ad194e686": {
      "source_id": "b8196edc1988ee6347d91b6ad194e686",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 867,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "\"Don't even think about hell\""
    },
    "2145e67a02c7480c0227098aaddf2b3c": {
      "source_id": "2145e67a02c7480c0227098aaddf2b3c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14194,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Specification gaming: the flip side of AI ingenuity"
    },
    "fa6fb1543c3eff7232e4b6ce25d46023": {
      "source_id": "fa6fb1543c3eff7232e4b6ce25d46023",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 534,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "If AI is based on GPT, how to ensure its safety?"
    },
    "513653d4f2f22457a24378e3e9e5383c": {
      "source_id": "513653d4f2f22457a24378e3e9e5383c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23810,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What's Your Cognitive Algorithm?"
    },
    "995a66eb091d430878553104e84e9b53": {
      "source_id": "995a66eb091d430878553104e84e9b53",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16074,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "How do takeoff speeds affect the probability of bad outcomes from AGI?"
    },
    "0845024dde7b54250a7cc15500ff9176": {
      "source_id": "0845024dde7b54250a7cc15500ff9176",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13742,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Research ideas to study humans with AI Safety in mind"
    },
    "2584651a6779b1616ded162786460748": {
      "source_id": "2584651a6779b1616ded162786460748",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7679,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Splitting Debate up  into Two Subsystems"
    },
    "285a5ce2460ec435279827ad2cc94ca4": {
      "source_id": "285a5ce2460ec435279827ad2cc94ca4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16381,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Solving Math Problems by Relay"
    },
    "7cb35f71d5755d5413b908739b4161fc": {
      "source_id": "7cb35f71d5755d5413b908739b4161fc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1066,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "\"Do Nothing\" utility function, 3\u00bd years later?"
    },
    "4f96469f8e2de9f259fd12a122e82156": {
      "source_id": "4f96469f8e2de9f259fd12a122e82156",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28986,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "The \"AI Dungeons\" Dragon Model is heavily path dependent (testing GPT-3 on ethic"
    },
    "6f7ef1e472043eb53140c8d5aed1ebb2": {
      "source_id": "6f7ef1e472043eb53140c8d5aed1ebb2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5357,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "How good is humanity at coordination?"
    },
    "00ba5576d96f6f4963f2dbb3adb103a1": {
      "source_id": "00ba5576d96f6f4963f2dbb3adb103a1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 101619,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "GPT-3 Gems"
    },
    "874b2b37dc8c64503953e3c56ae3511d": {
      "source_id": "874b2b37dc8c64503953e3c56ae3511d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7730,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Writing with GPT-3"
    },
    "1e9eb705bbc526383cb42d44be54a75d": {
      "source_id": "1e9eb705bbc526383cb42d44be54a75d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 371,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "How will internet forums like LW be able to defend against GPT-style spam?"
    },
    "262ce36af95f5e7c276f5c1782e7cd3c": {
      "source_id": "262ce36af95f5e7c276f5c1782e7cd3c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6055,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Engaging Seriously with Short Timelines"
    },
    "938204689d389975d5e567321ee0ed2d": {
      "source_id": "938204689d389975d5e567321ee0ed2d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1337,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Is the work on AI alignment relevant to GPT?"
    },
    "0b1fe2f044052f066c736d3e0386b3de": {
      "source_id": "0b1fe2f044052f066c736d3e0386b3de",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4321,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Agentic Language Model Memes"
    },
    "6d3c00eae75c36ef4c0c826858a8a732": {
      "source_id": "6d3c00eae75c36ef4c0c826858a8a732",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 955,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What should an Einstein-like figure in Machine Learning do?"
    },
    "0fe7632f4f4ce3d71d022425dbad4f17": {
      "source_id": "0fe7632f4f4ce3d71d022425dbad4f17",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5851,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "misc raw responses to a tract of Critical Rationalism"
    },
    "7a2eeb67972f892ad65a34bdea35fd15": {
      "source_id": "7a2eeb67972f892ad65a34bdea35fd15",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2644,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Thoughts on the Feasibility of Prosaic AGI Alignment?"
    },
    "c3fdf9a42b063c2f6dd7b7b17eae80c3": {
      "source_id": "c3fdf9a42b063c2f6dd7b7b17eae80c3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2896,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "A trick for Safer GPT-N"
    },
    "bad9d57232ab74f5a218371018641726": {
      "source_id": "bad9d57232ab74f5a218371018641726",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8724,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Preface to the sequence on economic growth"
    },
    "0db072246f82b927555b8b573116304b": {
      "source_id": "0db072246f82b927555b8b573116304b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 582,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "(Humor) AI Alignment Critical Failure Table"
    },
    "edac1016c296d9ace21f8ef49cfe8865": {
      "source_id": "edac1016c296d9ace21f8ef49cfe8865",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4691,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "How easily can we separate a friendly AI in design space from one which would br"
    },
    "26f2def1c9df58ab8972f60abeff9394": {
      "source_id": "26f2def1c9df58ab8972f60abeff9394",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15518,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "on\u00a0\u201clearning to summarize\u201d"
    },
    "872a7b969dedb90d60887d421b9dde5d": {
      "source_id": "872a7b969dedb90d60887d421b9dde5d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3603,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "How Much Computational Power Does It Take to Match the Human Brain?"
    },
    "a6b53a059c938862ae152008b033cf74": {
      "source_id": "a6b53a059c938862ae152008b033cf74",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9222,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Artificial Intelligence: A Modern Approach (4th edition) on the Alignment Proble"
    },
    "a53bcb03e9e7165bc1581f90734df9f2": {
      "source_id": "a53bcb03e9e7165bc1581f90734df9f2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19343,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Where is human level on text prediction? (GPTs task)"
    },
    "2c2d3b3452984950de7cdc5ac5f4d663": {
      "source_id": "2c2d3b3452984950de7cdc5ac5f4d663",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4704,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Forecasting Thread: Existential Risk"
    },
    "96e2e1c2cf900c89031a4edc54ac2815": {
      "source_id": "96e2e1c2cf900c89031a4edc54ac2815",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1663,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "A long reply to Ben Garfinkel on Scrutinizing Classic AI Risk Arguments"
    },
    "eaf02c69b781dd25607ddcd8a7877f73": {
      "source_id": "eaf02c69b781dd25607ddcd8a7877f73",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 461,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Competence vs Alignment"
    },
    "851c534905b2555ff99e1cbc628fb6d7": {
      "source_id": "851c534905b2555ff99e1cbc628fb6d7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26961,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "AI race considerations in a report by the U.S. House Committee on Armed Services"
    },
    "67061eedcfa5b8f23718bd8691727b1f": {
      "source_id": "67061eedcfa5b8f23718bd8691727b1f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50061,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Logical Foundations of Government Policy"
    },
    "5cf804e525954b1129026e634f960056": {
      "source_id": "5cf804e525954b1129026e634f960056",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2795,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "The Achilles Heel Hypothesis for AI"
    },
    "223a4269120442ad38a250b57c9579e5": {
      "source_id": "223a4269120442ad38a250b57c9579e5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11040,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "The Colliding Exponentials of AI"
    },
    "30ed827303c94555448be23401648896": {
      "source_id": "30ed827303c94555448be23401648896",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 653,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "What considerations influence whether I have more influence over short or long t"
    },
    "36e196d7f09a7b747064af190a8c63f3": {
      "source_id": "36e196d7f09a7b747064af190a8c63f3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2709,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "How can I bet on short timelines?"
    },
    "1d01d2007316e29bfac4da81f2b41a5e": {
      "source_id": "1d01d2007316e29bfac4da81f2b41a5e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2716,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "European Master's Programs in Machine Learning, Artificial Intelligence, and rel"
    },
    "c656623e9cd53e49c520591b994979c2": {
      "source_id": "c656623e9cd53e49c520591b994979c2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5456,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "How Roodman's GWP model translates to TAI timelines"
    },
    "6c1e96d99c6ad5c43b70d128f117055a": {
      "source_id": "6c1e96d99c6ad5c43b70d128f117055a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5045,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Should we postpone AGI until we reach safety?"
    },
    "2beb4aa42d71c8a2569fa1967bfe72f1": {
      "source_id": "2beb4aa42d71c8a2569fa1967bfe72f1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8143,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Delegated agents in practice:  How companies might end up selling AI services th"
    },
    "78afd07e0ded61af61d83cbfc2b30507": {
      "source_id": "78afd07e0ded61af61d83cbfc2b30507",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 734,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "In a multipolar scenario, how do people expect systems to be trained to interact"
    },
    "a567343baa6d2b59db3a73afc20c544a": {
      "source_id": "a567343baa6d2b59db3a73afc20c544a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5421,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "The AI Safety Game (UPDATED)"
    },
    "90e99e26e89789426c7b3b73e62e2e9b": {
      "source_id": "90e99e26e89789426c7b3b73e62e2e9b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2105,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Beta test GPT-3 based research assistant"
    },
    "0f517cdec2274cf50ade587da897cd44": {
      "source_id": "0f517cdec2274cf50ade587da897cd44",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27952,
        "year": "2020",
        "has_tags": true
      },
      "title_preview": "Intuition"
    },
    "abc00282ae7477044e4a0197b1696b58": {
      "source_id": "abc00282ae7477044e4a0197b1696b58",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11132,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Are we all misaligned?"
    },
    "eebc988b3e3f45f37a8b6c88b668f5fc": {
      "source_id": "eebc988b3e3f45f37a8b6c88b668f5fc",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5282,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Mental subagent implications for AI Safety"
    },
    "80e725263ab0963410f0a86a7bc24dc8": {
      "source_id": "80e725263ab0963410f0a86a7bc24dc8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1985,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The National Defense Authorization Act Contains AI Provisions"
    },
    "273b94540d46580bdf15f6fcc0a14d52": {
      "source_id": "273b94540d46580bdf15f6fcc0a14d52",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1256,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "How is reinforcement learning possible in non-sentient agents?"
    },
    "ea5cf991f6be3a3762a5c37fdea9c489": {
      "source_id": "ea5cf991f6be3a3762a5c37fdea9c489",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8806,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Grey Goo Requires AI"
    },
    "b2623dc43e9609d52cc676ad48aa25ba": {
      "source_id": "b2623dc43e9609d52cc676ad48aa25ba",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22054,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The Problem of the Criterion"
    },
    "cf592c9e06b0009745680b2fa6f99e63": {
      "source_id": "cf592c9e06b0009745680b2fa6f99e63",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48662,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "FC final: Can Factored Cognition schemes scale?"
    },
    "fcf34ca1cd80ab5a766969a18986b796": {
      "source_id": "fcf34ca1cd80ab5a766969a18986b796",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12518,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Evolutions Building Evolutions: Layers of Generate and Test"
    },
    "b06c1b3e0632b00fca88d011088e4bae": {
      "source_id": "b06c1b3e0632b00fca88d011088e4bae",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3649,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "2021-03-01 National Library of Medicine Presentation: \u201cAtlas of AI: Mapping the "
    },
    "4a03af24fb1e11613f84154b9b2dbd4b": {
      "source_id": "4a03af24fb1e11613f84154b9b2dbd4b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11969,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Google\u2019s Ethical AI team and AI Safety"
    },
    "b33dc174da7887282a88f14635a48e3e": {
      "source_id": "b33dc174da7887282a88f14635a48e3e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1114,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Is there any serious attempt to create a system to figure out the CEV of humanit"
    },
    "44da3a242fa4d109663b1ea7ba1e5ddc": {
      "source_id": "44da3a242fa4d109663b1ea7ba1e5ddc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3123,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "How might cryptocurrencies affect AGI timelines?"
    },
    "5965913fa09f30e599885b00432f3a8b": {
      "source_id": "5965913fa09f30e599885b00432f3a8b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3260,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "GPT-3 and the future of knowledge work"
    },
    "e78baa40131a10f0ce7f740483a05fa5": {
      "source_id": "e78baa40131a10f0ce7f740483a05fa5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2653,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What are the biggest current impacts of AI?"
    },
    "1239f3861354f993fc9df3b6ac776b64": {
      "source_id": "1239f3861354f993fc9df3b6ac776b64",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25009,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A simple way to make GPT-3 follow instructions"
    },
    "ac8bf7d8beadda53136cfda213f22602": {
      "source_id": "ac8bf7d8beadda53136cfda213f22602",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6241,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Is a Self-Iterating AGI Vulnerable to Thompson-style Trojans?"
    },
    "52b8804c4cac3f53a087119675bb746f": {
      "source_id": "52b8804c4cac3f53a087119675bb746f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 411,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "On language modeling and future abstract reasoning research"
    },
    "760b269cf5191ba36d68ff35f11daecc": {
      "source_id": "760b269cf5191ba36d68ff35f11daecc",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9882,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Notes on effective-altruism-related research, writing, testing fit, learning, an"
    },
    "38a1ff41ca49b3318bf770f657e12db3": {
      "source_id": "38a1ff41ca49b3318bf770f657e12db3",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5710,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AI oracles on blockchain"
    },
    "339cfd1bd2f96059d852717a10110ac9": {
      "source_id": "339cfd1bd2f96059d852717a10110ac9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2547,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What if AGI is near?"
    },
    "7267ef18630e79d6cba370c265d26727": {
      "source_id": "7267ef18630e79d6cba370c265d26727",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1664,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Is there anything that can stop AGI development in the near term?"
    },
    "96a2a9ea70c92fcd05a65ca96d8d6322": {
      "source_id": "96a2a9ea70c92fcd05a65ca96d8d6322",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1978,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "25 Min Talk on MetaEthical.AI with Questions from Stuart Armstrong"
    },
    "688a163e70abc2f37778662eb0e71d5f": {
      "source_id": "688a163e70abc2f37778662eb0e71d5f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1138,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[timeboxed exercise] write me your model of AI human-existential safety and the "
    },
    "ebf6d5843f7f12ed533241676b8795e0": {
      "source_id": "ebf6d5843f7f12ed533241676b8795e0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13223,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Is driving worth the risk?"
    },
    "4784a84649703733960b7949bc2aaa13": {
      "source_id": "4784a84649703733960b7949bc2aaa13",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15366,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Controlling Intelligent Agents The Only Way We Know How: Ideal Bureaucratic Stru"
    },
    "f144a41927e07095766b8f7237eda8e9": {
      "source_id": "f144a41927e07095766b8f7237eda8e9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7021,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Oracles, Informers, and Controllers"
    },
    "9bc23af10430da347d3bf8399a668839": {
      "source_id": "9bc23af10430da347d3bf8399a668839",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15797,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Reflection of Hierarchical Relationship via Nuanced Conditioning of Game Theory "
    },
    "e62ed2f359753041bf14a4ad5a2ddd0f": {
      "source_id": "e62ed2f359753041bf14a4ad5a2ddd0f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32155,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Escaping the L\u00f6bian Obstacle"
    },
    "accc40af0eb3d03f7a534a1aca728076": {
      "source_id": "accc40af0eb3d03f7a534a1aca728076",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3447,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Thoughts on a \"Sequences Inspired\" PhD Topic"
    },
    "d750d5986996adaaaa360ebc8d4730e1": {
      "source_id": "d750d5986996adaaaa360ebc8d4730e1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3859,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What are some claims or opinions about multi-multi delegation you've seen in the"
    },
    "44f546cdab5d9efc5675f6e23237da9f": {
      "source_id": "44f546cdab5d9efc5675f6e23237da9f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15604,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "How teams went about their research at AI Safety Camp edition 5"
    },
    "ffc6eff876fbaf6b5e23146abb41485f": {
      "source_id": "ffc6eff876fbaf6b5e23146abb41485f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1479,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Mauhn Releases AI Safety Documentation"
    },
    "6f0bc9bfee2309a13be30b4e9ad270fa": {
      "source_id": "6f0bc9bfee2309a13be30b4e9ad270fa",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38507,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Intermittent Distillations #4: Semiconductors, Economics, Intelligence, and Tech"
    },
    "1fbdffd000b2c7aac6bf256086e9de87": {
      "source_id": "1fbdffd000b2c7aac6bf256086e9de87",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1461,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Is the argument that AI is an xrisk valid?"
    },
    "bda2db145577c11c28f1be270eef68d4": {
      "source_id": "bda2db145577c11c28f1be270eef68d4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4051,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Entropic boundary conditions towards safe artificial superintelligence"
    },
    "44201a197f4dedffee5bb2ef536268c8": {
      "source_id": "44201a197f4dedffee5bb2ef536268c8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6641,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The biological intelligence explosion"
    },
    "c4b3c35be9429c261c8a556b45eebda1": {
      "source_id": "c4b3c35be9429c261c8a556b45eebda1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1691,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "How should my timelines influence my career choice?"
    },
    "e320c6795e8521e36bf027e2fb967dd9": {
      "source_id": "e320c6795e8521e36bf027e2fb967dd9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18767,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Chasing Infinities"
    },
    "1fd93cd2059133d7f70b7f9a8ba7176a": {
      "source_id": "1fd93cd2059133d7f70b7f9a8ba7176a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3295,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Is it worth making a database for moral predictions?"
    },
    "52f0959a3958479fefda17b6f36569dc": {
      "source_id": "52f0959a3958479fefda17b6f36569dc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 904,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "1h-volunteers needed for a small AI Safety-related research project "
    },
    "6d6abb3032938fa0801508f6ec49f141": {
      "source_id": "6d6abb3032938fa0801508f6ec49f141",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6013,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Autoregressive Propaganda"
    },
    "fcf97553ba1c1f23fefce4769abcb4d6": {
      "source_id": "fcf97553ba1c1f23fefce4769abcb4d6",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9782,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Extraction of human preferences  \ud83d\udc68\u2192\ud83e\udd16"
    },
    "1aff0a319e0a8b40e242a193eb2a82b8": {
      "source_id": "1aff0a319e0a8b40e242a193eb2a82b8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16875,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Could you have stopped Chernobyl?"
    },
    "ed8ba11c86f5a096c187e51de01d524c": {
      "source_id": "ed8ba11c86f5a096c187e51de01d524c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27296,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Brain-Computer Interfaces and AI Alignment"
    },
    "abfc49706060bb8d72dedb4205b75d2f": {
      "source_id": "abfc49706060bb8d72dedb4205b75d2f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8331,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Superintelligent Introspection: A Counter-argument to the Orthogonality Thesis"
    },
    "41c8423274cea8a37d5aba7a498f6996": {
      "source_id": "41c8423274cea8a37d5aba7a498f6996",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23922,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The Governance Problem and the \"Pretty Good\" X-Risk"
    },
    "6fe22bd45e80b0eaca654846931aedeb": {
      "source_id": "6fe22bd45e80b0eaca654846931aedeb",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 724,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Is there a name for the theory that \"There will be fast takeoff in real-world ca"
    },
    "0f0832a5c3249e7eaf0a1289cbb4c2d2": {
      "source_id": "0f0832a5c3249e7eaf0a1289cbb4c2d2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19458,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Why the technological singularity by AGI may never happen"
    },
    "525649e70f12346034e3459445fff056": {
      "source_id": "525649e70f12346034e3459445fff056",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3083,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Are there substantial research efforts towards aligning narrow AIs?"
    },
    "038abd16e10e0148067ac38afc57f887": {
      "source_id": "038abd16e10e0148067ac38afc57f887",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2039,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Multi-Agent Inverse Reinforcement Learning: Suboptimal Demonstrations and  Alter"
    },
    "289739fc9f7908ee4330df1504d0ea65": {
      "source_id": "289739fc9f7908ee4330df1504d0ea65",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3988,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Alignment via manually implementing the utility function"
    },
    "ace0da789bae5d71b800eaa1d9cae33d": {
      "source_id": "ace0da789bae5d71b800eaa1d9cae33d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22849,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "GPT-Augmented Blogging"
    },
    "efca00fbd0c8be637ac319872f5fe5dd": {
      "source_id": "efca00fbd0c8be637ac319872f5fe5dd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16092,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The Metaethics and Normative Ethics of AGI Value Alignment: Many Questions, Some"
    },
    "63fc335cc420b41121438839a9b4a439": {
      "source_id": "63fc335cc420b41121438839a9b4a439",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61203,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What is Compute? - Transformative AI and Compute [1/4]"
    },
    "3f84e6f705de5ac2841bb1baf91d81ef": {
      "source_id": "3f84e6f705de5ac2841bb1baf91d81ef",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21378,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Forecasting Transformative AI, Part 1: What Kind of AI?"
    },
    "2a0d55082cb314539c7d8c77ecf5d8d0": {
      "source_id": "2a0d55082cb314539c7d8c77ecf5d8d0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23274,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Transformative AI and Compute [Summary]"
    },
    "7509ee85331bb1184d8cc55a8392c7f9": {
      "source_id": "7509ee85331bb1184d8cc55a8392c7f9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 154,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Any writeups on GPT agency?"
    },
    "258b90f0a48596352b663ba3aa621c25": {
      "source_id": "258b90f0a48596352b663ba3aa621c25",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10312,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A Confused Chemist's Review of AlphaFold 2"
    },
    "11d8286986f8e2aeed39cd6628b99021": {
      "source_id": "11d8286986f8e2aeed39cd6628b99021",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15286,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AISC5 Retrospective: Mechanisms for Avoiding Tragedy of the Commons in Common Po"
    },
    "ac4359c3c775da62d2799deea4f7872e": {
      "source_id": "ac4359c3c775da62d2799deea4f7872e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2863,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Is progress in ML-assisted theorem-proving beneficial?"
    },
    "c495b98ee21b8754b7772065b6c5cc87": {
      "source_id": "c495b98ee21b8754b7772065b6c5cc87",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23714,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Proposal: Scaling laws for RL generalization"
    },
    "2fbce160d9fb129603854a572b7ad332": {
      "source_id": "2fbce160d9fb129603854a572b7ad332",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 60609,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Forecasting Compute - Transformative AI and Compute [2/4]"
    },
    "b33ce974830b4314dd07fe5b869da10d": {
      "source_id": "b33ce974830b4314dd07fe5b869da10d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 59348,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Occam's Razor and the Universal Prior"
    },
    "6c61fb863396fbf84dc7435063b485a1": {
      "source_id": "6c61fb863396fbf84dc7435063b485a1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22591,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A Framework of Prediction Technologies"
    },
    "d3bc378071a51df821658162f8ff6bef": {
      "source_id": "d3bc378071a51df821658162f8ff6bef",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34811,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The Dark Side of Cognition Hypothesis"
    },
    "5407f71c8bc4f35788a05f478cfcd1ba": {
      "source_id": "5407f71c8bc4f35788a05f478cfcd1ba",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54681,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Nuclear Espionage and AI Governance"
    },
    "308bdf1e2ea0085db4caeb20409f4a39": {
      "source_id": "308bdf1e2ea0085db4caeb20409f4a39",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2756,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "How to think about and deal with OpenAI"
    },
    "a7be4e3e222c8e1b481403ea724d91d2": {
      "source_id": "a7be4e3e222c8e1b481403ea724d91d2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5263,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "The evaluation function of an AI is not its aim"
    },
    "6f716afd530b79d4f93c62dc1d62862e": {
      "source_id": "6f716afd530b79d4f93c62dc1d62862e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11616,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "EDT with updating double counts"
    },
    "0647d8c9928ca70f06f2f91e71ffa938": {
      "source_id": "0647d8c9928ca70f06f2f91e71ffa938",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13026,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Compute Governance and Conclusions - Transformative AI and Compute [3/4]"
    },
    "8711f01881e4de740418ec6d35d0a61f": {
      "source_id": "8711f01881e4de740418ec6d35d0a61f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14334,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Resurrecting all humans ever lived as a technical problem"
    },
    "ca2179c4b01de57b1fd5bcb2b3406d19": {
      "source_id": "ca2179c4b01de57b1fd5bcb2b3406d19",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16484,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Using Brain-Computer Interfaces to get more data for AI alignment"
    },
    "ed6e533fa08cd06f19e01ae701f5f0a8": {
      "source_id": "ed6e533fa08cd06f19e01ae701f5f0a8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18194,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A Defense of Functional Decision Theory"
    },
    "8b78e07c366c3d6355679d5757f5ceb6": {
      "source_id": "8b78e07c366c3d6355679d5757f5ceb6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13792,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A FLI postdoctoral grant application: AI alignment via causal analysis and desig"
    },
    "4d0ac3bac6ac42e2fd6df925fc7fa3bd": {
      "source_id": "4d0ac3bac6ac42e2fd6df925fc7fa3bd",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4009,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "My current uncertainties regarding AI, alignment, and the end of the world"
    },
    "efe039c110c65715eda733265deb0fa1": {
      "source_id": "efe039c110c65715eda733265deb0fa1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6650,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Two Stupid AI Alignment Ideas"
    },
    "9ef020ab7fb2cdd68038e288defc47ed": {
      "source_id": "9ef020ab7fb2cdd68038e288defc47ed",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29049,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Super intelligent AIs that don't require alignment"
    },
    "68691eec797061fd83ab4939bbb62bf2": {
      "source_id": "68691eec797061fd83ab4939bbb62bf2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22129,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Potential Alignment mental tool: Keeping track of the types"
    },
    "a12410273e2bd2ccb17e3e5ae3cf3268": {
      "source_id": "a12410273e2bd2ccb17e3e5ae3cf3268",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 1650,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[linkpost] Acquisition of Chess Knowledge in AlphaZero"
    },
    "f2b4d2dcb5eba76256ca91e222c5d0fc": {
      "source_id": "f2b4d2dcb5eba76256ca91e222c5d0fc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53243,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Slightly advanced decision theory 102: Four reasons not to be a (naive) utility "
    },
    "b13118be71edee4b4b8f9559e647156f": {
      "source_id": "b13118be71edee4b4b8f9559e647156f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3450,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "HIRING: Inform and shape a new project on AI safety at Partnership on AI "
    },
    "ea9a5de888165925b353ddf380604593": {
      "source_id": "ea9a5de888165925b353ddf380604593",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54902,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Compute Research Questions and Metrics - Transformative AI and Compute [4/4]"
    },
    "957c29e9358e9920af6e78ba835d10a4": {
      "source_id": "957c29e9358e9920af6e78ba835d10a4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 956,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "AI Governance Fundamentals - Curriculum and Application"
    },
    "c33a3c8da76d4227ee73175b4d30e8d6": {
      "source_id": "c33a3c8da76d4227ee73175b4d30e8d6",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3034,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Does the Structure  of an algorithm matter for AI Risk and/or consciousness?"
    },
    "5970912fa27589c70f486fb3d1dbbf64": {
      "source_id": "5970912fa27589c70f486fb3d1dbbf64",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30660,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Information bottleneck for counterfactual corrigibility"
    },
    "92e5cd7baca10c7d9a1645dbd5f704c3": {
      "source_id": "92e5cd7baca10c7d9a1645dbd5f704c3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3580,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Exterminating humans might be on the to-do list of a Friendly AI"
    },
    "7c9e815881c3ced0544120bd6971a86a": {
      "source_id": "7c9e815881c3ced0544120bd6971a86a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3516,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "HIRING: Inform and shape a new project on AI safety at Partnership on AI"
    },
    "2fb155a5f291037359e1035d47738cc5": {
      "source_id": "2fb155a5f291037359e1035d47738cc5",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 2540,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "[Linkpost] Chinese government's guidelines on AI"
    },
    "aeb1c9f4bdd57967557d5dbc8dcc6d0e": {
      "source_id": "aeb1c9f4bdd57967557d5dbc8dcc6d0e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 111604,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "What role should evolutionary analogies play in understanding AI takeoff speeds?"
    },
    "1b76599b7ecb467bc0adf5f5f3508056": {
      "source_id": "1b76599b7ecb467bc0adf5f5f3508056",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2041,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Teaser: Hard-coding Transformer Models"
    },
    "bf30cd22cb1fdff22cbdb71f124ca461": {
      "source_id": "bf30cd22cb1fdff22cbdb71f124ca461",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 60706,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Framing approaches to alignment and the hard problem of AI cognition"
    },
    "f5cbb5314dbd1aa443c1006e084f9581": {
      "source_id": "f5cbb5314dbd1aa443c1006e084f9581",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2508,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Reviews of \u201cIs power-seeking AI an existential risk?\u201d"
    },
    "090fa9eb8f186908f02a28d1dacbd33e": {
      "source_id": "090fa9eb8f186908f02a28d1dacbd33e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29850,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Some motivations to gradient hack"
    },
    "d5257a0a847c2f43d8dad549bd07b362": {
      "source_id": "d5257a0a847c2f43d8dad549bd07b362",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9061,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "DL towards the unaligned Recursive Self-Optimization attractor"
    },
    "e80ef5c87bd9b2206d407f0a436ab55c": {
      "source_id": "e80ef5c87bd9b2206d407f0a436ab55c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3859,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Why don't governments seem to mind that companies are explicitly trying to make "
    },
    "e2041e768b1645cce0ed0af83385b13d": {
      "source_id": "e2041e768b1645cce0ed0af83385b13d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3434,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "Reinforcement Learning Study Group"
    },
    "74290a01745c828eaced7eabb087fe68": {
      "source_id": "74290a01745c828eaced7eabb087fe68",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32338,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "A Summary Of Anthropic's First Paper"
    },
    "4201cbaec52ef7c5fc158fa07596606c": {
      "source_id": "4201cbaec52ef7c5fc158fa07596606c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9203,
        "year": "2021",
        "has_tags": true
      },
      "title_preview": "We need a theory of anthropic measure binding"
    },
    "45c62a16642300e70a14e7fe10ad45b6": {
      "source_id": "45c62a16642300e70a14e7fe10ad45b6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 84027,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Brain Efficiency: Much More than You Wanted to Know"
    },
    "2ef7fba9ac2c84937978edb936751bb3": {
      "source_id": "2ef7fba9ac2c84937978edb936751bb3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16563,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "An Open Philanthropy grant proposal: Causal representation learning of human pre"
    },
    "ff77bebd3c7a89f0186b7af56c715036": {
      "source_id": "ff77bebd3c7a89f0186b7af56c715036",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30159,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "New year, new research agenda post "
    },
    "0655f521eab75613fb0b3ce0e46950ef": {
      "source_id": "0655f521eab75613fb0b3ce0e46950ef",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41348,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How I'm thinking about GPT-N"
    },
    "79c2375593324fd36d9eec86c8fe3965": {
      "source_id": "79c2375593324fd36d9eec86c8fe3965",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10410,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Emotions = Reward Functions"
    },
    "5d150b41f04ad39f7646ef349c8df15b": {
      "source_id": "5d150b41f04ad39f7646ef349c8df15b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38959,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Alignment Problems All the Way Down"
    },
    "204500949d8fa86226160ff16791e2fe": {
      "source_id": "204500949d8fa86226160ff16791e2fe",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10198,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why rationalists should care (more) about free software"
    },
    "fcb4499b03d31494cc06a3dc511c7eac": {
      "source_id": "fcb4499b03d31494cc06a3dc511c7eac",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29664,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Competitive programming with AlphaCode"
    },
    "d4ba6fd233f1d2030854bfc7a8b1677e": {
      "source_id": "d4ba6fd233f1d2030854bfc7a8b1677e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1244,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Do mesa-optimization problems correlate with low-slack?"
    },
    "b8163d92c05000fce3ca06c344404271": {
      "source_id": "b8163d92c05000fce3ca06c344404271",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4833,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Uncompetitive programming with GPT-3"
    },
    "fc00bd6a8a697a566a55831d45f062f0": {
      "source_id": "fc00bd6a8a697a566a55831d45f062f0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2477,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Metaculus launches contest for essays with quantitative predictions about AI"
    },
    "6d1c0f85e81c94ddc122e895ffb460c2": {
      "source_id": "6d1c0f85e81c94ddc122e895ffb460c2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28929,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Paradigm-building from first principles: Effective altruism, AGI, and alignment"
    },
    "9ea4be36a690f99a04c2475728074d8e": {
      "source_id": "9ea4be36a690f99a04c2475728074d8e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5556,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Paradigm-building: The hierarchical question framework"
    },
    "39113bda18646bd91c4297daa74a4e7e": {
      "source_id": "39113bda18646bd91c4297daa74a4e7e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 707,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "EleutherAI's GPT-NeoX-20B release"
    },
    "67a1b1522361ce8092aaf25f6191365c": {
      "source_id": "67a1b1522361ce8092aaf25f6191365c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14769,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Question 1: Predicted architecture of AGI learning algorithm(s)"
    },
    "573f7e076270d07dbe2e2279631188e6": {
      "source_id": "573f7e076270d07dbe2e2279631188e6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22238,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Question 2: Predicted bad outcomes of AGI learning architecture"
    },
    "5f8d80535ce44a39af2933514c5534b1": {
      "source_id": "5f8d80535ce44a39af2933514c5534b1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14541,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Question 3: Control proposals for minimizing bad outcomes"
    },
    "7377416382f455517bbde87e191f1e5d": {
      "source_id": "7377416382f455517bbde87e191f1e5d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5424,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Idea: build alignment dataset for very capable models"
    },
    "0f15e5d3fe3558f8854e63a130654491": {
      "source_id": "0f15e5d3fe3558f8854e63a130654491",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11947,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Question 4: Implementing the control proposals"
    },
    "d70253d31b8a25f91a3057d5b3c49141": {
      "source_id": "d70253d31b8a25f91a3057d5b3c49141",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14642,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Question 5: The timeline hyperparameter"
    },
    "b6045e08d755b7b8995abf803fafb29f": {
      "source_id": "b6045e08d755b7b8995abf803fafb29f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5587,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Paradigm-building: Conclusion and practical takeaways"
    },
    "aa5ab5b3afea28b43b4fe757a9b2d60e": {
      "source_id": "aa5ab5b3afea28b43b4fe757a9b2d60e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22197,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How harmful are improvements in AI? + Poll"
    },
    "5e1c3dd36d7f3ba6ef3723c40193e796": {
      "source_id": "5e1c3dd36d7f3ba6ef3723c40193e796",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29008,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": " [Intro to brain-like-AGI safety] 4. The \u201cshort-term predictor\u201d"
    },
    "89fcf77beaf28a1ac4c224c4d1f623f7": {
      "source_id": "89fcf77beaf28a1ac4c224c4d1f623f7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 69506,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "HCH and Adversarial Questions"
    },
    "1bd7a48800f6ddcf98e57f2416cbf55f": {
      "source_id": "1bd7a48800f6ddcf98e57f2416cbf55f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8954,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Thoughts on Dangerous Learned Optimization"
    },
    "e56672afb4f966763e987c8d5c0f06dd": {
      "source_id": "e56672afb4f966763e987c8d5c0f06dd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17429,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Trust-maximizing AGI"
    },
    "a7acc4a6d208ba0adb0aa39d09732424": {
      "source_id": "a7acc4a6d208ba0adb0aa39d09732424",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2405,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Would (myopic) general public good producers significantly accelerate the develo"
    },
    "56651be2f8404a2cfa1fc7537704a6bf": {
      "source_id": "56651be2f8404a2cfa1fc7537704a6bf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10113,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Preserving and continuing alignment research through a severe global catastrophe"
    },
    "786abe3801a70c17fb23f31fba961371": {
      "source_id": "786abe3801a70c17fb23f31fba961371",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7356,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "On presenting the case for AI risk"
    },
    "2a4ad8fcc9adb3c23a553a53a9f86ae1": {
      "source_id": "2a4ad8fcc9adb3c23a553a53a9f86ae1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3391,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Ask AI companies about what they are doing for AI safety?"
    },
    "1d2ef374ddc84cc4302e194c58a07cab": {
      "source_id": "1d2ef374ddc84cc4302e194c58a07cab",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4349,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is There a Valley of Bad Civilizational Adequacy?"
    },
    "8e0c29393fcaa3c6dc0f7fafd41ed66b": {
      "source_id": "8e0c29393fcaa3c6dc0f7fafd41ed66b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20189,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "New GPT3 Impressive Capabilities - InstructGPT3 [1/2]"
    },
    "84eca25950834abec4cf603714a2bd57": {
      "source_id": "84eca25950834abec4cf603714a2bd57",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6280,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Using GPT-3 for preventing conflict during messaging \u2014 a pitch for an app"
    },
    "813237b99796efab0449a8fa15d84c6d": {
      "source_id": "813237b99796efab0449a8fa15d84c6d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58643,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Goal-directedness: imperfect reasoning, limited knowledge and inaccurate beliefs"
    },
    "fda0bc0e618b0e46f682d4d762805778": {
      "source_id": "fda0bc0e618b0e46f682d4d762805778",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13123,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Can you be Not Even Wrong in AI Alignment?"
    },
    "1c114c02f26890c383a2d6f0bf1f68ef": {
      "source_id": "1c114c02f26890c383a2d6f0bf1f68ef",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9739,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Wargaming AGI Development"
    },
    "7c66e03ff726cd268420142c109994ad": {
      "source_id": "7c66e03ff726cd268420142c109994ad",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6975,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Natural Value Learning"
    },
    "25bfbc766e72a5ee3e9a49695e62f31d": {
      "source_id": "25bfbc766e72a5ee3e9a49695e62f31d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3102,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Closed] Job Offering: Help Communicate Infrabayesianism"
    },
    "20120cab1420b965c5bab86af514e47c": {
      "source_id": "20120cab1420b965c5bab86af514e47c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6610,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Practical everyday human strategizing"
    },
    "249a6e639c5f4592e0847c61ce8e5b8a": {
      "source_id": "249a6e639c5f4592e0847c61ce8e5b8a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 966,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "If AGI were coming in a year, what should we do?"
    },
    "70cf07c31649ca1aba7f05c83a69dc7b": {
      "source_id": "70cf07c31649ca1aba7f05c83a69dc7b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 68070,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Jeff Shainline thinks that there is too much serendipity in the physics of optic"
    },
    "1b949b0405290a0a824d02061baef987": {
      "source_id": "1b949b0405290a0a824d02061baef987",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10075,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Replacing Karma with Good Heart Tokens (Worth $1!)"
    },
    "0e09f3ea333d2cad5e86f8a3e09884a6": {
      "source_id": "0e09f3ea333d2cad5e86f8a3e09884a6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20828,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Questions about ''formalizing instrumental goals\""
    },
    "d13b6b64be6f63eef65d3b901da3f9b0": {
      "source_id": "d13b6b64be6f63eef65d3b901da3f9b0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6437,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Interacting with a Boxed AI"
    },
    "b46e2bc70eabc919098a887d303a060f": {
      "source_id": "b46e2bc70eabc919098a887d303a060f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32110,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "MIRI announces new \"Death With Dignity\" strategy"
    },
    "c90c4c241cd9dbfdf505b3d0c57a8d54": {
      "source_id": "c90c4c241cd9dbfdf505b3d0c57a8d54",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 487,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Inflection AI: New startup related to language models"
    },
    "16f79f1f2bc0d48a27dfb300432ac7dd": {
      "source_id": "16f79f1f2bc0d48a27dfb300432ac7dd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10538,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What an actually pessimistic containment strategy looks like"
    },
    "679dd61a8dc1e6ff9baa5a2434ad05bc": {
      "source_id": "679dd61a8dc1e6ff9baa5a2434ad05bc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4008,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The case for Doing Something Else (if Alignment is doomed)"
    },
    "ccba1f59534f6cd871a0600a3afb1ed1": {
      "source_id": "ccba1f59534f6cd871a0600a3afb1ed1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5076,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "My agenda for research into transformer capabilities - Introduction"
    },
    "760fc8d7d7ae7efa9aa0ee45221f83c3": {
      "source_id": "760fc8d7d7ae7efa9aa0ee45221f83c3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3791,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Research agenda: Can transformers do system 2 thinking?"
    },
    "7328ca3d38b87dafcfb7c6e94ea28658": {
      "source_id": "7328ca3d38b87dafcfb7c6e94ea28658",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14742,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How to train your transformer "
    },
    "2ec18501dc0807f9b21e23a7523c9256": {
      "source_id": "2ec18501dc0807f9b21e23a7523c9256",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4024,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Research agenda - Building a multi-modal chess-language model"
    },
    "70c865e897c31798e3223d48ed2c147f": {
      "source_id": "70c865e897c31798e3223d48ed2c147f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16711,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is GPT3 a Good Rationalist? - InstructGPT3 [2/2]"
    },
    "526bd14f2a370094d337d30a274ac203": {
      "source_id": "526bd14f2a370094d337d30a274ac203",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19089,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Playing with DALL\u00b7E 2"
    },
    "3aac4295b55c7c3c2b9f5ceb278582f8": {
      "source_id": "3aac4295b55c7c3c2b9f5ceb278582f8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6831,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[RETRACTED] It's time for EA leadership to pull the short-timelines fire alarm."
    },
    "6166153d7e135bb829d3dd696acd847c": {
      "source_id": "6166153d7e135bb829d3dd696acd847c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34223,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Hyperbolic takeoff"
    },
    "ad71ba8eea61decfca22c3bbea064b1d": {
      "source_id": "ad71ba8eea61decfca22c3bbea064b1d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6392,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": " Strategies for keeping AIs narrow in the short term"
    },
    "1dc9d6651ffffa9e91225527d072c450": {
      "source_id": "1dc9d6651ffffa9e91225527d072c450",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8306,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is Fisherian Runaway Gradient Hacking?"
    },
    "acdf9180892fca7c34b0fc398d84bd4a": {
      "source_id": "acdf9180892fca7c34b0fc398d84bd4a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4152,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Convince me that humanity is as doomed by AGI as Yudkowsky et al., seems to beli"
    },
    "256492701d0f992af3417c94c8767fed": {
      "source_id": "256492701d0f992af3417c94c8767fed",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6376,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is it time to start thinking about what AI Friendliness means?"
    },
    "61b70ea1d897e9a15c9e56db8509e05c": {
      "source_id": "61b70ea1d897e9a15c9e56db8509e05c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12820,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Goodhart's Law Causal Diagrams"
    },
    "b4cbaa70d6b457e6dc82da0d9f5399fa": {
      "source_id": "b4cbaa70d6b457e6dc82da0d9f5399fa",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11887,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Regulatory Option: A response to near 0% survival odds"
    },
    "d8812e06aa4720a85fc8969394172288": {
      "source_id": "d8812e06aa4720a85fc8969394172288",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19598,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "An AI-in-a-box success model"
    },
    "43831962f3c01a805595e194e3f226de": {
      "source_id": "43831962f3c01a805595e194e3f226de",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4413,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Three questions about mesa-optimizers"
    },
    "6f31eea232a7588aeabb8c06152f8c99": {
      "source_id": "6f31eea232a7588aeabb8c06152f8c99",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2102,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI governance student hackathon on Saturday, April 23: register now!"
    },
    "7855ba718cde0d4cee74cfb71b79553d": {
      "source_id": "7855ba718cde0d4cee74cfb71b79553d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3159,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is technical AI alignment research a net positive?"
    },
    "46d28cd63fcc4b2223525eee858e2fab": {
      "source_id": "46d28cd63fcc4b2223525eee858e2fab",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1027,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Peerless"
    },
    "af645c7a90877460fdbfde6085c88b2e": {
      "source_id": "af645c7a90877460fdbfde6085c88b2e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1170,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "\u201cFragility of Value\u201d vs. LLMs"
    },
    "928124e63ddea5c51071cac9f5e2d958": {
      "source_id": "928124e63ddea5c51071cac9f5e2d958",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25628,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What more compute does for brain-like models: response to Rohin"
    },
    "ea712ca3110b1f5e620d404c2a34775e": {
      "source_id": "ea712ca3110b1f5e620d404c2a34775e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4937,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Quick Guide to Confronting Doom"
    },
    "afcbf52f516521f453644ef109f4da40": {
      "source_id": "afcbf52f516521f453644ef109f4da40",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1268,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Can someone explain to me why MIRI is so pessimistic of our chances of survival?"
    },
    "5392102022c36eb2367143e1226562b7": {
      "source_id": "5392102022c36eb2367143e1226562b7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1047,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Convince me that humanity *isn\u2019t* doomed by AGI"
    },
    "091b5ad75e21cd023c64813ce139c108": {
      "source_id": "091b5ad75e21cd023c64813ce139c108",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1758,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Constraining narrow AI in a corporate setting"
    },
    "120109a5e305e2c66f0cf214c48b9902": {
      "source_id": "120109a5e305e2c66f0cf214c48b9902",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3915,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Code Generation as an AI risk setting"
    },
    "54721af092c379be511154a73e80fe61": {
      "source_id": "54721af092c379be511154a73e80fe61",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1774,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Deceptive Agents are a Good Way to Do Things"
    },
    "9500f2062e8f42e6ec4c17b378dd5443": {
      "source_id": "9500f2062e8f42e6ec4c17b378dd5443",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3835,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why No *Interesting* Unaligned Singularity?"
    },
    "0050bbadc788c910bbc566150d847021": {
      "source_id": "0050bbadc788c910bbc566150d847021",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9117,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Reflections on My Own Missing Mood"
    },
    "e2b85df0abd31c196716efe5c299f7e6": {
      "source_id": "e2b85df0abd31c196716efe5c299f7e6",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1771,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What are the numbers in mind for the super-short AGI timelines so many long-term"
    },
    "229aa7b211fbd0b00080af675c13426d": {
      "source_id": "229aa7b211fbd0b00080af675c13426d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7645,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Humanity as an entity: An alternative to Coherent Extrapolated Volition"
    },
    "e72a0f55159f1e711619bb2102076cc0": {
      "source_id": "e72a0f55159f1e711619bb2102076cc0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6536,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "If you\u2019re very optimistic about ELK then you should be optimistic about outer al"
    },
    "b48a91ba5cc862b60ab68852cc4d7913": {
      "source_id": "b48a91ba5cc862b60ab68852cc4d7913",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22624,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Alternative Futures: Scenario Mapping Artificial Intelligence Risk - Request "
    },
    "f4dea7dc7d1c6a6bfd28371746dec6f5": {
      "source_id": "f4dea7dc7d1c6a6bfd28371746dec6f5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3371,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How Might an Alignment Attractor Look like?"
    },
    "a760816341679ad95e11fab74eae6cfa": {
      "source_id": "a760816341679ad95e11fab74eae6cfa",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2684,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What is a training \"step\" vs. \"episode\" in machine learning?"
    },
    "49b99fa79e576ed9f4e5b825fa13fa3d": {
      "source_id": "49b99fa79e576ed9f4e5b825fa13fa3d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4867,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Quick Thoughts on A.I. Governance"
    },
    "3671ec69e79a213222e05f6d8dd5ac18": {
      "source_id": "3671ec69e79a213222e05f6d8dd5ac18",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 188,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What is the solution to the Alignment problem?"
    },
    "3a38a6d642691f4532611f512644212a": {
      "source_id": "3a38a6d642691f4532611f512644212a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1743,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "ELK shaving"
    },
    "33edf14fc04e41fbde13bb24659e8823": {
      "source_id": "33edf14fc04e41fbde13bb24659e8823",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24179,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Various Alignment Strategies (and how likely they are to work)"
    },
    "749d14b79d45259f26fecdc3c245bd1d": {
      "source_id": "749d14b79d45259f26fecdc3c245bd1d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9588,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Upgrading Imagination: The Promise Of DALL-E 2 As A Tool For Thought"
    },
    "7d9c3abf1e4476525bf4d228d065a076": {
      "source_id": "7d9c3abf1e4476525bf4d228d065a076",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53271,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Video and Transcript of Presentation on Existential Risk from Power-Seeking AI"
    },
    "9340ee2a3ed2db9e270254c8ad5518d6": {
      "source_id": "9340ee2a3ed2db9e270254c8ad5518d6",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4979,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Transcripts of interviews with AI researchers"
    },
    "3906400a1bc9d05757d54bf0e8cacabf": {
      "source_id": "3906400a1bc9d05757d54bf0e8cacabf",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7241,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI safety should be made more accessible using non text-based media"
    },
    "42f9f05ddaa456c2fafc832638cbbf57": {
      "source_id": "42f9f05ddaa456c2fafc832638cbbf57",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42455,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": " [Intro to brain-like-AGI safety] 14. Controlled AGI"
    },
    "c39c7f833188bf88f132f16107cca9c1": {
      "source_id": "c39c7f833188bf88f132f16107cca9c1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4780,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Positive outcomes under an unaligned AGI takeover"
    },
    "9f7271efc034896d2fc05a884ff46931": {
      "source_id": "9f7271efc034896d2fc05a884ff46931",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 705,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "\"A Generalist Agent\": New DeepMind Publication"
    },
    "493ef797255864cd1f1962f065a572c3": {
      "source_id": "493ef797255864cd1f1962f065a572c3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10079,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "RLHF"
    },
    "58faeb271954482a75a7da18a54342b5": {
      "source_id": "58faeb271954482a75a7da18a54342b5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13503,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Thoughts on AI Safety Camp"
    },
    "b9e5bb742c92488a0512509f14db9d35": {
      "source_id": "b9e5bb742c92488a0512509f14db9d35",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7507,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "\"Tech company singularities\", and steering them to reduce x-risk"
    },
    "a4778d178c7ad0787b7be20b4ae8b4e8": {
      "source_id": "a4778d178c7ad0787b7be20b4ae8b4e8",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 678,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Link post] Promising Paths to Alignment - Connor Leahy | Talk"
    },
    "f1b80d46f2f2c4d7ac3cad028f656650": {
      "source_id": "f1b80d46f2f2c4d7ac3cad028f656650",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26282,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Gato as the Dawn of Early AGI"
    },
    "bcf5dee4bfa38f46275efc7611ea80f5": {
      "source_id": "bcf5dee4bfa38f46275efc7611ea80f5",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5727,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is AI Progress Impossible To Predict?"
    },
    "46ba54d4cb3e3cdd96f283353a614526": {
      "source_id": "46ba54d4cb3e3cdd96f283353a614526",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2866,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why I'm Optimistic About Near-Term AI Risk"
    },
    "93f7868ded7d0a8b2ee5487e017e8ec6": {
      "source_id": "93f7868ded7d0a8b2ee5487e017e8ec6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13295,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "DeepMind\u2019s generalist AI, Gato: A non-technical explainer"
    },
    "b8defd601ee7b31b3b1f888d67e0399e": {
      "source_id": "b8defd601ee7b31b3b1f888d67e0399e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26200,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A bridge to Dath Ilan?  Improved governance on the critical path to AI alignment"
    },
    "c7d10facc4e9eb5265fd3383b8251f20": {
      "source_id": "c7d10facc4e9eb5265fd3383b8251f20",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10086,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Clarifying what ELK is trying to achieve"
    },
    "7b971dd3977f905f159f51aa5681beb9": {
      "source_id": "7b971dd3977f905f159f51aa5681beb9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39137,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why I'm Worried About AI"
    },
    "552ed97624cb72c8991e6ee8f82fb612": {
      "source_id": "552ed97624cb72c8991e6ee8f82fb612",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15404,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Synthetic Media and The Future of Film"
    },
    "35f3e190cf8ff3a399134bfcfec41d19": {
      "source_id": "35f3e190cf8ff3a399134bfcfec41d19",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18259,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Explaining inner alignment to myself"
    },
    "9e157bb24c5954bac01aa0d20d015809": {
      "source_id": "9e157bb24c5954bac01aa0d20d015809",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51515,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Infra-Bayesianism Distillation: Realizability and Decision Theory"
    },
    "84cfb7735f043bc6cc75516a5e351d42": {
      "source_id": "84cfb7735f043bc6cc75516a5e351d42",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4245,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The pointers problem, distilled"
    },
    "a914e8dbc6ed26bdb996a39e007e74e0": {
      "source_id": "a914e8dbc6ed26bdb996a39e007e74e0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23882,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Where Utopias Go Wrong, or: The Four Little Planets"
    },
    "157d9200a43466d0a5ebf28b42d9d36b": {
      "source_id": "157d9200a43466d0a5ebf28b42d9d36b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33431,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Croesus, Cerberus, and the magpies: a gentle introduction to Eliciting Latent Kn"
    },
    "adbca451539bffd3eb4ad59f84ac9c83": {
      "source_id": "adbca451539bffd3eb4ad59f84ac9c83",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3158,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Bootstrapping Language Models"
    },
    "a8ca1f14a2ca83c27bd74172a40336ae": {
      "source_id": "a8ca1f14a2ca83c27bd74172a40336ae",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24606,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Infernal Corrigibility, Fiendishly Difficult"
    },
    "2700c7ea35c40f56ae00068c31b47f6d": {
      "source_id": "2700c7ea35c40f56ae00068c31b47f6d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31667,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Understanding Selection Theorems"
    },
    "0a0614f82cfda66670c853d665f97137": {
      "source_id": "0a0614f82cfda66670c853d665f97137",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 996,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Bayesian Persuasion?"
    },
    "80a3b28d2f3cd710148a3ae8fad8efe6": {
      "source_id": "80a3b28d2f3cd710148a3ae8fad8efe6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27275,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Distilled - AGI Safety from First Principles"
    },
    "1327f6bde823f2743bd272678cc3d548": {
      "source_id": "1327f6bde823f2743bd272678cc3d548",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42241,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Multiple AIs in boxes, evaluating each other's alignment"
    },
    "7e4385f2292130a3dacf28c90abc5416": {
      "source_id": "7e4385f2292130a3dacf28c90abc5416",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34254,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "My SERI MATS Application"
    },
    "59db5e40fe710b6c93a304b75496e424": {
      "source_id": "59db5e40fe710b6c93a304b75496e424",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13019,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Machines vs Memes Part 1: AI Alignment and Memetics"
    },
    "821c04a9480c555184da22fced2f9107": {
      "source_id": "821c04a9480c555184da22fced2f9107",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26270,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Machines vs. Memes 2: Memetically-Motivated Model Extensions"
    },
    "5b211639ad06c3f01fdd83232fea6f2a": {
      "source_id": "5b211639ad06c3f01fdd83232fea6f2a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32820,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Machines vs Memes Part 3: Imitation and Memes"
    },
    "eed877df90517668201c7a0be68a8e7a": {
      "source_id": "eed877df90517668201c7a0be68a8e7a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7581,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Bio Anchors Forecast"
    },
    "b60234184988de90767ca4a6c42bdba1": {
      "source_id": "b60234184988de90767ca4a6c42bdba1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6234,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "I'm trying out \"asteroid mindset\""
    },
    "1df90be60c4ec68c8883fe926250f535": {
      "source_id": "1df90be60c4ec68c8883fe926250f535",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40440,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Towards a Formalisation of Returns on Cognitive Reinvestment (Part 1)"
    },
    "69733b73c4c9b746ea5f1450c6eecbbb": {
      "source_id": "69733b73c4c9b746ea5f1450c6eecbbb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 93577,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How to pursue a career in technical AI alignment"
    },
    "048856330b7418769ef74ecbf306e785": {
      "source_id": "048856330b7418769ef74ecbf306e785",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8813,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Optimization and Adequacy in Five Bullets"
    },
    "c31318abf7d4fab38c4d82590a041b6d": {
      "source_id": "c31318abf7d4fab38c4d82590a041b6d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26243,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Give the model a model-builder"
    },
    "8715d5b2ab473463fa6d60ab7d21670b": {
      "source_id": "8715d5b2ab473463fa6d60ab7d21670b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3086,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "We will be around in 30 years"
    },
    "5a7771307d1f7f0eb67d93f7b1e27c41": {
      "source_id": "5a7771307d1f7f0eb67d93f7b1e27c41",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6217,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AGI Safety FAQ / all-dumb-questions-allowed thread"
    },
    "b4de4fff566aea613c544071d89304bd": {
      "source_id": "b4de4fff566aea613c544071d89304bd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26399,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Thinking about Broad Classes of Utility-like Functions"
    },
    "036c682f0a9a4356a85f6ae957e9976e": {
      "source_id": "036c682f0a9a4356a85f6ae957e9976e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6527,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why I don't believe in doom"
    },
    "9695d496416f6ab3c07f821955587c8d": {
      "source_id": "9695d496416f6ab3c07f821955587c8d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4624,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Research Questions from Stained Glass Windows"
    },
    "ba18d050287a0c0b3990d64b56bc6ce7": {
      "source_id": "ba18d050287a0c0b3990d64b56bc6ce7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35335,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Could Defeat All Of Us Combined"
    },
    "0b8e432fb12f5a8956e742f3197af583": {
      "source_id": "0b8e432fb12f5a8956e742f3197af583",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 975,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "If there was a millennium equivalent prize for AI alignment, what would the prob"
    },
    "34d8f8101a90969ae59b2c1b809540ac": {
      "source_id": "34d8f8101a90969ae59b2c1b809540ac",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1715,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "If no near-term alignment strategy, research should aim for the long-term "
    },
    "67e55ea060a441b2048cc9ff031217cb": {
      "source_id": "67e55ea060a441b2048cc9ff031217cb",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7846,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A plausible story about AI risk."
    },
    "271f9a40f7b5259abfd7494044238cb4": {
      "source_id": "271f9a40f7b5259abfd7494044238cb4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14316,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How dangerous is human-level AI?"
    },
    "54d2199910696af0d856a1b0a0597958": {
      "source_id": "54d2199910696af0d856a1b0a0597958",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16831,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Summary of \"AGI Ruin: A List of Lethalities\""
    },
    "432c39ad78c751779548bfb58132c02a": {
      "source_id": "432c39ad78c751779548bfb58132c02a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7515,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Steganography and the CycleGAN - alignment failure case study"
    },
    "27296073c7afc8bc86021c31962f5cec": {
      "source_id": "27296073c7afc8bc86021c31962f5cec",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7243,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Poorly-Aimed Death Rays"
    },
    "2dc08c6aedaabd4a35cdef390543ca20": {
      "source_id": "2dc08c6aedaabd4a35cdef390543ca20",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13296,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why all the fuss about recursive self-improvement?"
    },
    "f8c0365ec258c45a4ad3c533f2b4d1f0": {
      "source_id": "f8c0365ec258c45a4ad3c533f2b4d1f0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27857,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Intuitive Explanation of AIXI"
    },
    "d0162c37a24d7f32697544ba7a23125f": {
      "source_id": "d0162c37a24d7f32697544ba7a23125f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49819,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Grokking \u201cSemi-informative priors over AI timelines\u201d"
    },
    "f2f0b1d763e7b71b9610b8f40a34dcae": {
      "source_id": "f2f0b1d763e7b71b9610b8f40a34dcae",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 96821,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "On A List of Lethalities"
    },
    "bf272273c634e3d23d027e695d604b1b": {
      "source_id": "bf272273c634e3d23d027e695d604b1b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31103,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Contra EY: Can AGI destroy us without trial & error?"
    },
    "9f65e0d1a748964b23cb9c227ce8ca58": {
      "source_id": "9f65e0d1a748964b23cb9c227ce8ca58",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1415,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "OpenAI: GPT-based LLMs show ability to discriminate between its own wrong answer"
    },
    "6626e73607357bc34638631927797f0e": {
      "source_id": "6626e73607357bc34638631927797f0e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41100,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Resources I send to AI researchers about AI safety"
    },
    "1d5fce2bfc9006ab5648ec219dec9962": {
      "source_id": "1d5fce2bfc9006ab5648ec219dec9962",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21426,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why multi-agent safety is important "
    },
    "d39ef573893d88240dfdf9fc30b7ad5a": {
      "source_id": "d39ef573893d88240dfdf9fc30b7ad5a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2793,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Slow motion videos as AI risk intuition pumps"
    },
    "71ad91fa453c1baf0c3c9d06babcd5a1": {
      "source_id": "71ad91fa453c1baf0c3c9d06babcd5a1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4186,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Alignment Risk Doesn't Require Superintelligence"
    },
    "ffc680ce1f24e5fdbca8cbf603a0eca7": {
      "source_id": "ffc680ce1f24e5fdbca8cbf603a0eca7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2512,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What are all the AI Alignment and AI Safety Communication Hubs?"
    },
    "7e900cc761c0070e16650a5d8724e82c": {
      "source_id": "7e900cc761c0070e16650a5d8724e82c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3565,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "FYI: I\u2019m working on a book about the threat of AGI/ASI for a general audience. I"
    },
    "afc6090c7138f6e56cb290eb03960954": {
      "source_id": "afc6090c7138f6e56cb290eb03960954",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37367,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Towards Gears-Level Understanding of Agency"
    },
    "6afebce9330cdcc858eefc2d2454a361": {
      "source_id": "6afebce9330cdcc858eefc2d2454a361",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11774,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Unified Theory of Normative Ethics"
    },
    "32b10903c95cfba4f1f0b718e1de7bb0": {
      "source_id": "32b10903c95cfba4f1f0b718e1de7bb0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 651,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Scott Aaronson is joining OpenAI to work on AI safety"
    },
    "41ab6850d99f9b22b85b1aca1169ba5d": {
      "source_id": "41ab6850d99f9b22b85b1aca1169ba5d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1504,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI misalignment risk from GPT-like systems?"
    },
    "2c390d778febd740a659c128df95d97b": {
      "source_id": "2c390d778febd740a659c128df95d97b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9542,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Steam"
    },
    "6e857db7ae2fbf03f61882bd1e40d6b4": {
      "source_id": "6e857db7ae2fbf03f61882bd1e40d6b4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16918,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Getting from an unaligned AGI to an aligned AGI? "
    },
    "58e1cef96ddf4167acb5f429dc16a5d9": {
      "source_id": "58e1cef96ddf4167acb5f429dc16a5d9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19471,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The inordinately slow spread of good AGI conversations in ML"
    },
    "4743b0bf5153169c3e96b197836cb2bb": {
      "source_id": "4743b0bf5153169c3e96b197836cb2bb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13420,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Quick List of Some Problems in AI Alignment As A Field"
    },
    "af3d65ce2d4762c10c6c041be01f9639": {
      "source_id": "af3d65ce2d4762c10c6c041be01f9639",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6990,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Confusion about neuroscience/cognitive science as a danger for AI Alignment"
    },
    "ed25db70245bebdbb949405c18172627": {
      "source_id": "ed25db70245bebdbb949405c18172627",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2540,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Loose thoughts on AGI risk"
    },
    "948c788e1b99b6b34808bb5cd2790d9c": {
      "source_id": "948c788e1b99b6b34808bb5cd2790d9c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1740,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is CIRL a promising agenda?"
    },
    "8c0b6172e4c61ef1f19035e3092a6971": {
      "source_id": "8c0b6172e4c61ef1f19035e3092a6971",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12686,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[LQ] Some Thoughts on Messaging Around AI Risk"
    },
    "dee9fa6d7e956815e1b5ba931109a887": {
      "source_id": "dee9fa6d7e956815e1b5ba931109a887",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13935,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Identification of Natural Modularity"
    },
    "a9fcff33ee980e3dac2b3a3ddbab567d": {
      "source_id": "a9fcff33ee980e3dac2b3a3ddbab567d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4123,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Conversation with Eliezer: What do you want the system to do?"
    },
    "3ace9a2488106a310d55dd47adac466d": {
      "source_id": "3ace9a2488106a310d55dd47adac466d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1945,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Doom doubts - is inner alignment a likely problem?"
    },
    "21f6e76ce00a452936d751cbf30cea14": {
      "source_id": "21f6e76ce00a452936d751cbf30cea14",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32971,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI safety university groups: a promising opportunity to reduce existential risk"
    },
    "6e88d0c06962aef840d616bf97a98851": {
      "source_id": "6e88d0c06962aef840d616bf97a98851",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12331,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Reframing the AI Risk"
    },
    "71fbd55de568bea76191c41398ee99c8": {
      "source_id": "71fbd55de568bea76191c41398ee99c8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10797,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Agenty AGI \u2013 How Tempting?"
    },
    "6a212e2c1a07309fdb84f14ebd6009f9": {
      "source_id": "6a212e2c1a07309fdb84f14ebd6009f9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 93923,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Goal-directedness: tackling complexity"
    },
    "85f759c9c01ff1d05452e3738de08bf9": {
      "source_id": "85f759c9c01ff1d05452e3738de08bf9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3806,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Follow along with Columbia EA's Advanced AI Safety Fellowship!"
    },
    "7547d4dadf1689dc97a88e6b95fa1d3b": {
      "source_id": "7547d4dadf1689dc97a88e6b95fa1d3b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32179,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Tree of Life: Stanford AI Alignment Theory of Change"
    },
    "5f8181a41f08efc43c557d568c93b738": {
      "source_id": "5f8181a41f08efc43c557d568c93b738",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9210,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Naive Hypotheses on AI Alignment"
    },
    "42e8298f132c54f6d4682fb11fb7e90e": {
      "source_id": "42e8298f132c54f6d4682fb11fb7e90e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25886,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Can we achieve AGI Alignment by balancing multiple human objectives?"
    },
    "a868ff09622fb67e1dab65382980bd2d": {
      "source_id": "a868ff09622fb67e1dab65382980bd2d",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 2163,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "New US Senate Bill on X-Risk Mitigation [Linkpost]"
    },
    "fe8cbaed4a7b76635cc51c746d1a68ef": {
      "source_id": "fe8cbaed4a7b76635cc51c746d1a68ef",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2668,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A compressed take on recent disagreements"
    },
    "284bd163f9bb8a013c01555707271a6e": {
      "source_id": "284bd163f9bb8a013c01555707271a6e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12372,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Forecasting: One Year In"
    },
    "6fec6d8821c6d2cfe6fe4065d5340c2f": {
      "source_id": "6fec6d8821c6d2cfe6fe4065d5340c2f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57474,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is General Intelligence \"Compact\"?"
    },
    "3eb2cc804ab8a15e9d9826ff28e82509": {
      "source_id": "3eb2cc804ab8a15e9d9826ff28e82509",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7498,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "My Most Likely Reason to Die Young is AI X-Risk"
    },
    "2b82d427395a673c554a2574555b1788": {
      "source_id": "2b82d427395a673c554a2574555b1788",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4449,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Please help us communicate AI xrisk. It could save the world."
    },
    "5c364a346652d99849984942a1db9e39": {
      "source_id": "5c364a346652d99849984942a1db9e39",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7432,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The curious case of Pretty Good human inner/outer alignment"
    },
    "479646a3a3d3be45e99aaf3543add7a1": {
      "source_id": "479646a3a3d3be45e99aaf3543add7a1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3538,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How humanity would respond to slow takeoff, with takeaways from the entire COVID"
    },
    "10a62578f49f42f644fbd748509b8f7a": {
      "source_id": "10a62578f49f42f644fbd748509b8f7a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8931,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Confusions in My Model of AI Risk"
    },
    "ac2d7297cd2b62d34e9c8f7dcc6b4af9": {
      "source_id": "ac2d7297cd2b62d34e9c8f7dcc6b4af9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7900,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Reinforcement Learner Wireheading"
    },
    "e11ef497573a956756bc2e63ff11ec37": {
      "source_id": "e11ef497573a956756bc2e63ff11ec37",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3845,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Research Notes: What are we aligning for?"
    },
    "2849f6ab0cbccb87255f7a28933415ff": {
      "source_id": "2849f6ab0cbccb87255f7a28933415ff",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24174,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Alignment Problem"
    },
    "68dc317d2d6d5444594750d6d21e014f": {
      "source_id": "68dc317d2d6d5444594750d6d21e014f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40639,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "MIRI Conversations: Technology Forecasting & Gradualism (Distillation)"
    },
    "332ebd70b6353c4ab6dce0e4f8eae0a8": {
      "source_id": "332ebd70b6353c4ab6dce0e4f8eae0a8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23649,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Making decisions using multiple worldviews"
    },
    "eebbb1fbc4486cb7894ac18478318437": {
      "source_id": "eebbb1fbc4486cb7894ac18478318437",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8658,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Goal Alignment Is Robust To the Sharp Left Turn"
    },
    "d6cd59d36f501e908fddf19109a62f68": {
      "source_id": "d6cd59d36f501e908fddf19109a62f68",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5741,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "All AGI safety questions welcome (especially basic ones) [July 2022]"
    },
    "2147040eebb82d971e2fcbed65865d3f": {
      "source_id": "2147040eebb82d971e2fcbed65865d3f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4169,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Alignment as Game Design"
    },
    "d0b2c7bf5d876fc94f49797a40c83e9a": {
      "source_id": "d0b2c7bf5d876fc94f49797a40c83e9a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17313,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Critique of AI Alignment Pessimism"
    },
    "a7314fa6581a87d5911d6db2b0a26135": {
      "source_id": "a7314fa6581a87d5911d6db2b0a26135",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1903,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How much to optimize for the short-timelines scenario?"
    },
    "5d42386e9b19d9ebedaa0a4803126599": {
      "source_id": "5d42386e9b19d9ebedaa0a4803126599",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6313,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Our Existing Solutions to AGI Alignment (semi-safe)"
    },
    "86f34cfd486fedbe1994037d4c97d8ad": {
      "source_id": "86f34cfd486fedbe1994037d4c97d8ad",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14964,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Making DALL-E Count"
    },
    "f7ba398834c56a6c8eb692d53b4f8421": {
      "source_id": "f7ba398834c56a6c8eb692d53b4f8421",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25200,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Connor Leahy on Dying with Dignity, EleutherAI and Conjecture"
    },
    "9943519141ff8cbe613d3704dd5a720a": {
      "source_id": "9943519141ff8cbe613d3704dd5a720a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17213,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Which singularity schools plus the no singularity school was right?"
    },
    "e5aee6b6dc5611f466ec35165f7676ee": {
      "source_id": "e5aee6b6dc5611f466ec35165f7676ee",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37696,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Information theoretic model analysis may not lend much insight, but we may have "
    },
    "3c3a958045ca301d0bad5a867e07780f": {
      "source_id": "3c3a958045ca301d0bad5a867e07780f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2958,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Impact of \" 'Let's think step by step' is all you need\"?"
    },
    "cd208bfb21b9525b31442da431966ab9": {
      "source_id": "cd208bfb21b9525b31442da431966ab9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4740,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Alignment being impossible might be better than it being really difficult"
    },
    "b78d18f894f29faede91801b39524642": {
      "source_id": "b78d18f894f29faede91801b39524642",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20582,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Utility functions and probabilities are entangled"
    },
    "d39b422f0c5d6e25d6089e3a8ced1450": {
      "source_id": "d39b422f0c5d6e25d6089e3a8ced1450",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12448,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing the AI Safety Field Building Hub, a new effort to provide AISFB proje"
    },
    "22c82ad92f24a616292ceac69a36dab5": {
      "source_id": "22c82ad92f24a616292ceac69a36dab5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33849,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Translating between Latent Spaces"
    },
    "5407544a49b8bf7fb08cdefa01fe62d1": {
      "source_id": "5407544a49b8bf7fb08cdefa01fe62d1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1463,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AGI-level reasoner will appear sooner than an agent; what the humanity will do w"
    },
    "7587a919b0ec87287c6b1f0a51cba4f7": {
      "source_id": "7587a919b0ec87287c6b1f0a51cba4f7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1977,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Wanted: Notation for credal resilience"
    },
    "cfcd05673c430d0087e613551c8b239f": {
      "source_id": "cfcd05673c430d0087e613551c8b239f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 773,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How likely do you think worse-than-extinction type fates to be?"
    },
    "18968339d0d0d1af306acf28fadab372": {
      "source_id": "18968339d0d0d1af306acf28fadab372",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3854,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Transformer language models are doing something more general"
    },
    "67d4f886f476e9c05cc8851bbfa8ceef": {
      "source_id": "67d4f886f476e9c05cc8851bbfa8ceef",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40235,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Three pillars for avoiding AGI catastrophe: Technical alignment, deployment deci"
    },
    "2611d2c99df509c13a7c2982cccad180": {
      "source_id": "2611d2c99df509c13a7c2982cccad180",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10680,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Surprised by ELK report's counterexample to Debate, IDA"
    },
    "80f50335b9e399c33c68e4d0a517f82f": {
      "source_id": "80f50335b9e399c33c68e4d0a517f82f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5441,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What do ML researchers think about AI in 2022?"
    },
    "d032548f4fd9c909786181f36212021e": {
      "source_id": "d032548f4fd9c909786181f36212021e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1636,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Would \"Manhattan Project\" style be beneficial or deleterious for AI Alignment?"
    },
    "07c5f986ac165a99a24650f10cefd7cb": {
      "source_id": "07c5f986ac165a99a24650f10cefd7cb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11364,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Deontology and Tool AI"
    },
    "ebaa516acf67005c9c00d233cd95fd43": {
      "source_id": "ebaa516acf67005c9c00d233cd95fd43",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11943,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Where are the red lines for AI?"
    },
    "d0620ae80dd8dbf2217cb2c886222c5a": {
      "source_id": "d0620ae80dd8dbf2217cb2c886222c5a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4447,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why I Am Skeptical of AI Regulation as an X-Risk Mitigation Strategy"
    },
    "614abf56da67987e4c5851bdf2efb270": {
      "source_id": "614abf56da67987e4c5851bdf2efb270",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 526,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Deceptively Simple Argument in favor of Problem Factorization"
    },
    "b590d7cf428f5a43e846ea7b61987dfa": {
      "source_id": "b590d7cf428f5a43e846ea7b61987dfa",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5809,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Jack Clark on the realities of AI policy"
    },
    "f6b167504431fb916c1a6a93d0fe9ac3": {
      "source_id": "f6b167504431fb916c1a6a93d0fe9ac3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32109,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Broad Basins and Data Compression"
    },
    "bcc8d8333de312dc732cda43e5f2ed0c": {
      "source_id": "bcc8d8333de312dc732cda43e5f2ed0c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13758,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How (not) to choose a research project"
    },
    "3fc674635efeaf1be356f777cf3ee8d1": {
      "source_id": "3fc674635efeaf1be356f777cf3ee8d1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23380,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Project proposal: Testing the IBP definition of agent "
    },
    "b6aa756f7de72a985a1d2686d22808d3": {
      "source_id": "b6aa756f7de72a985a1d2686d22808d3",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5315,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Team Shard Status Report"
    },
    "7ab94ed87deeaacc8ec2e0c8f9963573": {
      "source_id": "7ab94ed87deeaacc8ec2e0c8f9963573",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1604,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How would two superintelligent AIs interact, if they are unaligned with each oth"
    },
    "9c4de83d6658cc1ef0b4a5a7c55f1f8b": {
      "source_id": "9c4de83d6658cc1ef0b4a5a7c55f1f8b",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 1716,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Emergent Abilities of Large Language Models [Linkpost]"
    },
    "60bcd6ce9cb0f7ae8596481c0dafd380": {
      "source_id": "60bcd6ce9cb0f7ae8596481c0dafd380",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24812,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How Do We Align an AGI Without Getting Socially Engineered?  (Hint: Box It)"
    },
    "8def0e649108793bcca76daa2e9715a0": {
      "source_id": "8def0e649108793bcca76daa2e9715a0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2443,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Artificial intelligence wireheading"
    },
    "88c899f73a0210ed7a52f6e3c129d910": {
      "source_id": "88c899f73a0210ed7a52f6e3c129d910",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3294,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Anti-squatted AI x-risk domains index"
    },
    "3644ed81ad7acf375467db23ef135372": {
      "source_id": "3644ed81ad7acf375467db23ef135372",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1959,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A little playing around with Blenderbot3"
    },
    "9fe9ca2b25b3b09b1e4d4cfac998dbdb": {
      "source_id": "9fe9ca2b25b3b09b1e4d4cfac998dbdb",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3746,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Timelines explanation post part 1 of ?"
    },
    "b361c71ea3206df641c279b5ccfa13c8": {
      "source_id": "b361c71ea3206df641c279b5ccfa13c8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6152,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Infant AI Scenario"
    },
    "9960985abbe91b8acbeca5ccdc74a189": {
      "source_id": "9960985abbe91b8acbeca5ccdc74a189",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39447,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What Makes an Idea Understandable? On Architecturally and Culturally Natural Ide"
    },
    "bfc7089331e5fdf9150e10724b5595e8": {
      "source_id": "bfc7089331e5fdf9150e10724b5595e8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10464,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Deception as the optimal: mesa-optimizers and inner alignment  "
    },
    "abfb3b3f062436b244b8d7fd3b83346a": {
      "source_id": "abfb3b3f062436b244b8d7fd3b83346a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7061,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Mesa-optimization for goals defined only within a training environment is danger"
    },
    "24f70fe601bdadd48bb0c82686bf3faa": {
      "source_id": "24f70fe601bdadd48bb0c82686bf3faa",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20010,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Thoughts on 'List of Lethalities'"
    },
    "570686a41686623a158778ce031d4c6b": {
      "source_id": "570686a41686623a158778ce031d4c6b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2933,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Interpretability Tools Are an Attack Channel"
    },
    "150b60d60b17d82cb19f01be33ee34db": {
      "source_id": "150b60d60b17d82cb19f01be33ee34db",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1370,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Matt Yglesias on AI Policy"
    },
    "39744a3f91ab15089ebd9a9d87882a1a": {
      "source_id": "39744a3f91ab15089ebd9a9d87882a1a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3581,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Alignment's phlogiston "
    },
    "cab15bfd0b989c7d3f92f4e2c3715cca": {
      "source_id": "cab15bfd0b989c7d3f92f4e2c3715cca",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 545,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Can You Upload Your Mind & Live Forever? From Kurzgesagt - In a Nutshell"
    },
    "0677216d8db010c7b2f98eef64093bb9": {
      "source_id": "0677216d8db010c7b2f98eef64093bb9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 832,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What's the Least Impressive Thing GPT-4 Won't be Able to Do"
    },
    "b148b2d44e1e3c600e8e2e396bf51de4": {
      "source_id": "b148b2d44e1e3c600e8e2e396bf51de4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13185,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "My Plan to Build Aligned Superintelligence"
    },
    "077eae671d68c8424b1709fd6b50f5c5": {
      "source_id": "077eae671d68c8424b1709fd6b50f5c5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16929,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Pivotal acts using an unaligned AGI?"
    },
    "3d7b7f4ae06fad6e5ed15aba24da577c": {
      "source_id": "3d7b7f4ae06fad6e5ed15aba24da577c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9772,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Alignment Problem Needs More Positive Fiction"
    },
    "9dfcb9c50ed108c88a9bba5c530b6fd8": {
      "source_id": "9dfcb9c50ed108c88a9bba5c530b6fd8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 817,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What if we solve AI Safety but no one cares"
    },
    "e7b8110cdc111d5d1311289fdfdfde23": {
      "source_id": "e7b8110cdc111d5d1311289fdfdfde23",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4830,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI art isn't \"about to shake things up\". It's already here."
    },
    "aeeed96c95a42e1972dc016c33399ffd": {
      "source_id": "aeeed96c95a42e1972dc016c33399ffd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17485,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "It Looks Like You\u2019re Trying To Take Over The Narrative"
    },
    "9da4b015509cb17bcc1120eb7ed79ba6": {
      "source_id": "9da4b015509cb17bcc1120eb7ed79ba6",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3404,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Thoughts about OOD alignment"
    },
    "4f9b7179145e5ca288dd216df359bbd2": {
      "source_id": "4f9b7179145e5ca288dd216df359bbd2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10404,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "OpenAI's Alignment Plans"
    },
    "9a773b06f35666ed8b48d5dbf7a6394d": {
      "source_id": "9a773b06f35666ed8b48d5dbf7a6394d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4855,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Shard Theory Alignment Scheme"
    },
    "bc8e0d70213c064f4586d35a1e23a18d": {
      "source_id": "bc8e0d70213c064f4586d35a1e23a18d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12715,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Solomonoff prior is malign. It's not a big deal."
    },
    "4f6ae8230fe9b4830f24ab36f17c4bf3": {
      "source_id": "4f6ae8230fe9b4830f24ab36f17c4bf3",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9602,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Evaluating OpenAI's alignment plans using training stories"
    },
    "f594ec726ae7d159bfd4b906280b034d": {
      "source_id": "f594ec726ae7d159bfd4b906280b034d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20821,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Taking the parameters which seem to matter and rotating them until they don't"
    },
    "2dc557a1719384433c1099c3c242d3ba": {
      "source_id": "2dc557a1719384433c1099c3c242d3ba",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12876,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Risk in Terms of Unstable Nuclear Software"
    },
    "7d453043202d6f99b57d3722f100524a": {
      "source_id": "7d453043202d6f99b57d3722f100524a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49720,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Solving Alignment by \"solving\" semantics"
    },
    "48376dc56a66e90dc111b1c028858e26": {
      "source_id": "48376dc56a66e90dc111b1c028858e26",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45900,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How Do AI Timelines Affect Existential Risk?"
    },
    "e0e4faae39cfc0ddfa158eeb36fc5ca0": {
      "source_id": "e0e4faae39cfc0ddfa158eeb36fc5ca0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6985,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Are Generative World Models a Mesa-Optimization Risk?"
    },
    "86f99fc4dbfbe31f7a26df8aa6b3274e": {
      "source_id": "86f99fc4dbfbe31f7a26df8aa6b3274e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45440,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Can We Align a Self-Improving AGI?"
    },
    "d8bf8afa2aa3b1e724c74a85deb319df": {
      "source_id": "d8bf8afa2aa3b1e724c74a85deb319df",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 80506,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A gentle primer on caring, including in strange senses, with applications"
    },
    "7ab08a1af0d593dec44c4a87c5194790": {
      "source_id": "7ab08a1af0d593dec44c4a87c5194790",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8717,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Inner Alignment via Superpowers"
    },
    "d29888c23c9b9ba031ff09d53f42f859": {
      "source_id": "d29888c23c9b9ba031ff09d53f42f859",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 352,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How might we make better use of AI capabilities research for alignment purposes?"
    },
    "85010ec68c630f75eeef862a518ca720": {
      "source_id": "85010ec68c630f75eeef862a518ca720",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7279,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Alignment is hard. Communicating that, might be harder "
    },
    "134bad3b67bf61ec4eb70ae7dea95941": {
      "source_id": "134bad3b67bf61ec4eb70ae7dea95941",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43300,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Survey of Foundational Methods in Inverse Reinforcement Learning"
    },
    "fc87526cc52738dd6f0b221c8caf69f6": {
      "source_id": "fc87526cc52738dd6f0b221c8caf69f6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40395,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Levelling Up in AI Safety Research Engineering"
    },
    "ad8e11e470328cd327958d240b736b7c": {
      "source_id": "ad8e11e470328cd327958d240b736b7c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2260,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Laziness in AI"
    },
    "f50e8f882efb0f98780e2ba1472b0ef2": {
      "source_id": "f50e8f882efb0f98780e2ba1472b0ef2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13410,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Agency engineering: is AI-alignment \"to human intent\" enough?"
    },
    "e6ee3f761b458d5465f37ac7357e2c8a": {
      "source_id": "e6ee3f761b458d5465f37ac7357e2c8a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6536,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Three scenarios of pseudo-alignment "
    },
    "18bee7890f3a13d385ec65bc1c3557de": {
      "source_id": "18bee7890f3a13d385ec65bc1c3557de",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10550,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How To Know What the AI Knows - An ELK Distillation"
    },
    "d5bc0d568d764a5d5b58d0031c6cef3a": {
      "source_id": "d5bc0d568d764a5d5b58d0031c6cef3a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 831,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Help me find a good Hackathon subject "
    },
    "f76854a8bae0580ad199d8335429057e": {
      "source_id": "f76854a8bae0580ad199d8335429057e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2726,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Game About AI Alignment (& Meta-Ethics): What Are the Must Haves?"
    },
    "4919b280fb5318177912059a44290dee": {
      "source_id": "4919b280fb5318177912059a44290dee",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3788,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "program searches"
    },
    "85daf962ca8130c1af35f5738f8c1980": {
      "source_id": "85daf962ca8130c1af35f5738f8c1980",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20843,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Governance Needs Technical Work"
    },
    "a5330336dc368d3c054ba2ba0a62c39a": {
      "source_id": "a5330336dc368d3c054ba2ba0a62c39a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5065,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Alex Lawsen On Forecasting AI Progress"
    },
    "967f855c4742f30331d39bc95baa2c84": {
      "source_id": "967f855c4742f30331d39bc95baa2c84",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2158,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How Josiah became an AI safety researcher"
    },
    "e7d8d1e4c65245f7e9d47f0fffb4fcda": {
      "source_id": "e7d8d1e4c65245f7e9d47f0fffb4fcda",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7967,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Community Building for Graduate Students: A Targeted Approach"
    },
    "81f8fe1d6700d48f407863e3fe360a39": {
      "source_id": "81f8fe1d6700d48f407863e3fe360a39",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1725,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How can we secure more research positions at our universities for x-risk researc"
    },
    "7fa257adb7deb4dac0e8692422d27908": {
      "source_id": "7fa257adb7deb4dac0e8692422d27908",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9621,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Progress Report 7: making GPT go hurrdurr instead of brrrrrrr"
    },
    "04fce5e6e4513e5ed06204e78689ea12": {
      "source_id": "04fce5e6e4513e5ed06204e78689ea12",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35468,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Can \"Reward Economics\" solve AI Alignment?"
    },
    "3c36f9e72dad40230177c31c1084bff0": {
      "source_id": "3c36f9e72dad40230177c31c1084bff0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4121,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "It's (not) how you use it "
    },
    "2fec97eae5b7b01f33536ebe89ddcec6": {
      "source_id": "2fec97eae5b7b01f33536ebe89ddcec6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30187,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Searching for Modularity in Large Language Models"
    },
    "5234adbd72f2fa7459ccd62cfdb36c13": {
      "source_id": "5234adbd72f2fa7459ccd62cfdb36c13",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5563,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "All AGI safety questions welcome (especially basic ones) [Sept 2022]"
    },
    "dfd57f4798febd21e7563c3104b40443": {
      "source_id": "dfd57f4798febd21e7563c3104b40443",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 78876,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What Should AI Owe To Us? Accountable and Aligned AI Systems via Contractualist "
    },
    "23f61e2e9afdef2abfd64345d4908895": {
      "source_id": "23f61e2e9afdef2abfd64345d4908895",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3680,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A rough idea for solving ELK: An approach for training generalist agents like GA"
    },
    "c199eea2f63ce1f3edb1d2cc03d2a5a0": {
      "source_id": "c199eea2f63ce1f3edb1d2cc03d2a5a0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14128,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Gatekeeper Victory: AI Box Reflection"
    },
    "b708b2d37d88d805bea53d74ebca3a62": {
      "source_id": "b708b2d37d88d805bea53d74ebca3a62",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62852,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Risk Intro 1: Advanced AI Might Be Very Bad"
    },
    "0daaccc301af821de8d7528132a7fd5f": {
      "source_id": "0daaccc301af821de8d7528132a7fd5f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7893,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Briefly thinking through some analogs of debate"
    },
    "90d61d7d3ebf55adf0b809bf58e4a2dd": {
      "source_id": "90d61d7d3ebf55adf0b809bf58e4a2dd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14491,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Safety field-building projects I'd like to see"
    },
    "d65c94c3ed690ad4cf1ccfebd0f30118": {
      "source_id": "d65c94c3ed690ad4cf1ccfebd0f30118",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5147,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Black Box Investigation Research Hackathon"
    },
    "9d3e85991bbd59501c4a766bb857d136": {
      "source_id": "9d3e85991bbd59501c4a766bb857d136",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14460,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Alignment via prosocial brain algorithms"
    },
    "39963701dbd5d8bf29361ac55816d782": {
      "source_id": "39963701dbd5d8bf29361ac55816d782",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2765,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why do People Think Intelligence Will be \"Easy\"?"
    },
    "385feba312af3cfcc044f63d80f54e26": {
      "source_id": "385feba312af3cfcc044f63d80f54e26",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 60541,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Deep Q-Networks Explained"
    },
    "90ecfd8d17e0fa9dd21830471fd2b146": {
      "source_id": "90ecfd8d17e0fa9dd21830471fd2b146",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44685,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "An investigation into when agents may be incentivized to manipulate our beliefs."
    },
    "88f35f3667b9bb72f9e872a47e0bfd7a": {
      "source_id": "88f35f3667b9bb72f9e872a47e0bfd7a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1672,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Risk aversion and GPT-3"
    },
    "f91f19148ec058e154a025b4ac0820b5": {
      "source_id": "f91f19148ec058e154a025b4ac0820b5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12146,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Would a Misaligned SSI Really Kill Us All?"
    },
    "2c6a031f0b13c767ad62d18d720c8b75": {
      "source_id": "2c6a031f0b13c767ad62d18d720c8b75",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5303,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why Do People Think Humans Are Stupid?"
    },
    "ab8521290140f25e09fde8bf94aa933b": {
      "source_id": "ab8521290140f25e09fde8bf94aa933b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1223,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Emily Bront\u00eb on: Psychology Required for Serious\u2122 AGI Safety Research"
    },
    "43d503ed73b506872cb4881ace317a22": {
      "source_id": "43d503ed73b506872cb4881ace317a22",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1705,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Precise P(doom) isn't very important for prioritization or strategy"
    },
    "93d0b1a8cb8898331101bfdbf32ce5dd": {
      "source_id": "93d0b1a8cb8898331101bfdbf32ce5dd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42520,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Responding to 'Beyond Hyperanthropomorphism'"
    },
    "26c3baba39111a0d5f8f3714c4aedc87": {
      "source_id": "26c3baba39111a0d5f8f3714c4aedc87",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 979,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Forecasting thread: How does AI risk level vary based on timelines?"
    },
    "6cc33eff90db8c6bb175027c298aa0de": {
      "source_id": "6cc33eff90db8c6bb175027c298aa0de",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23671,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "General advice for transitioning into Theoretical AI Safety"
    },
    "1a33d39fbd64b0903c1cc3527cf3f643": {
      "source_id": "1a33d39fbd64b0903c1cc3527cf3f643",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23319,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Capability and Agency as Cornerstones of AI risk \u00ad\u2014 My current model"
    },
    "0387b0e937dab9620adb2e69be7ed1f6": {
      "source_id": "0387b0e937dab9620adb2e69be7ed1f6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45981,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How should DeepMind's Chinchilla revise our AI forecasts?"
    },
    "c96b89705c259d3bb01c99b8296dbb3e": {
      "source_id": "c96b89705c259d3bb01c99b8296dbb3e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25719,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Understanding Conjecture: Notes from Connor Leahy interview"
    },
    "0ee5a55b37b7872d16c812e97877ebcb": {
      "source_id": "0ee5a55b37b7872d16c812e97877ebcb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12066,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Bite Sized Introduction to ELK"
    },
    "97defd9cde06889e445ab56ada1fde61": {
      "source_id": "97defd9cde06889e445ab56ada1fde61",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3107,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Apply for mentorship in AI Safety field-building"
    },
    "ca3d9d8995a979af13f9fa4e6906d829": {
      "source_id": "ca3d9d8995a979af13f9fa4e6906d829",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6789,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Sparse trinary weighted RNNs as a path to better language model interpretability"
    },
    "6f67a1e35f33e87ca3904f2e5aea8fc4": {
      "source_id": "6f67a1e35f33e87ca3904f2e5aea8fc4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1245,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Updates on FLI's Value Aligment Map?"
    },
    "75a894390a5605bebdac942ae1106907": {
      "source_id": "75a894390a5605bebdac942ae1106907",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6658,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Leveraging Legal Informatics to Align AI"
    },
    "87894f1cd732eaf79e51a22895861ac3": {
      "source_id": "87894f1cd732eaf79e51a22895861ac3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2685,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The ELK Framing I\u2019ve Used"
    },
    "efc8f38cd10701d82823489fee31c566": {
      "source_id": "efc8f38cd10701d82823489fee31c566",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36784,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Safety timelines: How long will it take to solve alignment?"
    },
    "7ba9be3f2049b205cc7e3e161ee95bf2": {
      "source_id": "7ba9be3f2049b205cc7e3e161ee95bf2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3281,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Character alignment"
    },
    "b4087ec90f7240ace8d24f71958c596c": {
      "source_id": "b4087ec90f7240ace8d24f71958c596c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11544,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Alignment Org Cheat Sheet"
    },
    "e9ca8d93b1161a704afe6c22d724fe18": {
      "source_id": "e9ca8d93b1161a704afe6c22d724fe18",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9647,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Cryptocurrency Exploits Show the Importance of Proactive Policies for AI X-Risk"
    },
    "f03df8531a071eb9ae47fe2f2009f209": {
      "source_id": "f03df8531a071eb9ae47fe2f2009f209",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25381,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "An issue with MacAskill's Evidentialist's Wager"
    },
    "d557a1c5fe0d1aae94c7c3f6b1ec5c40": {
      "source_id": "d557a1c5fe0d1aae94c7c3f6b1ec5c40",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4865,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Understanding Infra-Bayesianism: A Beginner-Friendly Video Series"
    },
    "2e410aa1dff03d89a174b043c3ee1699": {
      "source_id": "2e410aa1dff03d89a174b043c3ee1699",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62071,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Risk Intro 2: Solving The Problem"
    },
    "1faa238ce0c8ae04477d10329b2fa1e3": {
      "source_id": "1faa238ce0c8ae04477d10329b2fa1e3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24670,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Dath Ilan's Views on Stopgap Corrigibility"
    },
    "c445a50b6400a004454759c393ab43c1": {
      "source_id": "c445a50b6400a004454759c393ab43c1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13370,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Public-facing Censorship Is Safety Theater, Causing Reputational Damage "
    },
    "f164772b9c1a11eaaaa9a0cc355a97e9": {
      "source_id": "f164772b9c1a11eaaaa9a0cc355a97e9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9093,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Shahar Avin On How To Regulate Advanced AI Systems"
    },
    "f8cb616eea6da4984a12b14ad19b690f": {
      "source_id": "f8cb616eea6da4984a12b14ad19b690f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5930,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why Do AI researchers Rate the Probability of Doom So Low?"
    },
    "7bd02d1d4ab97ccf26f28b0088a4d2c5": {
      "source_id": "7bd02d1d4ab97ccf26f28b0088a4d2c5",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8810,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Two reasons we might be closer to solving alignment than it seems"
    },
    "322485a8d4351b93138ddf723c785247": {
      "source_id": "322485a8d4351b93138ddf723c785247",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2626,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Papers to start getting into NLP-focused alignment research"
    },
    "f022466c7d3f98ab9bda61b27dc35e1a": {
      "source_id": "f022466c7d3f98ab9bda61b27dc35e1a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26160,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "On Generality"
    },
    "1fa5f9eab932a265e74c7200d41bcc23": {
      "source_id": "1fa5f9eab932a265e74c7200d41bcc23",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5312,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "You are Underestimating The Likelihood That Convergent Instrumental Subgoals Lea"
    },
    "6aa3c4526d5f16b6f523d7f408338207": {
      "source_id": "6aa3c4526d5f16b6f523d7f408338207",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7293,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "7 traps that (we think) new alignment researchers often fall into"
    },
    "ac37c1ff449901881bfc81061ee3db68": {
      "source_id": "ac37c1ff449901881bfc81061ee3db68",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 93092,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why I think strong general AI is coming soon"
    },
    "170925562a2c4c47d57eb57ae36a686c": {
      "source_id": "170925562a2c4c47d57eb57ae36a686c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53953,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Strange Loops - Self-Reference from Number Theory to AI"
    },
    "cbcdb68961c2a8192c15f331c0477019": {
      "source_id": "cbcdb68961c2a8192c15f331c0477019",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36447,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Will Values and Competition Decouple?"
    },
    "d24c35c35fa2fc8ace3e925dfc30efda": {
      "source_id": "d24c35c35fa2fc8ace3e925dfc30efda",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21363,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Do anthropic considerations undercut the evolution anchor from the Bio Anchors r"
    },
    "2a00c7753e3ffd57183525a4e3a21e8c": {
      "source_id": "2a00c7753e3ffd57183525a4e3a21e8c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2983,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Any further work on AI Safety Success Stories?"
    },
    "c31991a7428eb0d03eebf6c040901428": {
      "source_id": "c31991a7428eb0d03eebf6c040901428",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43919,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Data for IRL: What is needed to learn human values?"
    },
    "d4e73502d25de6fd69c0d0da2502acf7": {
      "source_id": "d4e73502d25de6fd69c0d0da2502acf7",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 4245,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Linkpost] \"Blueprint for an AI Bill of Rights\" - Office of Science and Technolo"
    },
    "b38882e8026dbb521c5d573f0ad91d29": {
      "source_id": "b38882e8026dbb521c5d573f0ad91d29",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33114,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Neural Tangent Kernel Distillation"
    },
    "38f6c5e17f235353c548208b758e1e1c": {
      "source_id": "38f6c5e17f235353c548208b758e1e1c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15927,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Generative, Episodic Objectives for Safe AI"
    },
    "73bd392d3f5ac6c9a47ab7e774213a1a": {
      "source_id": "73bd392d3f5ac6c9a47ab7e774213a1a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58216,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Timelines via Cumulative Optimization Power: Less Long, More Short"
    },
    "91da12857b09cf27b45bfd9e250cedff": {
      "source_id": "91da12857b09cf27b45bfd9e250cedff",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 94773,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Analysing a 2036 Takeover Scenario"
    },
    "2c588ab099e31a166fe505559838c754": {
      "source_id": "2c588ab099e31a166fe505559838c754",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7149,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Alignment Might Never Be Solved, By Humans or AI"
    },
    "0c40f881393f3c4fe141543781bd56f4": {
      "source_id": "0c40f881393f3c4fe141543781bd56f4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37198,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Boolean Primitives for Coupled Optimizers"
    },
    "48733407fa94505badc81380f1d0c941": {
      "source_id": "48733407fa94505badc81380f1d0c941",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10661,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Analysis: US restricts GPU sales to China"
    },
    "ee37a62b144fee5c0fa90919c6dc6061": {
      "source_id": "ee37a62b144fee5c0fa90919c6dc6061",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6150,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Let\u2019s talk about uncontrollable AI"
    },
    "d59aaa8e94c43a48070fbcadc88ffa29": {
      "source_id": "d59aaa8e94c43a48070fbcadc88ffa29",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41452,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Uncontrollable AI as an Existential Risk"
    },
    "19a91362cd970d20d78049f0984e9cd8": {
      "source_id": "19a91362cd970d20d78049f0984e9cd8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16793,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Possible miracles"
    },
    "9b3287184a4cc9d13a32991bbd0a9f4a": {
      "source_id": "9b3287184a4cc9d13a32991bbd0a9f4a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9999,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Results from the language model hackathon"
    },
    "38feed187286702eabf66a594687b83e": {
      "source_id": "38feed187286702eabf66a594687b83e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20107,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Misalignment Harms Can Be Caused by Low Intelligence Systems"
    },
    "67bb86a0e7338c503686c5cb61dc5fc1": {
      "source_id": "67bb86a0e7338c503686c5cb61dc5fc1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18664,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Power-Seeking AI and Existential Risk"
    },
    "c87f0bef1fef791083884f9b50f0d5fc": {
      "source_id": "c87f0bef1fef791083884f9b50f0d5fc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41752,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Article Review: Google's AlphaTensor"
    },
    "43d4b5839b0d1a89fa082ff08998b8fe": {
      "source_id": "43d4b5839b0d1a89fa082ff08998b8fe",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42705,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "You are better at math (and alignment) than you think"
    },
    "68c9981c6be9799e2e0f85adfa6a956d": {
      "source_id": "68c9981c6be9799e2e0f85adfa6a956d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4203,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Job]: AI Standards Development Research Assistant"
    },
    "5ad9dfe60e4b5fef64682e44b56432c5": {
      "source_id": "5ad9dfe60e4b5fef64682e44b56432c5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2047,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Best resource to go from \"typical smart tech-savvy person\" to \"person who gets A"
    },
    "f9415013d45468a9994f410226e369e0": {
      "source_id": "f9415013d45468a9994f410226e369e0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27039,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Maximal lotteries for value learning"
    },
    "97a286a3388960d8adbd7c271e120185": {
      "source_id": "97a286a3388960d8adbd7c271e120185",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2597,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "They gave LLMs access to physics simulators"
    },
    "b4f4342f74f32a26b2e84a0407c9feea": {
      "source_id": "b4f4342f74f32a26b2e84a0407c9feea",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3707,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is GPT-N bounded by human capabilities? No."
    },
    "11b419c6967bfd36c8c0d7f14850e831": {
      "source_id": "11b419c6967bfd36c8c0d7f14850e831",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1109,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Should we push for requiring AI training data to be licensed?"
    },
    "0d394b56b41d09a6a5c1bb1680308abc": {
      "source_id": "0d394b56b41d09a6a5c1bb1680308abc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1281,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What Does AI Alignment Success Look Like?"
    },
    "dc5596c8569b526c9260915d4b289c97": {
      "source_id": "dc5596c8569b526c9260915d4b289c97",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51566,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The heritability of human values: A behavior genetic critique of Shard Theory"
    },
    "de6af9955206f4d28ac5de9be7b8cba8": {
      "source_id": "de6af9955206f4d28ac5de9be7b8cba8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 48121,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Trajectories to 2036"
    },
    "42562c33f114f307c9be97e0cdb85103": {
      "source_id": "42562c33f114f307c9be97e0cdb85103",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8327,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Plans Are Predictions, Not Optimization Targets"
    },
    "d66c7e9389572d6ef7ec16b678f0ca62": {
      "source_id": "d66c7e9389572d6ef7ec16b678f0ca62",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 120971,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Learning societal values from law as part of an AGI alignment strategy"
    },
    "63eee8712a9e881489528503f6ed8c47": {
      "source_id": "63eee8712a9e881489528503f6ed8c47",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 219,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Simple question about corrigibility and values in AI."
    },
    "6d0f1e71941a55ff415c5518765ad1f3": {
      "source_id": "6d0f1e71941a55ff415c5518765ad1f3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12899,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI researchers announce NeuroAI agenda"
    },
    "e12fc621adb9e905cc694772aac5d0a2": {
      "source_id": "e12fc621adb9e905cc694772aac5d0a2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1832,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "What will the scaled up GATO look like? (Updated with questions)"
    },
    "a96487e0cec8f73ad01569822084ea8b": {
      "source_id": "a96487e0cec8f73ad01569822084ea8b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7383,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Intent alignment should not be the goal for AGI x-risk reduction"
    },
    "cda1e0c088cbf0e99ba7e3ca54d63773": {
      "source_id": "cda1e0c088cbf0e99ba7e3ca54d63773",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 561,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is the Orthogonality Thesis true for humans?"
    },
    "ee7e21d6dc4ad44e394f9d812923720d": {
      "source_id": "ee7e21d6dc4ad44e394f9d812923720d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1992,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "aisafety.community - A living document of AI safety communities"
    },
    "df71df12d194f3257144c6a7745218d1": {
      "source_id": "df71df12d194f3257144c6a7745218d1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10174,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Resources that (I think) new alignment researchers should know about"
    },
    "28807122d6fe70c839a6062c8ff3d99c": {
      "source_id": "28807122d6fe70c839a6062c8ff3d99c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6223,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Am I secretly excited for AI getting weird?"
    },
    "b9de3062f8966fc5262b1a086ec2edf3": {
      "source_id": "b9de3062f8966fc5262b1a086ec2edf3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22681,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI as a Civilizational Risk Part 2/6: Behavioral Modification"
    },
    "8ae3004c00242131ea63154a1cc2a738": {
      "source_id": "8ae3004c00242131ea63154a1cc2a738",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9076,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "\"Normal\" is the equilibrium state of past optimization processes"
    },
    "0a5518b43ac9c43ddb1b021602764656": {
      "source_id": "0a5518b43ac9c43ddb1b021602764656",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1322,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Me (Steve Byrnes) on the \u201cBrain Inspired\u201d podcast"
    },
    "ad33a5f03a72c35c6bb4468aa2b371fc": {
      "source_id": "ad33a5f03a72c35c6bb4468aa2b371fc",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8921,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "My (naive) take on Risks from Learned Optimization"
    },
    "173b08bf0b91d1abf4e180e408b7ba84": {
      "source_id": "173b08bf0b91d1abf4e180e408b7ba84",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3430,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Book] Interpretable Machine Learning: A Guide for Making Black Box Models Expla"
    },
    "581a44610673022179c9e1e8d49511f4": {
      "source_id": "581a44610673022179c9e1e8d49511f4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29039,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI as a Civilizational Risk Part 3/6: Anti-economy and Signal Pollution"
    },
    "fe16f7c34a548f127850f38cedb3f85d": {
      "source_id": "fe16f7c34a548f127850f38cedb3f85d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9832,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "a casual intro to AI doom and alignment"
    },
    "a6f25ae56a01f082429d4c63b04e580c": {
      "source_id": "a6f25ae56a01f082429d4c63b04e580c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17107,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI as a Civilizational Risk Part 4/6: Bioweapons and Philosophy of Modification"
    },
    "23d4a22bc01252ca4d00b14426e2844c": {
      "source_id": "23d4a22bc01252ca4d00b14426e2844c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5636,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "All AGI Safety questions welcome (especially basic ones) [~monthly thread]"
    },
    "d4c3c0e351d952232fc41a881a68fd55": {
      "source_id": "d4c3c0e351d952232fc41a881a68fd55",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14432,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI as a Civilizational Risk Part 5/6: Relationship between C-risk and X-risk "
    },
    "d350fbb55871b5b7491735db6df475fe": {
      "source_id": "d350fbb55871b5b7491735db6df475fe",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17103,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Mirror Chamber: A short story exploring the anthropic measure function and w"
    },
    "690113713b26883eb732c4b4177f0fc2": {
      "source_id": "690113713b26883eb732c4b4177f0fc2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23245,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why do we post our AI safety plans on the Internet?"
    },
    "05e25db2050113bc9c8b36942d07c6dc": {
      "source_id": "05e25db2050113bc9c8b36942d07c6dc",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9812,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI as a Civilizational Risk Part 6/6: What can be done"
    },
    "44233d6d69a94d280414ffc33ada82e6": {
      "source_id": "44233d6d69a94d280414ffc33ada82e6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38370,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Further considerations on the Evidentialist's Wager"
    },
    "11f3574e9e4d792f45256fb87ce7ba47": {
      "source_id": "11f3574e9e4d792f45256fb87ce7ba47",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 867,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Don't you think RLHF solves outer alignment?"
    },
    "9f955c578e92e9c3122abc341cffe043": {
      "source_id": "9f955c578e92e9c3122abc341cffe043",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5580,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Are alignment researchers devoting enough time to improving their research capac"
    },
    "c1e6d932a56e93b2850c6a32bba1bcd6": {
      "source_id": "c1e6d932a56e93b2850c6a32bba1bcd6",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9207,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "My summary of \u201cPragmatic AI Safety\u201d"
    },
    "dea641cc0f4492ff430ef4b3611245cf": {
      "source_id": "dea641cc0f4492ff430ef4b3611245cf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49692,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "When can a mimic surprise you? Why generative models handle seemingly ill-posed "
    },
    "32aa142494618a969ecd7f648d60c12e": {
      "source_id": "32aa142494618a969ecd7f648d60c12e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32348,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Provably Honest - A First Step"
    },
    "129adb473459eb97b06f195dfb3e1ebe": {
      "source_id": "129adb473459eb97b06f195dfb3e1ebe",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31224,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Instead of technical research, more people should focus on buying time"
    },
    "d97000ce447904d50aaa634f8c3ef52c": {
      "source_id": "d97000ce447904d50aaa634f8c3ef52c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5950,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Recommend HAIST resources for assessing the value of RLHF-related alignment rese"
    },
    "90b52a49f55dcadde21f6b66c73035e8": {
      "source_id": "90b52a49f55dcadde21f6b66c73035e8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9541,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Takeaways from a survey on AI alignment resources"
    },
    "e887c934c18d66c46ecfb532e65f2aad": {
      "source_id": "e887c934c18d66c46ecfb532e65f2aad",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16009,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "You won\u2019t solve alignment without agent foundations"
    },
    "c5f21e22575155e858dbfddbc88828d8": {
      "source_id": "c5f21e22575155e858dbfddbc88828d8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3843,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A philosopher's critique of RLHF"
    },
    "10a857f5ad2b74f9bfbd970a93422ca5": {
      "source_id": "10a857f5ad2b74f9bfbd970a93422ca5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13524,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "4 Key Assumptions in AI Safety"
    },
    "00992474545aa9e39ca749f6ebbaaedf": {
      "source_id": "00992474545aa9e39ca749f6ebbaaedf",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2360,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[ASoT] Thoughts on GPT-N"
    },
    "b9a19e77057382bcf8090c40cfdab93b": {
      "source_id": "b9a19e77057382bcf8090c40cfdab93b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14483,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Applying superintelligence without collusion "
    },
    "35b6e3f9412b6d4b7e1d6e6ab22ad57c": {
      "source_id": "35b6e3f9412b6d4b7e1d6e6ab22ad57c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2026,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A first success story for Outer Alignment: InstructGPT "
    },
    "40dc8eabeee6b33b293c99be4258d623": {
      "source_id": "40dc8eabeee6b33b293c99be4258d623",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3808,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A caveat to the Orthogonality Thesis"
    },
    "99350aae44eb5a9734e4dae593992faf": {
      "source_id": "99350aae44eb5a9734e4dae593992faf",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2462,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[ASoT] Instrumental convergence is useful"
    },
    "cf6cf785159b7febd34f6d90544ae84e": {
      "source_id": "cf6cf785159b7febd34f6d90544ae84e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1768,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is full self-driving an AGI-complete problem?"
    },
    "2a50392d97748d8f9bc692cb814c036c": {
      "source_id": "2a50392d97748d8f9bc692cb814c036c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5346,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Adversarial Priors: Not Paying People to Lie to You"
    },
    "5b1dcae168d906678a55893982378c99": {
      "source_id": "5b1dcae168d906678a55893982378c99",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1358,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "I there a demo of \"You can't fetch the coffee if you're dead\"? "
    },
    "c254ed49461592247d5f561dd9c29c85": {
      "source_id": "c254ed49461592247d5f561dd9c29c85",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4985,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why I'm Working On Model Agnostic Interpretability"
    },
    "c09b8d873b0e6b08492854d2a7860dbf": {
      "source_id": "c09b8d873b0e6b08492854d2a7860dbf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25546,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Instrumental convergence is what makes general intelligence possible"
    },
    "b0726ddfa58450fb8b5d5ffd0f324109": {
      "source_id": "b0726ddfa58450fb8b5d5ffd0f324109",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4742,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is AI Gain-of-Function research a thing?"
    },
    "6134fffa6a4420fad2d3669b56d09777": {
      "source_id": "6134fffa6a4420fad2d3669b56d09777",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30274,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Ways to buy time"
    },
    "49dae4a556ebe214ec5191279e2186db": {
      "source_id": "49dae4a556ebe214ec5191279e2186db",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3368,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Alignment Community Is Culturally Broken"
    },
    "0e071ce469264adbaf1e515ab2c4af9e": {
      "source_id": "0e071ce469264adbaf1e515ab2c4af9e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2494,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "I (with the help of a few more people) am planning to create an introduction to "
    },
    "7db15b34fabb28a8dcc71752f5a2cfd5": {
      "source_id": "7db15b34fabb28a8dcc71752f5a2cfd5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46732,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Questions about Value Lock-in, Paternalism, and Empowerment"
    },
    "429a1d8071be842cddb49bffe3f5287a": {
      "source_id": "429a1d8071be842cddb49bffe3f5287a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10354,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Massive Scaling Should be Frowned Upon"
    },
    "fd2fd128d6c6ef25e5f957838e32ec89": {
      "source_id": "fd2fd128d6c6ef25e5f957838e32ec89",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4269,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Ground Truth Problem (Or, Why Evaluating Interpretability Methods Is Hard)"
    },
    "2a7f00c6fccc9709b8abbaff3d9c1ce4": {
      "source_id": "2a7f00c6fccc9709b8abbaff3d9c1ce4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13353,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Results from the interpretability hackathon"
    },
    "d09a53b7cbe6abe1dc9894458ed956a1": {
      "source_id": "d09a53b7cbe6abe1dc9894458ed956a1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18513,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Distillation of \"How Likely Is Deceptive Alignment?\""
    },
    "95af351fa98403b131656abe8781a267": {
      "source_id": "95af351fa98403b131656abe8781a267",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 954,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is there any policy for a fair treatment of AIs whose friendliness is in doubt?"
    },
    "69516fda6440347a1f9be59a15b5a304": {
      "source_id": "69516fda6440347a1f9be59a15b5a304",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23927,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The Disastrously Confident And Inaccurate AI "
    },
    "4aff9dc0e07ac95e9c0418a5d8e4664f": {
      "source_id": "4aff9dc0e07ac95e9c0418a5d8e4664f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1922,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[ASoT] Reflectivity in Narrow AI"
    },
    "c99934add9dcd1b27308f6e1f9486a40": {
      "source_id": "c99934add9dcd1b27308f6e1f9486a40",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10278,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Hebbian Natural Abstractions] Introduction"
    },
    "d7e642306c2345481350285d40a3e91c": {
      "source_id": "d7e642306c2345481350285d40a3e91c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34294,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Sets of objectives for a multi-objective RL agent to optimize"
    },
    "8cc2522441295ec6b2c1c0c670539721": {
      "source_id": "8cc2522441295ec6b2c1c0c670539721",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5738,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Injecting some numbers into the AGI debate - by Boaz Barak"
    },
    "2c4d072adc85de01470a1f903ac29c84": {
      "source_id": "2c4d072adc85de01470a1f903ac29c84",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10063,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Against a General Factor of Doom"
    },
    "3f5b552516b3cc90ffac2b3bb86fb755": {
      "source_id": "3f5b552516b3cc90ffac2b3bb86fb755",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20895,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Gliders in Language Models"
    },
    "150abc6c3225617dc8efd05b82ae015c": {
      "source_id": "150abc6c3225617dc8efd05b82ae015c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15950,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The AI Safety community has four main work groups, Strategy, Governance, Technic"
    },
    "48340ea092758f86d7a69f439928a099": {
      "source_id": "48340ea092758f86d7a69f439928a099",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16002,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Podcast: Shoshannah Tekofsky on skilling up in AI safety, visiting Berkeley, and"
    },
    "7baefcec9cf0ee9f4ad6af46a50138cf": {
      "source_id": "7baefcec9cf0ee9f4ad6af46a50138cf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11668,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Three Alignment Schemas & Their Problems"
    },
    "4a681fa0b72bfbf3eceec8fefb7650dc": {
      "source_id": "4a681fa0b72bfbf3eceec8fefb7650dc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1904,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The First Filter"
    },
    "5db8bd75d306ba4b12a774e646b44f9a": {
      "source_id": "5db8bd75d306ba4b12a774e646b44f9a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 100381,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Discussing how to align Transformative AI if it\u2019s developed very soon "
    },
    "7f4cfe76125ced657caaa6f5ca91093a": {
      "source_id": "7f4cfe76125ced657caaa6f5ca91093a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40253,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Notes on Caution"
    },
    "0dee8456cef299e49dbe8378e3b53c31": {
      "source_id": "0dee8456cef299e49dbe8378e3b53c31",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16408,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Did ChatGPT just gaslight me?"
    },
    "c3405d4d48a9df7fca71a53d743e44a9": {
      "source_id": "c3405d4d48a9df7fca71a53d743e44a9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23260,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "ChatGPT: First Impressions"
    },
    "d3b4f8f668c1c365f56a1384eb99847e": {
      "source_id": "d3b4f8f668c1c365f56a1384eb99847e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9419,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "NeurIPS Safety & ChatGPT. MLAISU W48"
    },
    "97c75c03f37efe01d99edd77b5eb538a": {
      "source_id": "97c75c03f37efe01d99edd77b5eb538a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8097,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Takeoff speeds, the chimps analogy, and the Cultural Intelligence Hypothesis"
    },
    "053962b5efd6754348e90780ce606734": {
      "source_id": "053962b5efd6754348e90780ce606734",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30539,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "ChatGPT is surprisingly and uncanningly good at pretending to be sentient"
    },
    "cd7951bd51c1efe25cad2a26b2861da0": {
      "source_id": "cd7951bd51c1efe25cad2a26b2861da0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 640,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Will the first AGI agent have been designed as an agent (in addition to an AGI)?"
    },
    "b5322a39e5029df90f5cf392d2a32aba": {
      "source_id": "b5322a39e5029df90f5cf392d2a32aba",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29671,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "ChatGPT seems overconfident to me"
    },
    "3fe2e00b7d07d5f16a1b85bd6457a640": {
      "source_id": "3fe2e00b7d07d5f16a1b85bd6457a640",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2934,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Race to the Top: Benchmarks for AI Safety"
    },
    "70ca9aee508dd779b41f24cfd50bcb13": {
      "source_id": "70ca9aee508dd779b41f24cfd50bcb13",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6504,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Probably good projects for the AI safety ecosystem"
    },
    "39408948dfd1f14afd1ffbf0ff2fb3aa": {
      "source_id": "39408948dfd1f14afd1ffbf0ff2fb3aa",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7915,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A Tentative Timeline of The Near Future (2022-2025) for Self-Accountability"
    },
    "77669a2bfd4a7fc53ef2e47dc19db757": {
      "source_id": "77669a2bfd4a7fc53ef2e47dc19db757",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2072,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Who are some prominent reasonable people who are confident that AI won't kill ev"
    },
    "230000d176f79b24c67b81c257d665b8": {
      "source_id": "230000d176f79b24c67b81c257d665b8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4762,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is the \"Valley of Confused Abstractions\" real?"
    },
    "ba8219bf5e86ec23b98ca8df5784a812": {
      "source_id": "ba8219bf5e86ec23b98ca8df5784a812",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29816,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Aligned Behavior is not Evidence of Alignment Past a Certain Level of Intelligen"
    },
    "9af8a5ce1b2519bb86de2645cc627b79": {
      "source_id": "9af8a5ce1b2519bb86de2645cc627b79",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16309,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Foresight for AGI Safety Strategy: Mitigating Risks and Identifying Golden Oppor"
    },
    "677ade8b74979e9082f860798f5f6e68": {
      "source_id": "677ade8b74979e9082f860798f5f6e68",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16934,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Testing Ways to Bypass ChatGPT's Safety Features"
    },
    "35e06dd4f3b48f7aaa29155286832154": {
      "source_id": "35e06dd4f3b48f7aaa29155286832154",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11231,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Analysis of AI Safety surveys for field-building insights"
    },
    "db31b2a314a70ed5797451105469027d": {
      "source_id": "db31b2a314a70ed5797451105469027d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4550,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Updating my AI timelines"
    },
    "aacdf010f1f12b6af08e475d3a76d75d": {
      "source_id": "aacdf010f1f12b6af08e475d3a76d75d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7484,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "ChatGPT on Spielberg\u2019s A.I. and AI Alignment"
    },
    "43b1041ab39cdfd8b28c1636be9edb75": {
      "source_id": "43b1041ab39cdfd8b28c1636be9edb75",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6804,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Safety in a Vulnerable World: Requesting Feedback on Preliminary Thoughts"
    },
    "920dc5622dfa7743efb3e2ca2194a730": {
      "source_id": "920dc5622dfa7743efb3e2ca2194a730",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2093,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Simple Way to Prevent Power-Seeking AI"
    },
    "b8db5f4c0799cbc8961c950f00027ae5": {
      "source_id": "b8db5f4c0799cbc8961c950f00027ae5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25144,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why I'm Sceptical of Foom"
    },
    "d4d6c82e881a8bb28ab98910d3e83e26": {
      "source_id": "d4d6c82e881a8bb28ab98910d3e83e26",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8972,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "If Wentworth is right about natural abstractions, it would be bad for alignment"
    },
    "f45c00d452735366ea63c03aed77947f": {
      "source_id": "f45c00d452735366ea63c03aed77947f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32912,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Safety Seems Hard to Measure"
    },
    "1415e30a4e7bacbe8431705ddd823a29": {
      "source_id": "1415e30a4e7bacbe8431705ddd823a29",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14412,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Of pumpkins, the Falcon Heavy, and Groucho Marx: High-Level discourse structure "
    },
    "be9b02898536185abc9a16b69493c770": {
      "source_id": "be9b02898536185abc9a16b69493c770",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 880,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How is the \"sharp left turn defined\"?"
    },
    "a24f4fab529513630bdfe0b118c548f1": {
      "source_id": "a24f4fab529513630bdfe0b118c548f1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9559,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Fear mitigated the nuclear threat, can it do the same to AGI risks?"
    },
    "bea3795f8ea358176c1a2077f6bf9be9": {
      "source_id": "bea3795f8ea358176c1a2077f6bf9be9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10360,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "ML Safety at NeurIPS & Paradigmatic AI Safety? MLAISU W49"
    },
    "5e798961ce8a01ae2b37a5f60b9f333b": {
      "source_id": "5e798961ce8a01ae2b37a5f60b9f333b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 685,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Does a LLM have a utility function?"
    },
    "a75c84e5801a9f00c466ab67545af6df": {
      "source_id": "a75c84e5801a9f00c466ab67545af6df",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27527,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Prosaic misalignment from the Solomonoff Predictor"
    },
    "e7774aaca51e19640a9ea39642c3c049": {
      "source_id": "e7774aaca51e19640a9ea39642c3c049",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2749,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "A crisis for online communication: bots and bot users will overrun the Internet?"
    },
    "078b9ed01106663e4e6b95e8cde96fde": {
      "source_id": "078b9ed01106663e4e6b95e8cde96fde",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4829,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Benchmarks for Comparing Human and AI Intelligence"
    },
    "0b1ce5c85148f50941d6878264f662c9": {
      "source_id": "0b1ce5c85148f50941d6878264f662c9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3990,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "12 career-related questions that may (or may not) be helpful for people interest"
    },
    "087cf145118ec21cd048934a6bd09f88": {
      "source_id": "087cf145118ec21cd048934a6bd09f88",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1970,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Limits of Superintelligence"
    },
    "a7638d8685922fe9f4afb23df7a10e4c": {
      "source_id": "a7638d8685922fe9f4afb23df7a10e4c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7192,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Best introductory overviews of AGI safety?"
    },
    "2329ac8d189b821aa30c87a1d3be23ac": {
      "source_id": "2329ac8d189b821aa30c87a1d3be23ac",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18734,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "all claw, no world \u2014 and other thoughts on the universal distribution"
    },
    "a95ab30a68cf9a6c3bd5705db15fec29": {
      "source_id": "a95ab30a68cf9a6c3bd5705db15fec29",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 289,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How is ARC planning to use ELK?"
    },
    "fae20517876e374fba19b5a57f690245": {
      "source_id": "fae20517876e374fba19b5a57f690245",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11958,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AI Safety Movement Builders should help the community to optimise three factors:"
    },
    "3de418ac4eb13510a11bc406c4afcc9d": {
      "source_id": "3de418ac4eb13510a11bc406c4afcc9d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8701,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Will Machines Ever Rule the World? MLAISU W50"
    },
    "5128968e4428223a6ed3825bf250e801": {
      "source_id": "5128968e4428223a6ed3825bf250e801",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23725,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Abstract concepts and metalingual definition: Does ChatGPT understand justice an"
    },
    "69aa5a52660805bc4a670cbe80d7f988": {
      "source_id": "69aa5a52660805bc4a670cbe80d7f988",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3768,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "There have been 3 planes (billionaire donors) and 2 have crashed"
    },
    "6f78bf4af4a6f96b57bcbfec353668e1": {
      "source_id": "6f78bf4af4a6f96b57bcbfec353668e1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73366,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Bad at Arithmetic, Promising at Math"
    },
    "0c13325d4f7a451c4783696956ca6bee": {
      "source_id": "0c13325d4f7a451c4783696956ca6bee",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4665,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Why I think that teaching philosophy is high impact"
    },
    "71101db4c6ee18eb83f0dfc2b05f6343": {
      "source_id": "71101db4c6ee18eb83f0dfc2b05f6343",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45224,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Computational signatures of psychopathy"
    },
    "1b774fe0ec8ff4cd3291eb6571fc2cc0": {
      "source_id": "1b774fe0ec8ff4cd3291eb6571fc2cc0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23176,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "AGI Timelines in Governance: Different Strategies for Different Timeframes"
    },
    "11c6b28c88d116e1eae0300e39c54165": {
      "source_id": "11c6b28c88d116e1eae0300e39c54165",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1812,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Will research in AI risk jinx it?   Consequences of training AI on AI risk argum"
    },
    "471548f042ae4db1a8afd82a49b18bf1": {
      "source_id": "471548f042ae4db1a8afd82a49b18bf1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28805,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "(Extremely) Naive Gradient Hacking Doesn't Work"
    },
    "1e426ca751c8fdbb4f7ffa791df2d0c8": {
      "source_id": "1e426ca751c8fdbb4f7ffa791df2d0c8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 95806,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Properties of current AIs and some predictions of the evolution of AI from the p"
    },
    "03604a659e63a498fafb98e365a67806": {
      "source_id": "03604a659e63a498fafb98e365a67806",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19233,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Podcast: Tamera Lanham on AI risk, threat models, alignment proposals, externali"
    },
    "19d42c77f7386c43a8445497ea9f12c8": {
      "source_id": "19d42c77f7386c43a8445497ea9f12c8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22823,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[DISC] Are Values Robust?"
    },
    "4b0dff98bfe8032377b68f741de6d3d8": {
      "source_id": "4b0dff98bfe8032377b68f741de6d3d8",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 4194,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "New AI risk intro from Vox [link post]"
    },
    "9d700ef996c334778737f2b6fd14a37d": {
      "source_id": "9d700ef996c334778737f2b6fd14a37d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31067,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Notes on Meta's Diplomacy-Playing AI"
    },
    "a3eaf55c567451cb55a57b16858fc362": {
      "source_id": "a3eaf55c567451cb55a57b16858fc362",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31293,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Racing through a minefield: the AI deployment problem"
    },
    "f0f271b83c58744cc052558aabb83f15": {
      "source_id": "f0f271b83c58744cc052558aabb83f15",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14462,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Article Review: Discovering Latent Knowledge (Burns, Ye, et al)"
    },
    "dd145fa6ebee742654c2d12a367139c9": {
      "source_id": "dd145fa6ebee742654c2d12a367139c9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11029,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "ChatGPT understands, but largely does not generate Spanglish (and other code-mix"
    },
    "447fe7056e03864ae2c9344c297b44ea": {
      "source_id": "447fe7056e03864ae2c9344c297b44ea",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10522,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Issues with uneven AI resource distribution"
    },
    "11d6790302faae23ac4f2fd585be0148": {
      "source_id": "11d6790302faae23ac4f2fd585be0148",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40594,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Content and Takeaways from SERI MATS Training Program with John Wentworth"
    },
    "97439868ce5a1b9f2493f443a1abf27b": {
      "source_id": "97439868ce5a1b9f2493f443a1abf27b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5851,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "List #2:  Why coordinating to align as humans to not develop AGI is a lot easier"
    },
    "e3a40f01238cdf0e1cc67cb023452f66": {
      "source_id": "e3a40f01238cdf0e1cc67cb023452f66",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19334,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Accurate Models of AI Risk Are Hyperexistential Exfohazards"
    },
    "9a97bb42f9695b8e910da8b383ea4987": {
      "source_id": "9a97bb42f9695b8e910da8b383ea4987",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17979,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "How evolutionary lineages of LLMs can plan their own future and act on these pla"
    },
    "5d3c6ff24ad9034faa05ccdc90acb2d7": {
      "source_id": "5d3c6ff24ad9034faa05ccdc90acb2d7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33500,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "[Hebbian Natural Abstractions] Mathematical Foundations"
    },
    "4b9fc8bf456bd04cab409b04170955ec": {
      "source_id": "4b9fc8bf456bd04cab409b04170955ec",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4916,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Mlyyrczo"
    },
    "4dd4d4164189a28816b2846bd9eea7f6": {
      "source_id": "4dd4d4164189a28816b2846bd9eea7f6",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9313,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "An overview of some promising work by junior alignment researchers"
    },
    "89d8a89facf276a20104fff70ab503f4": {
      "source_id": "89d8a89facf276a20104fff70ab503f4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53228,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Safety of Self-Assembled Neuromorphic Hardware"
    },
    "d3568018f11635c162d78cb6d098503e": {
      "source_id": "d3568018f11635c162d78cb6d098503e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 924,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Announcing: The Independent AI Safety Registry"
    },
    "6d8f27a8f2e99ba0a351cd8ec051f878": {
      "source_id": "6d8f27a8f2e99ba0a351cd8ec051f878",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4204,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Air-gapping evaluation and support"
    },
    "3b0eb38ffb85ea31343b5fa0a6cf6b79": {
      "source_id": "3b0eb38ffb85ea31343b5fa0a6cf6b79",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11763,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Recent advances in Natural Language Processing\u2014Some Woolly speculations (2019 es"
    },
    "9fe7d48b97115b6ac0d90402ca6efdc6": {
      "source_id": "9fe7d48b97115b6ac0d90402ca6efdc6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42295,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "MDPs and the Bellman Equation, Intuitively Explained"
    },
    "b419e2b88e6627915bf26a5560f1227b": {
      "source_id": "b419e2b88e6627915bf26a5560f1227b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8411,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Introduction: Bias in Evaluating AGI X-Risks"
    },
    "3713cc8501a061cea955d0d13a4598f1": {
      "source_id": "3713cc8501a061cea955d0d13a4598f1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9040,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Institutions Cannot Restrain Dark-Triad AI Exploitation"
    },
    "2a4a8d98d1476d326c8b98a64f5f6831": {
      "source_id": "2a4a8d98d1476d326c8b98a64f5f6831",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15769,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Reflections on my 5-month alignment upskilling grant"
    },
    "418c8889802aaf6d30a99520105ab842": {
      "source_id": "418c8889802aaf6d30a99520105ab842",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25974,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "My Reservations about Discovering Latent Knowledge (Burns, Ye, et al)"
    },
    "868cb196318e33de424d2f754c89fdea": {
      "source_id": "868cb196318e33de424d2f754c89fdea",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1753,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Is checking that a state of the world is not dystopian easier than constructing "
    },
    "f752e9dacbae7b7fc9a7a52b7ec7e582": {
      "source_id": "f752e9dacbae7b7fc9a7a52b7ec7e582",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9423,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Large Language Models Suggest a Path to Ems"
    },
    "2fcab5cb2015e5b08228bcb20a07c8bb": {
      "source_id": "2fcab5cb2015e5b08228bcb20a07c8bb",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7393,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "The commercial incentive to intentionally train AI to deceive us"
    },
    "596fd1fa6af8e50023f260403a63c910": {
      "source_id": "596fd1fa6af8e50023f260403a63c910",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45696,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Beyond Rewards and Values: A Non-dualistic Approach to Universal Intelligence"
    },
    "15be2008e9901266c554a65defeddd5d": {
      "source_id": "15be2008e9901266c554a65defeddd5d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39981,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "My thoughts on OpenAI's alignment plan"
    },
    "01b03555349c49810a0bbcb6f70cf683": {
      "source_id": "01b03555349c49810a0bbcb6f70cf683",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1437,
        "year": "2022",
        "has_tags": true
      },
      "title_preview": "Are Mixture-of-Experts Transformers More Interpretable Than Dense Transformers? "
    },
    "7d65601d8f8763b39252b2a5ce1612ef": {
      "source_id": "7d65601d8f8763b39252b2a5ce1612ef",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15619,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Summary of 80k's AI problem profile"
    },
    "e3459b3e466df8f467f7fbac6b6a36c5": {
      "source_id": "e3459b3e466df8f467f7fbac6b6a36c5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2480,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Would it be good or bad for the US military to get involved in AI risk?"
    },
    "33f32a70be93b97d85f97de61f3a37fe": {
      "source_id": "33f32a70be93b97d85f97de61f3a37fe",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14163,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Thoughts On Expanding the AI Safety Community: Benefits and Challenges of Outrea"
    },
    "30ef0e285269dad2693d82277fef0892": {
      "source_id": "30ef0e285269dad2693d82277fef0892",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12477,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "My first year in AI alignment"
    },
    "39196a370b0c4175ce8ed8303070449f": {
      "source_id": "39196a370b0c4175ce8ed8303070449f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1893,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Alignment, Anger, and Love: Preparing for the Emergence of Superintelligent AI"
    },
    "322fdd54a5628792c5437e5507a9e06e": {
      "source_id": "322fdd54a5628792c5437e5507a9e06e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12889,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "On the Importance of Open Sourcing Reward Models"
    },
    "991a40ecda98c3a59607585989c5390e": {
      "source_id": "991a40ecda98c3a59607585989c5390e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7981,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": " [Simulators seminar sequence] #1 Background & shared assumptions"
    },
    "7d6d81916d8664bfa6309634d60ff591": {
      "source_id": "7d6d81916d8664bfa6309634d60ff591",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6910,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "On the naturalistic study of the linguistic behavior of artificial intelligence"
    },
    "9d68f241ea941c77deff5e4855a1f509": {
      "source_id": "9d68f241ea941c77deff5e4855a1f509",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1456,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is recursive self-alignment possible?"
    },
    "83998e10070c2e92d8f55d4a3b895888": {
      "source_id": "83998e10070c2e92d8f55d4a3b895888",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3815,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "I have thousands of copies of HPMOR in Russian. How to use them with the most im"
    },
    "2eeba07dea756e56947ae0ed09c0d983": {
      "source_id": "2eeba07dea756e56947ae0ed09c0d983",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28745,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Whisper's Wild Implications"
    },
    "b7d24c1f69292e60c6f6bde23b04c78f": {
      "source_id": "b7d24c1f69292e60c6f6bde23b04c78f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7487,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "My Advice for Incoming SERI MATS Scholars"
    },
    "b2baef4fdc3c3e32421ca67752e27931": {
      "source_id": "b2baef4fdc3c3e32421ca67752e27931",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11273,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An ML interpretation of Shard Theory"
    },
    "7945c8b8e9fd8c59066a8b45ee2d67d8": {
      "source_id": "7945c8b8e9fd8c59066a8b45ee2d67d8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6939,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "2022 was the year AGI arrived (Just don't call it that)"
    },
    "163eefc53f1673ab881d3c906eab0660": {
      "source_id": "163eefc53f1673ab881d3c906eab0660",
      "quality_score": 2.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 5255,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "List of links for getting into AI safety"
    },
    "26ed8c372c995c634385bd8196e00c95": {
      "source_id": "26ed8c372c995c634385bd8196e00c95",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12934,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Discursive Competence in ChatGPT, Part 1: Talking with Dragons"
    },
    "dd383ec1dc4277227fea25bee3483778": {
      "source_id": "dd383ec1dc4277227fea25bee3483778",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1815,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Camp: Machine Learning for Scientific Discovery "
    },
    "cb734a50cc897b2ce414f5791f7676ba": {
      "source_id": "cb734a50cc897b2ce414f5791f7676ba",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10837,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI improving AI [MLAISU W01!]"
    },
    "aaa9b6cb9613beda3c8972c21a411fdb": {
      "source_id": "aaa9b6cb9613beda3c8972c21a411fdb",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3035,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI security might be helpful for AI alignment"
    },
    "fd11e01367baf584deac829407b1340b": {
      "source_id": "fd11e01367baf584deac829407b1340b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11592,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Limit of Language Models"
    },
    "9fc38fbf63c9cf1a3b62cfa85c97b175": {
      "source_id": "9fc38fbf63c9cf1a3b62cfa85c97b175",
      "quality_score": 2.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 5590,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] Jan Leike on three kinds of alignment taxes"
    },
    "62964bc575812dd66d3602486ebe9cdf": {
      "source_id": "62964bc575812dd66d3602486ebe9cdf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25296,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Implications of simulators"
    },
    "66e97fe8de96b7e7c55c54a1b43c0ac9": {
      "source_id": "66e97fe8de96b7e7c55c54a1b43c0ac9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 827,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Looking for Spanish AI Alignment Researchers"
    },
    "2d72bed35e6b9abf42b8aa02dfdff8d7": {
      "source_id": "2d72bed35e6b9abf42b8aa02dfdff8d7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4674,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Protectionism will Slow the Deployment of AI"
    },
    "72bbcbb48ddbf2bbebabb5bb675ee5ea": {
      "source_id": "72bbcbb48ddbf2bbebabb5bb675ee5ea",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1057,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Research ideas (AI Interpretability & Neurosciences) for a 2-months project"
    },
    "f31fbf5707e278a93c2a610d6c991929": {
      "source_id": "f31fbf5707e278a93c2a610d6c991929",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29579,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "ChatGPT tells stories about XP-708-DQ, Eliezer, dragons, dark sorceresses, and u"
    },
    "acfbffbda5e8c04b2ec72aaab2b2f5d9": {
      "source_id": "acfbffbda5e8c04b2ec72aaab2b2f5d9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 909,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Big list of AI safety videos"
    },
    "372e043a6a75684bbe47a122e546c85b": {
      "source_id": "372e043a6a75684bbe47a122e546c85b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22404,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Wentworth and Larsen on buying time"
    },
    "a0e330032f00a843532c04b79db98c5f": {
      "source_id": "a0e330032f00a843532c04b79db98c5f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5080,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Against using stock prices to forecast AI timelines"
    },
    "fc83700e6f81919621240a9544979953": {
      "source_id": "fc83700e6f81919621240a9544979953",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 79028,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AGI and the EMH: markets are not expecting aligned\u00a0or unaligned AI in the next 3"
    },
    "b6db5e6331c377d477d4560420c49f2f": {
      "source_id": "b6db5e6331c377d477d4560420c49f2f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29352,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How it feels to have your mind hacked by an AI"
    },
    "2363076a45ebe722b2eefb243018c350": {
      "source_id": "2363076a45ebe722b2eefb243018c350",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21165,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Alignment is not enough"
    },
    "c16f54e26d8a17abd3b0e3b060bd51a1": {
      "source_id": "c16f54e26d8a17abd3b0e3b060bd51a1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8163,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Victoria Krakovna on AGI Ruin, The Sharp Left Turn and Paradigms of AI Alignment"
    },
    "996a802afaa44be8644b3ecf25811974": {
      "source_id": "996a802afaa44be8644b3ecf25811974",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21909,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The AI Control Problem in a wider intellectual context"
    },
    "2debeda11d0b77077d00101fb5e7e39c": {
      "source_id": "2debeda11d0b77077d00101fb5e7e39c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7497,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Robustness & Evolution [MLAISU W02]"
    },
    "e8dca08a6ae78162f93885cbc82d8029": {
      "source_id": "e8dca08a6ae78162f93885cbc82d8029",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40494,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How we could stumble into AI catastrophe"
    },
    "7b4770e3cb8eb950e580ce15111054cd": {
      "source_id": "7b4770e3cb8eb950e580ce15111054cd",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1239,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Tracr: Compiled Transformers as a Laboratory for Interpretability | DeepMind "
    },
    "d4d42a8c5742badfc26b0599db74319c": {
      "source_id": "d4d42a8c5742badfc26b0599db74319c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35463,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How does GPT-3 spend its 175B parameters? "
    },
    "71d641a3c7cf75109c6fd105eeef8349": {
      "source_id": "71d641a3c7cf75109c6fd105eeef8349",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1273,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Podcast with Divia Eden on operant conditioning"
    },
    "0ba4b2655c7d2b92e88e0cc2dfa5de67": {
      "source_id": "0ba4b2655c7d2b92e88e0cc2dfa5de67",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19038,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Deceptive failures short of full catastrophe."
    },
    "843bc1069b5f03701b074c9951f272e3": {
      "source_id": "843bc1069b5f03701b074c9951f272e3",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6062,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Reflections on Trusting Trust & AI"
    },
    "7eeafd5fe732f356255d138d170fae45": {
      "source_id": "7eeafd5fe732f356255d138d170fae45",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8338,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Status conscious"
    },
    "71564e7cb044c2b2a353cd114a90c1a1": {
      "source_id": "71564e7cb044c2b2a353cd114a90c1a1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49815,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Consequentialists: One-Way Pattern Traps"
    },
    "ec4f2709e714b7b46525e3c1da41491c": {
      "source_id": "ec4f2709e714b7b46525e3c1da41491c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8126,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Collin Burns on Alignment Research And Discovering Latent Knowledge Without Supe"
    },
    "210d3ac55de38fd8e221d7e59f3c459b": {
      "source_id": "210d3ac55de38fd8e221d7e59f3c459b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7079,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "OpenAI\u2019s Alignment Plan is not S.M.A.R.T."
    },
    "4e56034115c73c9946a9e5e3c39e19cb": {
      "source_id": "4e56034115c73c9946a9e5e3c39e19cb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 76852,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Prototype of Using GPT-3 to Generate Textbook-length Content"
    },
    "a8c36385150c01ef64a9eb0f052e4e82": {
      "source_id": "a8c36385150c01ef64a9eb0f052e4e82",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4077,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "6-paragraph AI risk intro for MAISI"
    },
    "3050471b5957b6ba49c874fc759919a9": {
      "source_id": "3050471b5957b6ba49c874fc759919a9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7036,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "List of technical AI safety exercises and projects"
    },
    "363bb2a2788a0138e63385559f3add00": {
      "source_id": "363bb2a2788a0138e63385559f3add00",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9140,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\"Heretical Thoughts on AI\" by Eli Dourado"
    },
    "4d11981dce18328df5ea1924ee5a16ae": {
      "source_id": "4d11981dce18328df5ea1924ee5a16ae",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3704,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing Cavendish Labs"
    },
    "d02664c489e9bc9684ee14f8183506df": {
      "source_id": "d02664c489e9bc9684ee14f8183506df",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20157,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AGI safety field building projects I\u2019d like to see"
    },
    "e2148c2510f0b336bbd729e71c34bec0": {
      "source_id": "e2148c2510f0b336bbd729e71c34bec0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4871,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Generalizability & Hope for AI [MLAISU W03]"
    },
    "1d0b23c599bdf5585c8cd7f47b69e474": {
      "source_id": "1d0b23c599bdf5585c8cd7f47b69e474",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33943,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Transcript of Sam Altman's interview touching on AI safety "
    },
    "8ab843bb6b5a220e841e7056283b5421": {
      "source_id": "8ab843bb6b5a220e841e7056283b5421",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2475,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing aisafety.training"
    },
    "aaad6ea58d10d314b093a7674e07d828": {
      "source_id": "aaad6ea58d10d314b093a7674e07d828",
      "quality_score": 2.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 6891,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] TIME article: DeepMind\u2019s CEO Helped Take AI Mainstream. Now He\u2019s Urgi"
    },
    "35b98e80d49365e7e5b720617294f7e0": {
      "source_id": "35b98e80d49365e7e5b720617294f7e0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22433,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety \"Textbook\". Test chapter. Orthogonality Thesis, Goodhart Law and Instr"
    },
    "244eb74918955178466db438cb6203da": {
      "source_id": "244eb74918955178466db438cb6203da",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1920,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "NYT: Google will \u201crecalibrate\u201d the risk of releasing AI due to competition with "
    },
    "ed7571c76be988d4a1de39ce182c2393": {
      "source_id": "ed7571c76be988d4a1de39ce182c2393",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 575,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI safety milestones?"
    },
    "036a381658ab3524ec0fcd4e8981b043": {
      "source_id": "036a381658ab3524ec0fcd4e8981b043",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28747,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Parameter Scaling Comes for RL, Maybe"
    },
    "94bbdec48c1126bb7676d0ec912f4b97": {
      "source_id": "94bbdec48c1126bb7676d0ec912f4b97",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10784,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "ChatGPT intimates a tantalizing future; its core LLM is organized on multiple le"
    },
    "1a7badc9637268e0573ce7f644b2392a": {
      "source_id": "1a7badc9637268e0573ce7f644b2392a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6982,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Thatcher's Axiom"
    },
    "b34b91688368c1944edcfb7543996b7e": {
      "source_id": "b34b91688368c1944edcfb7543996b7e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4924,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Pessimistic Shard Theory"
    },
    "e19c43f42fcd5e783b5ff24309e13f5d": {
      "source_id": "e19c43f42fcd5e783b5ff24309e13f5d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42194,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[RFC] Possible ways to expand on \"Discovering Latent Knowledge in Language Model"
    },
    "2389d3851fdeb7d6e3254081615636d5": {
      "source_id": "2389d3851fdeb7d6e3254081615636d5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16301,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Next steps after AGISF at UMich"
    },
    "627a57a9fa11630c9c366dd802a4ce45": {
      "source_id": "627a57a9fa11630c9c366dd802a4ce45",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5722,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "All AGI Safety questions welcome (especially basic ones) [~monthly thread]"
    },
    "b2787912a429bf4ba38e3166a7b439ca": {
      "source_id": "b2787912a429bf4ba38e3166a7b439ca",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3677,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Optimality is the tiger, and annoying the user is its teeth"
    },
    "0922b739995f3e020aa8dcdc3d5b2399": {
      "source_id": "0922b739995f3e020aa8dcdc3d5b2399",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23172,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Compendium of problems with RLHF"
    },
    "8325c5feb73c7fb09bc715848120d90b": {
      "source_id": "8325c5feb73c7fb09bc715848120d90b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6362,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What is the ground reality of countries taking steps to recalibrate AI developme"
    },
    "2bf15e6e2310c81a8096c7078679f93d": {
      "source_id": "2bf15e6e2310c81a8096c7078679f93d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25299,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Medical Image Registration: The obscure field where Deep Mesaoptimizers are alre"
    },
    "b81ddea3a858688f79c56671f601f06e": {
      "source_id": "b81ddea3a858688f79c56671f601f06e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3282,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Apply to HAIST/MAIA\u2019s AI Governance Workshop in DC (Feb 17-20)"
    },
    "3ee9b7926b82a6dd02f42090abf9cff8": {
      "source_id": "3ee9b7926b82a6dd02f42090abf9cff8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3127,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Talk to me about your summer/career plans"
    },
    "bdbbecbab496e7f2d63cfe0b5e3d3d4f": {
      "source_id": "bdbbecbab496e7f2d63cfe0b5e3d3d4f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7109,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Arguments: An Interactive Guide"
    },
    "9b690d96dda562a9bfc209d2edf3f893": {
      "source_id": "9b690d96dda562a9bfc209d2edf3f893",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20236,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Product safety is a poor model for AI governance"
    },
    "32b0960ce2f7bf4a247bdd531c44fb85": {
      "source_id": "32b0960ce2f7bf4a247bdd531c44fb85",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15713,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Interviews with 97 AI Researchers: Quantitative Analysis"
    },
    "1fac4ec508e16636b7fba39705493ecd": {
      "source_id": "1fac4ec508e16636b7fba39705493ecd",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4212,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A Brief Overview of AI Safety/Alignment Orgs, Fields, Researchers, and Resources"
    },
    "a54a7a5b0b5db3fdc91e55623afc1743": {
      "source_id": "a54a7a5b0b5db3fdc91e55623afc1743",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9334,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "You are probably not a good alignment researcher, and other blatant lies"
    },
    "777d8e3a67a82fad89c2e1fc787f885d": {
      "source_id": "777d8e3a67a82fad89c2e1fc787f885d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9343,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Heritability, Behaviorism, and Within-Lifetime RL"
    },
    "96b3ee062db83eb0fd302b8e10f6d32f": {
      "source_id": "96b3ee062db83eb0fd302b8e10f6d32f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36016,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "ChatGPT: Tantalizing afterthoughts in search of story trajectories [induction he"
    },
    "7af62c6ed752f5029b8387e765ff304a": {
      "source_id": "7af62c6ed752f5029b8387e765ff304a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4791,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Many AI governance proposals have a tradeoff between usefulness and feasibility"
    },
    "d3d579e680f85a5b45e9b96fc3cbbd16": {
      "source_id": "d3d579e680f85a5b45e9b96fc3cbbd16",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30286,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Empathy as a natural consequence of learnt reward models"
    },
    "f575013f98d188d34c76b46ec7c0ebd4": {
      "source_id": "f575013f98d188d34c76b46ec7c0ebd4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2507,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Monthly Doom Argument Threads?  Doom Argument Wiki?"
    },
    "8f5ed7fc851ef3f8a6ab79d76beac237": {
      "source_id": "8f5ed7fc851ef3f8a6ab79d76beac237",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6330,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Some miscellaneous thoughts on ChatGPT, stories, and mechanical interpretability"
    },
    "9815bc0a19a7aaa0f15f2edc39e0439e": {
      "source_id": "9815bc0a19a7aaa0f15f2edc39e0439e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4199,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Questions about AI that bother me "
    },
    "adadbab938d1b55784708d21e94f81e8": {
      "source_id": "adadbab938d1b55784708d21e94f81e8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3301,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Second call: CFP for Rebellion and Disobedience in AI workshop"
    },
    "d8bdfd7d0624e9255d4f62e02f96c69f": {
      "source_id": "d8bdfd7d0624e9255d4f62e02f96c69f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6132,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Are short timelines actually bad?"
    },
    "fde8a3137aeec59ad923e337cd1e4f7c": {
      "source_id": "fde8a3137aeec59ad923e337cd1e4f7c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27261,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Addendum: More Efficient FFNs via Attention"
    },
    "42e08562a7e6da02eb258601d3344467": {
      "source_id": "42e08562a7e6da02eb258601d3344467",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4164,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Google announces 'Bard' powered by LaMDA"
    },
    "eda449e73a9dac2a10ac93b9edd52e32": {
      "source_id": "eda449e73a9dac2a10ac93b9edd52e32",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6407,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Early situational awareness and its implications, a story"
    },
    "4871b81a5f5d1b658278198a72a61b90": {
      "source_id": "4871b81a5f5d1b658278198a72a61b90",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19153,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[ASoT] Policy Trajectory Visualization"
    },
    "58f6de29e33b67d1388fc9dfd916700a": {
      "source_id": "58f6de29e33b67d1388fc9dfd916700a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3714,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "so you think you're not qualified to do technical alignment research?"
    },
    "e564c07284197db5b797098a5a235a4b": {
      "source_id": "e564c07284197db5b797098a5a235a4b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14830,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Review of AI Alignment Progress"
    },
    "eaf85ef53632cbbf6e091f7a89ff9251": {
      "source_id": "eaf85ef53632cbbf6e091f7a89ff9251",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17550,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How evals might (or might not) prevent  catastrophic risks from AI"
    },
    "92a1e246a23c1553691f834f1558013e": {
      "source_id": "92a1e246a23c1553691f834f1558013e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2080,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A (EtA: quick) note on terminology:  AI Alignment != AI x-safety"
    },
    "38b3045e3c31002fcf890837bf09da6f": {
      "source_id": "38b3045e3c31002fcf890837bf09da6f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17814,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Using PICT against PastaGPT Jailbreaking"
    },
    "0ab18426ef97aa784356b5e77466036f": {
      "source_id": "0ab18426ef97aa784356b5e77466036f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4285,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Do the Safety Properties of Powerful AI Systems Need to be Adversarially Robust?"
    },
    "398cbb6d23ca9c09af17bc976fabe3cf": {
      "source_id": "398cbb6d23ca9c09af17bc976fabe3cf",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7428,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "EIS II: What is \u201cInterpretability\u201d? "
    },
    "5872a7f68927a3bab12768267bd72310": {
      "source_id": "5872a7f68927a3bab12768267bd72310",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7494,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Security Mindset - Fire Alarms and Trigger Signatures"
    },
    "6b61c9eccc1645d4a04dce30fd65d52f": {
      "source_id": "6b61c9eccc1645d4a04dce30fd65d52f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3931,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Many important technologies start out as science fiction before becoming real "
    },
    "d7edd39ae53391689ae37065f1295170": {
      "source_id": "d7edd39ae53391689ae37065f1295170",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19856,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "In Defense of Chatbot Romance"
    },
    "4bd8bd7e5a6fcdba1c1685eab0bbfd58": {
      "source_id": "4bd8bd7e5a6fcdba1c1685eab0bbfd58",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4582,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Morphological intelligence, superhuman empathy, and ethical arbitration"
    },
    "b320132eada7353267d54bc319478bbe": {
      "source_id": "b320132eada7353267d54bc319478bbe",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2274,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is InstructGPT Following Instructions in Other Languages Surprising? "
    },
    "03239cf78b756ff6c72a00384233935e": {
      "source_id": "03239cf78b756ff6c72a00384233935e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4619,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Linguistic Blind Spot of Value-Aligned Agency, Natural and Artificial "
    },
    "800f913351b699cb65e8c79283611da0": {
      "source_id": "800f913351b699cb65e8c79283611da0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35956,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Explaining SolidGoldMagikarp by looking at it from random directions"
    },
    "550930d33a1699e1fa136146df73976a": {
      "source_id": "550930d33a1699e1fa136146df73976a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5695,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Qualities that alignment mentors value in junior researchers"
    },
    "2aa625fc980aa87be30d9b77b21ccc81": {
      "source_id": "2aa625fc980aa87be30d9b77b21ccc81",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11292,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "a narrative explanation of the QACI alignment plan"
    },
    "9c6e5e039940f13b629358a4c9478624": {
      "source_id": "9c6e5e039940f13b629358a4c9478624",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6898,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Beyond Reinforcement Learning: Predictive Processing and Checksums"
    },
    "249b6bc940a646cdb740d147d387708d": {
      "source_id": "249b6bc940a646cdb740d147d387708d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8989,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "EIS IV: A Spotlight on Feature Attribution/Saliency "
    },
    "bfe8a0f8e9aa2aefccc33ed76c95bb82": {
      "source_id": "bfe8a0f8e9aa2aefccc33ed76c95bb82",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15785,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Order Matters for Deceptive Alignment"
    },
    "8121c9079d6634be0e8f0b9d073d4d56": {
      "source_id": "8121c9079d6634be0e8f0b9d073d4d56",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2901,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How should AI systems behave, and who should decide? [OpenAI blog]"
    },
    "cf9be7602a593cd2b4601895b62fa0bc": {
      "source_id": "cf9be7602a593cd2b4601895b62fa0bc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2565,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The public supports regulating AI for safety"
    },
    "1a8a44f283613dbc651e0602313cdd54": {
      "source_id": "1a8a44f283613dbc651e0602313cdd54",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6959,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Self-Reference Breaks the Orthogonality Thesis"
    },
    "d12eb787d219be2e957798fda4ef2daa": {
      "source_id": "d12eb787d219be2e957798fda4ef2daa",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5763,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Bing chat is the AI fire alarm"
    },
    "d517ccb3430dcec5a6b29c6aa64380a8": {
      "source_id": "d517ccb3430dcec5a6b29c6aa64380a8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6701,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Info Distillation Fellowship"
    },
    "71fbc13f06966fd22df1ec430e2b7f1c": {
      "source_id": "71fbc13f06966fd22df1ec430e2b7f1c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2193,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "I Am Scared of Posting Negative Takes About Bing's AI"
    },
    "a70476986f0d337a2536cddd0df7d690": {
      "source_id": "a70476986f0d337a2536cddd0df7d690",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45085,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "GPT-4 Predictions"
    },
    "c85e72cc19dbece2e6be885220a59e98": {
      "source_id": "c85e72cc19dbece2e6be885220a59e98",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13938,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Near-Term Risks of an Obedient Artificial Intelligence"
    },
    "c658b9d9ba062fd92471a818592e3b61": {
      "source_id": "c658b9d9ba062fd92471a818592e3b61",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2727,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Stop posting prompt injections on Twitter and calling it \"misalignment\""
    },
    "fa201e377ca07a8fd1cd2804d4ecdb1a": {
      "source_id": "fa201e377ca07a8fd1cd2804d4ecdb1a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4320,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Navigating public AI x-risk hype while pursuing technical solutions"
    },
    "8f048e50ff5e89e0c55dfbcc9c457653": {
      "source_id": "8f048e50ff5e89e0c55dfbcc9c457653",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35934,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AGI doesn't need understanding, intention, or consciousness in order to kill us,"
    },
    "5ac3dd5c998200e11f57d7effe320bf4": {
      "source_id": "5ac3dd5c998200e11f57d7effe320bf4",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8970,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The idea that ChatGPT is simply \u201cpredicting\u201d the next word is, at best, misleadi"
    },
    "4d843fcf12098d7e7b518cebf91b3577": {
      "source_id": "4d843fcf12098d7e7b518cebf91b3577",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 544,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Bankless Podcast: 159 - We\u2019re All Gonna Die with Eliezer Yudkowsky"
    },
    "d6a87340a10dc0c47ae7befab4a2b798": {
      "source_id": "d6a87340a10dc0c47ae7befab4a2b798",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7377,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Validator models: A simple approach to detecting goodharting"
    },
    "7eb3299d0c19b7d7580e3d68b895fe46": {
      "source_id": "7eb3299d0c19b7d7580e3d68b895fe46",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43210,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Breaking the Optimizer\u2019s Curse, and Consequences for Existential Risks and Value"
    },
    "59b92f786594f8dc0986d8681243a3f9": {
      "source_id": "59b92f786594f8dc0986d8681243a3f9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1769,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Preprint] Pretraining Language Models with Human Preferences"
    },
    "16f0a4436badbd9e42362836aae3579f": {
      "source_id": "16f0a4436badbd9e42362836aae3579f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 140203,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI #1: Sydney and Bing"
    },
    "c5b9912410ebc7228d44dbe0f0f69327": {
      "source_id": "c5b9912410ebc7228d44dbe0f0f69327",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29897,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Deceptive Alignment is <1% Likely by Default"
    },
    "69bef5556df9f87e2b7011fd841a7697": {
      "source_id": "69bef5556df9f87e2b7011fd841a7697",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7505,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The shallow reality of 'deep learning theory'"
    },
    "7a754057ca094f8c2ab134055c581930": {
      "source_id": "7a754057ca094f8c2ab134055c581930",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13696,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Power-Seeking = Minimising free energy"
    },
    "55723f073d1b1a66bcb8da14a060e8ec": {
      "source_id": "55723f073d1b1a66bcb8da14a060e8ec",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41533,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Intervening in the Residual Stream"
    },
    "0af34709943b966ef935f9cabfa6382f": {
      "source_id": "0af34709943b966ef935f9cabfa6382f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1881,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is there a ML agent that abandons it's utility function out-of-distribution with"
    },
    "c1ed867e853dd7ba3fb45f1757f6ba20": {
      "source_id": "c1ed867e853dd7ba3fb45f1757f6ba20",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25060,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Can submarines swim?"
    },
    "fa468192881b364272aa7d7fdb9efb77": {
      "source_id": "fa468192881b364272aa7d7fdb9efb77",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 473,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Video/animation: Neel Nanda explains what mechanistic interpretability is"
    },
    "a108391b39e5a9d48dbac3fff156d7df": {
      "source_id": "a108391b39e5a9d48dbac3fff156d7df",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7265,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Hello, Elua."
    },
    "a39f0322884a44f011ebfcd2ef9b1b37": {
      "source_id": "a39f0322884a44f011ebfcd2ef9b1b37",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13699,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Automated Sandwiching & Quantifying Human-LLM Cooperation: ScaleOversight hackat"
    },
    "10ec3e049573ccfce7695c51ac788825": {
      "source_id": "10ec3e049573ccfce7695c51ac788825",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14753,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "EIS XII: Summary "
    },
    "c9cda8ebb83d8c42ec88927f310235b0": {
      "source_id": "c9cda8ebb83d8c42ec88927f310235b0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 69764,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Searching for a model's concepts by their shape \u2013 a theoretical framework"
    },
    "7c4117148dafbb0e121f904ead1fd865": {
      "source_id": "7c4117148dafbb0e121f904ead1fd865",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7542,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AGI systems & humans will both need to solve the alignment problem"
    },
    "f933540fdeea1f150549949671b7cbcd": {
      "source_id": "f933540fdeea1f150549949671b7cbcd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12565,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How major governments can help with the most important century"
    },
    "af5e78a06bea632b480213d2f6778c1d": {
      "source_id": "af5e78a06bea632b480213d2f6778c1d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14185,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A Proposed Test to Determine the Extent to Which Large Language Models Understan"
    },
    "53e757c2c289d48b779dc94a43fd48ca": {
      "source_id": "53e757c2c289d48b779dc94a43fd48ca",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4586,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Are you stably aligned?"
    },
    "559ebf6fd3145b11bc977c5f958ff4f9": {
      "source_id": "559ebf6fd3145b11bc977c5f958ff4f9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19361,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Pink Shoggoths: What does alignment look like in practice?"
    },
    "eb97e7db6d0d77db5a1adc02b99da0d3": {
      "source_id": "eb97e7db6d0d77db5a1adc02b99da0d3",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5177,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Incentives and Selection: A Missing Frame From AI Threat Discussions? "
    },
    "97668eb4e2bd4f27899a116b663d54f1": {
      "source_id": "97668eb4e2bd4f27899a116b663d54f1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2719,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A library for safety research in conditioning on RLHF tasks"
    },
    "4a656b4e19723a90e1e5862eeaaf6cf3": {
      "source_id": "4a656b4e19723a90e1e5862eeaaf6cf3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2348,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Taboo \"human-level intelligence\""
    },
    "83415c84d7f82f40c13a742cb05cd369": {
      "source_id": "83415c84d7f82f40c13a742cb05cd369",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 1531,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Link Post] Cyber Digital Authoritarianism (National Intelligence Council Report"
    },
    "81b0dd78465d3858449b000eac2f9b22": {
      "source_id": "81b0dd78465d3858449b000eac2f9b22",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5484,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Curiosity as a Solution to AGI Alignment"
    },
    "93f8b0ac34d6eea43e87215f8135f18e": {
      "source_id": "93f8b0ac34d6eea43e87215f8135f18e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6614,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The idea of an \"aligned superintelligence\" seems misguided"
    },
    "ad86f24617a3a0e6bac6db7f570df09a": {
      "source_id": "ad86f24617a3a0e6bac6db7f570df09a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6341,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Some thoughts pointing to slower AI take-off "
    },
    "1d1df3060a9beccfdb49a600bf078001": {
      "source_id": "1d1df3060a9beccfdb49a600bf078001",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2735,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A case for capabilities work on AI as net positive "
    },
    "444190b6bdb2af1969df77f93cc7d02a": {
      "source_id": "444190b6bdb2af1969df77f93cc7d02a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37391,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Transcript: Yudkowsky on Bankless follow-up Q&A"
    },
    "1d19b1397af85345dd234872e46a37a5": {
      "source_id": "1d19b1397af85345dd234872e46a37a5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10315,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Evil autocomplete: Existential Risk and Next-Token Predictors"
    },
    "b14af2774c06cf7fd045bf7896ba8ba1": {
      "source_id": "b14af2774c06cf7fd045bf7896ba8ba1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2928,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Heuristics on bias to action versus status quo?"
    },
    "c47ee98a172ed544b5c5244ae47bfac5": {
      "source_id": "c47ee98a172ed544b5c5244ae47bfac5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73297,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Performance guarantees in classical learning theory and infra-Bayesianism"
    },
    "c512f9df911546f4e30e2b3754438f03": {
      "source_id": "c512f9df911546f4e30e2b3754438f03",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 72893,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A mostly critical review of infra-Bayesianism"
    },
    "a01ba156d745d298dc75a432faf3b982": {
      "source_id": "a01ba156d745d298dc75a432faf3b982",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3547,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The burden of knowing"
    },
    "d4b841f062379a9bfbf7cf6222385ca8": {
      "source_id": "d4b841f062379a9bfbf7cf6222385ca8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13310,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Problems of people new to AI safety and my project ideas to mitigate them"
    },
    "71eb3479923022735a86c94e509ccc4e": {
      "source_id": "71eb3479923022735a86c94e509ccc4e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19819,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Scoring forecasts from the 2016 \u201cExpert Survey on Progress in AI\u201d"
    },
    "1b6b2e1bdba15791bc8ffe800db2b0ba": {
      "source_id": "1b6b2e1bdba15791bc8ffe800db2b0ba",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6380,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Call for Cruxes by Rhyme, a Longtermist History Consultancy"
    },
    "89e2d44588efa4ea08c61be28cbf3fde": {
      "source_id": "89e2d44588efa4ea08c61be28cbf3fde",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23870,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How truthful can LLMs be: a theoretical perspective with a request for help from"
    },
    "0bcf0bac9653f1913a891e2d733d48ad": {
      "source_id": "0bcf0bac9653f1913a891e2d733d48ad",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 852,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Extreme GDP growth is a bad operating definition of \"slow takeoff\""
    },
    "ade26bde0b1d703e5babdf55c00a55e1": {
      "source_id": "ade26bde0b1d703e5babdf55c00a55e1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3697,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Human level AI can plausibly take over the world"
    },
    "d9e27368301d9a74912c7e9c8e4c6e23": {
      "source_id": "d9e27368301d9a74912c7e9c8e4c6e23",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3747,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Clippy, the friendly paperclipper"
    },
    "3c00dcd6c1af6eb3f76af97fd0dc328d": {
      "source_id": "3c00dcd6c1af6eb3f76af97fd0dc328d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14781,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Reflection Mechanisms as an Alignment Target - Attitudes on \u201cnear-term\u201d AI "
    },
    "1ca8e7c08d5f26eac1e8ee9e24bd5189": {
      "source_id": "1ca8e7c08d5f26eac1e8ee9e24bd5189",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 132073,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI #2"
    },
    "15774be39c3704055d418df9749d5aa5": {
      "source_id": "15774be39c3704055d418df9749d5aa5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3317,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Aspiring AI safety researchers should ~argmax over AGI timelines"
    },
    "ed095c714c5a838aff1614bb33653070": {
      "source_id": "ed095c714c5a838aff1614bb33653070",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11504,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Sydney can play chess and kind of keep track of the board state"
    },
    "0a810ec2984817b7eb149972be347654": {
      "source_id": "0a810ec2984817b7eb149972be347654",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1259,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Robin Hanson\u2019s latest AI risk position statement"
    },
    "3db65d76d5388c856076494a87fd31a4": {
      "source_id": "3db65d76d5388c856076494a87fd31a4",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9804,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Governance & Strategy: Priorities, talent gaps, & opportunities"
    },
    "1be938342d2f26a9d3f445dd01bf7297": {
      "source_id": "1be938342d2f26a9d3f445dd01bf7297",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14977,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Situational awareness in Large Language Models"
    },
    "ed9ff26869fbcd40d91a6a650aa9cab7": {
      "source_id": "ed9ff26869fbcd40d91a6a650aa9cab7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42913,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Comments on OpenAI's \"Planning for AGI and beyond\""
    },
    "830704172ea9830fbd57218ce54b8e67": {
      "source_id": "830704172ea9830fbd57218ce54b8e67",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15928,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Contra Hanson on AI Risk"
    },
    "f6944392e04185df3134491c6afb6f70": {
      "source_id": "f6944392e04185df3134491c6afb6f70",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9816,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Contra \"Strong Coherence\""
    },
    "b93403ee157b419f169ab97ffa5df146": {
      "source_id": "b93403ee157b419f169ab97ffa5df146",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3893,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Research proposal: Leveraging Jungian archetypes to create values-based models"
    },
    "5b69d64d78bb6d5060473d7afddd08f3": {
      "source_id": "5b69d64d78bb6d5060473d7afddd08f3",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5146,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A concerning observation from media coverage of AI industry dynamics"
    },
    "2ead304c3cb6f85f3d8a5274aed36393": {
      "source_id": "2ead304c3cb6f85f3d8a5274aed36393",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23458,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Who Aligns the Alignment Researchers?"
    },
    "dafc2823eefc9989ae390fc6f1639c56": {
      "source_id": "dafc2823eefc9989ae390fc6f1639c56",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2824,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Introducing Leap Labs, an AI interpretability startup"
    },
    "50171b1a81ee0ce8479eb165e1766e83": {
      "source_id": "50171b1a81ee0ce8479eb165e1766e83",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3512,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Against ubiquitous alignment taxes"
    },
    "fea74250ef3fca716cba908e8e54b655": {
      "source_id": "fea74250ef3fca716cba908e8e54b655",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1484,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Google's PaLM-E: An Embodied Multimodal Language Model"
    },
    "a979eed220fd37f3e717e60bc2acca9b": {
      "source_id": "a979eed220fd37f3e717e60bc2acca9b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3659,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Alignment works both ways"
    },
    "c5c284b1538db7f7352f4cb7cec2e4e8": {
      "source_id": "c5c284b1538db7f7352f4cb7cec2e4e8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8812,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The View from 30,000 Feet: Preface to the Second EleutherAI Retrospective"
    },
    "4330f0a550e64b7bbdcf4c5c9d23fa4c": {
      "source_id": "4330f0a550e64b7bbdcf4c5c9d23fa4c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 132674,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Podcast Transcript: Daniela and Dario Amodei on Anthropic"
    },
    "8f753447e5026b3de090c3f5d5b25109": {
      "source_id": "8f753447e5026b3de090c3f5d5b25109",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 417,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Introducing AI Alignment Inc., a California public benefit corporation..."
    },
    "0533ad6a99cadb67ef8ba0c6913732ea": {
      "source_id": "0533ad6a99cadb67ef8ba0c6913732ea",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1079,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What\u2018s in your list of unsolved problems in AI alignment?"
    },
    "bde2c92ac6d731e8dded10d87d684172": {
      "source_id": "bde2c92ac6d731e8dded10d87d684172",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7056,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Language models are not inherently safe"
    },
    "ef45532cfad96eebae34a6fab7d5608e": {
      "source_id": "ef45532cfad96eebae34a6fab7d5608e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8618,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why Uncontrollable AI Looks More Likely Than Ever"
    },
    "764289f1eb6633d5c8bfd2bfcc8e8d23": {
      "source_id": "764289f1eb6633d5c8bfd2bfcc8e8d23",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47938,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Against LLM Reductionism"
    },
    "29583d4719fad19435ada31571f68d17": {
      "source_id": "29583d4719fad19435ada31571f68d17",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2801,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Speed running everyone through the bad alignment bingo. $5k bounty for a LW conv"
    },
    "718d6ad44037758b61b69081998eb2b6": {
      "source_id": "718d6ad44037758b61b69081998eb2b6",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4349,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why do we assume there is a \"real\" shoggoth behind the LLM? Why not masks all th"
    },
    "d53c6719c019cf7e4cf91cf0e2f2e9d7": {
      "source_id": "d53c6719c019cf7e4cf91cf0e2f2e9d7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43765,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Anthropic: Core Views on AI Safety: When, Why, What, and How"
    },
    "626236c51b9b113ce02322e8829f71df": {
      "source_id": "626236c51b9b113ce02322e8829f71df",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5137,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Questions about Conjecure's CoEm proposal"
    },
    "4b6f2dc0857e9cb1dff027200962d3b7": {
      "source_id": "4b6f2dc0857e9cb1dff027200962d3b7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6778,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Everything's normal until it's not "
    },
    "8d1fa844546bf747ff761e2b35136427": {
      "source_id": "8d1fa844546bf747ff761e2b35136427",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25401,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Reflections On The Feasibility Of Scalable-Oversight"
    },
    "996b781baa1e138ba6e24ff8abdcc4d7": {
      "source_id": "996b781baa1e138ba6e24ff8abdcc4d7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6842,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Operationalizing timelines"
    },
    "e831279632d6cdf43a66e594e492e387": {
      "source_id": "e831279632d6cdf43a66e594e492e387",
      "quality_score": 2.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 9414,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] Scott Alexander reacts to OpenAI's latest post"
    },
    "f16fa0069bad1619c34f3974b5b13e4c": {
      "source_id": "f16fa0069bad1619c34f3974b5b13e4c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8327,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Thoughts on self-inspecting neural networks."
    },
    "3d0c8bf34a069564970678c378dc9a3e": {
      "source_id": "3d0c8bf34a069564970678c378dc9a3e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1913,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "On taking AI risk seriously "
    },
    "11d646d4ca11334a109bde33473d4714": {
      "source_id": "11d646d4ca11334a109bde33473d4714",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 124,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Linkpost: A tale of 2.5 orthogonality theses"
    },
    "29c6f174763783d6159be109857d48dd": {
      "source_id": "29c6f174763783d6159be109857d48dd",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1810,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Could Roko's basilisk acausally bargain with a paperclip maximizer?"
    },
    "fb1b4daaf36745eee8b3229c3cc5b22e": {
      "source_id": "fb1b4daaf36745eee8b3229c3cc5b22e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10613,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A better analogy and example for teaching AI takeover: the ML Inferno"
    },
    "332a0ef98895fdc4788c03f7f21b9270": {
      "source_id": "332a0ef98895fdc4788c03f7f21b9270",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32566,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Success without dignity: a nearcasting story of avoiding catastrophe by luck"
    },
    "b24555af6abae9e1351153b8948ccdc2": {
      "source_id": "b24555af6abae9e1351153b8948ccdc2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 878,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "GPT-4 developer livestream"
    },
    "36f7a395ae0e4f1ff5865b65a1df50c8": {
      "source_id": "36f7a395ae0e4f1ff5865b65a1df50c8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24134,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "PaperclipGPT(-4)"
    },
    "299bd80cca4ea729832d77ce43def0b7": {
      "source_id": "299bd80cca4ea729832d77ce43def0b7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17018,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Human preferences as RL critic values\u00a0- implications for alignment"
    },
    "f311903206cac02d0bc88c9db2df0cc8": {
      "source_id": "f311903206cac02d0bc88c9db2df0cc8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20995,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "ARC tests to see if GPT-4 can escape human control; GPT-4 failed to do so"
    },
    "a5cde8b95e86cf95afa5e9c897b1c9cd": {
      "source_id": "a5cde8b95e86cf95afa5e9c897b1c9cd",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8142,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Nokens: A potential method of investigating glitch tokens"
    },
    "ab992d73cf61e9e8c6c62033b469d27c": {
      "source_id": "ab992d73cf61e9e8c6c62033b469d27c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6427,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why not just boycott LLMs?"
    },
    "46411ff63dddceeb48f9c00429b2f3bf": {
      "source_id": "46411ff63dddceeb48f9c00429b2f3bf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47302,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "GPT-4: What we (I) know about it"
    },
    "53fb9873faa94e7fd3410faf2ea574d5": {
      "source_id": "53fb9873faa94e7fd3410faf2ea574d5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2093,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is there an analysis of the common consideration that splitting an AI lab into t"
    },
    "e625033d1ff2e3e39662dc926ba029c9": {
      "source_id": "e625033d1ff2e3e39662dc926ba029c9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19937,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Are AI developers playing with fire?"
    },
    "690e32121339c64d54a8cceed3b8fd1b": {
      "source_id": "690e32121339c64d54a8cceed3b8fd1b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 637,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is it a bad idea to pay for GPT-4?"
    },
    "d2ece935c925900ed81614f0afd66618": {
      "source_id": "d2ece935c925900ed81614f0afd66618",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10794,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Gradual takeoff, fast failure"
    },
    "2707a1d4795ce9f010c9c5da1cf32b90": {
      "source_id": "2707a1d4795ce9f010c9c5da1cf32b90",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28510,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The algorithm isn't doing X, it's just doing Y."
    },
    "b263c5a04db73be10c1a9c30fc593e44": {
      "source_id": "b263c5a04db73be10c1a9c30fc593e44",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3683,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Survey on intermediate goals in AI governance"
    },
    "25b7e822ee3cdb6f405c4004f73d9f72": {
      "source_id": "25b7e822ee3cdb6f405c4004f73d9f72",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22760,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\"Carefully Bootstrapped Alignment\" is organizationally hard"
    },
    "5bf027675d6b489d1f533557675d6e85": {
      "source_id": "5bf027675d6b489d1f533557675d6e85",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13558,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Retrospective on \u2018GPT-4 Predictions\u2019 After the Release of GPT-4"
    },
    "ed269f1af9fac42b8a24cb289baf1124": {
      "source_id": "ed269f1af9fac42b8a24cb289baf1124",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8027,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "(retired article) AGI With Internet Access: Why we won't stuff the genie back in"
    },
    "e80b5755c29df9218394c4fa795377df": {
      "source_id": "e80b5755c29df9218394c4fa795377df",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2067,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A tension between two prosaic alignment subgoals"
    },
    "a3663ed49e5f43fd464ca13399f5726b": {
      "source_id": "a3663ed49e5f43fd464ca13399f5726b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9396,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Humanity's Lack of Unity Will Lead to AGI Catastrophe"
    },
    "2b30bdef09a3c8fefeca550e9732bdd6": {
      "source_id": "2b30bdef09a3c8fefeca550e9732bdd6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62093,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Instantiating an agent with GPT-4 and text-davinci-003"
    },
    "f94da34d0698aaa0d8d2e8d501caf4ce": {
      "source_id": "f94da34d0698aaa0d8d2e8d501caf4ce",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4492,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Natural State is Goodhart"
    },
    "b630272615c838ecf80fb2e6e5bb5eb1": {
      "source_id": "b630272615c838ecf80fb2e6e5bb5eb1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23685,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What does it mean for an LLM such as GPT to be aligned / good / positive impact?"
    },
    "c8cdb12dbf5cae1d89e70029dab75f38": {
      "source_id": "c8cdb12dbf5cae1d89e70029dab75f38",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27879,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "RLHF does not appear to differentially cause mode-collapse"
    },
    "e4ea604c58c1058ee0dda2767384b163": {
      "source_id": "e4ea604c58c1058ee0dda2767384b163",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17702,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The dreams of GPT-4"
    },
    "296476081e3b8803077bc86a4dd925ba": {
      "source_id": "296476081e3b8803077bc86a4dd925ba",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12550,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI and the Map of Your Mind: Pattern Recognition "
    },
    "aa350196ce2f8bb008562cf16ebd8d69": {
      "source_id": "aa350196ce2f8bb008562cf16ebd8d69",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14779,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Wizard of Oz Problem: How incentives and narratives can skew our perception "
    },
    "0983f4d12cdf15d93f2238c0a34e36ae": {
      "source_id": "0983f4d12cdf15d93f2238c0a34e36ae",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1144,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What does pulling the fire alarm look like?"
    },
    "82167f08563c7b7e376c49f217da348e": {
      "source_id": "82167f08563c7b7e376c49f217da348e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 81265,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Remarks 1\u201318 on GPT (compressed)"
    },
    "ae8a23bb56334bb0856b9392328c3e96": {
      "source_id": "ae8a23bb56334bb0856b9392328c3e96",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6067,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Capabilities Denial: The Danger of Underestimating AI"
    },
    "0d68884a0d1adaf4966cc19d98021f44": {
      "source_id": "0d68884a0d1adaf4966cc19d98021f44",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 264853,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI #4: Introducing GPT-4"
    },
    "531dfd6bc78037df373d1346c7248e88": {
      "source_id": "531dfd6bc78037df373d1346c7248e88",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4410,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Employer considering partnering with major AI labs. What to do?"
    },
    "ce0937233f5b97e437cd26c6f2395e14": {
      "source_id": "ce0937233f5b97e437cd26c6f2395e14",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1660,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why not constrain wetlabs instead of AI?"
    },
    "14c3615f5c2927ae23d8c128e4e5b5cd": {
      "source_id": "14c3615f5c2927ae23d8c128e4e5b5cd",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2699,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Emergent Analogical Reasoning in Large Language Models"
    },
    "02acc89e28c169a90c08ce681a949f4d": {
      "source_id": "02acc89e28c169a90c08ce681a949f4d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3084,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Agentic GPT simulations: a risk and an opportunity"
    },
    "4c51e3e2210c0e0b8040c2afb634f042": {
      "source_id": "4c51e3e2210c0e0b8040c2afb634f042",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14707,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why AI Safety is Hard"
    },
    "051e25d4f28a73ca9a7ebe6b4deb21c7": {
      "source_id": "051e25d4f28a73ca9a7ebe6b4deb21c7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38245,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Empirical risk minimization is fundamentally confused"
    },
    "9599bae5cf641c6ee4eec075c803e509": {
      "source_id": "9599bae5cf641c6ee4eec075c803e509",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20205,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Key Questions for Digital Minds"
    },
    "af3bc696094ab596aae8ead085e189f4": {
      "source_id": "af3bc696094ab596aae8ead085e189f4",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 1990,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] Shorter version of report on existential risk from power-seeking AI"
    },
    "33813ef0a9d9714ebbec78c8d78cb463": {
      "source_id": "33813ef0a9d9714ebbec78c8d78cb463",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1730,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Sparks of Artificial General Intelligence: Early experiments with GPT-4 | Micros"
    },
    "85e99ee17df57b0aabfedb9561293d6a": {
      "source_id": "85e99ee17df57b0aabfedb9561293d6a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7366,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "ChatGPT's \"fuzzy alignment\" isn't evidence of AGI alignment: the banana test"
    },
    "7f6c150be29343b7ab6cf62d5d70032c": {
      "source_id": "7f6c150be29343b7ab6cf62d5d70032c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13197,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "GPT-4 aligning with acasual decision theory when instructed to play games, but i"
    },
    "ea6a8c6da07191c8d905e8c6d0d6bb2a": {
      "source_id": "ea6a8c6da07191c8d905e8c6d0d6bb2a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14677,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Overton Window widens: Examples of AI risk in the media"
    },
    "20feb40421afefa0d53dff3f902be7dc": {
      "source_id": "20feb40421afefa0d53dff3f902be7dc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2523,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is your job replaceable by GPT-4? (as of March 2023)"
    },
    "acf7844c386ed66ea791345dff22a510": {
      "source_id": "acf7844c386ed66ea791345dff22a510",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2159,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "continue working on hard alignment! don't give up!"
    },
    "065b32e96b396c0cc153b3a8d9d6d312": {
      "source_id": "065b32e96b396c0cc153b3a8d9d6d312",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6816,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Grinding slimes in the dungeon of AI alignment research"
    },
    "85f66738cc22fba7ae0d4fefd34de70b": {
      "source_id": "85f66738cc22fba7ae0d4fefd34de70b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12821,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Microsoft Research Paper Claims Sparks of Artificial Intelligence in GPT-4"
    },
    "9ccbdd89e89785f4656e54a07b3c65f0": {
      "source_id": "9ccbdd89e89785f4656e54a07b3c65f0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40143,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "GPT-2005: A conversation with ChatGPT (featuring semi-functional Wolfram Alpha p"
    },
    "e6e295deb04a6b206ad251996074e3fc": {
      "source_id": "e6e295deb04a6b206ad251996074e3fc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1716,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Are extrapolation-based AIs alignable?"
    },
    "99ab6052a52e656a312598d529aac47f": {
      "source_id": "99ab6052a52e656a312598d529aac47f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19578,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "More experiments in GPT-4 agency: writing memos"
    },
    "16bee30587a300bd80cd50aeb6365bc7": {
      "source_id": "16bee30587a300bd80cd50aeb6365bc7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4191,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Good News, Everyone!"
    },
    "7946647e4e7a472cf9ec9eb7d7ceb8ae": {
      "source_id": "7946647e4e7a472cf9ec9eb7d7ceb8ae",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2383,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Aligned AI as a wrapper around an LLM"
    },
    "f985a2a778c04950977eaa3f483fc230": {
      "source_id": "f985a2a778c04950977eaa3f483fc230",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3585,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Sam Altman on GPT-4, ChatGPT, and the Future of AI | Lex Fridman Podcast #367"
    },
    "16aef5d94a7299ba0f8438d00548fa95": {
      "source_id": "16aef5d94a7299ba0f8438d00548fa95",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 55555,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Draft: Introduction to optimization"
    },
    "967b43d671604bdfd526b14b3c9c82f8": {
      "source_id": "967b43d671604bdfd526b14b3c9c82f8",
      "quality_score": 2.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 6886,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What would a compute monitoring plan look like? [Linkpost]"
    },
    "a9eb630886c0922a8eb23acca2ebdf7f": {
      "source_id": "a9eb630886c0922a8eb23acca2ebdf7f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16205,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What can we learn from Lex Fridman\u2019s interview with Sam Altman?"
    },
    "71c4ab33d03715d1f397ea84a3dd2d13": {
      "source_id": "71c4ab33d03715d1f397ea84a3dd2d13",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20681,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "GPT-4 Plugs In"
    },
    "1f0d333aa2de23d3d9f49e88a30cbf49": {
      "source_id": "1f0d333aa2de23d3d9f49e88a30cbf49",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1195,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "CAIS-inspired approach towards safer and more interpretable AGIs"
    },
    "89d6232b2d77b062168db8fadf638e1b": {
      "source_id": "89d6232b2d77b062168db8fadf638e1b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9907,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Nobody knows how to reliably test for AI safety"
    },
    "3c6636a8f859836ac3d5d47e01aa674f": {
      "source_id": "3c6636a8f859836ac3d5d47e01aa674f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6390,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Three of my beliefs about upcoming AGI "
    },
    "b7053384154fec3d9d23e761670c0227": {
      "source_id": "b7053384154fec3d9d23e761670c0227",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37991,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Prospect of an AI Winter"
    },
    "de33ee97d960a8b14865fde871aa2e6d": {
      "source_id": "de33ee97d960a8b14865fde871aa2e6d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12494,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "100 Dinners And A Workshop: Information Preservation And Goals"
    },
    "5a5966c4b8a33b90f48f275e23089b79": {
      "source_id": "5a5966c4b8a33b90f48f275e23089b79",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19465,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Creating a family with GPT-4"
    },
    "2a76bfc91b00c35b2f4a818af651cc91": {
      "source_id": "2a76bfc91b00c35b2f4a818af651cc91",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12928,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Corrigibility, Self-Deletion, and Identical Strawberries"
    },
    "298d8494d4180bf36567ddeafa97bb2a": {
      "source_id": "298d8494d4180bf36567ddeafa97bb2a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1179,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Half-baked alignment idea "
    },
    "b6c6784cd88cc23dbd419347eccf8ed0": {
      "source_id": "b6c6784cd88cc23dbd419347eccf8ed0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16626,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "I had a chat with GPT-4 on the future of AI and AI safety"
    },
    "cd2846f32d26904e8fb344e7e819c965": {
      "source_id": "cd2846f32d26904e8fb344e7e819c965",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1003,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Governing High-Impact AI Systems: Understanding Canada\u2019s Proposed AI Bill. April"
    },
    "f5d4b80d000a0cac048b878a4649006d": {
      "source_id": "f5d4b80d000a0cac048b878a4649006d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13082,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How do we align humans and what does it mean for the new Conjecture's strategy"
    },
    "b3fd92481d4c82e6198b42bfaee623af": {
      "source_id": "b3fd92481d4c82e6198b42bfaee623af",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5318,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Inching \u201cKubla Khan\u201d and GPT into the same intellectual framework @ 3 Quarks Dai"
    },
    "848a1c5487cb66409794f47f7361ffee": {
      "source_id": "848a1c5487cb66409794f47f7361ffee",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30565,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": " Draft: The optimization toolbox"
    },
    "899773933aaef2f46361639f43b25ca8": {
      "source_id": "899773933aaef2f46361639f43b25ca8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5527,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Four lenses on AI risks"
    },
    "7a62dd74c58efa704e7e4e908df740b8": {
      "source_id": "7a62dd74c58efa704e7e4e908df740b8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16209,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\u201cUnintentional AI safety research\u201d: Why not systematically mine AI technical res"
    },
    "996f8f4450aa490a6a7d7351cd4a3304": {
      "source_id": "996f8f4450aa490a6a7d7351cd4a3304",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11494,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Want to win the AGI race? Solve alignment."
    },
    "1886c7551b20bea82c6fa76474d0d085": {
      "source_id": "1886c7551b20bea82c6fa76474d0d085",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1258,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\"Sorcerer's Apprentice\" from Fantasia as an analogy for alignment"
    },
    "3149aa16aea68d316cb37809068628ca": {
      "source_id": "3149aa16aea68d316cb37809068628ca",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30916,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Draft: Detecting optimization"
    },
    "3d5f65099670939f31af2a665e07beb7": {
      "source_id": "3d5f65099670939f31af2a665e07beb7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4697,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Pausing AI Developments Isn't Enough. We Need to Shut it All Down by Eliezer Yud"
    },
    "082268541ac416696d2a4832bebde91d": {
      "source_id": "082268541ac416696d2a4832bebde91d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9533,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Doom Is Not (Only) Disjunctive"
    },
    "d20700e354c2a61375264813a6b09eba": {
      "source_id": "d20700e354c2a61375264813a6b09eba",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3503,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Alignment - Path to AI as ally, not slave nor foe"
    },
    "a674a5da60f8b877d1ed282ac667c231": {
      "source_id": "a674a5da60f8b877d1ed282ac667c231",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22636,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Role Architectures: Applying LLMs to consequential tasks"
    },
    "b9d9d6869283dbd9b4b9cdfe08fcb01f": {
      "source_id": "b9d9d6869283dbd9b4b9cdfe08fcb01f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15039,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Arguing all sides with ChatGPT"
    },
    "56c0870ae41b1c87f3a74de600659492": {
      "source_id": "56c0870ae41b1c87f3a74de600659492",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7797,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "It Can't Be Mesa-Optimizers All The Way Down (Or Else It Can't Be Long-Term Supe"
    },
    "d74e5df010709a0503ee2641c889b472": {
      "source_id": "d74e5df010709a0503ee2641c889b472",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 740,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Widening Overton Window - Open Thread"
    },
    "f6c9851de9928f8fd17a73ce1ce899da": {
      "source_id": "f6c9851de9928f8fd17a73ce1ce899da",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6669,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Harry Potter and the Data Centers of Doom"
    },
    "679c5c4b4e3d4096278001d56b12412d": {
      "source_id": "679c5c4b4e3d4096278001d56b12412d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2277,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Peril of the Great Leaks (written with ChatGPT)"
    },
    "94a14a62be4005ef9299d1e8f6511e5c": {
      "source_id": "94a14a62be4005ef9299d1e8f6511e5c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14012,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Wizards and prophets of AI [draft for comment]"
    },
    "e866ff9957e63b988951fc98268cccbe": {
      "source_id": "e866ff9957e63b988951fc98268cccbe",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1652,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[New LW Feature] \"Debates\" "
    },
    "cc9676333e7995723f6f691d749bc2dd": {
      "source_id": "cc9676333e7995723f6f691d749bc2dd",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4932,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[April Fools'] Definitive confirmation of shard theory"
    },
    "de06e09caac17842a9adbe0f3e4edca6": {
      "source_id": "de06e09caac17842a9adbe0f3e4edca6",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2066,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Campaign for AI Safety: Please join me"
    },
    "1dc65b1d18bd9a9bad1be462a184fed1": {
      "source_id": "1dc65b1d18bd9a9bad1be462a184fed1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1811,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Transformer trained on it's own content?"
    },
    "ef6248b20936813a67a19d7eb3042880": {
      "source_id": "ef6248b20936813a67a19d7eb3042880",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4426,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI community building: EliezerKart"
    },
    "10990e4088db6e7c5005675fe90ae399": {
      "source_id": "10990e4088db6e7c5005675fe90ae399",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19102,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why I Think the Current Trajectory of AI Research has Low P(doom) - LLMs"
    },
    "0b61282af0557ab30efd160b38e4f08d": {
      "source_id": "0b61282af0557ab30efd160b38e4f08d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26940,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Analysis of GPT-4 competence in assessing complex legal language: Example of Bil"
    },
    "25e15072f979eba9ea0926dfe6d946a3": {
      "source_id": "25e15072f979eba9ea0926dfe6d946a3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 66570,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Pessimism about AI Safety"
    },
    "ce2983ca421abfa68c2484a486654679": {
      "source_id": "ce2983ca421abfa68c2484a486654679",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33144,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Advanced AI can beat humanity"
    },
    "630111f920be607971114cacae6ca71d": {
      "source_id": "630111f920be607971114cacae6ca71d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28111,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISC 2023, Progress Report for March: Team Interpretable Architectures"
    },
    "f5545d4a2dbbc4975e4b5394a21004ee": {
      "source_id": "f5545d4a2dbbc4975e4b5394a21004ee",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 625,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "GTP4 capable of limited recursive improving?"
    },
    "54bf181f0fcd9b1e815b4dc50e9f53e8": {
      "source_id": "54bf181f0fcd9b1e815b4dc50e9f53e8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2126,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Orthogonality is Expensive"
    },
    "79e8bef92b633f90de6ef01dccf2c204": {
      "source_id": "79e8bef92b633f90de6ef01dccf2c204",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2961,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Repeated Play of Imperfect Newcomb's Paradox in Infra-Bayesian Physicalism"
    },
    "91e6400aa04aa520f0f22a7a589828fb": {
      "source_id": "91e6400aa04aa520f0f22a7a589828fb",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5095,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Orthogonality is expensive"
    },
    "077e031f1bc22d21e8acc3e1c9ab8a90": {
      "source_id": "077e031f1bc22d21e8acc3e1c9ab8a90",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3672,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Mati's introduction to pausing giant AI experiments"
    },
    "2ceb51ae260a666357fd45889b7e3b91": {
      "source_id": "2ceb51ae260a666357fd45889b7e3b91",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7706,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Exploring non-anthropocentric aspects of AI existential safety"
    },
    "42e630605e979f2f07835e6bb26f4f72": {
      "source_id": "42e630605e979f2f07835e6bb26f4f72",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1493,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Towards empathy in RL agents and beyond: Insights from cognitive science for AI "
    },
    "e38994444c2432d532b38b8b0ee5fa82": {
      "source_id": "e38994444c2432d532b38b8b0ee5fa82",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23334,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Complex Systems are Hard to Control"
    },
    "c8fb927f253445aff5b13a1d8b92af0b": {
      "source_id": "c8fb927f253445aff5b13a1d8b92af0b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28816,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Steering systems"
    },
    "4ddcfc195aa8878ff164f0e165ad17b0": {
      "source_id": "4ddcfc195aa8878ff164f0e165ad17b0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2996,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Summer Harvest"
    },
    "94794da168f5100cc713575b8b68aa35": {
      "source_id": "94794da168f5100cc713575b8b68aa35",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7746,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Invocations: The Other Capabilities Overhang?"
    },
    "8a5fce2ccbb3511ac19e3f6960580a49": {
      "source_id": "8a5fce2ccbb3511ac19e3f6960580a49",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2406,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "New survey: 46% of Americans are concerned about extinction from AI; 69% support"
    },
    "86600e8068e146c37dbb122ef774c6e7": {
      "source_id": "86600e8068e146c37dbb122ef774c6e7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2223,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Empathy bandaid for immediate AI catastrophe"
    },
    "68b7a902e3edb95263043492f3ea3336": {
      "source_id": "68b7a902e3edb95263043492f3ea3336",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23161,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AGI deployment as an act of aggression"
    },
    "0facde72374bf79449e5b80187232d32": {
      "source_id": "0facde72374bf79449e5b80187232d32",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13487,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "ICA Simulacra"
    },
    "0f73686e24abd542fc341ecdd17d44c9": {
      "source_id": "0f73686e24abd542fc341ecdd17d44c9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 592,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Best arguments against instrumental convergence?"
    },
    "05a0a502d7bdd2f1a8dd50c882c7fa53": {
      "source_id": "05a0a502d7bdd2f1a8dd50c882c7fa53",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1405,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "OpenAI: Our approach to AI safety"
    },
    "1475a5aa9f349318a68ba64ed8d0d370": {
      "source_id": "1475a5aa9f349318a68ba64ed8d0d370",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1620,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Daisy-chaining epsilon-step verifiers"
    },
    "2dfd52b83680bbd21fb016904c9430a0": {
      "source_id": "2dfd52b83680bbd21fb016904c9430a0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9026,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Yoshua Bengio: \"Slowing down development of AI systems passing the Turing test\""
    },
    "e4d5ebc799b8cee31a83feefd2db5851": {
      "source_id": "e4d5ebc799b8cee31a83feefd2db5851",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2105,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Dual-Useness is a Ratio"
    },
    "8c3ce6d7c981074b418f42f1cc6b4477": {
      "source_id": "8c3ce6d7c981074b418f42f1cc6b4477",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 70526,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is \"Recursive Self-Improvement\" Relevant in the Deep Learning Paradigm?"
    },
    "a64c6681ab03db9dba8f7ce602f3bd9a": {
      "source_id": "a64c6681ab03db9dba8f7ce602f3bd9a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4651,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "I asked my senator to slow AI"
    },
    "ef0b7d16405847590648a3bdbb7175fd": {
      "source_id": "ef0b7d16405847590648a3bdbb7175fd",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2218,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISafety.world is a map of the AIS ecosystem"
    },
    "4c29963c8d430e5070147aba25903027": {
      "source_id": "4c29963c8d430e5070147aba25903027",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12519,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI scares and changing public beliefs"
    },
    "38def21954a9c23b746de95f647cbec4": {
      "source_id": "38def21954a9c23b746de95f647cbec4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4215,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "You can use GPT-4 to create prompt injections against GPT-4"
    },
    "6a919f23a415a1fc99705f1eb952e1a7": {
      "source_id": "6a919f23a415a1fc99705f1eb952e1a7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6838,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "One Does Not Simply Replace the Humans "
    },
    "5bde6edd7fdf997d50e3055730b655b6": {
      "source_id": "5bde6edd7fdf997d50e3055730b655b6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20099,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Risks from GPT-4 Byproduct of Recursively Optimizing AIs"
    },
    "b90441e947301a3230358206e83bec18": {
      "source_id": "b90441e947301a3230358206e83bec18",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1270,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "If Alignment is Hard, then so is Self-Improvement"
    },
    "6f4f79c3b6f132152fd2abc5130b0265": {
      "source_id": "6f4f79c3b6f132152fd2abc5130b0265",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4275,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Goal alignment without alignment on epistemology, ethics, and science is futile"
    },
    "32bd0499c1f2b526308759c7a34fc642": {
      "source_id": "32bd0499c1f2b526308759c7a34fc642",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3936,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Stampy's AI Safety Info - New Distillations #1 [March 2023] (Expansive interacti"
    },
    "391a05ccbbb67987bd885037bdb89952": {
      "source_id": "391a05ccbbb67987bd885037bdb89952",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1155,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "ChatGTP \"Writing \" News Stories for The Guardian?"
    },
    "d22836eac2ec5b552db6c22c70f75f07": {
      "source_id": "d22836eac2ec5b552db6c22c70f75f07",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9307,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Reliability, Security, and AI risk: Notes from infosec textbook chapter 1"
    },
    "b9f07c27266e2f222799b980cd399fed": {
      "source_id": "b9f07c27266e2f222799b980cd399fed",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8750,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "n=3 AI Risk Quick Math and Reasoning"
    },
    "299c374a20b2d4b0c9f1a7eca94f21fc": {
      "source_id": "299c374a20b2d4b0c9f1a7eca94f21fc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30416,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Select Agent Specifications as Natural Abstractions"
    },
    "1584041a8366820effc243f16ac6548c": {
      "source_id": "1584041a8366820effc243f16ac6548c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22116,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Pausing AI Developments Isn't Enough. We Need to Shut it All Down"
    },
    "5bb06ceb49aa112179aa662d782ceb49": {
      "source_id": "5bb06ceb49aa112179aa662d782ceb49",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5482,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "All AGI Safety questions welcome (especially basic ones) [April 2023]"
    },
    "b27fde0141d500d134d366349c0222fb": {
      "source_id": "b27fde0141d500d134d366349c0222fb",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5553,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "All images from the WaitButWhy sequence on AI"
    },
    "810ed8834206e997939b3c808323fd05": {
      "source_id": "810ed8834206e997939b3c808323fd05",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12210,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "SERI MATS - Summer 2023 Cohort"
    },
    "83e201347617ed4935f68b2cf588f113": {
      "source_id": "83e201347617ed4935f68b2cf588f113",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5692,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\"warning about ai doom\" is also \"announcing capabilities progress to noobs\""
    },
    "21863ec55f82f2c77f1b5f9e6520966f": {
      "source_id": "21863ec55f82f2c77f1b5f9e6520966f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10967,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A decade of lurking, a month of posting"
    },
    "6c48404d6eb3fa957237dc42783f9318": {
      "source_id": "6c48404d6eb3fa957237dc42783f9318",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6410,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Agentized LLMs will change the alignment landscape"
    },
    "c1232773e381c27ec8ce4c277eff33a6": {
      "source_id": "c1232773e381c27ec8ce4c277eff33a6",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1917,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Foom seems unlikely in the current LLM training paradigm"
    },
    "163d3cb5e10773f0c1a79045b64f633b": {
      "source_id": "163d3cb5e10773f0c1a79045b64f633b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15923,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An AI Realist Manifesto: Neither Doomer nor Foomer, but a third more reasonable "
    },
    "bcc20fa163d0ff0376e4cd5ff99cd636": {
      "source_id": "bcc20fa163d0ff0376e4cd5ff99cd636",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7894,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why I'm not worried about imminent doom"
    },
    "300a3c4efe210b21b2687d40a8a33903": {
      "source_id": "300a3c4efe210b21b2687d40a8a33903",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 973,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Does GPT-4's ability to compress text in a way that it can actually decompress i"
    },
    "e30bf2edd1e75be154146e1f20ac0ab5": {
      "source_id": "e30bf2edd1e75be154146e1f20ac0ab5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 11422,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Newsletter #1 [CAIS Linkpost]"
    },
    "9836d776ae21314ef8a197abfaa2c9bc": {
      "source_id": "9836d776ae21314ef8a197abfaa2c9bc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4550,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Humans are not prepared to operate outside their moral training distribution"
    },
    "306389128fa53f68f5a9ceae0be6c008": {
      "source_id": "306389128fa53f68f5a9ceae0be6c008",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41943,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "FLI And Eliezer Should Reach Consensus"
    },
    "1f25f601e45f958bd7a8529a105a0912": {
      "source_id": "1f25f601e45f958bd7a8529a105a0912",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16099,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Some Intuitions Around Short AI Timelines Based on Recent Progress"
    },
    "fd1335f3da5f9b10727c1d6b39327a5b": {
      "source_id": "fd1335f3da5f9b10727c1d6b39327a5b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6079,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A couple of questions about Conjecture's Cognitive Emulation proposal"
    },
    "a74add9486b81c5a225a03528f9716f5": {
      "source_id": "a74add9486b81c5a225a03528f9716f5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4169,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Where's the foom?"
    },
    "890cb33d98ef357c8074b743f6478e1d": {
      "source_id": "890cb33d98ef357c8074b743f6478e1d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3097,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Request to AGI organizations: Share your views on pausing AI progress"
    },
    "793c3a9c1f124972c2e872dd2b4fdbc6": {
      "source_id": "793c3a9c1f124972c2e872dd2b4fdbc6",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8315,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "In favor of accelerating problems you're trying to solve"
    },
    "a1bca00cb63c73ab1702786969d276de": {
      "source_id": "a1bca00cb63c73ab1702786969d276de",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 853,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Risk US Presidential Candidate"
    },
    "a2790248585e37fc60ec294b1cbd0db1": {
      "source_id": "a2790248585e37fc60ec294b1cbd0db1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 305,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Link] Sarah Constantin: \"Why I am Not An AI Doomer\""
    },
    "29c84c3b020c5b4d15c1bfcf8875a436": {
      "source_id": "29c84c3b020c5b4d15c1bfcf8875a436",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24196,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Scaffolded LLMs as natural language computers"
    },
    "b3678ea099d7a80376efa280da2a5648": {
      "source_id": "b3678ea099d7a80376efa280da2a5648",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12488,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Boundaries-based security and AI safety approaches"
    },
    "dffeccb1d7c40b9e4ae6883827e2f96e": {
      "source_id": "dffeccb1d7c40b9e4ae6883827e2f96e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7904,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Alignment of AutoGPT agents"
    },
    "feb8a6b73e2dcf4d98f1592de9c94900": {
      "source_id": "feb8a6b73e2dcf4d98f1592de9c94900",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26114,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Towards a solution to the alignment problem via objective detection and evaluati"
    },
    "fae1fedab850c302cd194e67c3c9cc05": {
      "source_id": "fae1fedab850c302cd194e67c3c9cc05",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16508,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Identifying semantic neurons, mechanistic circuits & interpretability web apps"
    },
    "a6302efd949306eef9760f09585e45a5": {
      "source_id": "a6302efd949306eef9760f09585e45a5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37032,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "On AutoGPT"
    },
    "893890a0d3fe711a79f89e7e8e3a687a": {
      "source_id": "893890a0d3fe711a79f89e7e8e3a687a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30341,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Navigating the Open-Source AI Landscape: Data, Funding, and Safety"
    },
    "f8039ece9af1c037cd84a29b68e0a920": {
      "source_id": "f8039ece9af1c037cd84a29b68e0a920",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4531,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Intro to Ontogenetic Curriculum"
    },
    "dbc583428cc93d386de4b79e1f050dc9": {
      "source_id": "dbc583428cc93d386de4b79e1f050dc9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3689,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Polluting the agentic commons"
    },
    "ee22aa1b749106aa13b21e6423849880": {
      "source_id": "ee22aa1b749106aa13b21e6423849880",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34558,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Financial Times: We must slow down the race to God-like AI"
    },
    "28ed3396845a8963568036e806f2827f": {
      "source_id": "28ed3396845a8963568036e806f2827f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6429,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Europe Retreat 2023 Retrospective"
    },
    "5c4aaad95703da2e44cabee1029c16ea": {
      "source_id": "5c4aaad95703da2e44cabee1029c16ea",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25573,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Research Report: Incorrectness Cascades"
    },
    "deb73c092c2ae2da84d331b2fea87cf1": {
      "source_id": "deb73c092c2ae2da84d331b2fea87cf1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5457,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "LLMs and hallucination, like white on rice? "
    },
    "876efb8510f7d84797bf6aa0b76283ca": {
      "source_id": "876efb8510f7d84797bf6aa0b76283ca",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5552,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "List of requests for an AI slowdown/halt."
    },
    "8c0f0ed2dcdc8456bb31faa6a636356a": {
      "source_id": "8c0f0ed2dcdc8456bb31faa6a636356a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 110234,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The \u2018 petertodd\u2019 phenomenon"
    },
    "67a4fd6e819ce818928bb7f7c11b16d2": {
      "source_id": "67a4fd6e819ce818928bb7f7c11b16d2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2450,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An example elevator pitch for AI doom"
    },
    "4416b532b5c165f0f65aa569bff5f811": {
      "source_id": "4416b532b5c165f0f65aa569bff5f811",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 590,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "FLI report: Policymaking in the Pause"
    },
    "3e21741ca155344fed4af1be3ad3adcc": {
      "source_id": "3e21741ca155344fed4af1be3ad3adcc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2799,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Open-source LLMs may prove Bostrom's vulnerable world hypothesis"
    },
    "edb9f325703c5d040c83ce9bbf76360d": {
      "source_id": "edb9f325703c5d040c83ce9bbf76360d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2499,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Link/crosspost] [US] NTIA: AI Accountability Policy Request for Comment"
    },
    "afbe186376ce3cec5ecc4701def6f7f4": {
      "source_id": "afbe186376ce3cec5ecc4701def6f7f4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 63248,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Mechanistically interpreting time in GPT-2 small"
    },
    "ffcccca9e4341459c176816d04f94b52": {
      "source_id": "ffcccca9e4341459c176816d04f94b52",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2336,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Top lesson from GPT: we will probably destroy humanity \"for the lulz\" as soon as"
    },
    "089667899cd6261159e3afb6fef9ed51": {
      "source_id": "089667899cd6261159e3afb6fef9ed51",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14463,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Takeover Scenario with Scaled LLMs"
    },
    "55168bd761fcc562248784b37de2507c": {
      "source_id": "55168bd761fcc562248784b37de2507c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5697,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Prediction: any uncontrollable AI will turn earth into a giant computer"
    },
    "0e8726f3bc263aa7b8292c9caa634dc3": {
      "source_id": "0e8726f3bc263aa7b8292c9caa634dc3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44381,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Slowing AI: Foundations"
    },
    "0f73270d0b4e0ff04bc450f27a3a2661": {
      "source_id": "0f73270d0b4e0ff04bc450f27a3a2661",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8398,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An alternative of PPO towards alignment"
    },
    "d1312e85c8245f5c08643a6b0684a6aa": {
      "source_id": "d1312e85c8245f5c08643a6b0684a6aa",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17874,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI policy ideas: Reading list"
    },
    "bfe3d60a33e192df7fd96718e7e38de2": {
      "source_id": "bfe3d60a33e192df7fd96718e7e38de2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13306,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Alignment Research Engineer Accelerator (ARENA): call for applicants"
    },
    "c73532c1a7a3d6ba0056a1a6a1a7130a": {
      "source_id": "c73532c1a7a3d6ba0056a1a6a1a7130a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8587,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Green goo is plausible"
    },
    "c9d7ea0ffdeafb453f0dabede3e3b8b8": {
      "source_id": "c9d7ea0ffdeafb453f0dabede3e3b8b8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10603,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "No, really, it predicts next tokens."
    },
    "9766e9647a28e6da94cd6f38394e2cdc": {
      "source_id": "9766e9647a28e6da94cd6f38394e2cdc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 256,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "World and Mind in Artificial Intelligence: arguments against the AI pause"
    },
    "9343416fd422baad1e0c48436ba7de82": {
      "source_id": "9343416fd422baad1e0c48436ba7de82",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25555,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Scientism vs. people"
    },
    "fea6a0d6a83b92007427b2590502a035": {
      "source_id": "fea6a0d6a83b92007427b2590502a035",
      "quality_score": 2.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 9142,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Newsletter #2: ChaosGPT, Natural Selection, and AI Safety in the Media"
    },
    "921c7cd56081e4244c0b561cf53f40e5": {
      "source_id": "921c7cd56081e4244c0b561cf53f40e5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28624,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Guardian Version 1"
    },
    "e23c5a4f5d042b07d0d5f96183d78086": {
      "source_id": "e23c5a4f5d042b07d0d5f96183d78086",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8334,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Crosspost] Organizing a debate with experts and MPs to raise AI xrisk awareness"
    },
    "67334fb0a5812bbbb1eb30cddd66fc00": {
      "source_id": "67334fb0a5812bbbb1eb30cddd66fc00",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43664,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Approximation is expensive, but the lunch is cheap"
    },
    "74dc6306efa0c87006d86e3bdea2b7ee": {
      "source_id": "74dc6306efa0c87006d86e3bdea2b7ee",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3588,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Orthogonal: A new agent foundations alignment organization"
    },
    "c92259854c93f31bd1bdcc135f370c91": {
      "source_id": "c92259854c93f31bd1bdcc135f370c91",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3989,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is there any literature on using socialization for AI alignment?"
    },
    "cb1b55030f2303bf968c42dc09ad3cf0": {
      "source_id": "cb1b55030f2303bf968c42dc09ad3cf0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7869,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Responsible Deployment in 20XX"
    },
    "232111fc77b41e30a5855c73df367bff": {
      "source_id": "232111fc77b41e30a5855c73df367bff",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12844,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Alien Axiology"
    },
    "a839cd0be233ec5c074ab2f62f07c6a2": {
      "source_id": "a839cd0be233ec5c074ab2f62f07c6a2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 308,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Stability AI releases StableLM, an open-source ChatGPT counterpart"
    },
    "6bc3f8422ea83b1c1e543d2323370dc8": {
      "source_id": "6bc3f8422ea83b1c1e543d2323370dc8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16891,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Japan AI Alignment Conference Postmortem"
    },
    "18d35ba1d5179f228f00a04801d5daa8": {
      "source_id": "18d35ba1d5179f228f00a04801d5daa8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2971,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "OpenAI could help X-risk by wagering itself"
    },
    "9d4c632b4cf68cd2d94f25a80924e03d": {
      "source_id": "9d4c632b4cf68cd2d94f25a80924e03d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8617,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An open letter to SERI MATS program organisers"
    },
    "1d3e25bfd675304c7da76d20a5b976fd": {
      "source_id": "1d3e25bfd675304c7da76d20a5b976fd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14287,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Study 1b: This One Weird Trick does NOT cause incorrectness cascades"
    },
    "8afa8357e967b66b032c31ba8d199115": {
      "source_id": "8afa8357e967b66b032c31ba8d199115",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37647,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Ideas for studies on AGI risk"
    },
    "ad2d0dd9ac8b0531cfb3e72f1a2aa8ee": {
      "source_id": "ad2d0dd9ac8b0531cfb3e72f1a2aa8ee",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6706,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Proposal: Using Monte Carlo tree search instead of RLHF for alignment research"
    },
    "6ae79015db2cb59cf68d9e0ee6431480": {
      "source_id": "6ae79015db2cb59cf68d9e0ee6431480",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12814,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Notes on \"the hot mess theory of AI misalignment\""
    },
    "c050d00e08f818bc38371a6c0b03a2e5": {
      "source_id": "c050d00e08f818bc38371a6c0b03a2e5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11756,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Talking publicly about AI risk"
    },
    "546e8417a9c31325a8ec5980662f0d7d": {
      "source_id": "546e8417a9c31325a8ec5980662f0d7d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11994,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Security Mindset, S-Risk and Publishing Prosaic Alignment Research"
    },
    "7ea115bf50dc7620b3ecc17500152735": {
      "source_id": "7ea115bf50dc7620b3ecc17500152735",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8040,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "We Need To Know About Continual Learning"
    },
    "51f9e7f04b9bdb8071c31c336fd67e7c": {
      "source_id": "51f9e7f04b9bdb8071c31c336fd67e7c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7105,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "OpenAI's GPT-4 Safety Goals"
    },
    "bfd4c41bae0aef1c9b742a4fc1e083c6": {
      "source_id": "bfd4c41bae0aef1c9b742a4fc1e083c6",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1457,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A great talk for AI noobs (according to an AI noob)"
    },
    "7285be4131708e4545c319f7d1f9dc76": {
      "source_id": "7285be4131708e4545c319f7d1f9dc76",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36656,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Value Learning \u2013 Towards Resolving Confusion "
    },
    "30f0f4cbea36b55ceeb2f773fc9f1bf8": {
      "source_id": "30f0f4cbea36b55ceeb2f773fc9f1bf8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8255,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A response to Conjecture's CoEm proposal"
    },
    "57fbb565f9c8728f12c871bfd8ec2c30": {
      "source_id": "57fbb565f9c8728f12c871bfd8ec2c30",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3122,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A concise sum-up of the basic argument for AI doom"
    },
    "1ab1f00d590e365187e4b8d6c6ed0c7b": {
      "source_id": "1ab1f00d590e365187e4b8d6c6ed0c7b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11299,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": " Making Nanobots isn't a one-shot process, even for an artificial superintelliga"
    },
    "5c4aec0999a3814c7b3baae2a7e0bcf3": {
      "source_id": "5c4aec0999a3814c7b3baae2a7e0bcf3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4601,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "My Assessment of the Chinese AI Safety Community"
    },
    "1572695514b3cfa16513219567c935f9": {
      "source_id": "1572695514b3cfa16513219567c935f9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17814,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Paths to failure"
    },
    "2416f3acdfa00bfad02766d0150f783b": {
      "source_id": "2416f3acdfa00bfad02766d0150f783b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16558,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Notes on Potential Future AI Tax Policy"
    },
    "67b052fcddeb95f54e9329e254aa410f": {
      "source_id": "67b052fcddeb95f54e9329e254aa410f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5077,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Briefly how I've updated since ChatGPT"
    },
    "f9bb638a9cb9f16921a3904322abb402": {
      "source_id": "f9bb638a9cb9f16921a3904322abb402",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7948,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Reframing the burden of proof: Companies should prove that models are safe (rath"
    },
    "c5514440680264f3aaceafb93edc999b": {
      "source_id": "c5514440680264f3aaceafb93edc999b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19732,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Implementing a Transformer from scratch in PyTorch - a write-up on my experience"
    },
    "ffc2d7597e026636fb14fe42bca06c1d": {
      "source_id": "ffc2d7597e026636fb14fe42bca06c1d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22719,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Archetypal Transfer Learning: a Proposed Alignment Solution that solves the Inne"
    },
    "5803e4df8e335e246f522c6ba91e2fb3": {
      "source_id": "5803e4df8e335e246f522c6ba91e2fb3",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3921,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A simple presentation of AI risk arguments"
    },
    "0bc2a3c53c41446c592132e5dbdc9ef5": {
      "source_id": "0bc2a3c53c41446c592132e5dbdc9ef5",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8786,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "I was Wrong, Simulator Theory is Real"
    },
    "89d45a7704b7f8b59e528119eddd5e12": {
      "source_id": "89d45a7704b7f8b59e528119eddd5e12",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3483,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Chad Jones paper modeling AI and x-risk vs. growth"
    },
    "10ecf5a95ea5421ed534133c76a4ac41": {
      "source_id": "10ecf5a95ea5421ed534133c76a4ac41",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25687,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Infra-Bayesianism naturally leads to the monotonicity principle, and I think thi"
    },
    "4d43c87e32286f4ce54355b59bf30e77": {
      "source_id": "4d43c87e32286f4ce54355b59bf30e77",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5067,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "LM Situational Awareness, Evaluation Proposal: Violating Imitation"
    },
    "302bd1b4513ed87be1e2a1c40a548191": {
      "source_id": "302bd1b4513ed87be1e2a1c40a548191",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9483,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What are the limits of superintelligence?"
    },
    "d3fe5d2b04b2362dac241cd2cb7fa213": {
      "source_id": "d3fe5d2b04b2362dac241cd2cb7fa213",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15066,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Social Alignment Problem"
    },
    "5aab74b3dd4fcf91eaae91f9e8d525d6": {
      "source_id": "5aab74b3dd4fcf91eaae91f9e8d525d6",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 15892,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] Sam Altman's 2015 Blog Posts Machine Intelligence Parts 1 & 2"
    },
    "666994a5fd736bf1a5e2ad2f513c67b8": {
      "source_id": "666994a5fd736bf1a5e2ad2f513c67b8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10952,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "LLMs and computation complexity"
    },
    "0365798d2c36ab3c7ac0fce15fb632df": {
      "source_id": "0365798d2c36ab3c7ac0fce15fb632df",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10476,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[SEE EDIT] No, *You* Need to Write Clearer"
    },
    "5d109f294c002b1a476c268bb4f10e84": {
      "source_id": "5d109f294c002b1a476c268bb4f10e84",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11017,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A Guide to Forecasting AI Science Capabilities "
    },
    "c6cfb77b07a66f5252c040c3651910ed": {
      "source_id": "c6cfb77b07a66f5252c040c3651910ed",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 943,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Accuracy of arguments that are seen as ridiculous and intuitively false but don'"
    },
    "29c220f07a6ae653f3ae7f95b4144af6": {
      "source_id": "29c220f07a6ae653f3ae7f95b4144af6",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3600,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Call for submissions: Choice of Futures survey questions"
    },
    "ac4d6ff77e8304da68af0fe45ae5a0cb": {
      "source_id": "ac4d6ff77e8304da68af0fe45ae5a0cb",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9624,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Simulators Increase the Likelihood of Alignment by Default"
    },
    "802b446082604d23067abf846a76c252": {
      "source_id": "802b446082604d23067abf846a76c252",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17461,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Fundamental Uncertainty: Chapter 7 - Why is truth useful?"
    },
    "0c30c920552075c2530da52313929990": {
      "source_id": "0c30c920552075c2530da52313929990",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16770,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Safety standards: a framework for AI regulation"
    },
    "3d0ac52800da7159d78fa3c2b0e36ce9": {
      "source_id": "3d0ac52800da7159d78fa3c2b0e36ce9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1713,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Does agency necessarily imply self-preservation instinct?"
    },
    "db378ec76505ec95eaf175361be60e83": {
      "source_id": "db378ec76505ec95eaf175361be60e83",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31738,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What 2025 looks like"
    },
    "37d3e8fde5c487e294241587175b93ac": {
      "source_id": "37d3e8fde5c487e294241587175b93ac",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12300,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Some Thoughts on Virtue Ethics for AIs"
    },
    "f86cab2dd8b06531ce0c8a796d72ef5d": {
      "source_id": "f86cab2dd8b06531ce0c8a796d72ef5d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 15155,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Newsletter #4: AI and Cybersecurity, Persuasive AIs, Weaponization, an"
    },
    "27e500dce6cd744f0828d2d491e0d0c7": {
      "source_id": "27e500dce6cd744f0828d2d491e0d0c7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8023,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Formalizing the \"AI x-risk is unlikely because it is ridiculous\" argument"
    },
    "8647bad1c0637860fcc6f567ae364aa6": {
      "source_id": "8647bad1c0637860fcc6f567ae364aa6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37791,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\u00abBoundaries/Membranes\u00bb and AI safety compilation"
    },
    "7b786eb057f27c79c0aeb1fbdb7a7edc": {
      "source_id": "7b786eb057f27c79c0aeb1fbdb7a7edc",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6620,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How MATS addresses \u201cmass movement building\u201d concerns"
    },
    "408cbe73fee4777c69985b42ffe1757c": {
      "source_id": "408cbe73fee4777c69985b42ffe1757c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2223,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Has the Symbol Grounding Problem just gone away?"
    },
    "f32b1e705bb384d4f7238c5268cf1eda": {
      "source_id": "f32b1e705bb384d4f7238c5268cf1eda",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10139,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "We don\u2019t need AGI for an amazing future"
    },
    "ff312e3b08b6e37a1d08be8c3f1ec2a5": {
      "source_id": "ff312e3b08b6e37a1d08be8c3f1ec2a5",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6888,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "White House Announces \"New Actions to Promote Responsible AI Innovation\""
    },
    "f4710b8d5741a9a9a274343bf38f1d1b": {
      "source_id": "f4710b8d5741a9a9a274343bf38f1d1b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6024,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why aren\u2019t more of us working to prevent AI hell?"
    },
    "e011da467a9d5993bf06ed910dc619b4": {
      "source_id": "e011da467a9d5993bf06ed910dc619b4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12464,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Trying to measure AI deception capabilities using temporary simulation fine-tuni"
    },
    "d2ccb97b4a2b0f72bc76320b82d0bd7b": {
      "source_id": "d2ccb97b4a2b0f72bc76320b82d0bd7b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4617,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Recursive Middle Manager Hell: AI Edition"
    },
    "299b7536371b523e7e99343ec53dc09a": {
      "source_id": "299b7536371b523e7e99343ec53dc09a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16339,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Transcript of a presentation on catastrophic risks from AI"
    },
    "73573c4e67237205593e8cafd53121ea": {
      "source_id": "73573c4e67237205593e8cafd53121ea",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8572,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Investigating Emergent Goal-Like Behavior in Large Language Models using Experim"
    },
    "74f58d935e59210b23dda32282dc95c0": {
      "source_id": "74f58d935e59210b23dda32282dc95c0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1481,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why not use active SETI to prevent AI Doom?"
    },
    "14f4b8b789340c03cb84467c84d9aa7a": {
      "source_id": "14f4b8b789340c03cb84467c84d9aa7a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33476,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Regulate or Compete? The China Factor in U.S. AI Policy (NAIR #2)"
    },
    "7be96b1610275359d3b4b639cb4e765b": {
      "source_id": "7be96b1610275359d3b4b639cb4e765b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16291,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "CHAT Diplomacy: LLMs and National Security"
    },
    "89fa0ae38471cbff21e435dd76560ba7": {
      "source_id": "89fa0ae38471cbff21e435dd76560ba7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17303,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A smart enough LLM might be deadly simply if you run it for long enough"
    },
    "314aed0e30f9b5d7b912e886be1319d8": {
      "source_id": "314aed0e30f9b5d7b912e886be1319d8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18018,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "My preferred framings for reward misspecification and goal misgeneralisation"
    },
    "d0942a2246e7b2ea726d4fbde70821f2": {
      "source_id": "d0942a2246e7b2ea726d4fbde70821f2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 43652,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Alignment as Function Fitting"
    },
    "a8c28cd4979e9abc4b393c440e0b8b57": {
      "source_id": "a8c28cd4979e9abc4b393c440e0b8b57",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5178,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is \"red\" for GPT-4 the same as \"red\" for you?"
    },
    "86971b198a3f0ea4c5d793191c6c8fcd": {
      "source_id": "86971b198a3f0ea4c5d793191c6c8fcd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46868,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How much do you believe your results?"
    },
    "591f5b12aa564c52bd6be5dd86874a64": {
      "source_id": "591f5b12aa564c52bd6be5dd86874a64",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32203,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Corrigibility, Much more detail than anyone wants to Read"
    },
    "de7669967f896e37a145e1623e260ae7": {
      "source_id": "de7669967f896e37a145e1623e260ae7",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3739,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Against sacrificing AI transparency for generality gains"
    },
    "9d4b864ec51a6f2efc05cfd56657cf1a": {
      "source_id": "9d4b864ec51a6f2efc05cfd56657cf1a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14713,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "LLM cognition is probably not human-like"
    },
    "86d25a217fe9b6f0b34f75cdab81b1b0": {
      "source_id": "86d25a217fe9b6f0b34f75cdab81b1b0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17780,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Annotated reply to Bengio's \"AI Scientists: Safe and Useful AI?\""
    },
    "cc29218e27ed042b8fdacc76eb0ebbbf": {
      "source_id": "cc29218e27ed042b8fdacc76eb0ebbbf",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5485,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "All AGI Safety questions welcome (especially basic ones) [May 2023]"
    },
    "3f2e1791288d6858f0cf3af1a575b02f": {
      "source_id": "3f2e1791288d6858f0cf3af1a575b02f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15340,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "H-JEPA might be technically alignable in a modified form"
    },
    "7baa597a6d59a025d68d71c787694d1b": {
      "source_id": "7baa597a6d59a025d68d71c787694d1b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14661,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Yoshua Bengio argues for tool-AI and to ban \"executive-AI\""
    },
    "f57c5633c242ee57f2be34754eb60e43": {
      "source_id": "f57c5633c242ee57f2be34754eb60e43",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 10920,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Newsletter #5: Geoffrey Hinton speaks out on AI risk, the White House "
    },
    "e2642a7732c5ffa81006b4a910602568": {
      "source_id": "e2642a7732c5ffa81006b4a910602568",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5133,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Stopping dangerous AI: Ideal lab behavior"
    },
    "4144b2ec0915ec033ee407fc2669da70": {
      "source_id": "4144b2ec0915ec033ee407fc2669da70",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5626,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Stopping dangerous AI: Ideal US behavior"
    },
    "4b2fccd75c2dbcf6e91ae2e1e100049b": {
      "source_id": "4b2fccd75c2dbcf6e91ae2e1e100049b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22164,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Research Report: Incorrectness Cascades (Corrected)"
    },
    "6ad7330b7e199f4669442cb51cb9dbac": {
      "source_id": "6ad7330b7e199f4669442cb51cb9dbac",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7625,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Gradient hacking via actual hacking"
    },
    "dd17e42de8ab7deb9126945f5e2418c2": {
      "source_id": "dd17e42de8ab7deb9126945f5e2418c2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14495,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AGI-Automated Interpretability is Suicide"
    },
    "4d69b46eaab0fe356ded4f6487915080": {
      "source_id": "4d69b46eaab0fe356ded4f6487915080",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26598,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Roadmap for a collaborative prototype of an Open Agency Architecture"
    },
    "60e4f158e2e1a9c07941c4dfadb1d071": {
      "source_id": "60e4f158e2e1a9c07941c4dfadb1d071",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2121,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Link] PaLM 2 Technical Report"
    },
    "06466148de2c2fd06932005944ce32f2": {
      "source_id": "06466148de2c2fd06932005944ce32f2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2314,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI interpretability could be harmful?"
    },
    "9ced2fa1b508a54701a9e16a9915bdbc": {
      "source_id": "9ced2fa1b508a54701a9e16a9915bdbc",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6901,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How should we think about the decision relevance of models estimating p(doom)? "
    },
    "4db21ed821bdad1850323fc3e7a5b73c": {
      "source_id": "4db21ed821bdad1850323fc3e7a5b73c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2446,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is Infra-Bayesianism Applicable to Value Learning?"
    },
    "70901768eac3fbdd471daa17bcaef121": {
      "source_id": "70901768eac3fbdd471daa17bcaef121",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8640,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Separating the \"control problem\" from the \"alignment problem\""
    },
    "f6d1bf2e9a984db7603bd0d1792c80b7": {
      "source_id": "f6d1bf2e9a984db7603bd0d1792c80b7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8169,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Notes on the importance and implementation of safety-first cognitive architectur"
    },
    "e868139fde19ab2a874e2344a40e213d": {
      "source_id": "e868139fde19ab2a874e2344a40e213d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28934,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Alignment, Goals, and The Gut-Head Gap: A Review of Ngo. et al."
    },
    "34a95ffbbd77f53eca85ff3d55a458d6": {
      "source_id": "34a95ffbbd77f53eca85ff3d55a458d6",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4084,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Formulating the AI Doom Argument for Analytic Philosophers"
    },
    "e34010a1c700a717b4615b906610ff4c": {
      "source_id": "e34010a1c700a717b4615b906610ff4c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8995,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "DELBERTing as an Adversarial Strategy"
    },
    "3f67d611b91983c30aea9791a7bcc345": {
      "source_id": "3f67d611b91983c30aea9791a7bcc345",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61804,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Aggregating Utilities for Corrigible AI [Feedback Draft] "
    },
    "24647dde763090e672eabca8713f1386": {
      "source_id": "24647dde763090e672eabca8713f1386",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9195,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Value drift threat models"
    },
    "15a67fa1e9fab52b30386674d7fa87bc": {
      "source_id": "15a67fa1e9fab52b30386674d7fa87bc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18396,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Notes on Antelligence"
    },
    "c06ad75382fee4cc5c14239c01de941e": {
      "source_id": "c06ad75382fee4cc5c14239c01de941e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19836,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "On the possibility of impossibility of AGI Long-Term Safety"
    },
    "7986eb7147b789414218a5e1a75bf59b": {
      "source_id": "7986eb7147b789414218a5e1a75bf59b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2503,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "PCAST Working Group on Generative AI Invites Public\u00a0Input"
    },
    "aef2376fd0955139dc9182d62c2f5eb2": {
      "source_id": "aef2376fd0955139dc9182d62c2f5eb2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4499,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "LLM Guardrails Should Have Better Customer Service Tuning"
    },
    "250aa96c5ef5d5da64a07f747758fb4a": {
      "source_id": "250aa96c5ef5d5da64a07f747758fb4a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50804,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A Study of AI Science Models"
    },
    "d3ee233b06c7148c8ea5437239aadd6a": {
      "source_id": "d3ee233b06c7148c8ea5437239aadd6a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5435,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Simpler explanations of AGI risk"
    },
    "0628587ce0b0569b2a97d27324211410": {
      "source_id": "0628587ce0b0569b2a97d27324211410",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18063,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Coordination by common knowledge to prevent uncontrollable AI"
    },
    "47a4475cacd9aafa5ed29f947836e811": {
      "source_id": "47a4475cacd9aafa5ed29f947836e811",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1687,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "GovAI: Towards best practices in AGI safety and governance: A survey of expert o"
    },
    "e27d40498d1983555d1b9346456cc1a8": {
      "source_id": "e27d40498d1983555d1b9346456cc1a8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2590,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Can we learn much by studying the behaviour of RL policies?"
    },
    "6495bddae7fe6dfd143cb361e01c2ecb": {
      "source_id": "6495bddae7fe6dfd143cb361e01c2ecb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24703,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Un-unpluggability - can't we just unplug it?"
    },
    "1a2cf3a90dd28264c8d7d7dc6c3967a4": {
      "source_id": "1a2cf3a90dd28264c8d7d7dc6c3967a4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26188,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Evaluating Language Model Behaviours for Shutdown Avoidance in Textual Scenarios"
    },
    "391b86da9e646ff7103f49a6deb9253a": {
      "source_id": "391b86da9e646ff7103f49a6deb9253a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2983,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Tyler Cowen's challenge to develop an 'actual mathematical model' for AI X-Risk"
    },
    "e5c0c9e3e38ae50e1c33ef5d3004ecb2": {
      "source_id": "e5c0c9e3e38ae50e1c33ef5d3004ecb2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 15206,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Newsletter #6: Examples of AI safety progress, Yoshua Bengio proposes "
    },
    "33fa91805ce34ee8367593ff236a4e44": {
      "source_id": "33fa91805ce34ee8367593ff236a4e44",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4809,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Proposal: we should start referring to the risk from unaligned AI as a type of *"
    },
    "bf14107f5eef79cac4c38038610eaad5": {
      "source_id": "bf14107f5eef79cac4c38038610eaad5",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9182,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Decision Theory with the Magic Parts Highlighted"
    },
    "2039c93830cd8fc7f9a985d59985a982": {
      "source_id": "2039c93830cd8fc7f9a985d59985a982",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19586,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Risk & Policy Forecasts from Metaculus & FLI's AI Pathways Workshop"
    },
    "f7394254e9fbc61e42f74d48b3aee69d": {
      "source_id": "f7394254e9fbc61e42f74d48b3aee69d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3511,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Brief notes on the Senate hearing on AI oversight"
    },
    "0cc6b13c16847b80862e227e7075c170": {
      "source_id": "0cc6b13c16847b80862e227e7075c170",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33531,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A Mechanistic Interpretability Analysis of a GridWorld Agent-Simulator (Part 1 o"
    },
    "0597e2de64cf9b45376a04fc0bdda517": {
      "source_id": "0597e2de64cf9b45376a04fc0bdda517",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53342,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Are AIs like Animals? Perspectives and Strategies from Biology"
    },
    "72099014cd27b76147eb836d83cb4798": {
      "source_id": "72099014cd27b76147eb836d83cb4798",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22493,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "GPT-4 implicitly values identity preservation: a study of LMCA identity manageme"
    },
    "4a65e2e28d493823629fdfbbdde33ba2": {
      "source_id": "4a65e2e28d493823629fdfbbdde33ba2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27086,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Creating a self-referential system prompt for GPT-4"
    },
    "159c2670b6d6b760cb32f12d6f6c2cf1": {
      "source_id": "159c2670b6d6b760cb32f12d6f6c2cf1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19807,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Eisenhower's Atoms for Peace Speech"
    },
    "5c4775329ca3a9c1306909df38eac0b1": {
      "source_id": "5c4775329ca3a9c1306909df38eac0b1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28810,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "ACI #3: The Origin of Goals and Utility"
    },
    "c7c0f316d400925dcdd312e4b6953c63": {
      "source_id": "c7c0f316d400925dcdd312e4b6953c63",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 50247,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Crosspost] A recent write-up of the case for AI (existential) risk"
    },
    "b86b7981d7bc22b96d0c927a5625f3cd": {
      "source_id": "b86b7981d7bc22b96d0c927a5625f3cd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 129845,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI #12:The Quest for Sane Regulations"
    },
    "6f15ea4f1d96ad10dd0ec06a10c59a17": {
      "source_id": "6f15ea4f1d96ad10dd0ec06a10c59a17",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14387,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "We Shouldn't Expect AI to Ever be Fully Rational"
    },
    "b19fe89a4b38d29f524e91a434efac5f": {
      "source_id": "b19fe89a4b38d29f524e91a434efac5f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11364,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Microsoft and Google using LLMs for Cybersecurity"
    },
    "51b21e6d750513216c777c24a3b5f03b": {
      "source_id": "51b21e6d750513216c777c24a3b5f03b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45448,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Compleat Cybornaut"
    },
    "27f6ee13676202b8e5fef85a2c48aac1": {
      "source_id": "27f6ee13676202b8e5fef85a2c48aac1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5721,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Confusions and updates on STEM AI"
    },
    "44f4ec61596743abdfb9d1c954f7ed95": {
      "source_id": "44f4ec61596743abdfb9d1c954f7ed95",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32159,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Distillation of Neurotech and Alignment Workshop January 2023"
    },
    "a243246dec1ba0d710a522055ce331b9": {
      "source_id": "a243246dec1ba0d710a522055ce331b9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3856,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety in China: Part 2"
    },
    "f6ee6193dbf2b354b788e756806cfa14": {
      "source_id": "f6ee6193dbf2b354b788e756806cfa14",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15945,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why I Believe LLMs Do Not Have Human-like Emotions"
    },
    "2990f0d6b3661ed1bd8481ab3785a19f": {
      "source_id": "2990f0d6b3661ed1bd8481ab3785a19f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17634,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI self-improvement is possible"
    },
    "599291c5bde7b47aeee7b503272be29b": {
      "source_id": "599291c5bde7b47aeee7b503272be29b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39204,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How I learned to stop worrying and love skill trees"
    },
    "804c3e6a5de78990c31b9be0cdc33db3": {
      "source_id": "804c3e6a5de78990c31b9be0cdc33db3",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 2417,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] The AGI Show podcast"
    },
    "1951b53ad18741f57b3b4c90edc166c4": {
      "source_id": "1951b53ad18741f57b3b4c90edc166c4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 121642,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "GPT4 is capable of writing decent long-form science fiction (with the right prom"
    },
    "eb7e37e4d0fcf3a9cc070c6b5cad84be": {
      "source_id": "eb7e37e4d0fcf3a9cc070c6b5cad84be",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45610,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Will Artificial Superintelligence Kill Us?"
    },
    "5db84f9f0cc5c6aca7c86131fe6c1435": {
      "source_id": "5db84f9f0cc5c6aca7c86131fe6c1435",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4794,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is \"brittle alignment\" good enough?"
    },
    "9708ae4fa328b35106410b914ba75406": {
      "source_id": "9708ae4fa328b35106410b914ba75406",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34533,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": " Yoshua Bengio: How Rogue AIs may Arise"
    },
    "767ee618531806222c31a43e2e66f036": {
      "source_id": "767ee618531806222c31a43e2e66f036",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 16915,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Newsletter #7: Disinformation, Governance Recommendations for AI labs,"
    },
    "e1d432c86b03dd0e2b6c0b0089950641": {
      "source_id": "e1d432c86b03dd0e2b6c0b0089950641",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14387,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "My May 2023 priorities for AI x-safety: more empathy, more unification of concer"
    },
    "281addc9c402df4fdc63d3acf02d3c9e": {
      "source_id": "281addc9c402df4fdc63d3acf02d3c9e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 538,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What projects and efforts are there to promote AI safety research?"
    },
    "7cb45031550d3ddb28ee8387a60da2f0": {
      "source_id": "7cb45031550d3ddb28ee8387a60da2f0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1117,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Rishi Sunak mentions \"existential threats\" in talk with OpenAI, DeepMind, Anthro"
    },
    "2cdbccface049d7bd68143e0a5fa5c33": {
      "source_id": "2cdbccface049d7bd68143e0a5fa5c33",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25031,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Two ideas for alignment, perpetual mutual distrust and induction"
    },
    "5612e7421a4d8a7d3191ba7ccd1cdc5a": {
      "source_id": "5612e7421a4d8a7d3191ba7ccd1cdc5a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2068,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "DeepMind: Model evaluation for extreme risks"
    },
    "77a9d452a6fe1782edd25fe3f7c0bc50": {
      "source_id": "77a9d452a6fe1782edd25fe3f7c0bc50",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46994,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Requirements for a STEM-capable AGI Value Learner (my Case for Less Doom)"
    },
    "c9f2ee5b872e921a2694ec1dec038510": {
      "source_id": "c9f2ee5b872e921a2694ec1dec038510",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14815,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Evaluating strategic reasoning in GPT models"
    },
    "12263cde39c0b70a3945112ed0d56f92": {
      "source_id": "12263cde39c0b70a3945112ed0d56f92",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45328,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Genie in the Bottle: An Introduction to AI Alignment and Risk "
    },
    "279b9a0262b65bea9b03bb49545e944d": {
      "source_id": "279b9a0262b65bea9b03bb49545e944d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7453,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "RecurrentGPT: a loom-type tool with a twist"
    },
    "0113f60c0c133a845bd050c909862e64": {
      "source_id": "0113f60c0c133a845bd050c909862e64",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4129,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is behavioral safety \"solved\" in non-adversarial conditions?"
    },
    "c0f3700264afa803d14d80e1aa929d41": {
      "source_id": "c0f3700264afa803d14d80e1aa929d41",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2564,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "how humans are aligned"
    },
    "d21dc8263127eb68963bf0fc156caa64": {
      "source_id": "d21dc8263127eb68963bf0fc156caa64",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 727,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What's your viewpoint on the likelihood of GPT-5 being able to autonomously crea"
    },
    "6d1a4ec7fd9e294be06c3fe9ad5a6f18": {
      "source_id": "6d1a4ec7fd9e294be06c3fe9ad5a6f18",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1708,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Request: stop advancing AI capabilities"
    },
    "b4c09b49858d660e0a2a19cf0d06187c": {
      "source_id": "b4c09b49858d660e0a2a19cf0d06187c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2571,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Project Idea: Challenge Groups for Alignment Researchers"
    },
    "2f6c8f9c4c19891af5e16adbade54c09": {
      "source_id": "2f6c8f9c4c19891af5e16adbade54c09",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19093,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why and When Interpretability Work is Dangerous"
    },
    "d7c59ab859c83051bf0e12bcf1d8057e": {
      "source_id": "d7c59ab859c83051bf0e12bcf1d8057e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15086,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "My AI Alignment Research Agenda and Threat Model, right now (May 2023)"
    },
    "02edb7368f5920281a977502ac0b3cff": {
      "source_id": "02edb7368f5920281a977502ac0b3cff",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1938,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Devil's Advocate: Adverse Selection Against Conscientiousness "
    },
    "d741ad6bc45835cc6202b292073f7263": {
      "source_id": "d741ad6bc45835cc6202b292073f7263",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11101,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Proposed Alignment Technique: OSNR (Output Sanitization via Noising and Reconstr"
    },
    "da3473f14c2f0689694d9f69e104e8a9": {
      "source_id": "da3473f14c2f0689694d9f69e104e8a9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11059,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Minimum Viable Exterminator"
    },
    "08b595c071be736ac9741e9e5349053c": {
      "source_id": "08b595c071be736ac9741e9e5349053c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 789,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What are some of the best introductions/breakdowns of AI existential risk for th"
    },
    "a7f7f931d09a25da6f52b48a73a45484": {
      "source_id": "a7f7f931d09a25da6f52b48a73a45484",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5650,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Winners-take-how-much?"
    },
    "651415c67cbad2b0dee0d0f1196df5d8": {
      "source_id": "651415c67cbad2b0dee0d0f1196df5d8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 35028,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Without a trajectory change, the development of AGI is likely to go badly"
    },
    "eaed540e3c6784af09fb09dc0695c242": {
      "source_id": "eaed540e3c6784af09fb09dc0695c242",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29357,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Lesswrong can, and should, become a hacker community"
    },
    "e501da55b08387093f024f4ad7dfe3a1": {
      "source_id": "e501da55b08387093f024f4ad7dfe3a1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9145,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Advice for new alignment people: Info Max"
    },
    "9a0b3466dd625415a0456dabb0936910": {
      "source_id": "9a0b3466dd625415a0456dabb0936910",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7802,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "My current research questions for \u00abmembranes/boundaries\u00bb"
    },
    "af51456605a608d1a9528f8b6cf00503": {
      "source_id": "af51456605a608d1a9528f8b6cf00503",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3671,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI X-risk is a possible solution to the Fermi Paradox"
    },
    "01d5479e4838f7eb8049ef74d1a73be3": {
      "source_id": "01d5479e4838f7eb8049ef74d1a73be3",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8829,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The case for removing alignment and ML research from the training dataset"
    },
    "500d6cd517b9f32e4da73de6410c8773": {
      "source_id": "500d6cd517b9f32e4da73de6410c8773",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11468,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Abstraction is Bigger than Natural Abstraction"
    },
    "7b3ed3bc9b14ba7226c9b86faa54e6b7": {
      "source_id": "7b3ed3bc9b14ba7226c9b86faa54e6b7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7399,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An Analysis of the \u2018Digital Gaia\u2019 Proposal from a Safety Perspective"
    },
    "d066b79b395af4df5329128975a6d650": {
      "source_id": "d066b79b395af4df5329128975a6d650",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 758,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "My AI-risk cartoon"
    },
    "168a212fb3345b1af163f5b630f18e59": {
      "source_id": "168a212fb3345b1af163f5b630f18e59",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40156,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Intent-aligned AI systems deplete human agency: the need for agency foundations "
    },
    "2f9dc7784eecba51af47d248ded2bd46": {
      "source_id": "2f9dc7784eecba51af47d248ded2bd46",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58757,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Unpredictability and the Increasing Difficulty of AI Alignment for Increasingly "
    },
    "36e630fda6d23bf92a1ae7eae8f908a0": {
      "source_id": "36e630fda6d23bf92a1ae7eae8f908a0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12237,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Limiting factors to predict AI take-off speed"
    },
    "2f658cf81f6e57ec838203e13463a492": {
      "source_id": "2f658cf81f6e57ec838203e13463a492",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6327,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Intrinsic vs. Extrinsic Alignment"
    },
    "0921c3ff4864880637ca10613c8310d9": {
      "source_id": "0921c3ff4864880637ca10613c8310d9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10238,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An explanation of decision theories"
    },
    "f6ab92d0ed21bc93940f941b892600ca": {
      "source_id": "f6ab92d0ed21bc93940f941b892600ca",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13460,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\"LLMs Don't Have a Coherent Model of the World\" - What it Means, Why it Matters "
    },
    "e293e8d2ee7f6f8b119d97b15209099b": {
      "source_id": "e293e8d2ee7f6f8b119d97b15209099b",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8993,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How will they feed us"
    },
    "32c41e42a34970baa7c247793695ea0f": {
      "source_id": "32c41e42a34970baa7c247793695ea0f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11562,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Yes, avoiding extinction from AI *is* an urgent priority: a response to Seth Laz"
    },
    "72b1bd8da61a477513bddca0d2c5d1be": {
      "source_id": "72b1bd8da61a477513bddca0d2c5d1be",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8906,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Four levels of understanding decision theory"
    },
    "81ed083ff51b3264194b2575efee2d0c": {
      "source_id": "81ed083ff51b3264194b2575efee2d0c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7457,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Open Source LLMs Can Now Actively Lie "
    },
    "5284171f4c57a822a8a9005198078f23": {
      "source_id": "5284171f4c57a822a8a9005198078f23",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 134859,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Outreach success: Intro to AI risk that has been successful"
    },
    "2658c06a80d94cddeb1efdd86c360a76": {
      "source_id": "2658c06a80d94cddeb1efdd86c360a76",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41904,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Control Problem: Unsolved or Unsolvable?"
    },
    "051cfbef143178d6ec5c1aaf2acfa2dd": {
      "source_id": "051cfbef143178d6ec5c1aaf2acfa2dd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12714,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Co-found an incubator for independent AI Safety researchers (rolling application"
    },
    "6b7b58ed85cb22bc5f3abc88c606ed58": {
      "source_id": "6b7b58ed85cb22bc5f3abc88c606ed58",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10371,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Advice for Entering AI Safety Research"
    },
    "438a3b4d9189d77b44b72fcca4b363ca": {
      "source_id": "438a3b4d9189d77b44b72fcca4b363ca",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46040,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Inference from a Mathematical Description of an Existing Alignment Research: a p"
    },
    "98bd0d5bac8a52a6fef43bee1df7cb7f": {
      "source_id": "98bd0d5bac8a52a6fef43bee1df7cb7f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7358,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Proposal: labs should precommit to pausing if an AI argues for itself to be impr"
    },
    "bf065719cc28ca5e51eb66642836ce95": {
      "source_id": "bf065719cc28ca5e51eb66642836ce95",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20353,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The AGI Race Between the US and China Doesn\u2019t Exist."
    },
    "b72fe26074a148fab7b80da5d38fabbc": {
      "source_id": "b72fe26074a148fab7b80da5d38fabbc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 661,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Terry Tao is hosting an \"AI to Assist Mathematical Reasoning\" workshop"
    },
    "d86aa5f2716c6beb9a93e143889a71d6": {
      "source_id": "d86aa5f2716c6beb9a93e143889a71d6",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1014,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A Double-Feature on The Extropians"
    },
    "ec3c035aeceb6c8e5a139a6de002c78d": {
      "source_id": "ec3c035aeceb6c8e5a139a6de002c78d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27184,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Optimization happens inside the mind, not in the world"
    },
    "1152848d12227009f8dd11001c9b3583": {
      "source_id": "1152848d12227009f8dd11001c9b3583",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1206,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": " AI Safety Fundamentals: An Informal Cohort Starting Soon!"
    },
    "5c358ad0768b1267e63e0ed338feb04e": {
      "source_id": "5c358ad0768b1267e63e0ed338feb04e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10998,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "One implementation of regulatory GPU restrictions"
    },
    "5c5679df7dd7400343d28dcbe4b64935": {
      "source_id": "5c5679df7dd7400343d28dcbe4b64935",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13371,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Nature < Nurture for AIs"
    },
    "94e6dc29aba6e416a57e95c224950e9a": {
      "source_id": "94e6dc29aba6e416a57e95c224950e9a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9232,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Tutor-GPT & Pedagogical Reasoning"
    },
    "0025d72749d6a98638ecca82b567492e": {
      "source_id": "0025d72749d6a98638ecca82b567492e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11217,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The (local) unit of intelligence is FLOPs"
    },
    "e61c4fbd7dabbdc784302208ce3def38": {
      "source_id": "e61c4fbd7dabbdc784302208ce3def38",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3731,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISafety.info \"How can I help?\" FAQ"
    },
    "f50ab36adc8f0cf593cdcb92460022a0": {
      "source_id": "f50ab36adc8f0cf593cdcb92460022a0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2255,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Sharp Right Turn: sudden deceptive alignment as a convergent goal"
    },
    "0e16bddf1917990e6a4ab890e3c59618": {
      "source_id": "0e16bddf1917990e6a4ab890e3c59618",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25579,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Agentic Mess (A Failure Story)"
    },
    "23de221fbe5145ab878419991dd6f773": {
      "source_id": "23de221fbe5145ab878419991dd6f773",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10625,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Transformative AGI by 2043 is <1% likely"
    },
    "e7c451e7308a4151650e09b72df493d1": {
      "source_id": "e7c451e7308a4151650e09b72df493d1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28124,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A moral backlash against AI will probably slow down AGI development"
    },
    "c028d59f94a33847c4838efbaad94929": {
      "source_id": "c028d59f94a33847c4838efbaad94929",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8691,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Transformative AI is a process "
    },
    "82f68f78113fe1107e7a223b50a70767": {
      "source_id": "82f68f78113fe1107e7a223b50a70767",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5055,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A potentially high impact differential technological development area"
    },
    "ea116f9a0ef3a34f7f2890884656c07a": {
      "source_id": "ea116f9a0ef3a34f7f2890884656c07a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 42919,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Improvement on MIRI's Corrigibility"
    },
    "cf40c7ee3c818537fc6d9b55cb4a5f37": {
      "source_id": "cf40c7ee3c818537fc6d9b55cb4a5f37",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13609,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A plea for solutionism on AI safety"
    },
    "67b9e149dc135c8bb4eeab7da8ad80fb": {
      "source_id": "67b9e149dc135c8bb4eeab7da8ad80fb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11141,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Using Consensus Mechanisms as an approach to Alignment"
    },
    "a7a9da9d76918e3078182454b0867e6b": {
      "source_id": "a7a9da9d76918e3078182454b0867e6b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28824,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Higher Dimension Cartesian Objects and Aligning \u2018Tiling Simulators\u2019"
    },
    "d9f66f94eef983d0920201dc55f19a99": {
      "source_id": "d9f66f94eef983d0920201dc55f19a99",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 84086,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Critiques of prominent AI safety labs: Conjecture"
    },
    "f8c77b4d3686012b031ce8af8d675cc2": {
      "source_id": "f8c77b4d3686012b031ce8af8d675cc2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23671,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Manifold Predicted the AI Extinction Statement and CAIS Wanted it Deleted"
    },
    "964a747af0597881fa7ff889e719cd68": {
      "source_id": "964a747af0597881fa7ff889e719cd68",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11094,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Introducing The Long Game Project: Improving Decision-Making Through Tabletop Ex"
    },
    "490068689682540b6e4d4e2d7d82f186": {
      "source_id": "490068689682540b6e4d4e2d7d82f186",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6894,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Anthropic | Charting a Path to AI Accountability"
    },
    "c8e2855c7ab73980c3d6aa76b98484ca": {
      "source_id": "c8e2855c7ab73980c3d6aa76b98484ca",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39907,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Philosophical Cyborg (Part 1)"
    },
    "eb1001b0ae4e6bf9ca5316464be638ae": {
      "source_id": "eb1001b0ae4e6bf9ca5316464be638ae",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8400,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why libertarians are advocating for regulation on AI"
    },
    "f25adb191b1f5e8fab922c0ac48342d4": {
      "source_id": "f25adb191b1f5e8fab922c0ac48342d4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2910,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why \"AI alignment\" would better be renamed into \"Artificial Intention research\""
    },
    "609e3e1302d9122979393ea791ba123f": {
      "source_id": "609e3e1302d9122979393ea791ba123f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4565,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Aligned Objectives Prize Competition"
    },
    "83b65b48db7c56696fe48d458eee9544": {
      "source_id": "83b65b48db7c56696fe48d458eee9544",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4111,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "human intelligence may be alignment-limited"
    },
    "fe191181ec682dcc46249199b9e76bad": {
      "source_id": "fe191181ec682dcc46249199b9e76bad",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 893,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Does anyone's full-time job include reading and understanding all the most-promi"
    },
    "d6c303b0a5135edebd640369dfc3a5d8": {
      "source_id": "d6c303b0a5135edebd640369dfc3a5d8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3897,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Conjecture: A standing offer for public debates on AI"
    },
    "f0c5feba33b550e253a5624f3b06b023": {
      "source_id": "f0c5feba33b550e253a5624f3b06b023",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31792,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The AI governance gaps in developing countries"
    },
    "a59433662125490dcdfc09e6564654f4": {
      "source_id": "a59433662125490dcdfc09e6564654f4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32108,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Partial Simulation Extrapolation: A Proposal for Building Safer Simulators"
    },
    "d5743d0c4008aeecbd2bfa0b709df81f": {
      "source_id": "d5743d0c4008aeecbd2bfa0b709df81f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29464,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A summary of current work in AI governance"
    },
    "ec9dfb49613ec4f156423b0861c628d9": {
      "source_id": "ec9dfb49613ec4f156423b0861c628d9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23230,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A Multidisciplinary Approach to Alignment (MATA) and Archetypal Transfer Learnin"
    },
    "89500cc7adf4113b0e9e80d9bacf989f": {
      "source_id": "89500cc7adf4113b0e9e80d9bacf989f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9301,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "OpenAI introduces function calling for GPT-4"
    },
    "ea069fade2ffa655b14c47ededb70b5d": {
      "source_id": "ea069fade2ffa655b14c47ededb70b5d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18266,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Corrigibility test #1: Shutdown activations in a Virus Research Lab"
    },
    "afefbee1774a2d0a378e47d9d2fea635": {
      "source_id": "afefbee1774a2d0a378e47d9d2fea635",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31396,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A Friendly Face (Another Failure Story)"
    },
    "b12c79cb112e968630b7f0c62f7ad121": {
      "source_id": "b12c79cb112e968630b7f0c62f7ad121",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3561,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Lightning Post: Things people in AI Safety should stop talking about"
    },
    "9f8197a788e11408caee3e299b57b6d5": {
      "source_id": "9f8197a788e11408caee3e299b57b6d5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24032,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A way to make solving alignment 10.000 times easier. The shorter case for a mass"
    },
    "ab9fa9456bf92a8b44b472593912b313": {
      "source_id": "ab9fa9456bf92a8b44b472593912b313",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 67808,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Philosophical Cyborg (Part 2)...or, The Good Successor"
    },
    "649133d17cf556520d9b4fbdc78cf882": {
      "source_id": "649133d17cf556520d9b4fbdc78cf882",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2223,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "EU AI Act passed Plenary vote, and X-risk was a main topic  "
    },
    "c20a9555f741cf597c92abed6aaa9b4d": {
      "source_id": "c20a9555f741cf597c92abed6aaa9b4d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7772,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Using Claude to convert dialog transcripts into great posts?"
    },
    "ee12a63bb99b680e3ddce75ba31a1f86": {
      "source_id": "ee12a63bb99b680e3ddce75ba31a1f86",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10119,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Catastrophic Risks from AI #1: Introduction"
    },
    "db2809fe5b746990835dbfce5f66cb55": {
      "source_id": "db2809fe5b746990835dbfce5f66cb55",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10811,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Slaying the Hydra: toward a new game board for AI"
    },
    "b77727383f1027b7cffccfd273919762": {
      "source_id": "b77727383f1027b7cffccfd273919762",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10421,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Democratic AI Constitution: Round-Robin Debate and Synthesis"
    },
    "bf0056986187e968080490d8044e5dea": {
      "source_id": "bf0056986187e968080490d8044e5dea",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7663,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI-Plans.com - a contributable compendium"
    },
    "0b50ce16a78021c390a019318be2b86d": {
      "source_id": "0b50ce16a78021c390a019318be2b86d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11219,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Did Bengio and Tegmark lose a debate about AI x-risk against LeCun and Mitchell?"
    },
    "0dda3c617ae3bcce54437a10a3a6308a": {
      "source_id": "0dda3c617ae3bcce54437a10a3a6308a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3240,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\"Safety Culture for AI\" is important, but isn't going to be easy"
    },
    "489607f596d9e96dd4f037fd7204b7f9": {
      "source_id": "489607f596d9e96dd4f037fd7204b7f9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5542,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Deceptive AI vs. shifting instrumental incentives"
    },
    "cdaaff2249d15c0912e58a89b1804aff": {
      "source_id": "cdaaff2249d15c0912e58a89b1804aff",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49740,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISC team report: Soft-optimization, Bayes and Goodhart"
    },
    "1bed891b4ea7221ac03d79a9275b43ad": {
      "source_id": "1bed891b4ea7221ac03d79a9275b43ad",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2288,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An overview of the points system"
    },
    "74a682dc0dbc2cc67ef4936919f2add0": {
      "source_id": "74a682dc0dbc2cc67ef4936919f2add0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3413,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Brief summary of ai-plans.com"
    },
    "8955e054c7760981d2197e7c8ddcc9aa": {
      "source_id": "8955e054c7760981d2197e7c8ddcc9aa",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10804,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Incident Sharing - Best practices from other fields and a comprehensive list "
    },
    "f5eaf9e4da0d4f9d7e93ef3772a21d3f": {
      "source_id": "f5eaf9e4da0d4f9d7e93ef3772a21d3f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22593,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "My research agenda in agent foundations"
    },
    "0ccbf17a1c885c2637412061b8c4c7af": {
      "source_id": "0ccbf17a1c885c2637412061b8c4c7af",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1112,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "LeCun says making a utility function is intractable"
    },
    "8e1f047808589e405c818c1037acf346": {
      "source_id": "8e1f047808589e405c818c1037acf346",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4784,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Levels of safety for AI and other technologies"
    },
    "80ecf858aa52b9c58b6aa9e776a9ccad": {
      "source_id": "80ecf858aa52b9c58b6aa9e776a9ccad",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8163,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A \"weak\" AGI may attempt an unlikely-to-succeed takeover"
    },
    "982706b82ad19d96f08216453f9084e9": {
      "source_id": "982706b82ad19d96f08216453f9084e9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26722,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Metaphors for AI, and why I don\u2019t like them"
    },
    "9429b1e75c5bb7b41cb7ba473b5634f4": {
      "source_id": "9429b1e75c5bb7b41cb7ba473b5634f4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11573,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "One path to coherence: conditionalization "
    },
    "007c527320deb9a654510f5ef86388e3": {
      "source_id": "007c527320deb9a654510f5ef86388e3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21566,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Anthropically Blind: the anthropic shadow is reflectively inconsistent"
    },
    "79549578e5dfe3bf0e3e50b3ff87cdc5": {
      "source_id": "79549578e5dfe3bf0e3e50b3ff87cdc5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18656,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Cheat sheet of AI X-risk"
    },
    "5db03a31d730baef9b09cc7e8516b709": {
      "source_id": "5db03a31d730baef9b09cc7e8516b709",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4311,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Challenge proposal: smallest possible self-hardening backdoor for RLHF"
    },
    "0c44014de8f09e8185f1898bb2635b47": {
      "source_id": "0c44014de8f09e8185f1898bb2635b47",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3151,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety without Alignment: How humans can WIN against AI"
    },
    "0b83ece5b988f5a5fa2e4d17fa725a46": {
      "source_id": "0b83ece5b988f5a5fa2e4d17fa725a46",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9155,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Biosafety Regulations (BMBL) and their relevance for AI"
    },
    "c71a3543e15abb8d7051c29a721b1f58": {
      "source_id": "c71a3543e15abb8d7051c29a721b1f58",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1752,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "I Think Eliezer Should Go on Glenn Beck"
    },
    "32278e478fa0819bd1f877ca7f50ade9": {
      "source_id": "32278e478fa0819bd1f877ca7f50ade9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11123,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Foom Liability"
    },
    "b124ce0e8be14f54bea83b2708d66df8": {
      "source_id": "b124ce0e8be14f54bea83b2708d66df8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19383,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "George Hotz on AI safety: ~\"centralized  power is bad\""
    },
    "bbec607f6f6d854afcd5922fe2739f51": {
      "source_id": "bbec607f6f6d854afcd5922fe2739f51",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24361,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Introducing EffiSciences\u2019 AI Safety Unit\u00a0"
    },
    "3090b5fbc7db5eeecd7520dd25e59e9a": {
      "source_id": "3090b5fbc7db5eeecd7520dd25e59e9a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1286,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Little attention seems to be on discouraging hardware progress"
    },
    "03b4e5659f312a29ffb1c3bc34fd2ce1": {
      "source_id": "03b4e5659f312a29ffb1c3bc34fd2ce1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6261,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "On Agent Foundations"
    },
    "c48e9aff068c30aa660e440b8d480236": {
      "source_id": "c48e9aff068c30aa660e440b8d480236",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26055,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Positive Attractors"
    },
    "e12039b509d4db8840ec65cf5ee573fa": {
      "source_id": "e12039b509d4db8840ec65cf5ee573fa",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15677,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Inherently Interpretable Architectures"
    },
    "039e9fd1b37f73b4805e61371bd5e63e": {
      "source_id": "039e9fd1b37f73b4805e61371bd5e63e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3229,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Introduction"
    },
    "1c29fda91c1d59d7378577a023bd1405": {
      "source_id": "1c29fda91c1d59d7378577a023bd1405",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 1027,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] A shared linguistic space for transmitting our thoughts from brain to"
    },
    "411f855aa0ceafb4cdffab4ded519f6d": {
      "source_id": "411f855aa0ceafb4cdffab4ded519f6d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12491,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Douglas Hofstadter changes his mind on Deep Learning & AI risk (June 2023)?"
    },
    "465ef7590649124e1de2add1b08baa7a": {
      "source_id": "465ef7590649124e1de2add1b08baa7a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4549,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "My Alignment Timeline"
    },
    "078ba322d914de1e155d4410d38e5658": {
      "source_id": "078ba322d914de1e155d4410d38e5658",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5320,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "My Central Alignment Priority (2 July 2023)"
    },
    "29b4722957e30fe78dfe3d402e74f22d": {
      "source_id": "29b4722957e30fe78dfe3d402e74f22d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 76183,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI labs' statements on governance"
    },
    "9e53ed6cf00123f566024e379fd2debd": {
      "source_id": "9e53ed6cf00123f566024e379fd2debd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13610,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Ways I Expect AI Regulation To Increase Extinction Risk"
    },
    "5c9c0783cb4d770ef5c06428aafd46c4": {
      "source_id": "5c9c0783cb4d770ef5c06428aafd46c4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53788,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Exploring Functional Decision Theory  (FDT) and a modified version (ModFDT)"
    },
    "74907b99699397014dc7fff5a84adef8": {
      "source_id": "74907b99699397014dc7fff5a84adef8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25960,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "If you wish to make an apple pie, you must first become dictator of the universe"
    },
    "acc85782cca8f5223c79cd8fa53ecb8d": {
      "source_id": "acc85782cca8f5223c79cd8fa53ecb8d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73315,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Infra-Bayesian Logic"
    },
    "f7dc22f839fa09459ed3099722854b15": {
      "source_id": "f7dc22f839fa09459ed3099722854b15",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26179,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Empirical Evidence Against \"The Longest Training Run\""
    },
    "28abec1b34ebae1cd2752d9855048925": {
      "source_id": "28abec1b34ebae1cd2752d9855048925",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25647,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Views on when AGI comes and on strategy to reduce existential risk "
    },
    "6d00492003a846c85a60c4fd87473a73": {
      "source_id": "6d00492003a846c85a60c4fd87473a73",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3700,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What Does LessWrong/EA Think of Human Intelligence Augmentation as of mid-2023?"
    },
    "e2ac7e523696c2f5d160acda0417eb35": {
      "source_id": "e2ac7e523696c2f5d160acda0417eb35",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1387,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing AI Alignment workshop at the ALIFE 2023 conference"
    },
    "a11d4ca69100041b6d7cad5770c9a7ea": {
      "source_id": "a11d4ca69100041b6d7cad5770c9a7ea",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10811,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What is everyone doing in AI governance"
    },
    "d65ab5143fb6cd521cc9f45babd9d99d": {
      "source_id": "d65ab5143fb6cd521cc9f45babd9d99d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16476,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Some basics of the hypercompetence theory of government"
    },
    "4eaf4c5b41f70647038a814999b82c73": {
      "source_id": "4eaf4c5b41f70647038a814999b82c73",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10283,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Arguments against existential risk from AI, part 2"
    },
    "c6bb980a95192cb194697bd2c060ea9e": {
      "source_id": "c6bb980a95192cb194697bd2c060ea9e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2376,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Consider Joining the UK Foundation Model Taskforce"
    },
    "29b76b90eeb15d3aa4bea35ff416ae89": {
      "source_id": "29b76b90eeb15d3aa4bea35ff416ae89",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16615,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Frontier AI Regulation"
    },
    "f91b27297c6f72577fdf02016e35d0b9": {
      "source_id": "f91b27297c6f72577fdf02016e35d0b9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9060,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "GPT-7: The Tale of the Big Computer (An Experimental Story)"
    },
    "2bde9957ee44db8e6d2484b3e91db7d4": {
      "source_id": "2bde9957ee44db8e6d2484b3e91db7d4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2787,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Disincentivizing deception in mesa optimizers with Model Tampering"
    },
    "9b59b60aaabfce4033ba2b5810b3f445": {
      "source_id": "9b59b60aaabfce4033ba2b5810b3f445",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7303,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[UPDATE: deadline extended to July 24!] New wind in rationality\u2019s sails: Applica"
    },
    "e4c6acd93eb4f3b7819b2937bf8b0f5b": {
      "source_id": "e4c6acd93eb4f3b7819b2937bf8b0f5b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 94251,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "OpenAI Launches Superalignment Taskforce"
    },
    "1590f8cbc343347fabd9e957a2315c75": {
      "source_id": "1590f8cbc343347fabd9e957a2315c75",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9984,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How I Learned To Stop Worrying And Love The Shoggoth"
    },
    "6d6adff5cf225683154ae52b6b720bd5": {
      "source_id": "6d6adff5cf225683154ae52b6b720bd5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4771,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Alignment Megaprojects: You're Not Even Trying to Have Ideas"
    },
    "8cafdfe308f17c3c353d2b43cebad8b8": {
      "source_id": "8cafdfe308f17c3c353d2b43cebad8b8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2904,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Elon Musk announces xAI"
    },
    "d07f34e40f264f0d787a49dbee0695bf": {
      "source_id": "d07f34e40f264f0d787a49dbee0695bf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23561,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Winners of AI Alignment Awards Research Contest"
    },
    "8a909613721ca45aa2016acce68445f9": {
      "source_id": "8a909613721ca45aa2016acce68445f9",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8113,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An attempt to steelman OpenAI's alignment plan"
    },
    "a113960836c153005ee0d7a1d4191cbb": {
      "source_id": "a113960836c153005ee0d7a1d4191cbb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13935,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Activation adding experiments with FLAN-T5"
    },
    "8ffcb3a6d45893155ea8c75c43f5f624": {
      "source_id": "8ffcb3a6d45893155ea8c75c43f5f624",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10561,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Gearing Up for Long Timelines in a Hard World"
    },
    "57fd0245e18fd793a7ccfb471e548ec6": {
      "source_id": "57fd0245e18fd793a7ccfb471e548ec6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27247,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Unsafe AI as Dynamical Systems"
    },
    "97d1586a25009a02b9a1e23fc3070866": {
      "source_id": "97d1586a25009a02b9a1e23fc3070866",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4578,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why was the AI Alignment community so unprepared for this moment?"
    },
    "bafaae7a692ec3db01d5b24420e5c9b9": {
      "source_id": "bafaae7a692ec3db01d5b24420e5c9b9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31572,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Only a hack can solve the shutdown problem"
    },
    "0df654acd0f684386dffb72da4b535e4": {
      "source_id": "0df654acd0f684386dffb72da4b535e4",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8577,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Introducci\u00f3n al Riesgo Existencial de Inteligencia Artificial"
    },
    "aa0d60cc19111422f85c4585ebfda087": {
      "source_id": "aa0d60cc19111422f85c4585ebfda087",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24223,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Less activations can result in high corrigibility?"
    },
    "1d54859969d0a1084bb833aa389af90a": {
      "source_id": "1d54859969d0a1084bb833aa389af90a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22622,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Activation adding experiments with llama-7b"
    },
    "892aac1b87defa74c6b372116e5aeaee": {
      "source_id": "892aac1b87defa74c6b372116e5aeaee",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25712,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Runaway Optimizers in Mind Space"
    },
    "5217b01685bddc1c59f7a57eb64edbdd": {
      "source_id": "5217b01685bddc1c59f7a57eb64edbdd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18634,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Scaling and Sustaining Standards: A Case Study on the Basel Accords"
    },
    "d81b378a4562966b1270ebf06ff46f71": {
      "source_id": "d81b378a4562966b1270ebf06ff46f71",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2958,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Even briefer summary of ai-plans.com"
    },
    "583c5c79bee302ae7d585d0f900276ad": {
      "source_id": "583c5c79bee302ae7d585d0f900276ad",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3867,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An upcoming US Supreme Court case  may impede AI governance efforts"
    },
    "b88611f55a6e060c07c9fc940bcd00b1": {
      "source_id": "b88611f55a6e060c07c9fc940bcd00b1",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4538,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A fictional AI law laced w/ alignment theory"
    },
    "6ac1464fbf6b7b2e221c7edc40e49889": {
      "source_id": "6ac1464fbf6b7b2e221c7edc40e49889",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8712,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Proof of posteriority: a defense against AI-generated misinformation"
    },
    "111563dd89c8d2b7466e32855c612c8f": {
      "source_id": "111563dd89c8d2b7466e32855c612c8f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32187,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The shape of AGI: Cartoons and back of envelope"
    },
    "0051ac9b8c269ca44bcdce8adcee6ca1": {
      "source_id": "0051ac9b8c269ca44bcdce8adcee6ca1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6463,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Quick Thoughts on Language Models"
    },
    "8cd92d8a7b897698e8cf6597d8da3ed5": {
      "source_id": "8cd92d8a7b897698e8cf6597d8da3ed5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1312,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Simple alignment plan that maybe works"
    },
    "ee014ef09c5be38ae972148532c9deae": {
      "source_id": "ee014ef09c5be38ae972148532c9deae",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8336,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Desiderata for an AI"
    },
    "a391757377933896b0f1d13ae9dfc879": {
      "source_id": "a391757377933896b0f1d13ae9dfc879",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 58838,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Using predictors in corrigible systems"
    },
    "217511f9b68364ef757e846fde5a9327": {
      "source_id": "217511f9b68364ef757e846fde5a9327",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7611,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Going Beyond Linear Mode Connectivity: The Layerwise Linear Feature Connectivity"
    },
    "c5aada8fdd80cb37fb91539629c4dd5c": {
      "source_id": "c5aada8fdd80cb37fb91539629c4dd5c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5440,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "All AGI Safety questions welcome (especially basic ones) [July 2023]"
    },
    "d98a473382daebdb8610b7b441a007b1": {
      "source_id": "d98a473382daebdb8610b7b441a007b1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10617,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Decoding intermediate activations in llama-2-7b"
    },
    "15132da5b6ff4ce22040026f3ef09a77": {
      "source_id": "15132da5b6ff4ce22040026f3ef09a77",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27725,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "BCIs and the ecosystem of modular minds"
    },
    "8478029a53cbc6e62922ca7606bf15e8": {
      "source_id": "8478029a53cbc6e62922ca7606bf15e8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3911,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "News : Biden-\u2060Harris Administration Secures Voluntary Commitments from Leading A"
    },
    "f5f4f3b8d6cf7f621712fe5fe62ad007": {
      "source_id": "f5f4f3b8d6cf7f621712fe5fe62ad007",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10135,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Fundamentally Fuzzy Concepts Can't Have Crisp Definitions: Cooperation and Align"
    },
    "3e39e6d00785b2b1ccedd735bc774ec0": {
      "source_id": "3e39e6d00785b2b1ccedd735bc774ec0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5030,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Optimization, loss set at variance in RL"
    },
    "093a7216a657d75cc54733367180fa4c": {
      "source_id": "093a7216a657d75cc54733367180fa4c",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5753,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Supplementary Alignment Insights Through a Highly Controlled Shutdown Incentive"
    },
    "ed82e12742ab805d0125b551b4fc5eec": {
      "source_id": "ed82e12742ab805d0125b551b4fc5eec",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19128,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "My favorite AI governance research this year so far"
    },
    "7bbda302ce1999922d7003a7786c8346": {
      "source_id": "7bbda302ce1999922d7003a7786c8346",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13743,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Crosspost] An AI Pause Is Humanity's Best Bet For Preventing Extinction (TIME)"
    },
    "6c4f4bb1e2f6c8d0eaa642e515c9e902": {
      "source_id": "6c4f4bb1e2f6c8d0eaa642e515c9e902",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24291,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Anticipation in LLMs"
    },
    "c92d2c0db82e67deaceab4a23c756755": {
      "source_id": "c92d2c0db82e67deaceab4a23c756755",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9964,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Slowing down AI progress is an underexplored alignment strategy"
    },
    "94d2c07084b4856a0f3be5b6740f19f1": {
      "source_id": "94d2c07084b4856a0f3be5b6740f19f1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44412,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Task decomposition for scalable oversight (AGISF Distillation)"
    },
    "07a232d871290d16553d531790c508fb": {
      "source_id": "07a232d871290d16553d531790c508fb",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6292,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety Hub Serbia Soft Launch"
    },
    "2178ea13e8f5749ce9c5e90687edc306": {
      "source_id": "2178ea13e8f5749ce9c5e90687edc306",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7783,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Frontier Model Forum"
    },
    "3a6f3ace5961c64d4fbe6b949cbd3ad7": {
      "source_id": "3a6f3ace5961c64d4fbe6b949cbd3ad7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18918,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A response to the Richards et al.'s \"The Illusion of AI's Existential Risk\""
    },
    "3dab31df2e5040eab0ed8ae861a45a7a": {
      "source_id": "3dab31df2e5040eab0ed8ae861a45a7a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 546,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Have you ever considered taking the 'Turing Test' yourself?"
    },
    "fb247e97332d2db64f452dd05549b91a": {
      "source_id": "fb247e97332d2db64f452dd05549b91a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29609,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Preference Aggregation as Bayesian Inference"
    },
    "6fe853958f7ff6bdc5d61fd1f385b14f": {
      "source_id": "6fe853958f7ff6bdc5d61fd1f385b14f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17832,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Reducing sycophancy and improving honesty via activation steering"
    },
    "12f004b4f8acfc3a56b538518b746f3f": {
      "source_id": "12f004b4f8acfc3a56b538518b746f3f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6962,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Awareness through Interaction with Blatantly Alien Models"
    },
    "4fad7ad3b672f3d5b27283a3eafdf63d": {
      "source_id": "4fad7ad3b672f3d5b27283a3eafdf63d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7568,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Visible loss landscape basins don't correspond to distinct algorithms"
    },
    "473bf195001add409f480df42f2ba3ed": {
      "source_id": "473bf195001add409f480df42f2ba3ed",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2631,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Introductory Textbook to Vision Models Interpretability"
    },
    "ae15e082e6b3e2ee556cb9475726b3e2": {
      "source_id": "ae15e082e6b3e2ee556cb9475726b3e2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25200,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Understanding and Aligning a Human-like Inductive Bias with Cognitive Science: a"
    },
    "4d1a671c871f6fcee47bae286982bde8": {
      "source_id": "4d1a671c871f6fcee47bae286982bde8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 650,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How to find AI alignment researchers to collaborate with?"
    },
    "6cd62e8e51b666e3ddd30f30d7c3b91d": {
      "source_id": "6cd62e8e51b666e3ddd30f30d7c3b91d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17964,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Trading off compute in training and inference (Overview)"
    },
    "67dc951903968c873bb8ad6b97230adb": {
      "source_id": "67dc951903968c873bb8ad6b97230adb",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 191,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is there any existing term summarizing non-scalable oversight methods in outer a"
    },
    "361230488029937bd585fedcdba2cf95": {
      "source_id": "361230488029937bd585fedcdba2cf95",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 78353,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The \"spelling miracle\": GPT-3 spelling abilities and glitch tokens revisited"
    },
    "7c4da744d33b0d21ff085730eedc2087": {
      "source_id": "7c4da744d33b0d21ff085730eedc2087",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20774,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Evaluating Superhuman Models with Consistency Checks"
    },
    "be5d1417adf40abbe97adb09e1fb0084": {
      "source_id": "be5d1417adf40abbe97adb09e1fb0084",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25755,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI romantic partners will harm society if they go unregulated"
    },
    "5a118f9383857176181e8c27ed1bdc79": {
      "source_id": "5a118f9383857176181e8c27ed1bdc79",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3022,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Untangling Infrabayesianism: A redistillation [PDF link; ~12k words + lots of ma"
    },
    "2bcc254513f36e08b3e8dbb37b525235": {
      "source_id": "2bcc254513f36e08b3e8dbb37b525235",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 27679,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Utility and Solubility of Anthropic Capture"
    },
    "23ba20094be9fda5bd5c8606191ce42a": {
      "source_id": "23ba20094be9fda5bd5c8606191ce42a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 83607,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI #23: Fundamental Problems with RLHF"
    },
    "54b32eafe768b0255420f8ee3b24135d": {
      "source_id": "54b32eafe768b0255420f8ee3b24135d",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 1346,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] Deception Abilities Emerged in Large Language Models"
    },
    "e1009bd0b9cef841f467b0fc37ee31f4": {
      "source_id": "e1009bd0b9cef841f467b0fc37ee31f4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1175,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Hypothetical: what would you do?"
    },
    "ed087d2d34eceef77f5c902ff23127fd": {
      "source_id": "ed087d2d34eceef77f5c902ff23127fd",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5189,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Apollo Research is hiring evals and interpretability engineers & scientists"
    },
    "91ee1be4effc762fea85a9e2fadaad4a": {
      "source_id": "91ee1be4effc762fea85a9e2fadaad4a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31384,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Ground-Truth Label Imbalance Impairs the Performance of Contrast-Consistent Sear"
    },
    "ace90c0214161c90e1506a397d4abadf": {
      "source_id": "ace90c0214161c90e1506a397d4abadf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12108,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Exploring the Multiverse of Large Language Models"
    },
    "578e096545d39ab823203190386b2a8c": {
      "source_id": "578e096545d39ab823203190386b2a8c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 62679,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Rebooting AI Governance: An AI-Driven Approach to AI Governance"
    },
    "ce1d804c19abed1721d9db8cacc2f2f3": {
      "source_id": "ce1d804c19abed1721d9db8cacc2f2f3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18851,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Acausal Now: We could totally acausally bargain with aliens at our current tech "
    },
    "cf51db2b4040d37c6bd210a745f28000": {
      "source_id": "cf51db2b4040d37c6bd210a745f28000",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7087,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Inflection.ai is a major AGI lab"
    },
    "c5e5037e8e9a0f0096fe402955e233d4": {
      "source_id": "c5e5037e8e9a0f0096fe402955e233d4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26190,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Modulating sycophancy in an RLHF model via activation steering"
    },
    "c4188fa46162d4543ee78e4ab4c72767": {
      "source_id": "c4188fa46162d4543ee78e4ab4c72767",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13289,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "LLMs are (mostly) not helped by filler tokens"
    },
    "523fdde71da5d14b70ad701000a744f9": {
      "source_id": "523fdde71da5d14b70ad701000a744f9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 53999,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Could We Automate AI Alignment Research?"
    },
    "5b799688dd7764cb1769a8c7cf0e52cd": {
      "source_id": "5b799688dd7764cb1769a8c7cf0e52cd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28417,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Some alignment ideas"
    },
    "09e76fe1132b7a16919d0f5981ac9429": {
      "source_id": "09e76fe1132b7a16919d0f5981ac9429",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25132,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Evaluating GPT-4 Theory of Mind Capabilities"
    },
    "f6328f5e9ea00023ad2030d96eaebfc0": {
      "source_id": "f6328f5e9ea00023ad2030d96eaebfc0",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2147,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Seeking Input to AI Safety Book for non-technical audience"
    },
    "1927dabc7188999a844e260d45a176be": {
      "source_id": "1927dabc7188999a844e260d45a176be",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9114,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Ilya Sutskever's thoughts on AI safety (July 2023): a transcript with my comment"
    },
    "f6ee76294b242f5b26088ef90a55763f": {
      "source_id": "f6ee76294b242f5b26088ef90a55763f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3275,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Google DeepMind's RT-2"
    },
    "599c384b90b1639d450ece0ee22743a1": {
      "source_id": "599c384b90b1639d450ece0ee22743a1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 70693,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Biological Anchors: The Trick that Might or Might Not Work"
    },
    "f3a047297ad078b9ad90e76ea02c9a03": {
      "source_id": "f3a047297ad078b9ad90e76ea02c9a03",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20944,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "We Should Prepare for a Larger Representation of Academia in AI Safety"
    },
    "7e404937c7b0b55f66fe75c4596973a6": {
      "source_id": "7e404937c7b0b55f66fe75c4596973a6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20984,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Fundamental Uncertainty: Chapter 1 - How can we know what's true?"
    },
    "a58702953e4bdc324b9b4a6f45b4c5df": {
      "source_id": "a58702953e4bdc324b9b4a6f45b4c5df",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51268,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Decomposing independent generalizations in neural networks via Hessian analysis"
    },
    "3d3e19d35e7b2fbf5c50ef35dc5089f4": {
      "source_id": "3d3e19d35e7b2fbf5c50ef35dc5089f4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15032,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISN #19: US-China Competition on AI Chips, Measuring Language Agent Development"
    },
    "a0f3bcb67fce5508278dba1326a96d9b": {
      "source_id": "a0f3bcb67fce5508278dba1326a96d9b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15155,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Understanding and visualizing sycophancy datasets"
    },
    "a343be23923ed4a3128bde6141fd5a36": {
      "source_id": "a343be23923ed4a3128bde6141fd5a36",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3426,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "If we had known the atmosphere would ignite"
    },
    "dcc6c4e211cd1fe8b8eb00e4e9470baf": {
      "source_id": "dcc6c4e211cd1fe8b8eb00e4e9470baf",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7949,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "One example of how LLM propaganda attacks can hack the brain"
    },
    "ab2c6375aa7da89a0af89d42c4d7f6f1": {
      "source_id": "ab2c6375aa7da89a0af89d42c4d7f6f1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16026,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Reflections on \"Making the Atomic Bomb\""
    },
    "3bb998986b2365824274e2da512ba003": {
      "source_id": "3bb998986b2365824274e2da512ba003",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 802,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Looking for judges for critiques of Alignment Plans"
    },
    "e75e600b8257dcb5526ed7b163c5d8c6": {
      "source_id": "e75e600b8257dcb5526ed7b163c5d8c6",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12214,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Supervised Program for Alignment Research (SPAR) at UC Berkeley: Spring 2023 sum"
    },
    "e07f09b6f6ad1bc81a7d639482bdf885": {
      "source_id": "e07f09b6f6ad1bc81a7d639482bdf885",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12215,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Chess as a case study in hidden capabilities in ChatGPT"
    },
    "328e620e0cbdffa03d9eb32326d45cc2": {
      "source_id": "328e620e0cbdffa03d9eb32326d45cc2",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3335,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Clarifying how misalignment can arise from scaling LLMs"
    },
    "a89782b0783fde3bffa8fabaae84f458": {
      "source_id": "a89782b0783fde3bffa8fabaae84f458",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13496,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Memetic Judo #3: The Intelligence of Stochastic Parrots v.2"
    },
    "b9e788d4187fb919b79b3dafcbffea78": {
      "source_id": "b9e788d4187fb919b79b3dafcbffea78",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12908,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Jan Kulveit's Corrigibility Thoughts Distilled"
    },
    "5c9aa3804956806dca4c8eb3d2a784aa": {
      "source_id": "5c9aa3804956806dca4c8eb3d2a784aa",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5040,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Self-shutdown AI"
    },
    "0b01161632a1fd5c8f2d1d7be965cf9b": {
      "source_id": "0b01161632a1fd5c8f2d1d7be965cf9b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19503,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Large Language Models will be Great for Censorship"
    },
    "7929fb9e99b291476bac3f538fb5ecb0": {
      "source_id": "7929fb9e99b291476bac3f538fb5ecb0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6839,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Ideas for improving epistemics in AI safety outreach"
    },
    "e870a5018c902f15cc0936d77d0bf7e7": {
      "source_id": "e870a5018c902f15cc0936d77d0bf7e7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36438,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Low-Hanging Fruit Prior and sloped valleys in the loss landscape"
    },
    "1fd1f2f4385f097d5355236a143f70cf": {
      "source_id": "1fd1f2f4385f097d5355236a143f70cf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21054,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Assessment of intelligence agency functionality is difficult yet important"
    },
    "87de8eec0a89341fd3fd592c4e613326": {
      "source_id": "87de8eec0a89341fd3fd592c4e613326",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14368,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Enhancing Corrigibility in AI Systems through Robust Feedback Loops"
    },
    "1f4f3fafc0fdd9c7ac1bb610251de741": {
      "source_id": "1f4f3fafc0fdd9c7ac1bb610251de741",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9561,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Regulation May Be More Important Than AI Alignment For Existential Safety"
    },
    "a57ddb1a74292b686d41f701dfc033c2": {
      "source_id": "a57ddb1a74292b686d41f701dfc033c2",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7901,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Ramble on STUFF: intelligence, simulation, AI, doom, default mode, the usual"
    },
    "30452df9145ef64c459127e0829f684b": {
      "source_id": "30452df9145ef64c459127e0829f684b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13442,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Mesa-Optimization: Explain it like I'm 10 Edition"
    },
    "f8e331903270fbefe44d63e78144409f": {
      "source_id": "f8e331903270fbefe44d63e78144409f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11081,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Game of Dominance"
    },
    "565d58347b67c893573d0e924c27715a": {
      "source_id": "565d58347b67c893573d0e924c27715a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2190,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Apply to a small iteration of MLAB to be run in Oxford"
    },
    "27c6cb3097acfac1f2ba834cbca823ab": {
      "source_id": "27c6cb3097acfac1f2ba834cbca823ab",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14803,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI pause/governance advocacy might be net-negative, especially without focus on "
    },
    "2f806bd0ccf0d57234d7866ce076f52e": {
      "source_id": "2f806bd0ccf0d57234d7866ce076f52e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6491,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Information warfare historically revolved around human conduits"
    },
    "548beb8bd552847a68de115542567e01": {
      "source_id": "548beb8bd552847a68de115542567e01",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3703,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Introducing the Center for AI Policy (& we're hiring!)"
    },
    "66f77bce0aa8da4c009127fa4d7eba0a": {
      "source_id": "66f77bce0aa8da4c009127fa4d7eba0a",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1171,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Incentives affecting alignment-researcher encouragement"
    },
    "0bb4e6f0423980a31f397c6e78cd0d8b": {
      "source_id": "0bb4e6f0423980a31f397c6e78cd0d8b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19130,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISN #20: LLM Proliferation, AI Deception, and Continuing Drivers of AI Capabili"
    },
    "8cd4a14ce77a20edc4a36a2d401972ef": {
      "source_id": "8cd4a14ce77a20edc4a36a2d401972ef",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57286,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Democratic Fine-Tuning"
    },
    "7e6873a350488233e87ec9b4fa666e93": {
      "source_id": "7e6873a350488233e87ec9b4fa666e93",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7767,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Epistemic Authority of Deep Learning Pioneers"
    },
    "5e065686cd374b6e412383c8eb5a323c": {
      "source_id": "5e065686cd374b6e412383c8eb5a323c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 61158,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "\"Wanting\" and \"liking\""
    },
    "24ad10824ed6829b2f334159331dea74": {
      "source_id": "24ad10824ed6829b2f334159331dea74",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37224,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An adversarial example for Direct Logit Attribution: memory management in gelu-4"
    },
    "b16f38d1b7eaa3946bcdcdaacb35ed8e": {
      "source_id": "b16f38d1b7eaa3946bcdcdaacb35ed8e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 54024,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Report on Frontier Model Training"
    },
    "1220890e8a7f57ce1d251a6514ea042d": {
      "source_id": "1220890e8a7f57ce1d251a6514ea042d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 90384,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Invulnerable Incomplete Preferences: A Formal Statement"
    },
    "46c5dccf7cd241a446aa73a29fd3346c": {
      "source_id": "46c5dccf7cd241a446aa73a29fd3346c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40750,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Responses to apparent rationalist confusions about game / decision theory"
    },
    "f1deef725b643fc588c3a51a321730f7": {
      "source_id": "f1deef725b643fc588c3a51a321730f7",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7712,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What is OpenAI's plan for making AI Safer?"
    },
    "8541c154723043da0fc18e00d68583e9": {
      "source_id": "8541c154723043da0fc18e00d68583e9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3780,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AGI isn't just a technology"
    },
    "f243c27dc9ce705c3bbacb3c8077c328": {
      "source_id": "f243c27dc9ce705c3bbacb3c8077c328",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26515,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Rational Agents Cooperate in the Prisoner's Dilemma"
    },
    "7a3a748ca2e095bcbcd8b4332b949a2e": {
      "source_id": "7a3a748ca2e095bcbcd8b4332b949a2e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4845,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Steven Harnad: Symbol grounding and the structure of dictionaries"
    },
    "4f1db78ac345fb6478d258b7ed18b47c": {
      "source_id": "4f1db78ac345fb6478d258b7ed18b47c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21018,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What must be the case that ChatGPT would have memorized \u201cTo be or not to be\u201d? \u2013 "
    },
    "beaa2f4d88d529fdd09595b0f198854f": {
      "source_id": "beaa2f4d88d529fdd09595b0f198854f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44562,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Hertford, Sourbut (rationality lessons from University Challenge)"
    },
    "5c5c7528b4dcbd7a3303216fdd4a9cf8": {
      "source_id": "5c5c7528b4dcbd7a3303216fdd4a9cf8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12834,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Against the Open Source / Closed Source Dichotomy: Regulated Source as a Model f"
    },
    "2a423c71ab52c621bc22d5b1ab3146c0": {
      "source_id": "2a423c71ab52c621bc22d5b1ab3146c0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11274,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Decision theory is not policy theory is not agent theory"
    },
    "ab8d82e4a3ce1a8ebbef6c493c643693": {
      "source_id": "ab8d82e4a3ce1a8ebbef6c493c643693",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11606,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISN #21: Google DeepMind\u2019s GPT-4 Competitor, Military Investments in Autonomous"
    },
    "cef395ef1ee7ea1538682d17e9049eed": {
      "source_id": "cef395ef1ee7ea1538682d17e9049eed",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6671,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Evolutionary Pathway from Biological to Digital Intelligence: A Cosmic Persp"
    },
    "4036954ab198d20a508a1ce58df90fdf": {
      "source_id": "4036954ab198d20a508a1ce58df90fdf",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1737,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What's in your list of important technical projects/experiments to run for AI al"
    },
    "d8ccecf71914b9e357b6633209088418": {
      "source_id": "d8ccecf71914b9e357b6633209088418",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25867,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "ActAdd: Steering Language Models without Optimization"
    },
    "3cf9017744dce4feeb978f77f8b79f34": {
      "source_id": "3cf9017744dce4feeb978f77f8b79f34",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17150,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Recreating the caring drive"
    },
    "97c5bb2acc47339fb34fd4edb40e106d": {
      "source_id": "97c5bb2acc47339fb34fd4edb40e106d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21846,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The L\u00f6bian Obstacle, And Why You Should Care"
    },
    "d4b1e476e69015b81ffc4af53d924532": {
      "source_id": "d4b1e476e69015b81ffc4af53d924532",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29974,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How teams went about their research at AI Safety Camp edition 8"
    },
    "dc91f054f958f2a95ba60cd01f764f46": {
      "source_id": "dc91f054f958f2a95ba60cd01f764f46",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 286,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "US presidents discuss AI alignment agendas"
    },
    "fcdab8b72e19b33803d9611b60850e8e": {
      "source_id": "fcdab8b72e19b33803d9611b60850e8e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5493,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Cruxes on US lead for some domestic AI regulation"
    },
    "2390ffa5b6a2214579ca54fd54cfb319": {
      "source_id": "2390ffa5b6a2214579ca54fd54cfb319",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8182,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "How useful is Corrigibility?"
    },
    "2b35649617fdb0a2e7089e3201688a7e": {
      "source_id": "2b35649617fdb0a2e7089e3201688a7e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 76560,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Automatically finding feature vectors in the OV circuits of Transformers without"
    },
    "31766bf037b51bf0ad04e65134b54a6c": {
      "source_id": "31766bf037b51bf0ad04e65134b54a6c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19437,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is AI Safety dropping the ball on privacy?"
    },
    "fc4cf6170a7a209592b6aa10bf34409a": {
      "source_id": "fc4cf6170a7a209592b6aa10bf34409a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10328,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Apply to lead a project during the next virtual AI Safety Camp"
    },
    "28341b2b5ff687f4d9ed9ed0e860598a": {
      "source_id": "28341b2b5ff687f4d9ed9ed0e860598a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16701,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Uncovering Latent Human Wellbeing in LLM Embeddings"
    },
    "ce82835e780a4af0436fe0f31e4cef0f": {
      "source_id": "ce82835e780a4af0436fe0f31e4cef0f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14679,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Eliciting Credit Hacking Behaviours in LLMs"
    },
    "116ede6dccc038b1dae0d0215c2f01f3": {
      "source_id": "116ede6dccc038b1dae0d0215c2f01f3",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15316,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Cruxes for overhang"
    },
    "382ea761e15db12da42e7b4f84ed2279": {
      "source_id": "382ea761e15db12da42e7b4f84ed2279",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1086,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Destroying the fabric of the universe as an instrumental goal. "
    },
    "f3e1b14a57d536db50f7b7488ffac92d": {
      "source_id": "f3e1b14a57d536db50f7b7488ffac92d",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6600,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Memory bandwidth constraints imply economies of scale in AI inference"
    },
    "0db5741ec37b8ebcf0849e2e5757edab": {
      "source_id": "0db5741ec37b8ebcf0849e2e5757edab",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1610,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Catalyst books"
    },
    "7b4dfad80598327fab84f4aec7bae264": {
      "source_id": "7b4dfad80598327fab84f4aec7bae264",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6284,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Microdooms averted by working on AI Safety"
    },
    "a708bbbbe1befa93f4708918a5620e83": {
      "source_id": "a708bbbbe1befa93f4708918a5620e83",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15329,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Technical AI Safety Research Landscape [Slides]"
    },
    "0770143609cbd1359cf34a1df7105636": {
      "source_id": "0770143609cbd1359cf34a1df7105636",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15510,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Knowledge Database 1: The structure and the method of building"
    },
    "5b0c7b3ff50d1a0a4930b1a1c88cc5e9": {
      "source_id": "5b0c7b3ff50d1a0a4930b1a1c88cc5e9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1435,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is there a publicly available list of examples of frontier model capabilities?"
    },
    "7d6a37176d333485330626f0f9e9ebc9": {
      "source_id": "7d6a37176d333485330626f0f9e9ebc9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14419,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Formalizing \u00abBoundaries\u00bb with Markov blankets + Criticism of this approach"
    },
    "d698aa3724b0acb71a53c742208ca4c2": {
      "source_id": "d698aa3724b0acb71a53c742208ca4c2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28786,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The AI Explosion Might Never Happen"
    },
    "343ce027548c50787d9612ce5664a636": {
      "source_id": "343ce027548c50787d9612ce5664a636",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21804,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Careless talk on US-China AI competition? (and criticism of CAIS coverage)"
    },
    "bc60d6b14a60933043d20ec4908848fb": {
      "source_id": "bc60d6b14a60933043d20ec4908848fb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21993,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Interpretability Externalities Case Study - Hungry Hungry Hippos"
    },
    "71e046b22392b41773a7c495aff3c37c": {
      "source_id": "71e046b22392b41773a7c495aff3c37c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20226,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Image Hijacks: Adversarial Images can Control Generative Models at Runtime"
    },
    "6cc5afa6c66331c54e8b1853eba4de1e": {
      "source_id": "6cc5afa6c66331c54e8b1853eba4de1e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28404,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Sparse Autoencoders Find Highly Interpretable Directions in Language Models"
    },
    "7ca6917ebadb5e35e1be33e97a2295b4": {
      "source_id": "7ca6917ebadb5e35e1be33e97a2295b4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30812,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Immortality or death by AGI"
    },
    "2bd8d2117063d837b78e356ec7c1cd11": {
      "source_id": "2bd8d2117063d837b78e356ec7c1cd11",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28562,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Taking features out of superposition with sparse autoencoders more quickly with "
    },
    "b23e8b4583eb70bf2c8252a852511222": {
      "source_id": "b23e8b4583eb70bf2c8252a852511222",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5736,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "I designed an AI safety course (for a philosophy department)"
    },
    "ef166c4453367f8bd05a542c14ba6c76": {
      "source_id": "ef166c4453367f8bd05a542c14ba6c76",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18807,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Five neglected work areas that could reduce AI risk"
    },
    "6d5472bb62e329d51c695974a0a3eb12": {
      "source_id": "6d5472bb62e329d51c695974a0a3eb12",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15238,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Understanding strategic deception and deceptive alignment"
    },
    "645b665eabfc161a76c6f0b4e2eac5a2": {
      "source_id": "645b665eabfc161a76c6f0b4e2eac5a2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33999,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Evaluating hidden directions on the utility dataset: classification, steering an"
    },
    "929be0662f214039a230d41fc5d8cec8": {
      "source_id": "929be0662f214039a230d41fc5d8cec8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5922,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Public Opinion on AI Safety: AIMS 2023 and 2021 Summary"
    },
    "76a06fd77a88c60429f6990ef219d102": {
      "source_id": "76a06fd77a88c60429f6990ef219d102",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30549,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "ARENA 2.0 - Impact Report"
    },
    "a90c6d6c7a428e69b65589fcd680dc8e": {
      "source_id": "a90c6d6c7a428e69b65589fcd680dc8e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9297,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "It Is Powerful, It Can't Be Aimed"
    },
    "4c5470f2be9c23c9598a365046b2f641": {
      "source_id": "4c5470f2be9c23c9598a365046b2f641",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10614,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "MMLU\u2019s Moral Scenarios Benchmark Doesn\u2019t Measure What You Think it Measures"
    },
    "77df9144fd725ccc1ad27bd94bbdd5c2": {
      "source_id": "77df9144fd725ccc1ad27bd94bbdd5c2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46459,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Towards Better Milestones for Monitoring AI Capabilities"
    },
    "e710557a4788c677cb5d75663f7d60d6": {
      "source_id": "e710557a4788c677cb5d75663f7d60d6",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8590,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Projects I would like to see (possibly at AI Safety Camp)"
    },
    "d70dc5f558a44d69da0db455b142ac02": {
      "source_id": "d70dc5f558a44d69da0db455b142ac02",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4860,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "ARC Evals: Responsible Scaling Policies"
    },
    "fd3b0d2e7486514e77b98bff3d139f14": {
      "source_id": "fd3b0d2e7486514e77b98bff3d139f14",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 69952,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "High-level interpretability: detecting an AI's objectives"
    },
    "d33649c1a2bd06bba9c1dee2832f37d0": {
      "source_id": "d33649c1a2bd06bba9c1dee2832f37d0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22918,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Steering subsystems: capabilities, agency, and alignment"
    },
    "f412daf47bdda085a3725a355f475d95": {
      "source_id": "f412daf47bdda085a3725a355f475d95",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 464,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "My submission to the ALTER Prize"
    },
    "a81fe7350f4b58864de3cf53a68f5609": {
      "source_id": "a81fe7350f4b58864de3cf53a68f5609",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22549,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Focusing your impact on short vs long TAI timelines"
    },
    "a9fc04e6579c85a5debb6ed7459c8499": {
      "source_id": "a9fc04e6579c85a5debb6ed7459c8499",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7570,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "New Tool: the Residual Stream Viewer"
    },
    "0d1481de5aa34076e77b2606d23fb7c9": {
      "source_id": "0d1481de5aa34076e77b2606d23fb7c9",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2118,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Expectations for Gemini: hopefully not a big deal"
    },
    "589e2e72a97ca83b56855232d1ded1df": {
      "source_id": "589e2e72a97ca83b56855232d1ded1df",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 29243,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Early Experiments in Reward Model Interpretation Using Sparse Autoencoders"
    },
    "a646708c9c1a1390c18fb35d426bc317": {
      "source_id": "a646708c9c1a1390c18fb35d426bc317",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15257,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What would it mean to understand how a large language model (LLM) works? Some qu"
    },
    "4858a5cec559dd24b5c73cc83a961858": {
      "source_id": "4858a5cec559dd24b5c73cc83a961858",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 70916,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Graphical tensor notation for interpretability"
    },
    "e7112601b9b920f5165c771fadac810e": {
      "source_id": "e7112601b9b920f5165c771fadac810e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1696,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "What are some examples of AIs instantiating the 'nearest unblocked strategy prob"
    },
    "41845072de7c6ca8c8a1fd37f1df9eb5": {
      "source_id": "41845072de7c6ca8c8a1fd37f1df9eb5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4560,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Entanglement and intuition about words and meaning "
    },
    "b74a464ff0569d553342f7a826290af4": {
      "source_id": "b74a464ff0569d553342f7a826290af4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13153,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISN #23: New OpenAI Models, News from Anthropic, and Representation Engineering"
    },
    "f373c186563183870f6ea038f342a403": {
      "source_id": "f373c186563183870f6ea038f342a403",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 108338,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "This anime storyboard doesn't exist: a graphic novel written and illustrated by "
    },
    "236b76e3c37a6fc7b2c3cddcbf061583": {
      "source_id": "236b76e3c37a6fc7b2c3cddcbf061583",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 38923,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Evaluating the historical value misspecification argument"
    },
    "c7e918b0919db6353bae898e4aef671d": {
      "source_id": "c7e918b0919db6353bae898e4aef671d",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4781,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Stampy's AI Safety Info soft launch"
    },
    "4a23428ab74df10b9608d7deede45a2b": {
      "source_id": "4a23428ab74df10b9608d7deede45a2b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31908,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Sam Altman's sister, Annie Altman, claims Sam has (severely) abused her"
    },
    "710eb9bf4845bfbf74bd8ed9c240cafd": {
      "source_id": "710eb9bf4845bfbf74bd8ed9c240cafd",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 65316,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Utilitarianism is irrational or self-undermining"
    },
    "49999e95b3566be17b801dbffc4d6949": {
      "source_id": "49999e95b3566be17b801dbffc4d6949",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10615,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Gradient \u2013 The Artificiality of Alignment"
    },
    "86bc7c68561ac26c613739b1858dbe8a": {
      "source_id": "86bc7c68561ac26c613739b1858dbe8a",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 4284,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Linkpost: Are Emergent Abilities in Large Language Models just In-Context Learni"
    },
    "b1b8ccd1ca31b215727c7773713f6fac": {
      "source_id": "b1b8ccd1ca31b215727c7773713f6fac",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 75952,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "FAQ: What the heck is goal agnosticism?"
    },
    "b98d35fb573d38a2b0a44d6e60c6caea": {
      "source_id": "b98d35fb573d38a2b0a44d6e60c6caea",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2013,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Paper: Identifying the Risks of LM Agents with an LM-Emulated Sandbox - Universi"
    },
    "1350ba095e6e7fecf7fed7b87d4c279c": {
      "source_id": "1350ba095e6e7fecf7fed7b87d4c279c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12240,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "We don't understand what happened with culture enough"
    },
    "a38a9b5e6900ebf68e75703fd1449aa9": {
      "source_id": "a38a9b5e6900ebf68e75703fd1449aa9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17446,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Knowledge Base 2: The structure and the method of building"
    },
    "5e154be040a8eadd8c54924d496433c1": {
      "source_id": "5e154be040a8eadd8c54924d496433c1",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6915,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Bostrom Buckle: Visualising the Vulnerable World Hypothesis"
    },
    "ee49b1b9cba8f731e3e04f7552b47f47": {
      "source_id": "ee49b1b9cba8f731e3e04f7552b47f47",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10480,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Documenting Journey Into AI Safety"
    },
    "8e3d7965b243eadef0f60e3330300cde": {
      "source_id": "8e3d7965b243eadef0f60e3330300cde",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10160,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A New Model for Compute Center Verification"
    },
    "c15adf41caa534693085107babbd4d74": {
      "source_id": "c15adf41caa534693085107babbd4d74",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34455,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An explanation for every token: using an LLM to sample another LLM"
    },
    "303b361788f4bba7bb3403759fdad2e3": {
      "source_id": "303b361788f4bba7bb3403759fdad2e3",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6960,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Shard Therapy, preambe"
    },
    "2e0bf01fd7986f0ddc4421b18241e152": {
      "source_id": "2e0bf01fd7986f0ddc4421b18241e152",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11632,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Update on the UK AI Taskforce & AI Safety Summit"
    },
    "d77d55f3a55cef589c647cfc870fe4fa": {
      "source_id": "d77d55f3a55cef589c647cfc870fe4fa",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7174,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "LLMs \u2014 Pure Reason Without The Critique"
    },
    "4d46b9a796f368e8a43625400449c69d": {
      "source_id": "4d46b9a796f368e8a43625400449c69d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 32949,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Attributing to interactions with GCPD and GWPD"
    },
    "07e9f9bdfdf9d855f4ff7b86931be60f": {
      "source_id": "07e9f9bdfdf9d855f4ff7b86931be60f",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9352,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Understanding LLMs: Some basic observations about words, syntax, and discourse ["
    },
    "2252c3292f63f9e78d40ae2f108761fc": {
      "source_id": "2252c3292f63f9e78d40ae2f108761fc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23665,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Relevance of 'Harmful Intelligence' Data in Training Datasets (WebText vs. Pile)"
    },
    "b4ad38e73e30aea7a380bec11b821a73": {
      "source_id": "b4ad38e73e30aea7a380bec11b821a73",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 51622,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "LoRA Fine-tuning Efficiently Undoes Safety Training from Llama 2-Chat 70B"
    },
    "ab6c3fd5ef4fd83f5521eef33ff27e30": {
      "source_id": "ab6c3fd5ef4fd83f5521eef33ff27e30",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 37760,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "unRLHF - Efficiently undoing LLM safeguards"
    },
    "72e5ace19af9766f831dca902d06508c": {
      "source_id": "72e5ace19af9766f831dca902d06508c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11245,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "To open-source or to not open-source, that is (an oversimplification of) the que"
    },
    "dafafe00473306eb4bc5a9bfea35d54f": {
      "source_id": "dafafe00473306eb4bc5a9bfea35d54f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11612,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "FLI podcast series, \"Imagine A World\", about aspirational futures with AGI"
    },
    "737650af385c56d4a5efb749f3fa0018": {
      "source_id": "737650af385c56d4a5efb749f3fa0018",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2367,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Which Anaesthetic To Choose?"
    },
    "08e73624efe459c635611b262508213e": {
      "source_id": "08e73624efe459c635611b262508213e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9765,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "ChatGPT tells 20 versions of its prototypical story, with a short note on method"
    },
    "674c961bca38395081c81d66483f59d4": {
      "source_id": "674c961bca38395081c81d66483f59d4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 102487,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Natural Abstraction: Convergent Preferences Over Information Structures"
    },
    "99556317513cfd3207ca8a86035608dc": {
      "source_id": "99556317513cfd3207ca8a86035608dc",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2704,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Unity Gridworlds"
    },
    "805bb4873b8944f264609d6444dd4c2c": {
      "source_id": "805bb4873b8944f264609d6444dd4c2c",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25912,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Discovering Latent Knowledge in the Human Brain: Part 1 \u2013 Clarifying the concept"
    },
    "79927cc0c026756326fd4136ac0c006f": {
      "source_id": "79927cc0c026756326fd4136ac0c006f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34150,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Mapping ChatGPT\u2019s ontological landscape, gradients and choices [interpretability"
    },
    "b1e93507c01f387a776fe3fb6e836224": {
      "source_id": "b1e93507c01f387a776fe3fb6e836224",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41488,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Thoughts on Hardware limits to Prevent AGI?"
    },
    "6ec96e2a3457c8c1e3494c6b79488268": {
      "source_id": "6ec96e2a3457c8c1e3494c6b79488268",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16385,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Taxonomy of AI-risk counterarguments"
    },
    "9fa235e8cf231f90761373e42735f655": {
      "source_id": "9fa235e8cf231f90761373e42735f655",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30277,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Goodhart's Law in Reinforcement Learning"
    },
    "c7454bf412139312faf875ea8688439d": {
      "source_id": "c7454bf412139312faf875ea8688439d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40399,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "UNGA General Debate speeches on AI"
    },
    "985939abd1d7e05b4e545388cec40920": {
      "source_id": "985939abd1d7e05b4e545388cec40920",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22399,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": " ChatGPT Plays 20 Questions [sometimes needs help] "
    },
    "c7c200187b52267551e00ee9c3836cff": {
      "source_id": "c7c200187b52267551e00ee9c3836cff",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1527,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Eleuther releases Llemma: An Open Language Model For Mathematics"
    },
    "cfb6b9734cc16c01a2367f889a4f627a": {
      "source_id": "cfb6b9734cc16c01a2367f889a4f627a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 33995,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "(Non-deceptive) Suboptimality Alignment"
    },
    "9fb44985ef0697f94a2c489305ea6ae0": {
      "source_id": "9fb44985ef0697f94a2c489305ea6ae0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8970,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "On Interpretability's Robustness"
    },
    "7a52405693ad10b3fee905bca42e4c57": {
      "source_id": "7a52405693ad10b3fee905bca42e4c57",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2493,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Back to the Past to the Future"
    },
    "4ab57e0dfe43ce4d55308a2933f01c8e": {
      "source_id": "4ab57e0dfe43ce4d55308a2933f01c8e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16174,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISN #24: Kissinger Urges US-China Cooperation on AI, China's New AI Law, US Exp"
    },
    "1852c03076d524db7d2ecd4183a2c6bc": {
      "source_id": "1852c03076d524db7d2ecd4183a2c6bc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 73410,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Alignment 101 - Ch.1 - AGI"
    },
    "86c97424acd81efccf7c65ce1f448157": {
      "source_id": "86c97424acd81efccf7c65ce1f448157",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 83567,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Alignment 101 - Ch.2 - Reward Misspecification"
    },
    "a09263e032a3e8e6b6319265c4170c73": {
      "source_id": "a09263e032a3e8e6b6319265c4170c73",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10179,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The (partial) fallacy of dumb superintelligence"
    },
    "94108d865e373b704fc09fd18b545746": {
      "source_id": "94108d865e373b704fc09fd18b545746",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11985,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Internal Target Information for AI Oversight"
    },
    "20ca89fbb248c3c05b4d95f9c0033979": {
      "source_id": "20ca89fbb248c3c05b4d95f9c0033979",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18141,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "I Would Have Solved Alignment, But I Was Worried That Would Advance Timelines"
    },
    "d2cec5161bfe70541b1467673ee03519": {
      "source_id": "d2cec5161bfe70541b1467673ee03519",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 25756,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Muddling Along Is More Likely Than Dystopia"
    },
    "9cf0efbadfb560878e3a0709c1cd2f2a": {
      "source_id": "9cf0efbadfb560878e3a0709c1cd2f2a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14117,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Apply for MATS Winter 2023-24!"
    },
    "62fc12a7a82e51aab4514491244797b5": {
      "source_id": "62fc12a7a82e51aab4514491244797b5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 44924,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Alignment Implications of LLM Successes: a Debate in One Act"
    },
    "226ae267b8adde2f41fd5799d842542a": {
      "source_id": "226ae267b8adde2f41fd5799d842542a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 66209,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety is Dropping the Ball on Clown Attacks, and Mind Control in General"
    },
    "3fc17b83753f22b1d4115b6493b0b612": {
      "source_id": "3fc17b83753f22b1d4115b6493b0b612",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12531,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Thoughts On (Solving) Deep Deception"
    },
    "0bb8140c68414660f5a130b455e41ccd": {
      "source_id": "0bb8140c68414660f5a130b455e41ccd",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 822,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Into AI Safety - Episode 0"
    },
    "ae128aba1dbd4687e2e9adb016cb65cc": {
      "source_id": "ae128aba1dbd4687e2e9adb016cb65cc",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11194,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "VLM-RM: Specifying Rewards with Natural Language"
    },
    "4664eda3948d6617f62d851e3f61f386": {
      "source_id": "4664eda3948d6617f62d851e3f61f386",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 41336,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Machine Unlearning Evaluations as Interpretability Benchmarks"
    },
    "9424ea088c57351665884b479a282a02": {
      "source_id": "9424ea088c57351665884b479a282a02",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7505,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Towards Understanding Sycophancy in Language Models"
    },
    "b8e703d9b13305139f1f1f320e57c075": {
      "source_id": "b8e703d9b13305139f1f1f320e57c075",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3208,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing #AISummitTalks featuring Professor Stuart Russell and many others"
    },
    "abc4b68b2f73e1e9f6f9ee7f4f727f6b": {
      "source_id": "abc4b68b2f73e1e9f6f9ee7f4f727f6b",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 474,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Interview w/ Quintin Pope] Evolution, values, and AI Safety"
    },
    "6906b39a664692fa620c7dcf072cf05a": {
      "source_id": "6906b39a664692fa620c7dcf072cf05a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 12189,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Compositional preference models for aligning LMs"
    },
    "b5cbd0d303fd4027cf99b146d1932d33": {
      "source_id": "b5cbd0d303fd4027cf99b146d1932d33",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7072,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Anthropic, Google, Microsoft & OpenAI announce Executive Director of the Frontie"
    },
    "d4c4eff1d0dd5cac8bb71b878ad979e9": {
      "source_id": "d4c4eff1d0dd5cac8bb71b878ad979e9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 21659,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Sensor Exposure can Compromise the Human Brain in the 2020s"
    },
    "fb18585354989cfc075b5839b3fac23f": {
      "source_id": "fb18585354989cfc075b5839b3fac23f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 47449,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Responsible Scaling Policies Are Risk Management Done Wrong"
    },
    "5f7d2d09f1a98ce43e6176bdff07633a": {
      "source_id": "5f7d2d09f1a98ce43e6176bdff07633a",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6327,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Architects of Our Own Demise: We Should Stop Developing AI"
    },
    "068b16b81301c73e7e62375540c38064": {
      "source_id": "068b16b81301c73e7e62375540c38064",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 114608,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI #35: Responsible Scaling Policies"
    },
    "c36dc582af05289e79cb119022b8de34": {
      "source_id": "c36dc582af05289e79cb119022b8de34",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3814,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "UK Government publishes \"Frontier AI: capabilities and risks\" Discussion Paper"
    },
    "b80e75b691dd31bb35b3f36d481b05fb": {
      "source_id": "b80e75b691dd31bb35b3f36d481b05fb",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15456,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Disagreements over the prioritization of existential risk from AI"
    },
    "d84f1881a238330260d12d64fce8dca8": {
      "source_id": "d84f1881a238330260d12d64fce8dca8",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 12864,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Linkpost: Rishi Sunak's Speech on AI (26th October)"
    },
    "92b42e9deded70db75ebb7dbf183b144": {
      "source_id": "92b42e9deded70db75ebb7dbf183b144",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 40391,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Aspiration-based Q-Learning"
    },
    "d1e015312ce70d36583f994daeedaaa0": {
      "source_id": "d1e015312ce70d36583f994daeedaaa0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 14589,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "We're Not Ready: thoughts on \"pausing\" and responsible scaling policies"
    },
    "c6acb36ad53d1883b539e94dba0782d4": {
      "source_id": "c6acb36ad53d1883b539e94dba0782d4",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6959,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Wireheading and misalignment by composition on NetHack"
    },
    "878f943e138e134f1e264a138aa48cf5": {
      "source_id": "878f943e138e134f1e264a138aa48cf5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26261,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Value systematization: how values become coherent (and misaligned)"
    },
    "b64da888416114cc067d0253c0bcf2ba": {
      "source_id": "b64da888416114cc067d0253c0bcf2ba",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3228,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Existential Safety Fellowships"
    },
    "444b944363977dc5e26ed289a3d8ce05": {
      "source_id": "444b944363977dc5e26ed289a3d8ce05",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4945,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Shane Legg interview on alignment"
    },
    "06dfb9ce36a9463e55c357c45e98561d": {
      "source_id": "06dfb9ce36a9463e55c357c45e98561d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16398,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Clarifying the free energy principle (with quotes)"
    },
    "09a69d6df1590e382d8af8d333456977": {
      "source_id": "09a69d6df1590e382d8af8d333456977",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 36878,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Charbel-Rapha\u00ebl and Lucius discuss Interpretability"
    },
    "af066205c5388d4381cc288976030d69": {
      "source_id": "af066205c5388d4381cc288976030d69",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23719,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "5 Reasons Why Governments/Militaries Already Want AI for Information Warfare"
    },
    "c3d63416d00c58d25fff747af11e6514": {
      "source_id": "c3d63416d00c58d25fff747af11e6514",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11586,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Response to \u201cCoordinated pausing: An evaluation-based coordination scheme for fr"
    },
    "b639fcc1a67ecaab577f80bdcf6a25f2": {
      "source_id": "b639fcc1a67ecaab577f80bdcf6a25f2",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 1981,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] Two major announcements in AI governance today"
    },
    "c102da6780d3f47649eaa76666b28893": {
      "source_id": "c102da6780d3f47649eaa76666b28893",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 26839,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Intrinsic Drives and Extrinsic Misuse: Two Intertwined Risks of AI"
    },
    "abb7ba106b650607f2898f98b80a4158": {
      "source_id": "abb7ba106b650607f2898f98b80a4158",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1461,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Urging an International AI Treaty: An Open Letter"
    },
    "2c8485f47ecbbb119a9bf3690b2f855e": {
      "source_id": "2c8485f47ecbbb119a9bf3690b2f855e",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28547,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Safety 101 - Chapter 5.1 - Debate"
    },
    "7e11a286096bd9ec370116d3d9c42e33": {
      "source_id": "7e11a286096bd9ec370116d3d9c42e33",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 15429,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISN #25: White House Executive Order on AI, UK AI Safety Summit, and Progress o"
    },
    "1174e4f150cf998dc374003149dd0651": {
      "source_id": "1174e4f150cf998dc374003149dd0651",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 23473,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Thoughts on the AI Safety Summit company policy requests and responses"
    },
    "ecb183ce3f7627f5d1589bb1de7d39b4": {
      "source_id": "ecb183ce3f7627f5d1589bb1de7d39b4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31534,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Robustness of Contrast-Consistent Search to Adversarial Prompting"
    },
    "1314a8feb3a56179634f2f706783f304": {
      "source_id": "1314a8feb3a56179634f2f706783f304",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 56977,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "On the Executive Order"
    },
    "24d091ddf8a4e40b6751a3cc7cc0be3e": {
      "source_id": "24d091ddf8a4e40b6751a3cc7cc0be3e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 8238,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "ChatGPT\u2019s Ontological Landscape"
    },
    "54747097e0484f2bc0c2413e47eac52e": {
      "source_id": "54747097e0484f2bc0c2413e47eac52e",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5176,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Snapshot of narratives and frames against regulating AI"
    },
    "183670b00365651ac2e576a01b16d805": {
      "source_id": "183670b00365651ac2e576a01b16d805",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22208,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "A list of all the deadlines in Biden's Executive Order on AI"
    },
    "ec822b2aac398c66d0628721112b74b5": {
      "source_id": "ec822b2aac398c66d0628721112b74b5",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 602,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI Alignment: A Comprehensive Survey"
    },
    "1d7596f857ab0be8a621f8935b8c0242": {
      "source_id": "1d7596f857ab0be8a621f8935b8c0242",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7548,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Dario Amodei\u2019s prepared remarks from the UK AI Safety Summit, on Anthropic\u2019s Res"
    },
    "0dec39d2ff5b2ecb0bde18ced6c014ca": {
      "source_id": "0dec39d2ff5b2ecb0bde18ced6c014ca",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57699,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Reactions to the Executive Order"
    },
    "9c7127142623b1683a0991387d8f18d9": {
      "source_id": "9c7127142623b1683a0991387d8f18d9",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 72258,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Singular learning theory and bridging from ML to brain emulations"
    },
    "fc5f77ce8d14394e1015717fe333edca": {
      "source_id": "fc5f77ce8d14394e1015717fe333edca",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2489,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Should people build productizations of open source AI models?"
    },
    "c1074d4ab8b8fcc320f23e895ab32416": {
      "source_id": "c1074d4ab8b8fcc320f23e895ab32416",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9135,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Saying the quiet part out loud: trading off x-risk for personal immortality"
    },
    "24e20854263440909310b31aa558b8a7": {
      "source_id": "24e20854263440909310b31aa558b8a7",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 49402,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Does davidad's uploading moonshot work?"
    },
    "a998f182189e0dd3ed04597a9bb0440f": {
      "source_id": "a998f182189e0dd3ed04597a9bb0440f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1811,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "If AGI is imminent, why can\u2019t I hail a robotaxi?"
    },
    "b647ed1c16e4ce8b5905f326585b9648": {
      "source_id": "b647ed1c16e4ce8b5905f326585b9648",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 24022,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "8 examples informing my pessimism on uploading without reverse engineering"
    },
    "a2ec9ba62da4318f44ea51004ca59aee": {
      "source_id": "a2ec9ba62da4318f44ea51004ca59aee",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 653,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Paul Christiano on Dwarkesh Podcast"
    },
    "79133d60e2d3fde425cf8458c5fc27e0": {
      "source_id": "79133d60e2d3fde425cf8458c5fc27e0",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 9491,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Despair about AI progressing too slowly"
    },
    "ad776c3c93c2a390949a667f961cbb7f": {
      "source_id": "ad776c3c93c2a390949a667f961cbb7f",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16792,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "We are already in a persuasion-transformed world and must take precautions"
    },
    "92b209fe72c0859e3fd9ac8e4a6002e6": {
      "source_id": "92b209fe72c0859e3fd9ac8e4a6002e6",
      "quality_score": 1.5,
      "quality_tier": "D",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": true,
        "text_length": 2131,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "[Linkpost] Concept Alignment as a Prerequisite for Value Alignment"
    },
    "b69fcd7f419795f56f679aa345ac8ef6": {
      "source_id": "b69fcd7f419795f56f679aa345ac8ef6",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 5423,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The 6D effect: When companies take risks, one email can be very powerful."
    },
    "3a6d21b7daab55a0dae3f14db0f0c33a": {
      "source_id": "3a6d21b7daab55a0dae3f14db0f0c33a",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 10956,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Stuxnet, not Skynet: Humanity's disempowerment by AI"
    },
    "03d6d655c532794ddb662a2ffabe0afa": {
      "source_id": "03d6d655c532794ddb662a2ffabe0afa",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1741,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Eric Schmidt on recursive self-improvement"
    },
    "9f71d5742a5414c32afa8844a3f54a3b": {
      "source_id": "9f71d5742a5414c32afa8844a3f54a3b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 18177,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AI as Super-Demagogue"
    },
    "11dabe873f883ad906bc783a8c8ffda2": {
      "source_id": "11dabe873f883ad906bc783a8c8ffda2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17655,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Disentangling four motivations for acting in accordance with UDT"
    },
    "a7e29facedd305b9ff5f2e580ae0ef40": {
      "source_id": "a7e29facedd305b9ff5f2e580ae0ef40",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19225,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Tips, tricks, lessons and thoughts on hosting hackathons"
    },
    "1f7b7145984aacce509144b1debb1958": {
      "source_id": "1f7b7145984aacce509144b1debb1958",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 46986,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "An illustrative model of backfire risks from pausing AI research"
    },
    "8fe0a8cc7b05d21f74d3ec9c4aea5043": {
      "source_id": "8fe0a8cc7b05d21f74d3ec9c4aea5043",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 410,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Why building ventures in AI Safety is particularly challenging"
    },
    "b8b5b2e10670fe8a06090a4321929c52": {
      "source_id": "b8b5b2e10670fe8a06090a4321929c52",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16880,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Box inversion revisited"
    },
    "aeb291eae42a26ab884cca96102c7a2d": {
      "source_id": "aeb291eae42a26ab884cca96102c7a2d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 63996,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "On the UK Summit"
    },
    "164ca2669025e10174562ac2b5c48a33": {
      "source_id": "164ca2669025e10174562ac2b5c48a33",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4542,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Preface to the Sequence on LLM Psychology"
    },
    "3f44b8fb5bf99a8b25cd4b6273ac1814": {
      "source_id": "3f44b8fb5bf99a8b25cd4b6273ac1814",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 20387,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Stochastic Parrot Hypothesis is debatable for the last generation of LLMs"
    },
    "de3ad8158e534a533b1865bb8ddff822": {
      "source_id": "de3ad8158e534a533b1865bb8ddff822",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6386,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Symbiotic self-alignment of AIs."
    },
    "9ac7cf9f3e65d9f49405e2264643215f": {
      "source_id": "9ac7cf9f3e65d9f49405e2264643215f",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4434,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Scalable And Transferable Black-Box Jailbreaks For Language Models Via Persona M"
    },
    "eda3d89a115a1fdf947aba4e6c9e43c8": {
      "source_id": "eda3d89a115a1fdf947aba4e6c9e43c8",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 6279,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Announcing Athena - Women in AI Alignment Research"
    },
    "c453d8a0be66b82d453c5d9fca50bb03": {
      "source_id": "c453d8a0be66b82d453c5d9fca50bb03",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22722,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Alignment Frame/Exercise: Building The Puzzle of Alignment"
    },
    "ebccf8dd01882bbcb2d81ada7760a58e": {
      "source_id": "ebccf8dd01882bbcb2d81ada7760a58e",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 3243,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Open Agency model can solve the AI regulation dilemma"
    },
    "0a41edef5e4fcfcffa7ed6389ac46caf": {
      "source_id": "0a41edef5e4fcfcffa7ed6389ac46caf",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19984,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Open-ended ethics of phenomena (a desiderata with universal morality)"
    },
    "536942f52d1a90fd655dd1aef75a0626": {
      "source_id": "536942f52d1a90fd655dd1aef75a0626",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 1085,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Into AI Safety Episodes 1 & 2"
    },
    "5677e879889435f6b3842cfc4d5ab9e8": {
      "source_id": "5677e879889435f6b3842cfc4d5ab9e8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 31444,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "On OpenAI Dev Day"
    },
    "3d05fbed90a798608020f420bf4d19b2": {
      "source_id": "3d05fbed90a798608020f420bf4d19b2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 13460,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Polysemantic Attention Head in a 4-Layer Transformer"
    },
    "5ac97646c7c5cf63ef7a7a46c5eb3b55": {
      "source_id": "5ac97646c7c5cf63ef7a7a46c5eb3b55",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2783,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Munk Debate on AI: a few observations and opinions"
    },
    "4cb080a60ced2dea033aff7fae890fc2": {
      "source_id": "4cb080a60ced2dea033aff7fae890fc2",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 30256,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "GPT-2030 and Catastrophic Drives: Four Vignettes"
    },
    "d7f050f7c7b7b4976ec87de57ed0e52d": {
      "source_id": "d7f050f7c7b7b4976ec87de57ed0e52d",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 19007,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Update on the UK AI Summit and the UK's Plans"
    },
    "cfc932dd1745b51831ae7d556bd27bae": {
      "source_id": "cfc932dd1745b51831ae7d556bd27bae",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 57168,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Game Theory without Argmax [Part 1]"
    },
    "72d41ded6515b45b1c562a42159bedd5": {
      "source_id": "72d41ded6515b45b1c562a42159bedd5",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 39146,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Game Theory without Argmax [Part 2]"
    },
    "814913204dfb20671c95e17f4ea181a4": {
      "source_id": "814913204dfb20671c95e17f4ea181a4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 4257,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Control Symmetry: why we might want to start investigating asymmetric alignment "
    },
    "ff04c712f7567e2ebff2efbd3f21a68c": {
      "source_id": "ff04c712f7567e2ebff2efbd3f21a68c",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2505,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISC project: SatisfIA \u2013 AI that satisfies without overdoing it"
    },
    "0d72931ec67149a63d26ae4043f573f4": {
      "source_id": "0d72931ec67149a63d26ae4043f573f4",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2675,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "The Science Algorithm AISC Project"
    },
    "d4be57ca5abeb327368b851e5d7636e1": {
      "source_id": "d4be57ca5abeb327368b851e5d7636e1",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 22735,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISC Project: Modelling Trajectories of Language Models"
    },
    "a7ef2d56a8daaf66d213e15b16bc67e4": {
      "source_id": "a7ef2d56a8daaf66d213e15b16bc67e4",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 16500,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "AISC Project: Benchmarks for Stable Reflectivity"
    },
    "6a966701a07b4e9c14f7fb191b3c4bb6": {
      "source_id": "6a966701a07b4e9c14f7fb191b3c4bb6",
      "quality_score": 4.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 7751,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Optionality approach to ethics"
    },
    "f8f47bafa8a6d8a80427ba0bf3a857c8": {
      "source_id": "f8f47bafa8a6d8a80427ba0bf3a857c8",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 17293,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Non-myopia stories"
    },
    "d8b52e1634ad7ff7a64c460d9d248189": {
      "source_id": "d8b52e1634ad7ff7a64c460d9d248189",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 11915,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Out of the Box"
    },
    "757fbe31eebc705014d26da1b9bd2833": {
      "source_id": "757fbe31eebc705014d26da1b9bd2833",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2688,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Is Interpretability All We Need?"
    },
    "7201674020ef79e8a34ddd361b0f2b76": {
      "source_id": "7201674020ef79e8a34ddd361b0f2b76",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 28570,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Do you want a first-principled preparedness guide to prepare yourself and loved "
    },
    "c03b8f30c13714b6168bcb3f56b09a6b": {
      "source_id": "c03b8f30c13714b6168bcb3f56b09a6b",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 45818,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "Betting on what is un-falsifiable and un-verifiable"
    },
    "3e7d25fba914fb5f3bb5accb830379d0": {
      "source_id": "3e7d25fba914fb5f3bb5accb830379d0",
      "quality_score": 5.5,
      "quality_tier": "B",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 34717,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "LLMs May Find It Hard to FOOM"
    },
    "e5964ce46be4fcab7588cef4eaf2a955": {
      "source_id": "e5964ce46be4fcab7588cef4eaf2a955",
      "quality_score": 3.5,
      "quality_tier": "C",
      "signals": {
        "source": "lesswrong",
        "has_authors": true,
        "is_newsletter": false,
        "text_length": 2271,
        "year": "2023",
        "has_tags": true
      },
      "title_preview": "With or without a scratchpad, Large Language Models can Strategically Deceive th"
    }
  },
  "tier_summary": {
    "A": {
      "count": 1166,
      "ids": [
        "4a1054779386836e2f5a0a629d4be60c",
        "2a9728dfa4edd6fd4ca83f5cfc73d0ba",
        "2831a92843a5e4894e843a5bcd863a02",
        "4f40d85a64ad679498eb38f70bc0f0b7",
        "867cf2251f9d32584e34aac6d9e2cda3",
        "2ad044ccbe86ca04e11cddcd42ee81aa",
        "6192ac5138b95d9ba7a6e15955b6639f",
        "d2248d916a22dd163258f77e05ba1cb4",
        "713254917f596bccea593a4652c31de9",
        "557bfceacbe79950a26b4a61c3cf31a4",
        "839abeea475aefba4c831163a3cdc59e",
        "bf605e3eb967ec3033dc26177fcf2dd9",
        "a69c2e99982903599f1ef0631a8d5b09",
        "42706567777fd6de60b6cc7f293041bf",
        "26679affba27c26529db833017df9a72",
        "68b377556f43831964291a398603458e",
        "3d2e35721e7e6af2493c419cc2c3365b",
        "e0208f404de76bd7b5b21d897aa45b57",
        "dc62ec723cf1430d839c54a149073e76",
        "56382c60c6c3e7b0d8f09fbe4da7e390",
        "85d693126567d48366b4cb6c0adfbc03",
        "9888ab8acacc8f4a0edc876afb49ef59",
        "3bc060c075113a3acd60bdc9fee45db1",
        "ac6144846c25f722ba9b2bba77ac908f",
        "abbee081bc54481999271ce83d546e3d",
        "d83deddb25098692a2b5bb7c85a4b94e",
        "f0e7df67a2fa5a4543ddfa70efa5b668",
        "5bba428001708f8d96fcec39f81d9810",
        "259e8b768252584d63d8f7a6652637eb",
        "1781dfeed21085a6a7ee0a0b68749e3e",
        "b61d7e33ba6251a41c6c156ef2e639a4",
        "7e5e07b1807afa4ed5462f42b26642d9",
        "cab1fd1544e648fd00584cde4e2007e1",
        "9c5d157ee6114e5f0c16006da7478fa0",
        "0de42c1e48b1ed5251f903790c642a3e",
        "bae9f6db20a311d37cf63b106c587304",
        "901b2797a974e58060ca150e820104fe",
        "caf3b68cdb1358556df0c374f522f8d0",
        "580086687492613b7515df11cd314efb",
        "cb0bea2dbf3f6dba4eef81703a81cf38",
        "1f79ae6b4d4c0df3339849be9199cfd4",
        "8a86edf03dc7b48ac1e14e8e763f0b2c",
        "ae99d6d74bc1c08e015eb5238fb4d718",
        "9e9525f3735aa4c6e6e545e673b0de84",
        "c5e91218315409dd2b62d5bf047a0f3e",
        "0ef3ae9d9df8bf40db98446623243249",
        "b6b762b2e10ccbe99dd3fce5a97cdb0d",
        "45ed72f40204d0dbb657eda01ea55146",
        "24008e5ce4a89c6c59440f9f964cdfca",
        "bb3ed7bc24be17f9113b3d56eaa37513",
        "21267b4187d0fc7eb4ab752aaf89b0d2",
        "2030b02686788da3b51878f5c01a2df9",
        "522f7a056dc115d329a63668811cb659",
        "a2c958c9052a7d8d538e5a00f047af19",
        "043fe6dc0beaa8b2568709fcda4eb27c",
        "62f122481baeefc37839452c033b625c",
        "30f1a7a1789ef9246894978888c3b349",
        "721ce41554be015d041a7feee9e241c5",
        "acd42e38d07345ab51f01dcc2d0b38db",
        "e20fd9f7d083bd38f5269711cd12433a",
        "f941eca7326ad9c4cc771ae52ba5abc9",
        "c5fc3042c65ffa8907ca5bdf23f58f41",
        "779a2317c0abb60273c9386a7709371f",
        "9c912055d2d387eea03c6bbf866ee7a5",
        "c92e4d9890809f73dfdbac7f58100d2f",
        "59bdc581d12f5d74d4ed64335e3dd8ec",
        "f9427d97b1de83b720ad86f95bcd3984",
        "408fdf74dfa3936ad822ac8a9b94b385",
        "44db885f14f4567f72154fbc506a3380",
        "02d29384d4f1acc9458c26dad3e8d8e1",
        "870cfbdf19d603ef0501a0241321a229",
        "a8daf511a90c10f666ef32399e8d2a51",
        "71e4b5b262c8176a5bbd4fe79c068215",
        "f7b6498293e5e00f72e44c8bc0425f72",
        "b7eb706ddf3fc687cdf60148a631401e",
        "6c1540dbd5a19818cf1b3df4f2101c6c",
        "d50b5ef4912f0d1aa4c7aa536c8b740f",
        "137bbec0e331870d3d466b58da7f706d",
        "60ce6df24e15aa3fbcafa1dfa793cd47",
        "0a524cefae2d947063c5c78a8300092f",
        "18f8987e4b8187c656a90cccdfabe6bf",
        "e58ee43c60372af136cca9bab0a40b9d",
        "52818dc9c9b0ec8ff07188cb0370ed9d",
        "0e3cde25cfb8379f8939ce496f2ada1f",
        "66b16ddb540dbf79c7963bd85697a6f4",
        "ad7cc0e44a27d325e9114a161fc7cc30",
        "13c24361877d0d2f290241ceb8da15c8",
        "f9434e9f3ee20787531f59b411ecd12d",
        "f2582a779889fe2c31fff53cd6859b17",
        "d3a402637ed5f7a2997b5e788862f6c5",
        "8d97dd0f7dbc55a01bc3e78473bca73e",
        "3b8e895af2010f42738083d679a2e50a",
        "92a5e7db3083500c6bf32244c23bdb93",
        "c66e65c42875adef72c388edcafa5eae",
        "0d235ae393c51863c6308726872964cb",
        "71ea3916b563f9c45c47c16bdde645c8",
        "5cc4fc269b34b5b6b1f592e7b79014f8",
        "f1216e608f8dd839d2e88816f23fda43",
        "319dc219983bf377a60116c9f31ff29a",
        "c50214c8f80f3b4095b8afe83d047c97",
        "ffbaa6c6637a57a216c019c045639253",
        "1413c089690f9c7066420e31ae3b76a7",
        "68473420afe61cd854f075520a1f5cb7",
        "07f0f2a80bb55b2df9de2c2129245ad5",
        "4d58fc236181a582f1daeb47956e4ad2",
        "2d7d2d0004b786679678cfec274aa018",
        "2be3bbe1029a6ad6235888b8d6c29189",
        "ec316c9e111cb696ebd078e8368e87ff",
        "999fd36ceabc972b84a58f24733406fc",
        "100ba189bf0dc01a921bdc8cd245b545",
        "dd92a06770fa00e4f80be247dd90ed59",
        "21fe8264295b133a2f69396a25c13a72",
        "6a8d9093f9310ee68f223417d1409ef8",
        "92555068989b194c19551823acd9be11",
        "b750fa887406a8834947bcbfb4af7fa4",
        "b1131d9d90cd50993fc20955aec24c01",
        "2bc37a9bb4a9990532da320e9bb1731a",
        "2cddd5559522d63033dee6882eac8238",
        "aa96e047b272d327b3f4f0482e83d282",
        "ba8057b3b54d04c0915585918bebad63",
        "c8093ac4da9fd19b5eda6923f84962ff",
        "301c7ed4b11f8ec0772b27961098f70b",
        "2e2b27a6cd1a3469f83ae94cc8cf65d2",
        "2cca17ac0cccda95db666a3539a070b2",
        "03dacb5f6ba0911a12ae607d9e6b2824",
        "235d4287bd5bc4f31d1d838ba4e48ecb",
        "ff9aa344fe987ce15f4521f145c7488c",
        "14670c094dee4d81f48f5d7ff247dd71",
        "078647ecabd0967199b33e371b7c0166",
        "34d8f5ef5275a7d8b02bbffdfc308ce9",
        "39f0309e9578100dcefae1a10d3017cc",
        "f8a26d70a7cb3ec9206f4f3e84cc159a",
        "f64435dc982350b15034a68d457c7446",
        "a52b988d2135f29986a05e830907945a",
        "8ba0cd4cd001a53e9526016491c3845d",
        "f27415a8ea03c98fce1bff903f76dbdc",
        "9d9b44a5a161898099d0e6c6063d1959",
        "1a1dc45a67dd7af20cdaf83b6c672551",
        "5b3fc1caecb2bdfbdd16fbffc23096b1",
        "241a89b020f41ca29e68b27e3787a6b3",
        "edcfb7b14bcd019f01ed28e5e9e307d7",
        "ee44771acb20d893238525b687082625",
        "3585f4371df3bbed5bb38a934723aa8b",
        "f219190c3da3ab10fa21b8b0f3b3f77b",
        "f283b89018a0ba9f0a18d5d57f5a03bf",
        "aff106819250bbd2fda234ac03c836bf",
        "86930a39f73f75bf6a1a7439ac8585b1",
        "19f1abcbac7010a11159da9709aef14d",
        "f9b3c39fa45299751448eb02e0f62e10",
        "347aeee287686933b139cc41d2c6821d",
        "0475b257aaff02e46ebf334dc623b968",
        "b489d7cfa3b043cdd54a644aa2cb10e7",
        "2731015320ee6b204aea7a9251f923a1",
        "45bb5f743065a655f55c40afdd0b8c94",
        "30d197f2abc4241ff2e83d3701c25509",
        "b63f209cc6a759ef2e075137c82a818d",
        "f950f006f5efb0120eb9dee0cce6e6c4",
        "50eceef4c4b20c6eb868b1193d898439",
        "90b5d7af9f5da8bf23e5e5b257801a3f",
        "7a25f9dac2f07281da16f94325ffa083",
        "e10bd434793cbcb959da40a40b8ebe69",
        "fd1a8691241568fdea23389e94e6d488",
        "42b5c7670cdc45c040d2a40caa773e27",
        "919161b4469fbbd27a582c674cfb5ec9",
        "c47368892bef3139e5e80a2c8c846521",
        "96cde62c4dd6e7be161f0df82b1b1e83",
        "4b97d1dac7514262eae5edd5cb42782b",
        "0ab857cd2ee86671502df2e380403f1d",
        "f5844f3a6e4347ca877dc243cded9814",
        "9ab3cecfa4c1951e55b7e2a5d128856b",
        "2fe8faa00c606c51a8a2c3b46ab2fd84",
        "1bb63b4bece57ce3ad8319c63c479e7e",
        "83849de1b9cb57cf72aef0469b6c9dc6",
        "e0cdee14a523d8d2dad74cb1d271241a",
        "047b16216740d354a2ee5d8d7e21144d",
        "4ba32345a0367d2bd3b18a59598528c6",
        "e551f77f4bbceddcfccc7e010d960faa",
        "6353ef31023a168ceea35bc577748baf",
        "2ff079707f38077331526ea3ee5ce378",
        "aa9a7266e2a3f6e8f34d60effc31a650",
        "5d45e51f2ea6d22bdcb9d30310c79a00",
        "7775b0d3b8cbad1703c53161c4e12115",
        "8e8ab37d7a89166c80aa3ca36539e811",
        "0b830fb1671c291a00adc2516fc8fd9b",
        "0a1c13b3bb93cd641700d3f269e30a86",
        "30334862e967a2341fef9742c2e699b0",
        "060a27387c4518c01b642d1e5bb387d2",
        "6d55735612b0d6459ba51dc5f6d07b5c",
        "8921c4e2df86ea1656794ff5682c1f63",
        "a2fa77ab4077cf22ca4255482ea069af",
        "3514608b30257527e6af3fcc3acf59ed",
        "fadbd429d0fa7b3ff2fc4e373dd95b00",
        "82972a89dab65e8fae8f8521ae4a290f",
        "669a2a89fe0b6b8658602a2d069bba39",
        "3d733b9f6a6b6091cb45b2bea11e5c93",
        "f48be4c3fb9d9ad0592fb15af644c0fb",
        "855de84aa73b3e514946a208515b7694",
        "4f0c4f943196c1b6b7b663a661ba7c0f",
        "59f6f938d8b690b2c9ee1a0aa314e35a",
        "73478b418cc331431af728c2ee6d56db",
        "9bb1056693c6746e757975141d1574ca",
        "5c831da76432b236a058fa254d49b1c4",
        "6026676ef70b61b371b5a8945a90540c",
        "d2f51e0350d3522167886b4f5b8d42e2",
        "6c033586fd63cd2eef2c414f74b9d305",
        "5223826fba8bc976904ad4b739288025",
        "135efea1cd78b777ce408b28bc082fee",
        "623d2a613c808d33657d2068cf143f40",
        "cdb5c302cf99a7be2bc503ca5fa99588",
        "352fdb904551171a1a3031f5b2c0e608",
        "fae8082a3663346be5c37dae351c0c1f",
        "bedbb9cfa9a577ebe9376c55927c4d9f",
        "e05f8c3e7a81ae955fe7f37b1972e757",
        "ecfece2c5b40a7df6a174d6db46cc72e",
        "f69600bf4fb8749b09909298aeb68f8a",
        "b09f079287d7fbd3f53897adf2ac57ca",
        "fa408ad6b951e2be15de9bf172f8df04",
        "01422b8e083200ef2cd47b6d3563f6d2",
        "bd414a44f110c5bc6ecba9b47cec694f",
        "894271b0598a47c63a47d1833d6a38fa",
        "6311d79b1c153e4a7a4ff3fd932f3dea",
        "79c7fe8d20495ec5f5860550c56b661b",
        "fa2a0311913b34e3d5b91dcef29ca7ba",
        "646147045c9c2ce65458a1f1e812740f",
        "a0da85a1768c4325dbfaa2fdbf1883b4",
        "44220c5f671b2e284c3340a64342c7fd",
        "6e217576bd92ec66a88c9f70b6e543eb",
        "1cf3dc49f86f8b079cde5c3acc994861",
        "2869e3c18f717d2825bcfcaf13294372",
        "160879eef4774db728ed3a67ab6c61c0",
        "ca295111ff1ec76d23bde1461f348b31",
        "ce9119bdee8da16b4102a973aef0c122",
        "424bac6c22c04486793dc18858eae5d0",
        "a644f0a3cb02d2e283987fa8cfba14b9",
        "98c0ce5ebb1c5dc957312a2c12f1fe5b",
        "6f3bebfdf31991d1bc7dfe03c9d80208",
        "cf093524c33472b7d2bad652d87a100a",
        "81e89e9c2a18756580bd928426b5f834",
        "3ff44c4c933a57fcce7aea425c095a0d",
        "af691406a00ffa9a57a67af95ece6355",
        "d57f07c9b5b2fcaaf48688e0ff97466b",
        "581e6b835ead35ec8683f2d00738203f",
        "bc1ffc64424f8b74fb6d9aed7120f82a",
        "a7adb7958fc7de7bc480d227f96ee174",
        "c45a03222f9a2430fa33b561fa6d7b58",
        "1b9933161043299517ce7853c55d4f35",
        "8d6bfe9fd2b3c4557965b7df7d48e12b",
        "74d2bed93d6eaa90f103b55a9c68edec",
        "9e6cbed97f1b3bc35f05d1c30d23f055",
        "b4892a585fac1e8ce7515129da55504b",
        "5cb441d6c32c9e98786b25a7848624be",
        "18f734504931d5cf478ace5a8ddaff69",
        "59be6f181258141623388beae3f3024f",
        "f699ce072a0d412e90ebd7a2ad07eeaf",
        "0da8cb466c437708553b34cd1c225ded",
        "a76d89c0283d4a2edfcf38bf651500ac",
        "9395c3d0914d369d4e9a4d55112904d5",
        "0631100f62ec42fb8eeaaf52acf7081c",
        "a4d7c73ba1684f7f17c1d58a1d0edad4",
        "84120dc4b15ae3897b67cea93e572e1c",
        "eaef206260f37f45a1e981ed388d5161",
        "26323c8f3a2e65098b8b69701e99db23",
        "3c7ec65d65c787492d9f80fc6540154c",
        "218ce086ce67d5739ddde8794db7f87c",
        "cbd42f5f1fdb1a3bd6edaad51406e535",
        "dadd385d71c754d216ffda1325140d24",
        "62ef0e364eab59718630edc0016f83ee",
        "c171694c2a004f27a32a583c0ed8db7b",
        "b521f441eb2544a1c71ef1683ce417a1",
        "2693c7142eae6286c2f17d17b5435a70",
        "7f8331f6c517ac35ef8f069317e4374a",
        "3f1c98bc443cac76d1c2dadc2d1dc290",
        "da2deeeadbeab0866eb3a993f88f48db",
        "53c3414e76f6b1bcc506da879e7d50e4",
        "441024d88860cc5552cc12869e401a7c",
        "31a5fe3f499ab05b2cf59866600148b2",
        "a57f6329c975e596dd8713ab7ff5f72f",
        "0a11a1aed371713f1c6e9cd580feecaa",
        "50e653fce3d60282155679ae4629da1e",
        "aa2a65a3e15dd26da0af907a5ca3f7c8",
        "cc4d70762dab69e18daf8c5ec854430b",
        "b6f519be57b453ca6a68621ae7b0b805",
        "05f9af1daa2926cf92fee0f088a6f5ca",
        "4d86e7039be72db776dd12d767e5f1e3",
        "022a0b73d5f487fae44178bcee6a8703",
        "ea0d3cf025dcd15408fd7876f15bc655",
        "ac7c2b65f2dc94f98f15b5809da2edbe",
        "6473bf92d37686f5ee1b1c1b8d9fbfed",
        "6e0f2c882ed2ded9333f20cc47412966",
        "ca9b96625c777525c419959f2af82f3d",
        "e413f8bb0dea4865235e8a2dc0f34bbf",
        "62048503a42e769816742a6e31cf93e5",
        "4c1601e7b988fad5844599c6678524ce",
        "f9ade5d3a5d6007790c5f35affa0d28f",
        "0b1f4debe314fa2ea7476d73425a6120",
        "80458dc82661aceb9b67ed0e0c31ca1c",
        "40199422e213e4674f2b87653ce8663e",
        "43da39bb4352078c85659806a2a487fc",
        "70b81709b37af2f60fb175073d836d0e",
        "380bb59b80887c6e766c66477d82370f",
        "c328090bc430541575f05eb6ea8418f8",
        "03b945a38102e0816f37dd67b7e975a4",
        "27c6059e550e8ff65617559023400b1c",
        "8fad072693ba66f91ea02e912436c655",
        "e66bebdb252a6220eda22876d977a84c",
        "15eb203180cab2f1b3c05f723a37f90c",
        "df96fcd4101b5279b55d051013e57a44",
        "6e27957f99ea08be41b331e52e28515b",
        "32193b4c5013c697aaa495098f6121cf",
        "5249c85b08bb42cad7baa16536c30594",
        "43f3d019e5a786f9e13ad48165961649",
        "88857fbe01e7fa536b3546526a91b7a7",
        "b990438c3d2f4172f63ed3fb376fc7ac",
        "b344183bfa91e6390d52521000889e57",
        "20e257a61198f4b85412e3111d39b638",
        "f3ed9ac8b53110c3f6800e3db67e8dfb",
        "02cb990df1910ff181c0ac70d969f3c2",
        "122063637b044550e340b44b05203408",
        "c07dc0e7916bb37d8a25132e2685d02c",
        "26f49ad8f2b64b02085bf9211104583b",
        "481bd6001ca2446636547dd0484ada51",
        "b743fa8ab99bc9f240cc52c50dbed97c",
        "386e990bbee71f34f9331846cdc36a84",
        "c8c6e6b65ff731ba4dcc96325494815c",
        "a8b94f643fb93c8095347c9e7f7472a2",
        "fef5f9443f14647102b30ed036ee471b",
        "9ee7e2ee3bd5913087d23cabcc3082c6",
        "2f21646ae78f5f10ed77fcaad20e4eaa",
        "d3e76392f9627e93fe968970ca175315",
        "0dfde4014fcd105b01e35bc80e2c8f67",
        "964be84536460180a9ffd3513b89f304",
        "5b9b42f6b9b6a09222b6882b91115c5c",
        "15a7dd0611e9002e7e9a0142d2faf3b1",
        "d41c93555f5da094cf7fef12df27bd38",
        "a26655f80e9f293214e71c18243aa6ec",
        "3a9a29b53f0b3b7e81e94cb652ebe4af",
        "81a46f2c0a82c9ffc3fa5982e4dec3d3",
        "42e2a4ce0af6455ab611ff9d90231490",
        "71844bc4a557c4d12fffc882003fc23a",
        "16b35f91b280207d8c17bd0b5e0493d3",
        "ba7514433f5f71f0e5ead90b6fd6524a",
        "058f69adbea22c2d895c56cf69f3df24",
        "2fd7f04f95ad51715e96693da14e7dce",
        "176a4ddb834e0c5f8c4922c7f6406ba2",
        "ca4584e9771465a220203544ca9bf1e4",
        "e57df4802928e8e2e7509e33bfaca007",
        "9330b17f4620fb2e19e5cd076527a7ce",
        "2fd3950d429dc65a41d3ae55ce75c11e",
        "2b4f7f998245e2411e5495426874fc24",
        "533541b26e68390c36521119379d06e3",
        "a18e21777c6faa10beb3e9c24f616c14",
        "4c0cd90e3924e3412e7825dbcc6258e0",
        "e62b5fe6bcdefb18020c648704d5ecc0",
        "db7e00145997644b20053d2a0432071a",
        "aef861ddf773883385b2b328babc4173",
        "402f917ef1f85b47c506866bb78d84f9",
        "db731640470abad78ef709a530ad95dc",
        "d0d350b2ac6e04b80d5870a09dc10d04",
        "26e147e49fc695c92311bc2395a9e663",
        "beb12a23a42976450182359dcde0702e",
        "0e186b0d516bdeb5605722bc5e6c6948",
        "e434ded2d51769f0242d251fba5544f0",
        "90075e5d06ca1445c532c2e9d7e2b9a2",
        "3f2a112d14cc408019266ba6954d54f1",
        "b995fa8df519db15caae77bb73062d03",
        "7cdb1233cf82deb93064bb2177ffb77a",
        "01e708118256c8679df0d69f97d1af1c",
        "05f3a92ca4a98b9f2206b81662131b4a",
        "08b82a9d28b9a5af07a4dc3f8032b3a5",
        "a8804756ba4b9e2cd91deecd611d5501",
        "b05147510dbab92f01b5919f178ba32a",
        "37ebf1f6d3262bef36a49ba6b9c7eb6e",
        "36c9d30e5926d5154a0f11d59964839b",
        "9c87c9876c628a0d073b186134baa08d",
        "a69b3787f140388f5d62a304306d529c",
        "1d2c96ed448dacfcc360262e81f03e3a",
        "a2adaf3e37e06221a98ef9f488cf1743",
        "fe539961451698cb4301a12d094dbed2",
        "4776a7ac86b1c7dd7556b25555cf8e0c",
        "0a373355a323506a9a62cd9091b75c3d",
        "e5d9799933b8dfd5a7562ada5ca1a875",
        "fa6d0106af1c5665a81188e680c061a5",
        "b4ac7edad0c3c69182b211405f0b6188",
        "9bba061071a331e95bcf1bb58fab4549",
        "cabb1d4226057aa67da05e9a27e87cce",
        "19553eb276e20e1bea36b0eff216cfe6",
        "55b08e232187491f1a93b7e5cfa79b20",
        "4af897b4f7e8de9e446732f52ed7c827",
        "16e9dd5f9342483a8f7944aea1bea73a",
        "8c44535e5835b120beecc8031ef06b63",
        "f9f91ab90cec59be762198e92e3c7aca",
        "b4656685cd55f878c25512c54fce5843",
        "61517cf54fe17bd587b28e6d2c6bd513",
        "1ae584b18d1d3cb27b8f7da4f90e6af2",
        "f568f9a05f383d1d188dbed83de33efb",
        "8dfe174756251e0dc34b08231bdd7920",
        "266a1fefecfd5b204686ddce2ff10447",
        "6d9c643dc346070e111e011b89b0227d",
        "4e6e866ec66e13ee6a0eb816ebf7bff4",
        "2c321a00435b902b01d250e9d3350687",
        "7260b5451ca708a208e5c3b0819d2a8f",
        "486e51b6eca9e0218cb92722a407efc5",
        "ec9006a24eeee38c1528c90760ba4e47",
        "45fa4bad8ce1fd796f7b3835c1b8711d",
        "cbf09e13232824de9b9b3fbeaae7fdb6",
        "f3f72edbee43cb389d03527008deceac",
        "f2b465bed533cd9fbfab2e631f50f26f",
        "1d8c98b2b9f9dbab05957e92aa8c598f",
        "a9df46959c30e10d9aba7e5e093629b6",
        "9b07c785b4cee566bb90f482705f0831",
        "f39e06c0ba93613877b99ea3f9030997",
        "18def41ad9ebddf14f29e506e7df9d1b",
        "acb8ec6d2eca4a070ddd9844ffd23626",
        "5de2b48b2c1f89fb21bb09c8b0d58030",
        "3f342b07edb81627f49fa61b3db643a4",
        "8c5a3cc4714aba1a63218bf0c79cc805",
        "bcfb223ceb5af178f44cf065cdee9397",
        "a7ee381d857e98a8e9c68be066943f70",
        "423dcda046865535a079901768f2ebba",
        "eb20cd0d24a7d6850d36c21a96aab7ee",
        "1dc156388ea7c94a7c61a1352ee40af4",
        "4a42a1e94a9df88b4eae9a33bc1df6e3",
        "ad8f9548298ee5468a1ba59b120ac242",
        "18135125de8f50d6919b5fe9d7a86e5b",
        "3507b1dfd2ca4512a7cc8812569ce409",
        "0ea949bb15660a63ac8a9da71860db9a",
        "a5e4ac92c362434f205fc758473236b6",
        "1e39f0a284624af12b314836b846b149",
        "0e7d9ea18dd95c60fb274334a5aaf66e",
        "b7e2676767766152882c5bda31a9d97d",
        "8ac12fda3d81382980f33ad55338ce49",
        "dcd0a0556ebfc56ad048df9140c995f3",
        "285e08b9eeca3f268751d175ee7145dd",
        "f1558dd5b768a5226ec3044cc2f4aced",
        "8284c45318e073dcda8af159093bc838",
        "6963078acea43dbac5071b09cf57cb9e",
        "b9a647ad554c990a5507d0f57de0a513",
        "77b8610cfe330f24d522d19456f7635c",
        "01150a46b8a08cef7aeb36334350ab03",
        "fae9b2be0f99a17996eebfb8f3ee4f83",
        "e6d0c3b2488775e39e5424c24377dcdc",
        "d2386b5bab1151ae84700ec595a55c69",
        "46a3f714374e488dc70bde99ee3474cd",
        "f528c0b9ea26bd08239a7a6ad382134d",
        "361d1c2119b692fdf854e1f56baf2195",
        "94c39b5469e869810a0ce1df4725c8af",
        "8c6ea1b019a85b11405ab027033bdd55",
        "0ae9c9a9e757ef788b4ebcc81d147aa2",
        "e7bcd86ebcadbd8e0fcd441d97f76c08",
        "38dcb38fbe42141ddf07534d1117cdeb",
        "3dfc5c5b2dbf412a1a8a81d3e421c5de",
        "50e1a7109df31a843ae823ed54ed2610",
        "393de4ce26114b76507f296a0fc15512",
        "bb50754d1bf1a3e3ecfa531ccd2c25a2",
        "56272308af8ac1b88486e07f97cd1225",
        "d706ac5200178150cf7afc4796a43776",
        "53872389fe614b7b66434c6da39b8378",
        "3aad3548ca62dc4d17e328f709c06032",
        "294dc6a8d1cbb403dd6266dabb93b0ca",
        "05d065dde75a50551187da7a6dd4ed02",
        "f794febf4f9decf7520ca8c3574650bb",
        "87702a5b51dcf88ecd5171e67bb40052",
        "e8c73364ac5f27fa6128f2061dddda57",
        "d802a08e209a39aacb5429ec2af36745",
        "b4b1eff26b3cd1d9e6d19a0e0a9960a5",
        "25cf381fb83a38b6522457d92f1273ba",
        "92d190e68f6baabbd38db0f4585623e8",
        "4ec878851f211ef9a47b3098ba313493",
        "e303c3cd7f0d8ebf1dc872cd5bbef297",
        "ee8a49ce57bed686095bb065f529b35f",
        "0b2cdf50657fa90e00771003b9e3501f",
        "b4fccbd27d6e5e6a50bd85b00717a11a",
        "c618fea8fc278406af26612a96fc0467",
        "56d0c65d1754d56352bd1f6235dbcccf",
        "0e7a23bf62ca3f623af64bdbf973409d",
        "616a90eae506a42d5a77d7c7e9aa70f7",
        "58d2f516697b4e3af9a17e8e8a3bcdf7",
        "86d35e688b6e822a34415ac47896b7c6",
        "0dc012241e048d4d5f503359db502796",
        "5d7cfd2d76544f71b84bb2f76112550f",
        "c237d4275da9341e2530047697e75b6a",
        "ebbdc0ac967f34cdd47187b74c0f6814",
        "e48b8a2aed3d856e97cb63de14fa31fa",
        "55080c9319c2415f18bd606b82cc5d08",
        "52cdcc7c93c441569e3ddc1f92d999de",
        "eadaa3228b2bbaf98d871a0c244ae4e3",
        "efd2865183fd7466c7997b47e372ff69",
        "ad6d23e1b1a90af6bcdcd81088a34325",
        "f5b852a2a9e6735018d31b477424d8d7",
        "230fb9bb493fe9e0c8b38f82a6ee65f8",
        "f3812df783dc106f5fd3217400bc3be4",
        "10237dc02782641388da598c58bfbca8",
        "95aad70e56a97db653bf057ee4027c6d",
        "e25da3f1799e8a257dafb79d416d1e10",
        "d093b4fbe7c5d4230b6c4db99cb7f3f1",
        "b788e4590d7267be8529186617c40d93",
        "00ccb2340d8ada5a143e794408a04e8c",
        "44bc639cf9816b05fc3371889c0c26f5",
        "6eaa8320041fb81d270985de24dd32b1",
        "2da04dc77304832bf07ce53277a31364",
        "106bc20476a329122eb0262b7a5df3a5",
        "0d1bdcf29c07ba19a0a428ab6a519a20",
        "3e08a4bd71197293a420b277aa1f4087",
        "c54433ebfff783d782221de95d43abd4",
        "334413a1e3315407cc5d7ea040822e21",
        "6ccfec6178816685bb9aa5f5e8fc7e0e",
        "6c87991453243015ac3212ffff727cec",
        "8e0b3bede15d2844f624a09eb2f55d0c",
        "c7b84bc87ee9cfb76f442a2d17610af6",
        "3220cd2617965b938e4126aae21b286a",
        "cf6d86c6187b65515c75270394302627",
        "e02500165c9882ce286184172d1ad1c0",
        "191e09b94ec233fdbfb7aa23877a7f2d",
        "dff8aedeb662848f79bc90a27eaf8f5a",
        "913763e4d36b0f9e4d7d12502362fa2e",
        "beb53e03ce611e669108a73fc0145a00",
        "2fa1b68cb500bcd1bf76eefa3a22b52f",
        "9312ad006aca35cb95f60f5b08fb07f2",
        "f1a46dbfbe90205f6d7d41fe82900dab",
        "99cb587661c88b56aa49ea81468c8f74",
        "4d29d4a065f90b60d68fd63bd6e70d60",
        "9985528a03f79df7ab395d787a35ab92",
        "378d3427c0ffac7400092b06246f15cb",
        "b71c7e1c9618e211deb045c196821411",
        "7349535db7a4ab6a9ec3cd0a369f4d4d",
        "3887e5490a7a9880f242d7505634adbc",
        "1717dd816d939c979042176b5a004557",
        "59f90d6e3944f784abd2420111e95882",
        "715784c647249f72190e8326440e99e0",
        "a359baed17693d647b41f3135eab958c",
        "fcc1ea7b94857d53fab935650a85f7b7",
        "7bec26c394380c20518e354080a16aba",
        "e1dbcfab2d880dae2e20d8eee2c4a15f",
        "0141cd563881ab4f5cc5498335ded12d",
        "cdeea8d88c36ce156a4d0e9f8ca81701",
        "ea8c2d32c25666984e45793dae543f09",
        "5fd293522bc3b6b6ce0a980ce21d644f",
        "f0c09aed3d03e5275006cb2565d8ea9f",
        "73643a60bb86bf2fd0995a74ce06f8b7",
        "bae10359a6547ffdba5e45b9df0c3ee7",
        "7d73ab05546a6fcfd82aa9713733128c",
        "41bc4ce3496b2fe92fd57bb393b3edfd",
        "f02af23f63156be9f54dad25a690fffe",
        "b92f2e30b3f18ed7058d7b8eba660c49",
        "7b0d451e8356828929085352e215f289",
        "a729a26f4f765bad65dc0151c3ecf8e7",
        "aa2397b1dcdda034045dbaf26525b126",
        "49d1e059b5b2252b1792f7fb47553887",
        "96d146702316db2130833097d65c5d6a",
        "357c9172db62c1a56eeea59cf764267c",
        "f9ac5781faaed74d3e26472bd1a7ed17",
        "feb742285ce9f746cedcd7f73b797083",
        "950357c48af628620ea7265ca9713fc6",
        "b49589e94ad75d344a9c2a5305b8549f",
        "d196c5722d7015956a5930d50bbc52ad",
        "942a97fcf69f4e992d9690a156fc986b",
        "342c6984900004ffe5467063dbc8ec6d",
        "93b71b609bfa6bfb22fb3aa9b2634396",
        "a1647aa4fae04ddf206f1473ff6efda3",
        "a0c29a80d370bee9e8c3ce0041e224a6",
        "839c200889ebc513bdd5cf615ccac273",
        "349b721fcb4e01cea631d2b13ae9a0c6",
        "62e683d54a625beee14632594079b8dd",
        "ffcecabe153f9af6ee57bd3da9f4a991",
        "ef2214c5eb3122eb7c35d6a85bd07b78",
        "46ba239757968f3f4a8421e9a457b1db",
        "844cb18b7b1f087bfc6df9709bc4dca8",
        "56ff800292644bea1be30f18f97ff2f3",
        "e279806c12c8a6682a05f0a33c5aacb0",
        "577ffc18173d346a11c90cd1a1f861d6",
        "f53e1e0c49789ad663c2d392f6f2470d",
        "95b381a292b906e9691057da8db17d1b",
        "ec9b13447a3e2519a1e3752b9e389386",
        "1a84b206594ab34ba77a101bd54bdf80",
        "c085d2d1d8ede63323f432acd928c2d8",
        "759a6e91ea8575e1e5b79c948bf9f426",
        "4d68272ca50e9711e6f8c83ac804cc15",
        "714861efdafd1851c3f7f71989d97e6a",
        "b2ad8022e71fd93f6a46722dd4a4cb3a",
        "6843e44989aaddcc3d44fe9d11c0b1b0",
        "c515598ed82b0e38f43042f1abda5cfb",
        "3f5d47ddec0cbf30f633913932b9d488",
        "bb5283252d7c5fdc2b489cb390913447",
        "ae08d781c06efe3de684d4e6e8f576ad",
        "e2b71b5b174e59cc7bfaf121367dd320",
        "d9b74722526e4fcd13dbf56813df0311",
        "6ae1ff25b772be686ef8c0fd75dfef94",
        "38262fb2240896fac01b0db87dcb1b82",
        "ffb3cdbe1647ac78495d6f64df006a37",
        "efc0cd3231bac3feea8077db475167c3",
        "76fd04d6177fa7e4a6fbf85c305943c9",
        "2d0f8fbf5aa491553e23b73b106a6494",
        "6c313d37e8b148d6c69057adb3280c5b",
        "542736ebb8aad1d00128b39f55844a50",
        "464de48531ae3c80a92faabee44103bf",
        "315b5d43a0d58bb6e2f341beb803c650",
        "da0cfd50754b61801a17af771fae27fd",
        "7e373da22bc9542af1e24fca4f84aeee",
        "118b4f6716338f5b7736a9034fb5cc63",
        "9f93c053bb136fda9f6c788de50ac321",
        "9c44e9033875db80d47817cbec8dba9c",
        "0a76ecf713853808cf41547d4342fbad",
        "f9b16944b77e75a3da916261754db651",
        "226dad31be434c16248ac394a0fce33c",
        "7c7c5101e999d894cf598473be662dae",
        "aa42112787cbc41499c090721f1c03b9",
        "3983b42c3f367b5a9daf0012c37eef39",
        "aee49bba8b9aac67bb7daed672ebed42",
        "56829389fad04d54124fd47a7416b6a7",
        "85f393e0d24a929a33e4c2f1049af1ef",
        "e086e270e0fa1cda183f1a14d92ee0d8",
        "b229b98591d4895d292b9e5a694de11b",
        "ee653d87f7edfc977fb9cca26814fbce",
        "2cc6d95d810cf3d71b92851d44975413",
        "54fce49dfd17b9cfa83507f08a7c58f5",
        "0e530f67c0d529102e834063a922cb2c",
        "813db9ba4098d5fb4b2ddc0895b07eb5",
        "aa8c44de8cf70353c88770a9c799bcf9",
        "8726f32562cff5eb4970ce4dd019aecc",
        "41880a502afdcb9f299595d0399975f4",
        "d2fb125a5bdcf1e208a2487003e720bf",
        "ca70467cf934e8af009ebff45f0809d8",
        "62776f407519f655311008a8dfe1e694",
        "837f414b898df86918590cca683a9489",
        "1aef4c64a68bc52e6074ba825f1f9af5",
        "407a89d50dd6ff35530bbbaff199e89a",
        "97a6e556f7ea88f7d1fa5efe9878afd1",
        "36215638a79b3cecd93e87deee0d59b7",
        "0b8e091c821c1248912096d41cf720af",
        "a9e748f28cffc1038924c8a3d387a61e",
        "7d71464129d360de614a26734b6ae910",
        "cad61abb903ac95e2b2b98070f868ad1",
        "4ede69fce8724f7a4bd4199f0764b04a",
        "cc61b8282355a9715a9ed0882d3e1064",
        "c9041a9f9410d0e0b2d217c99f6480a2",
        "68da4ab0079db5203d58905d9bcae9d0",
        "a330fb6324994e695e44a867aabcdd40",
        "8fc7eef981a673d2daecfe81f1eb8f28",
        "ff56b064384bb82c28b1977f1618fb80",
        "c65b99f477ddc2a692b97080326405ea",
        "205e847060cffe5809d9f1141cb6db68",
        "71955245b24a9957bf6e043baa4c84ed",
        "12ae1fc6cb0a054e9ef921589995bc69",
        "411295d672508f9356c6ff76adf01066",
        "c52390c5cf7e651ab370878d7f885fe3",
        "f8f35509051016e1c1b72a86c8339381",
        "d1469829e90fd39d090da256176b09dd",
        "f0c30e26a6a5c846b704c41a0da9ceb6",
        "f0761751cbd78c674ae07f234625b21c",
        "038cf60b42288177c5cb9a386f5f0266",
        "e194d39761efb0bc3c8e86dcca0e544b",
        "4b80438954bd57fdfadcef5fdf71e631",
        "c86d638a79093201bccd9c3e9143f311",
        "827b75911b8bf55aff890e0f750f937f",
        "da59e3fffc6d024a2b5e102b64502912",
        "fa94eb811e4ed6f48785234381e8a61d",
        "81d6196790eb7f2fc6d5fc43b5d449ce",
        "1aa18a5cdb5e7320bf1775144de3f08c",
        "d66efe89f7edc9c798b9626524d4f891",
        "568da857b5fce82c55c2186ea9e4ad26",
        "37c071c07d3ab37d154da7a8274878ee",
        "398f8d39b2bd93d775c118b74596d8de",
        "2034930e8b818514d927fd04cbe8ed89",
        "f92a4eb8634567a04e48c3858c7a35ea",
        "2f05d4ecf6a6e80f936e32bea90e54b2",
        "8fb6f61cf1e07a5bd68ae56f841ee0b6",
        "1dbd17639184d9aad73547f20f4e02bc",
        "0530e7dcfd24a85db0a160d66986e159",
        "3d1babdf4c39457041ad6638196a327c",
        "c3fe4405e8d21673c4200e989141782e",
        "d9ef3d1c335087535791133204004d14",
        "e0f20ce2810fbb03e95833c6e3aff86d",
        "cc24dc9a9485949057e532780b322613",
        "bce64cd381cfaef8c8ac7f81d0b1bc59",
        "08f6fc9e4b21ce87e5612e5a9fe3aac5",
        "87cef25502a7208a08d7982e414d1ba9",
        "996788ee14c025d6976db4f937b7b9dc",
        "bf30366d2c83852331c4d5275f15c51b",
        "e7aa7614cdd5882a2ac01fd0bef0acd5",
        "24824a8aca1cb4f169e5c5afd1d925d8",
        "12d4b77ba820650328a66f9c1bfdcf1c",
        "40b8cefc2fc84f5a3237d4ce204d2acb",
        "e2f6a639eab01084ec7e0f76673c92e3",
        "5f679aa5f67a93ba59a8e9c8281af336",
        "fc8a8d2a6ce0ac6b0658ef6b282cf97e",
        "72206017b1892b4eadba657bde41ab54",
        "b53638f9eff11ba5b861edf394b8addd",
        "a15c6ca1174331707173dbcf21fc54a1",
        "a20e7aa50600de9a7811e920a3fc5b14",
        "16071e9e4803e5d35d76d898117df2c8",
        "3673d000a2f561d403d057914c6a0fba",
        "813257bd6020c6436bfd74af92e7044c",
        "4ae4bd88689053a34a21932c4cee6b60",
        "6b2e6017f5a03ddce8d9c629f4bb4c32",
        "1cb7117de1a9757a88adfe9a4f8db0b6",
        "cada59fae9928dc643027aa3fccf7281",
        "ade5f50f2414624de91669067bb2e6de",
        "41f01220cbd1248ed9e690314dafb6ca",
        "49fd4c87928829fec0d60f6258537895",
        "013103aafe00cc7cd75a562d9bebc30f",
        "a52d7e463ed251177b52686e7428a683",
        "eb041408df75f83a2e148e47bee0ec16",
        "8bd5e5d8b24864fde396560cd272721a",
        "b9f4aa2968038b7d64602b63cdc934eb",
        "df249401a5807eac2045fb9774bcff48",
        "ab6a3d0259d742188cc5db00faf891c0",
        "81938f6faa998c07c6d7ff5111dddc8e",
        "1ba9a6fd67dca3f83480f37d6a86fdcb",
        "d89dc844516a9ac02e01b504b89427f3",
        "96251f8fa8c416e4bcb044e7d9e74196",
        "819170fb22a3fc275106d95277eab8da",
        "7d0c1226cf8dfc6c92d542d55db67c13",
        "0a40d2de6851709b88321bb64d77e4a6",
        "51462a55534263d1947608fbc3e4d9ef",
        "40adcd148ad64c639258cb6501b2feba",
        "311e5bef699a091625a3d1296b228fd2",
        "ae1cd229c3a155b3dfd0e6dcafcdb8f0",
        "c0390431ab3a215a3f4cc26ded0043e0",
        "dfc4726f702c6b413458d237cec85e99",
        "2d77f5b7adcea3e2894cdf4f02ab6b8b",
        "7d06b53a7df5e114f681ccfbdb97df41",
        "f1853376f2ccc7f00be031224a4be5c2",
        "583c6e401e206e4040db4b5538838945",
        "bfaa915ab1de8d52588c4ac72b59e731",
        "b6618e5296fd0bba272efb4857db70ce",
        "8ef5690345b73a743df15a558ea00844",
        "490dfc6810f0f52ebd4d2408e4667a8d",
        "e1689a1cb524a05d91cb438338f99d2e",
        "84fc757d197d496d48115712641d4413",
        "4aede7012db72353b00aed02610dfbe3",
        "a0402d3a00d97e1ef8fdf756457d1fc1",
        "7cfec0e7f7a0495a698449ab0ce02fcc",
        "5d8d41b153d13a07ae64c039e96fd6f4",
        "0ebf56aabf1e884f7b17b2c15bef9f65",
        "7a4d122a4cd5209895b35ae56a0f877f",
        "12c150d8843037ccd13f8fc2e07f2816",
        "a444c76549f57bb1172c5b8c9a1dae55",
        "5089b9ff46e9fa8a38f1e3a690398b44",
        "f95f04b04ff7a4b140b3d8687ce52165",
        "1f18fc5bb4cfac9854827d17db56b89b",
        "7aa7add91c4d9bde714f10971f2937c3",
        "fc1f4ca4b9f0f52f0aa4ef8a5f020dda",
        "1971dfd835458fc825a2c897f3b04a74",
        "29912d5e770917b0e0ab6c5a2649c725",
        "9588974df808d2b183e54b38430c5c51",
        "28785e694de9fb37dbd4a8b9b0d92e0c",
        "c1201a83d177fa631e89a6d5fbc36d87",
        "77f8c55109ae4cb3886681bac6dd6ac8",
        "aff90061d03fe488dacd3c35f4c365c7",
        "50f785472f9f981759bb03991e5b1643",
        "2d5fd096432bd8b9f56ee0826f75f872",
        "7010710588ce3649be49076da7782fd4",
        "e918941f9bdc21408c0d04fd0b22f31e",
        "f3b2634f69a529a49c8d5560d8ecd2d2",
        "67acbfb8e5ef736598192ed5586d9eec",
        "14ff96fd6948a4bf59798c37b18010fb",
        "17f6f61338a0d2b08005d3b077bdb349",
        "0f2df22712848c03edc4e6eed0d6ef3a",
        "f18e14f67088d23c5a8275e213727bc3",
        "0e44e17c3879b66756afe3fa13309399",
        "20004f3f3339a4fd2d63ed6245d5b4d1",
        "b29568681c7d32279ac192f2aa579bc2",
        "93539db90a16dfabd0f5c054b1185c78",
        "6fecf371e716d4a0bbc3c7436c892934",
        "6b434c3af993d14bb9e0b3474c6b9ba4",
        "aed15d8ec6db81a2ddedc674e97fd57a",
        "6252189f483ff7ffa7478e2b3de119f2",
        "a112033c840b076258ff2dbd262f1ee5",
        "f1cf4d6f754ad5fe761a277650a4471a",
        "c0a91469fb17f17e98e77fca82a4af84",
        "39c7fd0f423aa0036d839457e6618279",
        "455b444cf51f7bbd0d6bb1fd9d2d1662",
        "0f2f1b0c49e943459b2b5d1a55c9d2b5",
        "9ad41374f53f74d9e1544c663c777e2a",
        "4bcb6e5e5420699a0b0dc34ed6e69573",
        "92cde803b8cb2b1dc470ec723ca1c4f3",
        "5585b20ff1241af9c36663ebfc5f0174",
        "dece29c717e8505489f1ea19cef5111e",
        "7b1fcae71ae04aa54b08181819ab1d71",
        "5e6dd6e10068aa225fb1418ca71e4605",
        "1e952d5dd2d90cafe7b6f166d1aa785e",
        "673f5a66b8253c075b43c350fdf5514f",
        "1405aec1edf8be7e9d05c85a8fbb24fa",
        "117d259472867be5546d128c227fecea",
        "d5d871f8c38b842379b2abc4ca2280e5",
        "e442648d2f9714c2ca63c57376d0d94c",
        "858b9038e0a18fffa0c742d763b09aec",
        "f78c7ec5be74c3e3d4048db6d46d80bf",
        "a42af15d067364d3cf40823a78a575c4",
        "fda9554f87844fc3f415ef52fa25ef4e",
        "dfe8653b4e58290986ad480e1846b2f5",
        "4383a47169e01d45b34bbc3cb82c2248",
        "2645dbafdafd63d5516d352df81a482d",
        "f9f624688935e74ff0ecb044bab69012",
        "ad62fda39f25ed183773e91e608c03e8",
        "590c3520e8afde51315697b5e8bfd6d0",
        "07c0229080ab239986cce69f8756c5ed",
        "37dde144c26b9e56b323eece60d135e9",
        "7dd0fe90b65c521004bbc3247712b37f",
        "b208fd79f647fe24573decb2bc265c15",
        "e27044932d54ad260c56dfa4d367950d",
        "173c85a03b5009b4ae8420e7e1b70c42",
        "66b00ffd67710860ef809f8f79f738b6",
        "232f0e18dbb9e72281bc79f8098ff6c7",
        "7065ba6b881fd64f9b13a53f2347a8c0",
        "f2ac3447dea6aeca87ec27ef47bc5959",
        "c9abd238dd2b341d1ddbf188bbc161f4",
        "2d9e86d8bb50bdb387be62488d4a0ce5",
        "a11519be70a6561048be6f0efca35b21",
        "030d3ea251808602510afd8f864f4fec",
        "a24b6a306ac63ccf45187b66d81587ef",
        "8b6e99864384b2696f368597979fd9f1",
        "8606d4d1cec21bda37ddc73d86aebc7f",
        "21f2bad360e8a7d2095c0303a997d179",
        "0e8afc013c84e4e740d4bcf89b1df551",
        "9f4e3db3a06a3c145e79b68e853a3a8d",
        "c6e1d26604cebcd7d181573dfee094ae",
        "21a3c572c561138809f7c04e6d53652a",
        "a5042b5aab956d77d2e18b28ac40b521",
        "0fdf5b2c39518e9d4970baa99364266e",
        "810e39a469917c9d5369a7044908f820",
        "e5379b568f77d362f6dc0d5b1068e2ac",
        "fae603fcbb9051d84ca0564503cd57c7",
        "5b8bd5bb5035743d08628ee9fe478a79",
        "da793a00734aa3aaaf8303cf295d9056",
        "19783db6de007b65d10f4ddf4c52fa9a",
        "1670e43adbfe4218fd7b37b67941aee1",
        "bde187870c058fb9de22311837aff903",
        "9a865c22fd02cd194c81db733aa6378b",
        "f73ccdf3c4176eb4eead1b5caa8df223",
        "75e887cfeec8a3e0b7d582e3ccd3c72a",
        "1118b36d97a0748c1ebc2e7d85f27ab1",
        "a262d9743e00d85523b73e9284559b01",
        "641ff6dee15b77cf2ed27c75d450a762",
        "13e9b257e46a73161a608cbdc1b435c6",
        "eaf0dda90bdb58bcf5427325b2de713c",
        "82d12f25322fcc11c2fa9be90b2dcec4",
        "fe1c58202b218fa622a3d106fc7f9b41",
        "40981833e4aac1ab5d23165b64a6374f",
        "2ddfc52c8f61abd0d0abe51b2f1874bd",
        "686b8ae940e6d7723afd773f604f4057",
        "5c91e99695035a964333ff57768fbb8c",
        "a3b00e2c7467d45bd21bd31a2dc0746a",
        "a99ca4e2ecd6377ec84b271d6fe50ca6",
        "6af2c5740e297388c912560e7914299f",
        "2294e451ea1f1e52bc3fbfefa14f4d0e",
        "f60dc3ec42354be607c544ba174b952f",
        "568f000a038e4bfbbfcc6c15ab68b948",
        "c81baef1bf42629d3a5589b13b0260b9",
        "d633e3343d2a7ddf57976272300d828b",
        "56c4bb5d101fa24c150799b4aad96cd0",
        "2315ba0ad7702ea8a2ce47bc77411cab",
        "f4a05e444ea709d5ea0bcf5778064c84",
        "3df04342ed5b89b25dc3f16272c3244c",
        "ab8ad7fbfc76f44a2912cd5d42a82283",
        "2715c5be751ae5c0f42ddb691655c46c",
        "8cd0e4f9e43b214ea3cf807ff5963a32",
        "db5b97196116c8434680b8fc34eac6e3",
        "1381c91c590639748c5f5f1a9aae4e24",
        "f84b0a1d30cf89ae9236ce82a3e24551",
        "1c1b01ae4d1233f4b49ea050c8fbc0fc",
        "3d6bfae31f2f8beca77dacf06817bc2e",
        "3f4254f317701007b2a5e1c3253ca325",
        "f3749553512e1b6699cae2a8cf8f43d0",
        "7902a1192772be3d4b2622e184c1ddf1",
        "73592b70a3f5a792afd4c896bf5148de",
        "838c66e61a6f18fb27673c2ff4daef22",
        "eb789c40c7c9d84c091b2a3bf6cbd920",
        "81cbec0f7ca3bf7ecaabb78aae5cad75",
        "b3ec07e1af2d6ccb8c6301bde1a1b9fc",
        "8b5c292409e3da5233abebbf0b36200b",
        "f3b63431438b60d2d370268721746c7c",
        "c356f4bb1fc1101d2792f15a9195db94",
        "dc43714b96ecfc2beed9d3c86b31c971",
        "8b4d803b67aaf3b9b730b8d8b0700424",
        "bf0ff25d784f63805e9cfaad183042a0",
        "1a828311da6c652ee1982cd7216340d3",
        "ec060a99eb4e8e9a15cab3718c650549",
        "d515617e558a6b73441a6e275f8849c1",
        "9c2fbcdfc8dd0ae51c75f68b0d04ece1",
        "399d1e79027dcec2e1f7d729035f08de",
        "bea3a247e8e516c2fa7b755856128a59",
        "a8f634af414f0b09e1531308ef324d1f",
        "44744bf31057f3d2299f555a35ca0463",
        "961c51700a43ebc088587388657302ab",
        "c4281a21a93e37ca7fab27eb832aea4f",
        "4b13c4aa7548bc21ee3e7e8f47a87027",
        "1e1f88201aaae570f63f28606e6cea25",
        "23e75d98b422f570e1eb7eb45a315730",
        "5ab3b57cc0401a5d3198d09875b1b3b0",
        "4f277b537530f3d03d70405eaddf0108",
        "915a21392784fa54b433d2c7c2e7c90a",
        "980dbd86b111912d8d645238b9eaa92f",
        "fe0dc44c3e878801c884a5dc6765b6d1",
        "53bbe9ae329b1987abbc8b68e9159e19",
        "4d20560a864f229ffe534516bd8a8096",
        "846a5ff7a4b4af28bf3e50c603553773",
        "12e5756a832c2c9c847282dce8c817e7",
        "82e11ba0203ce145e86dd1dca5f59a5e",
        "fa2dc7d0bf954de3a265c16121ddf115",
        "125feae2ca4bf463f35c9295c88ef1d4",
        "54c4066155dbf604844db8635a54fa85",
        "8712b809a4aca35ea5df2f0544b59b83",
        "57723e6c17d3c7a55ec74830949724f3",
        "1dd6134f73afc29059fd3ce600396f8a",
        "ab9d8313ec8c9ad6f27216a3c7be5aff",
        "741d13de2d731c54718d8d32f2fcc4e7",
        "5a0f56ad4bbd83a58e36718643c07afa",
        "9e60622ab79fb17bb3d678a848e3d836",
        "5b7385484d3a48ca210c6af18446df00",
        "c67c4f1f99a3acf3a069f3ce526661a8",
        "a836978dfbfc5b75ff3965addddff470",
        "6f54b171cfee650e8335bd851c5f8522",
        "2409da6d09cd430233253d14379b0e01",
        "7bac61f7244aa0e9fc77cef4cae4aeef",
        "a6c16cdd16ab2351d458b6e5466fd022",
        "0f27b954a6dd747101e314aab2942c90",
        "e8d31791732b0a204e6fc89330d57350",
        "4fa22ceddc8532fa986de05cd7e53fd9",
        "693565496a05778fc7eee68217da5e25",
        "499a4638a0e2f313929527a759d887dc",
        "3f7138172c9331083d2e33da97787e14",
        "f08658e9cc2aba173b0270450a412cee",
        "153bcb3b49c0c5980991b5ddc2228ded",
        "e662dd63bdddd44f33a2e99b3f9ac3be",
        "0dbfdba362459a9ed82f9ef4f3ec650e",
        "a8e7867b6a2746011b0ba8fe04b56bed",
        "21e5965ab022e732472e0cc3deda877b",
        "30993e4d225c18200c1c4a6cef00e665",
        "c4f47b8ec83a65c43d0e159eb7227f2f",
        "598d0f8ff5beacac441b919e5328e493",
        "79624763ad62f1602a878554c229b3d0",
        "89cd3ef79c4ea526deb2899513439fbb",
        "21e9aed4c6db2398ff3168a1b7f49d46",
        "9037f853d10c9ac10bbc0d6b4c7a747a",
        "42153d4c6fb5d1f9e9190ddf4b1f74ad",
        "0242bd9afee7aace1c8365b0891a40c9",
        "f86f78b8dda14fded82720f80c05d016",
        "782a1b8a0e048fa7a0557ce27c6d3660",
        "793b9faea6d52dafd594c76a795aecf8",
        "64e368da441409b50a472889d5c1323c",
        "7ffcd3b363df9e5be6093fbaa0220f3e",
        "cc87f8208703018219498e01b060e785",
        "5b89337caf817fe3bf2498d4cbc62b49",
        "a338ff49276e0aa0c71004d1d1ff15a5",
        "9cce57483fe0df92ae65dfe5c3193948",
        "584641e15cc07415351b5314971d36e0",
        "1eda22f5f61402faf20c6879ecd0ba35",
        "dfe1a69ce0a509449e51cd9ffb176807",
        "38b411043c9d563e311ffea3f704bf2c",
        "30a2c9b450475104184f57f73bb344b7",
        "9e8530cde437a62a4ffabca9f953fe25",
        "7add01516d3cbae17e16e80d51b46a07",
        "b26648e7d3c2e4a815769958b50d60fc",
        "085c7909f407e916cec67c09112d9d3d",
        "e346718357f748f71ab6a67053b319ce",
        "1bf0c3e8c1c8c32b13c05faef8d505c1",
        "559978de79b22f4e9cb495b2f1e8fbb9",
        "aa8dbeb0c06350dec4aa7a3ccd61e107",
        "26a97802b8567bca28a99747a360dd18",
        "0a23eb62707408963a72a990ad63cd09",
        "bbfdc27ddeb5e3a5034a1537bbdd1eac",
        "f0be2e561501caeb262d62b6d68433d9",
        "90c0cd83d6e802b52508179a2d5df310",
        "9f33f3f44f3ec1447c56410a2abacf30",
        "c2ab3aad4eacb1d85f62658abb675652",
        "cf48826b533745eb6ed820b47d2b1c5c",
        "c2aad946ccdea78f940f9346ffc84101",
        "aa17774e4a5a101069329c36cb44e0ad",
        "9b11f2b4d3a6a1115592ca626084d0a5",
        "49d0e9c54598d75fa9261f1db5d11740",
        "dd0b51c92f88f0b89ab01ce455d0cf52",
        "ddb3aebf3b13c64731cf7afd0adb26b1",
        "8b3ae15fc7ee249ede4fafa62097e658",
        "2aa314412da90693e49b3d4ec9194793",
        "274e0974fa7ce720b9c56b21e0a9abdb",
        "99047282a1efb81b7f85d595ae657426",
        "012a30b8a005a12c92dc57c8ae3a413b",
        "8ab49e34de5d3ecdddd1910bbb27acae",
        "75da108fdfb3106ed5b53068646d7bc4",
        "198b1d3db5f95e27c228fdb6ab458dd6",
        "033334e7f192c5e2613d97bfdf74e564",
        "004aec5c84faaf313f2c417c3ca1f25f",
        "e7fd702eb3083e3ef639ef79e64696e3",
        "9eb0eb98a9c8293993514723d424831f",
        "cfa07cf755510e08ccc3eb19af34cbd5",
        "4c2ae2dfba07abf80982a32a8dfd775f",
        "526a6e05602d30c0649c6511b99412c7",
        "c42b9740e6b4194dbee7a320a07166d2",
        "30ab055e127baef8b3a57ae55c24706b",
        "02949cb93049b82c9d0bc7d2e46c52ac",
        "a1e6c86b13e4cc51d58ab9bc2c127bc8",
        "8f0ba0c8ecc32b173170d1f631240dd0",
        "e00f358687aa7aed6e2cd1818439c005",
        "9fccf5af82caf9b8a418f12e506b0992",
        "36050c782f2880a8bd5ba7edffa011d8",
        "7b03a29a7f0a47cbf07d5714d494fd65",
        "54b50aa3fdacde8fb31743e0f8abd9f4",
        "e4afc38afe231b0e95bde9ed0254c7c8",
        "2e8b186e1b754281d64b8ec6021b1b8e",
        "f12247aaa7c5a30132472244cd7a26a6",
        "14e5b7d17976f40024339770e01ada48",
        "b541b11c1418c27e97d4a0e8fc03a2e1",
        "7461e158ad377f9a601ca14b858bb6c4",
        "88b89589d5046f885be5bd243a2aa2ca",
        "d4d01f8ca206d12f59ec2f66aa4de1f4",
        "7a97baccf2d0dfad4798e86392a5fd2c",
        "63f483a077d61ed36a0d5d5e8a69dd10",
        "84ae7baf831ae7f9b13289a17aecb996",
        "80b432979afaa87683ab82ff9fc6914c",
        "2e13a5b9014cb67119d45d2e9cca9ed3",
        "ea99c17bfb8dff90e61d3a535b430bb3",
        "2da411f3489c10cb274d7ba7fac229c4",
        "3a5dfe29a457d0e7ce7e32b2ed6e6136",
        "837ba9a1554593f146d6b076605d56d9",
        "afea29156eae44db59e5ffb24367772c",
        "7c0a2d679a7a5ca50fa500ac44849906",
        "d14b7eb102a079d04894de72e703caf9",
        "08f395401d44b67d98c8e0b3852a20a3",
        "c6b7c317d780f22b37b6125efcd7590f",
        "a045c0d911610f0a2f1d9135ace16df3",
        "90af76072fa913d70b1efa4c7df7720a",
        "21a5d914cfa7094f26eb3fd27543f996",
        "96a14c1f19757223183a72e4c629050b",
        "82a90bff040c2d54b56fba6248003156",
        "16f65dedc5d5f097b5dc1886cc44f1bc",
        "235c01722602231561a5e9f1b7b82f38",
        "02273093eda16115251a2b894460e8d6",
        "2d7eb828d04a7c931a2fabf74bd2a4d4",
        "7de0fab79d9a9abbd2551ee2adb587e8",
        "95d1b51c0ecc668428902cf693dede4f",
        "55d2ee5a90362dccfab9fdfcf32a0508",
        "7e8d35b265d75290b3909df69b378adc",
        "e61c2ca786a879c2a80ec840a55090a2",
        "a7a43764ffb482b60a4176ef6520054d",
        "0701f434e0267fd460a2eb6a766c5710",
        "1d30ff2c0b8a1b22074752038d18399e",
        "80f6a648f25568e26d778a80296ddeca",
        "eae2467f1f42e1149c7c35b8cde33bfd",
        "d6d4f93f29f8c1e55edf7becc7ff8a53",
        "b941110f24a934df99263071691453ad",
        "0cf68bfe04a22e301801931fd6a76b99",
        "c5965d6b11fab9ce379fd91572c35543",
        "abfd963c7afe75892dc401c0d1b26215",
        "393a7a93bd7a4f3365f15f1072e40213",
        "8c46e9a4bb322ee97d1486e6dff512ae",
        "5cec28567850124715e607607e593a7c",
        "3625591de24ea61694a0bfd620623349",
        "9daa7dac3bcd0dbceb42f15efdb2835f",
        "e30130fcf4ab2d1649701de9666e2e47",
        "5bb7ca04067a7d2f5404dff7607932f0",
        "8bea59ce4526278233f0bfa854c2aea2",
        "436ef00c5c5fad81706d3da1c133e8a3",
        "5388c16b3140305d5543cab810d3f5a1",
        "cef47b8e28f2ee300a1ad3d5a352bd8e",
        "04ec3ee050cc951838ba9c9b29c1f48f",
        "6ffccb173ea283dc97f2cdd3d66cbe44",
        "8030d671c8dc7618b4843fd6a48492cb",
        "96bb7a101a3081a55bd02f8f9af72afa",
        "267f825a372778dc9a7b49aaabc411ab",
        "4a6c4493fd0d879ff4856f38bb851f7c",
        "22c9d63fe77ad41859beca6a341f1d36",
        "df26702cd0a432a510db455b29f0ce1a",
        "c73d1d24858a5a5824f3f53ecf51ec6b",
        "dfe4f6e3d2c81f5f75ee666f07400054",
        "613fb830395808b0b266bcd0b16ff870",
        "d17f296dd337d166eef3b39f38b283af",
        "b8666a1c7c7a0192a345abc96c9efc8c",
        "7ddf442b31f9baa67bd40831bb9bd289",
        "a40668486fbcb879a3f83199cd0121be",
        "545c495f3af5bccccba7d1dd38cb8fa7",
        "784d797528d0ab874992d1190123c1a8",
        "8a978f212608a0259e0978afd6ca1af3",
        "be90c7a8998cd326115556a0993409e4",
        "9afb76ce70b2f78e188d1d207932044b",
        "2e751e13428ed9ea208eddd4192a138d",
        "ec61370a4d0d45f75e622218893ae746",
        "4891c64c19a1494cb57fb7c38a4914bd",
        "681635096b39624d8c2cb8df45778133",
        "231c1c7eb2d2254414931a02742325c5",
        "28dfb02c5189ee73bb02f80a540a6acf",
        "bd5055688c17e7010cb5c3c50b7b9731",
        "fb06d2ea0e12476bcabb14f6eb57f310",
        "4debba2925275e6339727785ba27f02e",
        "d33fcb4bef6132b8b32997a047b488ac",
        "a1abb2d6195be076e8925c3286b6f681",
        "ec04d5adde44eb5444b9963eb2fef624",
        "60f689dd4baaa68b2819f17b579fdae6",
        "4efe878bf48a28f377071b10b6587eef",
        "d88381ef1676ad6ad7c7e94ad753313c",
        "dfb9b33fc00b483ff506c4b172ed95bd",
        "c61fe8a59ccfaa311d231acaf9fc16c0",
        "8160fe2c96d6932f1c10491050bc4d8d",
        "fc3ac5affbf4fcc3ecbce60a9bbea8df",
        "168f4b8a7feb0cd70efa51b60482b8ca",
        "028a9baaa9a77d42694d3a19d33a0321",
        "468ea22f2d5cf35eefbf8b727985b25e",
        "71661b9ac1ac2caed1d0a125a6672a3f",
        "8526802e51962e60e9273040e4fdc8b1",
        "42fe28637dfe77307c08d568cd608ada",
        "ad8cc8c5ccb611d2311f2496a329b541",
        "3b0031dba3084f2ec86955f75357ed5a",
        "066ad11bb2ff28fa427ea8b7e8eb3d8b",
        "9957f33fc4faa8359d3bf67a9292fcf9",
        "a1cdc1892cbdbd73d54630e5957a9a06",
        "17ef6ec21f8407a5ff3f77b505baa10f",
        "5ab982619e6ba5b082367c2a580a8701",
        "ecbf833c92b33a47f8652b466a012c5a",
        "faac12c9336f2e64da814b9a48b7bbe6",
        "c27c6f2ef9ae28b18c0a4f30f2a1b2aa",
        "162b2e1f034993c7d80bbcb1f823103a",
        "3d78f1acd91ad10a7f7d68e7658ea5fa",
        "4f5142e5b00a441fb2b3babdf663e5c8",
        "d604aa57800a22e1b1fd8fc3b9bdd8b1",
        "6d63b24af76850e7d94ffe092fba5d5b",
        "709c102c9237b620491e013c3f8f5a4c",
        "5488031cfaa2b302fc2e2e284893395b",
        "7fe6d29db39a82b35b6d63c8bc8b9bcb",
        "c3043a62c41391abff177cc994f03598",
        "c10b9456b03fcc59a381887333da0e3a",
        "78174b74c718cad835330a9b7aaa043a",
        "8c9b4b4fa66e855a3a67e1068e2e74bd",
        "e48e7429c48c2e394659644af92814fe",
        "0b9103d6dc8b3c04d62a406082e800e2",
        "2a755dc71d8b939c0ba58ba4eb68b837",
        "1051dda54eaf8c38f429413cd3a13d44",
        "b08e5f64b6d25f472e6ab9280b84c153",
        "c67778b1627c19d8b7d8cd73cc31b9e0",
        "ca4359c33a477287b56491cb81ac1e0d",
        "dd6a446845d57fed72059ee8bdb37857",
        "a15bd5a2f0b26e2015a03fdc5a2319a9",
        "46959ccf83a5e89dbf4fc4aee11b4af9",
        "d2af05099a4301be3320f05c220b8489",
        "8ca56371f32f6a2e55c8306b5fe94e7d",
        "e0055470e63b5b83359c358c17b108f9",
        "63e78aeacd5b314498232de7a27d4381",
        "e3fcaaea154f7c22f0e1e2cc814837d5",
        "9025e9a91810edf582669aac3764b350",
        "dcf03df9a5ecaa60883a9e6fcf18ac7f",
        "14ddb6790290338e5f5f48ae464dfb20",
        "c5dbee2ef12d51ed75670e597b7a1ab7",
        "db677f11f115381340bcd9afbaa95af3",
        "957e47782c32e397de3f788737eefba8",
        "16bba51135fb54b50506160f8e521ab3",
        "ed5ab808068ad61f2b5d9b519a94db3d",
        "fe09c2226ea403295828fbc9d50304ed",
        "67e0be00bc03466d6c890df4511e3a4d",
        "8ef6f034b4508a82d3da36f052345ec6",
        "4dab2fb3c6b0867cd11d51b1de9f1ecf",
        "9af84a92d724245f276f38cfe61d7b12",
        "109a9ad019ae9b2c07d878ac8650f88e",
        "90edb4745db80192530bcfcdb853ebb3",
        "929bb52cf50e0b8d42c3547eb0bb34e0",
        "6e90076e03f74714d63d7b09c7ad8e59",
        "bda18cad07b62a0dff8e37b69a396da0",
        "a9e837be3cded3d2c70b5d5864747eb6",
        "3a645443102ffa1eb6428f582ff73b62",
        "eb5c12bc89464f38db9f304e78f2c702",
        "f2c26f7be5a4bf71c811540aa79a57f3",
        "60c80cf91136c14dd9381b0cec55967f",
        "16581d92f7140bdd597b913e7ae78c38",
        "5445aad20630afcd10626117b6df4dcc",
        "467d4af00cf674a3225b371b2652faa6",
        "4c8e11a1925e403bf42b0b3a19850332",
        "790f8af19327d10549fc189402d764f6",
        "31099860fa969445fcceef8ad17f5754"
      ]
    },
    "B": {
      "count": 3966,
      "ids": [
        "4e3806e28ffb49e0cc745e576f7a01f9",
        "c46b6bd0749db7395b3e2804f7eadb09",
        "e820151a0cff0880453c0f15daf00063",
        "f9b4817ebff89e8953c762c9982c878d",
        "dd4ccb97b904bc5cd1739a3459c931c3",
        "a840765e7ffe6ef8b665fdef4ca199c5",
        "b8a98d48c82bf02ff46564eea16859bc",
        "59d658f078fbcf34d11f29189b691138",
        "8b8b89d37ec2a6d1a77f6326f6191e54",
        "1df672e18088c5533928608e094d786e",
        "10a6df80f3c144a0d42778422a5fce80",
        "aeeb5609c9d9391b858efd9da0ad2b53",
        "b53d9f1c6c6d8a4dca21f7aaa3a9a1fb",
        "e31a0e591d68faf4d1e0add11286a577",
        "9bc1dc39a77262f97e353ad9a5446b24",
        "d69b6434ab235540b761ab4cc426d265",
        "4717fe96daf8d07e6223b261463b59cf",
        "266a06a3379461ae85947d8cb058faeb",
        "b4299d04b5b899a7325714eb1dde2a47",
        "cf5ebc4ffcbf5b924434b489238581a9",
        "0f61e6cf2be608d7aa1f7aeb9406166b",
        "193274ca086081944c6e5054e555d12a",
        "29094e5fe6840da3a44493e7d7231bb3",
        "2a164efada35092620507524eabe401d",
        "1de1f9ce973a8428edb5b681f12c1848",
        "347795d5882aec9e047ba6d9d078d66c",
        "ad45fcc8964a4ae17689a11eac697969",
        "39d498ff718b7e6e776f0130e3e48f25",
        "da5c78dfaa54d78877a3f1ce1e384da6",
        "2201ab06940826177be7f4c8d66ee2b2",
        "04bf20c2fc94e87572ecde168b0750d9",
        "6d17dc8233070f81b12f38ce375aa92a",
        "5f96ec6bc566d3d86d949701f181f818",
        "c442292a657b46840d9837aea755bf19",
        "f66b39af2035c6d4a0c36151afc583ae",
        "0a622e0b50b9cffefd005177dcf8155b",
        "ebb9fac98db3c61bd1387f9d649dffde",
        "4de5d6ad4a4cdb57b6aedc38acaf00f9",
        "fc7132628641659309e0f0045a4f7176",
        "0e2c6e74d921c8e809ceb4f7b516fff9",
        "e2273ff25e0b3d1b4647228178da6905",
        "a9ca3c2469e1e88a0e93b905f675769e",
        "0adfaa1d6d6be95bcf266912b9e065f3",
        "3dae5d74351e87e0a7ea904a8146276d",
        "89fc9ed3e99a2bf1aa5dde7a6b0a500b",
        "516d61036389e76ed10406adaeeaf8ce",
        "27939bdf7b6b1503af82ea4479dad8db",
        "3f5a2a24a6a4a365cc18c6ee523673c1",
        "d335c9bec8d9676370f66494e98fa014",
        "ba49f6835f8e6af71ac0d6ac803f52d8",
        "8c372795646b78f3fc46858b2ddd316a",
        "56e3ea92eaea123280500230a31b71c7",
        "681730b4c556936bb00050263e58920e",
        "9feb06a5193fe6221dd164965077dfa1",
        "b20b71d5fe54abeedd496b1732284de0",
        "a2aee08c8c45786f03b465a63308f927",
        "03606e4abe2165052fb5844bf1ec664c",
        "c8ad4fdc0d6452c0c6a65b63e80cdf49",
        "040b3caec782fdd1bfd578e69ea3cb70",
        "71050c88772e0285eb5094c629b9147e",
        "24d5e373efb8616ccd32a90da11c8487",
        "55eaa3527bba87c680ab69f3c06e9078",
        "eb755f1e6b9b6f6f3f8d54be800a7f6e",
        "225e4d80e0f7e2c82dbe1ece1265e705",
        "d95b19d0d2f1bc3334b93e9c5d471481",
        "d811456343ad28857e5da3505bd61048",
        "23578464429c765782c9a30f246105ec",
        "cbda0a19711727a01177c71ddb66e2ca",
        "68173c0ab29d0767939c7a3d250e9489",
        "f9144670a738ac26fbf6f258a85d61cd",
        "b32f9a16d33669b2ff17e4c73423979c",
        "77ed7c73107f7783fecbdf8ae63ee6ac",
        "0426717380a1fd51fed9cbd594e98f4b",
        "ad107f9653b979cf8de408178e9ec9d0",
        "d2ef28cd9df2a545dafa626516fe93b9",
        "b910f39d5c07c49c7fc66b1a00bf8f10",
        "aa34b25cc03f1f7e05f57e29a6260108",
        "fae72bc41db63871e7d1ac201c2ab1e3",
        "10d15095f32f0caaa4d6fa2786d7e5fb",
        "391c344daf594238fc0f2d1dcdb52227",
        "04bf17d77300f89e4ad5ec10f7f29b34",
        "95189c573dfdbd7fb7ffb967495c9ad0",
        "068fcf232e779a9b9862355b6eaa5f78",
        "9d928b81487350d8c8fd9dacb4432470",
        "57c1f9bb831e1261ab62406570d889ac",
        "b12cc12058e3bf5be5ac3201a85a950f",
        "b3162e791d36b5b3a64f6b4b4ef1571b",
        "875dcc88a98d95e9e8c8feb39164b0a9",
        "95aa71d0f6e6fc4db2f36492f39ab3b5",
        "33b8775b3a3d1284981750308523f266",
        "172f687fcde27e25db787d03b26cfcb2",
        "d981e0a425069457ecfd18f7fe9f4710",
        "7fd0a920d0ad317515c008ebe1b3723b",
        "3512aeef198ee4f19b68bf2b19708ee5",
        "e9e37449817445409c50dfd86cada4c5",
        "17e1c5e4b697be0a17a692cded6a62a7",
        "5c8a39b7047ea58ff116a0e58b84567a",
        "cc99bdaf91be798b0e4fa701eeae6100",
        "b2be37ce5becd5d59a28298ac9c7ee5c",
        "47c075259af2b6a10ca000f9de0c17c8",
        "497bc9474b96ef019d3f27592d0050b2",
        "3dab5c7045e2e1aa9c41304328d96200",
        "fb756136d303a5ff1042afd7b0ab93f9",
        "b9748f2a7b6be1bf1394f80327377263",
        "9670468baa52836f1073ed04b7afb0c9",
        "32ac2e0da812f76d5f672aca7dac842e",
        "f18628945333c4de24e8520ff55ca022",
        "9b39c0d83b6a565b1813dc01dcf166ca",
        "77576bf130b9e5316e1d438128d2c3a5",
        "512ae065c3b7375b018dbf685d735756",
        "787520278e64bd0094b6ca0c673a59a5",
        "e6b94e711c694fc300309ba8b11e2e1f",
        "151de2fa1f7aff409f83db395e166f0f",
        "ad72cb7125f001a8985a21042183be8d",
        "d259e3450017f6f6e6151bb293c8fb47",
        "e1b30625588d7be4fb49378f441ce8fc",
        "b53c8f020c6c07be0a47713225226648",
        "45a6dc6a23037c9c1701d7d85ebda6f0",
        "eff5b60ecd47973305d1ea1b8712d8ae",
        "4192f8ace794eabd14e2362f095f1037",
        "6da081d10939e7b5db7ec37a3c3c2a89",
        "b846a937f304eb0264a779eeafc95d43",
        "25bc3c16b2623ccbdf8662a0f818704a",
        "d515905ddcf817f2ecb3de97ed22ac25",
        "25493f3893d73cf823e36806f549f905",
        "5e8120d700f75aeb7bc0d8ef1b30a966",
        "495a1936deccebf9aca83da2589f52de",
        "7abcb73716a9589663d704fc5e30fd5e",
        "fe4ff32694559b7ed8149a3c73433405",
        "0ae170159869333eabaa30133f95b8c6",
        "dd153a6a6492c343ce6041578c7ee709",
        "d54caa1d70db747eace15647b7bfd996",
        "dffa5b7a8c88675392c08ec0a6ee8bb0",
        "52a07bbe90f0b24af0361a48256a917d",
        "f0e8cd1b502500c55eb741b668d5d404",
        "148af6c1531fbf2593ed11baf28a0a3c",
        "de923b6ba8312fd7e73ca3b9170d6ee6",
        "f3e1335db06427bff3ad3f5ba08a65ab",
        "7da9b1000e8d593eab46614c004be756",
        "0c6724190128e75972d955ee9128fb68",
        "facae8ef9ee035c14ea730fe56e86f1f",
        "803f526dc8f9725eed01ca2977b09de3",
        "886aa0b80252cf2e7b03abd0b3f062cc",
        "cb91b3805a08936f93eaa64916d271a2",
        "893bc4ac5e373205217961eb7e72abb8",
        "9c566ffb511b6df71203978912a035a3",
        "d10ff3c41f9ba8c01f133626dc3c21a7",
        "25bf0d14950b3ebd45e166c17a2b14f3",
        "71c03425c23a51d2a7fde92537f913e3",
        "2a7afa6d493be9278aaf052ac7439621",
        "42ef268f3d8bd6d445bfb3bb545bd9d0",
        "df622a7c4fdec9e41b12792882713984",
        "8f9b399dbdf3e35c8f8b570900d6ab29",
        "b95a2e7a65cda7b05879955f90263f37",
        "96ebf5d991c20723af239af04a4dbe83",
        "3b2caa6e9c64f5ecc58c77350b4bc649",
        "183bab5ff480624cc1e465addce8a3c5",
        "7492d0f9a031ae1d0c2033fcc60ec4db",
        "a05655a741e26929aa29241c25a371ac",
        "dbf6006d14d53c360528957e7a1aa420",
        "152302f1c38acd9100de8bb5953f7f51",
        "65a65f3c29b42ad8803e06dcd017c21d",
        "eeb59a4b04032211254d396d5910e866",
        "d62c8449d606076e6bdf07798b508e72",
        "68cfc490acf9c686483501783e1971ff",
        "45b6a98876e7105977a27ecd793fe7cf",
        "b61c5a5d4d5d1c2eb0cca0a5e14b421e",
        "e127bd23580dfa3eb9710d1dd4545ec9",
        "d02ecf69661d8fd8e235a0325512b070",
        "7e04ddccb4a1311e5c71f71c83504fd7",
        "8569b2453a38bb18a10571219ae46d91",
        "b897eb77b6a6a87a31d71d17010a0a4f",
        "8d16728a0204ce3170c0e2d7f75916ed",
        "d695c4f5cd58abc99385e50288ee4f6e",
        "777efb8914a737be4f9da2bf9475b2a2",
        "4235a772f1d31bde945d0b3c9663b03a",
        "2eab18d3fe5301db3987cc8816727a76",
        "b6d1100e5402acf603d049cd2aacb96d",
        "d3b86a17f2b3c4cf81954825834693ba",
        "05b2390b643dcbf4e27b3f02058e0a5f",
        "dfdcf34a831c8a51175a726678e38ad7",
        "2a9fdfca18e11e6c8d82344f400c53c0",
        "8a413427c2fd2a6ae98e60d2ed92bee5",
        "a5a3388500722f88f059286ecd35d440",
        "f1a74a09c7ba0165a3cc30a6b7cdcffa",
        "ccbca925d8aa3a0a3889de982fc0b277",
        "22edf3f0301cb6807f3be0ab4e3779cb",
        "3c8239da1527ea6eb196c1ebb1b15eca",
        "292b9d20306ebfecbdcf432c3678b0a0",
        "5f0dd031af77866866bc812ed1392ffe",
        "68ad8512d86e011a46baef319022cf04",
        "a996e66d05d8de595162d4d61cf3a0fa",
        "b431d703c5f8120106506d331285a4cf",
        "5d39bd9d6c7adf3d74840d5149a30edd",
        "00730a44dbe49021dd2b9c8dbebba8e3",
        "5ffbf973194e48ade483cdc872a65894",
        "20e995e3a9d34089df234386338ebcdf",
        "7e7af0d6b8ebd1c09f37d833ae39836d",
        "c3ba716dd7c13897cea472dfc29cb1ef",
        "e2be2a191d70b25cc88492a4dd9561fc",
        "6a4ade4c540b7126195064a4916da15a",
        "54a4baf449784724c2235263abf9e022",
        "c9436cabccb79962a4510e8445fab237",
        "85bb8982b997d3ebdc06af836076caaf",
        "aebd4d4ba481af341db4612544db9cb7",
        "9d65c8f58b21d706dcd0b7b210f259f4",
        "902c866b1eaea14ee1c1d815a13ab192",
        "33f1fb6896b8face378c7b12e3233658",
        "fdd61eac989e5691918d1d3486d484bb",
        "1f961a02f0785a132978306d93b591f8",
        "3b08869102a4ecbce528dd1ed80c8f54",
        "e7fa1e0bd529c503541926feb4c8728d",
        "af41c3ddce47545588f3f4d576400ff0",
        "1b421946a626a4c3e745970f38be2da7",
        "57c6061fed9130ccf52269132e67c892",
        "5b28e5803b9b5091e1e5dc1882b92dbb",
        "4e3776251f54bb67cfc2f4a487f28b0d",
        "ede8e6ba4698b1d3c923c03d6d2b8878",
        "e444a17b1afe4292c7d49511a3fb959c",
        "e2d2fe36c5c53004e34c2ae855d4effc",
        "49a4a56003299a13467bde37524db3b7",
        "3cd531d0e0136874c4c636584df57922",
        "9ee3f77c6f8c6caaa08bf11bf7991b8b",
        "b970ac1752748415b2452bf1c22da601",
        "72ddddac25970441b2fe6a5045bad042",
        "b15e2fb8d96ccfb871568f5fe456f68b",
        "52c4dc480d794757d0689b5799ffdad0",
        "9bf7a20e1a14c9be9a05b6f9a66d72c8",
        "3444ef41ea8c602e57a67e2b8e0f76a1",
        "aa449168bd129b8ce2e98702d8ef08bc",
        "ffd94a1b0fc538f00612a0bf19d10876",
        "0e5911e0496549d75f55e3ca29ff3bef",
        "3d0b1602b08ce47ffb6aa4e071ec972a",
        "5460d8d6d2635c8b54ed9b5881a81542",
        "24c4e012395a7fe869da1b7337b20685",
        "ccb8dc2745b99ac9f2fc930aa7bc8daa",
        "a493ff100190048cdb5c364378f93647",
        "180bb6b3186ee0b134eb0ef8925bd167",
        "0f596b795cd00d7ce369d63f2faf399c",
        "5f418db2f508155f1828402f02d52b6f",
        "81bef4c44f1828ba4300974ad3845150",
        "fb4959952f68d872bcbc6b04c7a350d7",
        "dbc736f6151079aefae9bbe613302101",
        "41dd8855c3f9afd8881d625023b83a59",
        "77a79166481ec5e58d3c765de0a0e823",
        "8b4c8db1dc037a1e4a19c560b0f54833",
        "6fe1e12b890d7fc1fff131342bc01779",
        "b23ffbc31a3de977a73b0951f732cce5",
        "4da2f52633dbf0403401f5fc2f33c021",
        "e7b207efa0106b0a8fcbd6ee33e8f7f7",
        "97a9987fc4d35c27564523f675670602",
        "4f5e9658141f868b4552e820e6a610a7",
        "fc8f5b0f7f21b4986313ec0cb49df2e8",
        "b890b03d205df0f65ff2bb75f28ab99a",
        "0bc45796cbc9a5d00ec7553919319516",
        "d9bf6111a0a402a0e29b1d9c06d679ce",
        "b687ad25fd547156e6093179d7b357ef",
        "3db2fea639ade952169137d150b7174a",
        "2ba533c0e632c1ee02c3f585222b7291",
        "33d452836e422f13898aaa214ac0452a",
        "a289d0e9e2a7d6edb038ea979f28a116",
        "36c6ef08d2e515efeb059cb894189989",
        "b717732c78df10089864e1ccd41d2f36",
        "91749e92698f4c78f2c3ea6b09f9ae41",
        "634693f5f2e39af302c4acd6505f91c5",
        "8a2234903166456861208af581bb9dd9",
        "8f17ea2e15f0e2f41f4b0aecdc6baffe",
        "32862c7209236641a11594c0c3296020",
        "60879333d13131e368f4c890d2c5901f",
        "a53c3ee3194149c2578c604dcec38b77",
        "a39c0a143a0424c5ed1c7b9be298c042",
        "65c52207e5733a00da786bf1b58e51f4",
        "c69fcd6278281ba0ab518fd326ddea46",
        "2055305fc589c83fb91e6cfe0c54817a",
        "ce6e0b935eb40872c78cb110c8471e53",
        "517844cec9102175d39e1ff89aa42d26",
        "dc3a43b34da36d971cd9c92eaeb0d13a",
        "8bb97a8d1f33bb64f997a7f6ae123c2d",
        "54344eeeb281432b1e55f4dc2fe6dc7b",
        "18e458d90852d129b26e3cc238bd30ee",
        "919b34d159153dd163408eb328ab9fcb",
        "5eb4f7f326b25d88cd5a72fa33a3b31c",
        "c934c89dfe5bb80644a0c97d320326a0",
        "ef20ef5af584b47a3e829ed924aec2b6",
        "4a8c8d5998c427752af09a0ac3839614",
        "98fb4df863be169db891cc2d6966f72e",
        "6295e9e1969b7b0a775718b61f003557",
        "c4b43445e7f69b015f8913034644566f",
        "79eb135b9fe0b09968e46466bc92797f",
        "e8ebe5a452d9c918f2be99adeaa46caf",
        "49bf1e04c629a8d302c834032eb859c4",
        "974967abda49ec82c5aff18e8abbcad8",
        "cc322938c9ac5cb87e7f740203cf8c88",
        "327a9134f208785ed7e0131c6cd92655",
        "dd4fd42b723917de02349f9aad4a4238",
        "633d02adbecbf7b6241e0fd9bc2bd068",
        "0f4640215a771d4c196498e6f0177698",
        "4ae7ad5a27939366f9f6cf4ea425115e",
        "4367f38532435741076c5c037de6b01e",
        "3245a808ca843713d4d9338850cf82a0",
        "06ad4531cfbd69db957940ff2c8b6b7b",
        "87bb64e6a77044c2a96a518e9f0610df",
        "a4f5833b6c1b21a716165bb281a241b0",
        "5b22c476358fd67c13bf8854154962b0",
        "7ddd6cb083d53763c8caf16885e7e586",
        "0139afa472ce5c42df43296eb626ec34",
        "3791fcce734c3b80bebd331e054da082",
        "6fcee0ec6749616d0f32aa3c2c6c1b98",
        "d0015e2abd654f175011b30d09a8aaaa",
        "287eae9aa28d7683978334553965dc64",
        "14973c42ed647b57b04d889fb2d9c9b0",
        "6001052c6f5845c6c2fb9b9713595baf",
        "2edd36884f98a520d5906f355e28d883",
        "c2f6e5041dd41a14a3a44f81e4f2ee97",
        "b1cd8d99db33424d8258976a41742751",
        "91bd3378d94d42001cbe3f66523a78db",
        "8680ba0c10766bc4de0b24effd12c278",
        "c7739671f351b69b964b8e95f9a2e485",
        "b83a7c9977c1d48d6f7609a611173f65",
        "1e95834d5b1b210d2bab7552ff0e77af",
        "6d511f51d4dccfa16d93dc0f49b7c68f",
        "fc09d948b4ab581b53df84fe6638205f",
        "caa5894b46ab63c1d4dac7b9de3e94e9",
        "0d06b669f4d82bd90edde05d0217d57e",
        "15f9859871c42c6838a1584182105f2a",
        "44cede0ca9eb93bbfec4a3dc8a81eec7",
        "6c038e7dadb5c24766a78a335808a0ee",
        "d364b1860d78b156c1010eea52d836e5",
        "0590cb309303ed7a2dae03a824f8e1b8",
        "88b9b9570209e9e354b1ffb7701eb2d7",
        "408e5e39c7a7bbb0172043831e8e1dda",
        "c9e652d17df8ec7246183904bccc6ffd",
        "db09d3111bb277635b3ca78bb7b40b94",
        "c41127c13b6f3c471ec5604f4c8950f8",
        "6c82da8e3ecff05b039cdc1fa4992a90",
        "f19921bbacad1308534d56e794fa2642",
        "7ca99a9b24815725bceab431b4875029",
        "f08f156ab14088e131ec5180ad67b366",
        "eeb96f7aa54094880bc17b03b2676551",
        "8e7fa0f0159199f72ba1b068dad0d785",
        "0b149c616e43c62f9d3b4f179ead694e",
        "655bfbbda74a8e6dd308e12eb47bce8c",
        "de295dc646e1979653d793f92cf4a0a4",
        "784534a042fd1eac8a7f039464afa1f1",
        "4c65700117e86e22c17e6e10d7612d2f",
        "2c7efd08a11b462cba8f7b227291361d",
        "01d20fad171a081bc483f414b2f9f35b",
        "cc4842a138517920391bd4699202ae82",
        "c27d59dfed5a27e851b9ff65e6bc3f13",
        "826f914082e66028219bcec3bd773e9b",
        "a0f70b3d556958c47eb16da941819605",
        "4facef7d70c671db6cccde7530364104",
        "69a7724b52c4d2d8ac16164df2b2b0ee",
        "6715c5a123e8e08ffe5b16c9803a730a",
        "16cb1ad2ea290b0fff8f4fbc65935279",
        "6f41cbc7dfde5814a75004eeb36e3395",
        "a732b32d081c0c15c3c2635a6cdb75dd",
        "51fba6fabc26f406bc07d37b690f258e",
        "62454ec7f45689fba8f6de5f95f70414",
        "77d788e611b53794b2c9c82349464b04",
        "1127e9f4f9199dc49ca6dc718c9c7675",
        "1f42157ceda996402db94bdacdd73c68",
        "74ab2e6f01f08445b98b789daf5aadc9",
        "3f34418742af968801b1203da8720b10",
        "dab9cb99ec48b42cd04896a22e629d6b",
        "05fd0deca6e496222c8078a0b07d853c",
        "22901c6f65fbac98b6c70c54ba3d51a7",
        "1f287c290bc5a2feb8e3d3d29cf9fb8f",
        "fd8cbad6b08de8f66df141e4ff1072a9",
        "5df20e0f2fb0175ede83b453ab241c69",
        "4198dbe4a764bb6894c2ea0220a94bae",
        "30c3f8734d405cdd2d5c355ba31e2de2",
        "a4974b3260ab0eb64e913a39a15eba6a",
        "8de94a52ce46d8321da14d6c1f464d5e",
        "12659bf477496bb32db8f31ba9cd9dc9",
        "169cb33ed4b77f6637c5a3baa10a1349",
        "da9395cdad81c568f89230a0a2c54b42",
        "410842c0d9da9247e72869f3c017922d",
        "0a0f641febb4f6163fa5f170edb0dbec",
        "8e71ff8cfd5ed47a74482df4dd73f1e7",
        "a79afe32e2beef00c147327257dbf58b",
        "bbd50e11bc8fd3871a0993945413b84e",
        "84ad1e6af471fa3fdfdddecb5ff4ef45",
        "7ea1ac4a37e031f0682e621dd822b83e",
        "dec3c5d7eeb521fefff9a4acb727f2f7",
        "903bc04ae8f96ea50806f32a4477e74c",
        "34dbd20dcc7a1ec58df1dcf90da0d4f5",
        "daea13bad1d31b1c033d9498ab2461e7",
        "088f3d3eb0aa6beb183f7b52831c5d55",
        "3dcc44b42816621c1d8013a8f0b1adf4",
        "3b943f80b0c1f994cc3a22432fce8940",
        "af9e73f2774260efb862acb368e17582",
        "aff57fe8a743c3d7dbfd902b5bddbcfa",
        "f7d37210ea313f847a4debca8f689234",
        "2ad928d2fdd15e1ec22ee5454ca88218",
        "78b78f3de87f4edbdd98687ca3e9314a",
        "c43c6fc8c96d7fc2edc734b416e206e5",
        "1613a80307de005bc3898a11714a9c10",
        "ce725f008fd911200d79a7f6fc2ce340",
        "aed99420348891216560a4df432f6fe7",
        "c00e9fa6708717e173aab70820f68469",
        "df18fa2670ce4bf133e8a738bf45d5cd",
        "7c0efd06f2d9680881fb078fb45787fc",
        "5c28a52bdafb53e9ef56e0e1a3e7b94e",
        "1c1a206f970454a82738d6a9736bf643",
        "c51f5ca5b1d9e7c9a393eeb5f0c816bf",
        "fa3ffe0f4ae0f4ee801980a4d1ebe431",
        "8f1f2796d06d9082b030ec84d8573653",
        "cf228da698105ab8a3c21a4687058488",
        "5b2d7f9140de1627cac37fad1a0916be",
        "f35fcc7b111a920f909afb7ed6fc4f34",
        "8fdd0974c5f0ac8e9c8ddf70c44708eb",
        "1e6bf1ec08c06fe0f30b7cd8300beedd",
        "c9329ce90c9551dae66f53fdfb9f2308",
        "fe22308d33e2b05dfbb95081557f1810",
        "6320bde3a6b60c7ea12a73a393ceabbf",
        "3ed02eb5d609ffd970cf04eff457a6ea",
        "d32b2cc700b53f601a9d70bd7cca7c43",
        "0e12ffc390229a854e67cbe8746d86fd",
        "31792fa82be3420012df269233296583",
        "1d029130342841184905e9b9ff91b8d9",
        "19852a880661c825e69946ee2e0dd874",
        "6c8452562691e8a396bc45de9f4db7ba",
        "964b28072f467b8420dd5b3a6c8994b0",
        "11fe38781ba058c11631aab6f9effbe4",
        "feb0ab58247cedb8406dcb2cb52787b4",
        "fed24f043ccbd4d583bf13a99e64c8d9",
        "f61bfa282f241f7deaaa2314f1aa5465",
        "28c9f38b43807c65faacb81d91c7af64",
        "37c4653c6f89b70db20d6a5e4112aa31",
        "9843ed3236fb5278a20910ae63e586c5",
        "98bb204c7519335b04fc9289bfba191e",
        "f1aec2e3cc5a4b07321c2a45c735f5ff",
        "69f2bdac8e378f7331cff97f6421dd17",
        "611d65026a0d4b076083d092fa1c6746",
        "874c8d89116387687b98104a4bf32305",
        "eb1ad3f15a8260a93b2330ea1f1d30f4",
        "f470eb8b93f5a70cc394dc7aa1eca638",
        "20c7c73eb778b27e90cde12f4b6e9406",
        "1833daf1121085b5c132cf17946840ff",
        "222dfa0bcba6391e272ae3527a389e2d",
        "b13455d69d0bb44243dc36b15b70499e",
        "7f4ecef8e113f9e47a9e1d7b9b7cbbbd",
        "b6dd472a6a05288540c51e8fa3663ae1",
        "78004975cbfbb7e3011dc48a557a833c",
        "cef4b7a1811e1a9322c48c45b91bfaaa",
        "054a2bfba124eaa8b99f725fe094e4e2",
        "3d6e175d6dc8a3f548fc0bff06451c50",
        "1e303dc03ac09398034d3b36c30b7ad1",
        "37442e305ca529131dd395332c6bd682",
        "5353b9246380daef8df2f10d6b5acc6b",
        "b59381f21edb033c240e8dcdd53459cc",
        "38810ad3c8e80a6e1ce2d641de7025a2",
        "fdc33ef63f2ec976c779804c0eed1953",
        "bd82c86a3ddc5d2c57f44c7ee1fb1fbb",
        "bf8cec9afcdccae75e358cfdfad2a030",
        "64f18b0e78cea4e5f0c65aca85b92b7b",
        "9a640eb49f1ce8b8d99bafb278daa3ae",
        "539f0ed1ff9a51ea55d8c0707f51ae24",
        "e0fd79d4a9a86f30b03cb276e79d1c8a",
        "b5f7947171ec8bb3c3b53d070837ca1b",
        "1fba8f9379efcd3a147c067c9f0b497a",
        "bd1df714a76db50397e322bd22e254ac",
        "9596d03efbeb1ca974a577ebe55a5113",
        "243c980b03ba06f0f2adfab0722c786d",
        "9401ac7353242872956034997e42d391",
        "94b4f8e448015aa0815f7a9790d87371",
        "86f5dac406d33bfa6ddef2a92b12f6e7",
        "31136813627eb1d939efcc77051cdfd6",
        "7ec2e6e63be53f18a3902e96eff6e065",
        "b955993f8d4043d413f88a2f0c76c49d",
        "ef5dc0ed98201db14360813aa72b90e2",
        "ebec4adfb87b9a342e7d859bc4c29664",
        "1f311769994542a761294f964fee6296",
        "bb8470d58ae94012ae2cdcd60c73681b",
        "274cab22734060305c3bf2979fc58078",
        "73349bffd4c48a64bbec60a74268e288",
        "d256e899047dd41c23a74011f2c4fcff",
        "f0df039e92dca764927cf373498576b7",
        "cfc3c1348365437bfafbbb3c8a7fb598",
        "4d40ca113ad949784c04131aa079916d",
        "cab116a8a15ba8f5b9fac5a62cc05e0b",
        "6ad942c687ee89f4707fb91a365dce6f",
        "a88f6548ef36b2642bc39698f935c8fd",
        "ea4ecdc23d987ddcf7ea813e6b3565ab",
        "998a27a2d7825463fa6ef4435adc737e",
        "a95d38424b96a5757be2fc7ac9cde182",
        "89430ad40b04f2d118685766aad396cf",
        "15744a6a4b64c91e38b81955ade5abe2",
        "7399d1d32f2b81ac532ae64381abf69d",
        "75e2d1f5cfddf9f3451e3ebfed4ea845",
        "d3a08f4d7c83da61b86ef41c900e2d3f",
        "a2becb6f07357a2fdf135d0759074fb7",
        "ebe3f4e540c8faae7cbd0f405f6c91e4",
        "408c69497f6bcc998a96b915b3dde9a5",
        "ab1714c054b6bcc12c66db1a676269bf",
        "9556c2cd2b8d608535b511a487dfb616",
        "911ea940d7222e4065a419356c5aaacb",
        "aedea795b548c83e084441b9865d5585",
        "235c3f54728bcf889ea1956d237e5d81",
        "4b0cd1fcc2e00bac11f81569d8cb9536",
        "547ae7c5b784a3c76708d9efed151351",
        "73d81a2cfd48b26a8914a460f045e27a",
        "3ea19d8d03e8fb9c2d00d9f2f66e1f2b",
        "4df3f0b3f13dc5cf8372b640a1656e0d",
        "e71224864e3fa91958070604ac078d7b",
        "3e912ec166c473e1b1006dfebe51e167",
        "bdf2997a9edf9a6e708d54497c6c5b45",
        "fbc330c9e00692fee954bd0716f3d022",
        "38bdc87ccf314b393325bbd664861485",
        "c07536d81bf22e0269868b92c5b7c527",
        "1bbd93ee3efe91f6102e5b733a6131e5",
        "0cd8e518ee1e021b3ad88495852750e5",
        "bbf116d56f31343af7f1cf4302cc2b31",
        "1bd4645765b4f159cfab88fd7d937c18",
        "deb31b3e66f91751c6cc2aecf0e5e147",
        "61ecb19b4c26b6c11d71ca37828514f6",
        "12181b452dd5dda051c6f841d917133c",
        "d4d490e8363e47eabea2188c3dfad3ce",
        "99c56a863b9ad14b02538ded7876da47",
        "33c52573ac6821eca8a901dc3dbfde1f",
        "56c393054dfcec52d9aec5c7e5d5174a",
        "eeedd8f780c03709c4adee52502f7866",
        "1621cb4e50ec4e73f7204a809cfc804f",
        "f585815cc42a9b4a7b5edcb301b85547",
        "816e3ccc4edb61759b2343556d4dd31d",
        "84a0970145fc4e9f968303a0944e8639",
        "c1e75b4916e38413baa380a4658a79c9",
        "586ad764714021217d2fd52286c16ae4",
        "ad9b15522e32e47f7002343176feb549",
        "94037099323462591961ea92e261a193",
        "c1dc9d644bd3109c1815c3cf9a857a03",
        "755992d5694791e0785a1ac4990b0f51",
        "1f1b838aec949ee45b56ba586fc8d781",
        "da165e67a0885e279cbdffe0ec49e0f7",
        "0e33754ca220361a23506be6a2760647",
        "7cb2522efada9b895776c3e611464aa4",
        "1e94de601c5cf7f1d71cb7841e7609c9",
        "f62880c2461cb785f3b06fe908e4aefe",
        "fdde67d0d9ffcd07b96faf0208009546",
        "92741a9531f7cfe05b61b18bec7236bd",
        "79bad74b007f523f159dd07cc0bb62ee",
        "6679bd407056f3c333d7e329937f04f9",
        "19b1f4bc45b179a8091485150eba4334",
        "2ddc7951b87609eca1a167876b0e82f7",
        "9cf8d4234b24dbf2abd3956a362846a8",
        "0f20e9f11eb7da650de673bbe285ba38",
        "b28743e69f3e0612e51fe2ac615adc0e",
        "dea29a00b6e182dd351c387f57465ece",
        "baed50b975b7c4edccaad47555f6d4d0",
        "7d1073e9b49020590224870b11fc925b",
        "82ded0e6629c830915feceafe4f63b1e",
        "b0dbef76453306389b9b618bd20c208b",
        "aaba06c101037ea77610b88225844147",
        "850089265cec10da9ae12e055efff74a",
        "8e2c8ca81dbde692bab44b1cf646582d",
        "3b805aa388400ce935e2ef8e027d4a95",
        "e499ff1de7aded97269b4aefcc7be92a",
        "4a829d76c2bb606cc440bef9cf72f8dd",
        "a4cb5b1ce2fb3771d869769a03030bae",
        "e437b7f1e56542b010bf45502b63b1fb",
        "c0e8954d26e2abdf5e1e850a8f969f85",
        "0f5544f649dc97f897085efb6090bfc6",
        "dd8421e6a2c91eb4e5384f3bf177ef3a",
        "73798d888d505aa9a36419f8994c267f",
        "3d8660b5c9a436152df9a944e93701a5",
        "630b2d68a37907181741ee2f56ab8679",
        "edc6171827b32cf67322d2d1e77f3c9c",
        "522cb2982c20ffb9641d9538d24ed8ab",
        "4efbd94663eff0d12e0c7f0e05a6a82b",
        "63bb8c02798d5c362f1af9301206662e",
        "afa9224051a4e00e3be6df71303e7007",
        "8099cfd43448ee1514784b04a045477d",
        "e93eef718fe8472c16b2589885c4a9a3",
        "95dc03f91373f125dc486a9d67b11997",
        "f3515b42aa127138e43cf9b8e3b50472",
        "a433beae9c2760047372de1041bf5510",
        "1d3becb495f00b9f280be717c8034a8e",
        "048616e5c600aaacc02a1190227b87ab",
        "24c5d8b76ae96be87a7e727d423c1340",
        "9c543c7b51c910c2e4e89fa5ad731a0a",
        "3e78c1f93299be8c3466135b986bacf4",
        "26d131087cd40fcb93d4f5e7ecbc1c08",
        "03aead3b05c0aec58462302c1b8f1b70",
        "0c3d18fc7091aa16161707fd417d9843",
        "c2c316f306c154be3a5dde3fb3f329a3",
        "dcff3a5a68bf10290072d2f64fb85f5d",
        "898da267695e9d47e3bd567fc08d0894",
        "095c961a75cdab45670ffce10bd24bdc",
        "9dcfdc08d29e5ae53672934a654e557a",
        "e2c9b0267750077252a09ce5e29dcdd3",
        "3aaa1a501a97ed4c19a0019071b80d0d",
        "77b71b9037cd56f09a527b4c34c8a9d5",
        "de4c0455a1d7f7270e1df9cc72fe2f64",
        "d8cec8fbf59ec688eff4b88db134b076",
        "c04f8dfe06338ebb79d400a03edcc0da",
        "8cf8b19f327c7debb4bf3beb1433efec",
        "4f7d67ccb3b9b49238b9206e9c3b59fa",
        "edfe4377ebf54d73d35e40ef6a680f16",
        "fadeb3cc71fcc0adf4142654c4114758",
        "aaa896cd597e2544f81f54487b487881",
        "b75e30a367f20454dff916ae16380d22",
        "773d5a27b20bb1babd88306c30ba1319",
        "7ad3af07b34991fe5db7bd349c375d4f",
        "a08784881780a40e049c8b96a09ea156",
        "3910ea66302bf20e38d254882719b6b8",
        "d9de55330127f58140c7b19f5f3d5144",
        "92b41738908e808ce010d031ff77388c",
        "03a23a21e2f486fcc450387076b1e0d4",
        "e71f390234a0c0880426405fe9ba716e",
        "10196edbeb76c1a8b9b01abf37ea6ec4",
        "951337533c534cb88d8862e6b08001c2",
        "68aa02077de9904f6aca09cba531404b",
        "bba1de057ab5280d6522588ddfdbb0b3",
        "e4e5428853e4741ddda270b91d1bcc2d",
        "0c5cf17d3fbc78e26e7e0851133e6b30",
        "62bf952412bf08df4424ee400564fe20",
        "7fb8e12312317cb2c7cf3aaf1ede4c7c",
        "a0592fdfc8b88536b86630b14d00113a",
        "131fe90e3960212a7318561f076caedc",
        "a0e3291c8fd88f1e634f509ab21cab7b",
        "1e7bd578296c30057836284b5acc2989",
        "8327908b83017a0f3b9c62fee38eab1a",
        "f412b1d9fedb969894caa1c0131847e2",
        "59c9838e4ea8cb1541531544dff5bb0c",
        "cbcf1c1ce382a061161c9862ad8f35a6",
        "a3f8aade404e5b4063998a5dedb3f212",
        "302e91321def0cc365b2bad7dd084f43",
        "2608810fd28e1eb3c95a6389d0490b59",
        "ffcdfe927f0c36bd4fb12393d9867675",
        "3bd6328c190852078008fe6195ac875f",
        "de2612a2b9c3f6f02cd5d1dcfe092399",
        "447a3ceee355ae5fb8d98142eb2f6d09",
        "be30ea7fcf6abc60258f656e36548a80",
        "719de0af72a38816d3212a0df6054f42",
        "a2dcc2c90c41e2a607f1543f90fa95b6",
        "1eb97fca8419d495376c3510699e1891",
        "21c5d85faf4d21a92ed5ba46f14a9ad6",
        "a3fac625899e3e2917d0c2103be791c6",
        "b03e1414e703b567249d8892dff0f64b",
        "378e12e8266c53e3c43d25ffab762e77",
        "7d72316b2ff1cc1e666ad2a7cbc11700",
        "17f92a83396cdd65e514b8b074c4a3d9",
        "bb7a4e53166611113c119529aa0c7394",
        "0cfbe881362f3882eb9c7ca11dd96a02",
        "70145e3dc699593863144bd01996d02c",
        "63ed746ba31f25a5dbfc17a54bd351e2",
        "19273ff27b979f491768ead9cfdbdfc8",
        "2f58baff05742d1a5064844df70ad3cd",
        "cd0296d707ea9c44382fc3f7d7517c93",
        "d651603cae5fc034c12526fa268ccb30",
        "01b45b5d40a83c3ad675a59ff09fa43a",
        "037e009a9ffa4811b4a528b683ab65cd",
        "c38225b47b19c4512dd9b5eda3a50b21",
        "ad6fa9b8bcc96bf5d5d68d71bc1032ee",
        "8ffd1db048dfffd976385353c451df00",
        "05c78390d701e28c0104a0f4d9a97da7",
        "cb8adee160ea31d4fbbda9282a0f93c9",
        "e3d979d3f6f27eb1ef3c020f2b136683",
        "a86d3a08178c9e4d6b0401f10b78b955",
        "a3f748da0f4482271bc1370a64fe5866",
        "5f0a5b688c51f6256bf3e610ae341a0a",
        "f827f0c2658b5ad8dded6458193d8e1e",
        "64835f7e77795dd804884429b2598533",
        "e533c5574b1c46a1d636b0b687f5b97e",
        "50acd1416eb21320c61d2e44d0658917",
        "67626b44cd21b4f210f5545832020cfc",
        "49cb28f225610477aec7f75786dab29c",
        "01ccfc4f6c67010b08eb3383ca14cba0",
        "8a00a82fce89e2240409fbf230370db5",
        "b106920c069ddac96d8b698249a918e3",
        "bc99107b3afbf2e99eca4a8cb9719156",
        "c9fd1fee4ae3197bbdf1022c99487fa7",
        "1e24b9f6f5106c07fd495bdbc8a9a163",
        "5f6dd2d01a1576dcd2c65cd5e3de78a4",
        "eba03feafa513e2bb12fe863483125b7",
        "e4ac3117db9b3bd161a8fcd2433b5652",
        "cc128d58b3675fff926e2f18da7cdd0e",
        "e2ea474691a9f41365ddc4fd45aee142",
        "52c4926dd7df7b887717fc7767222c3c",
        "3a4b57ffc4de8239679777f4a4a096ba",
        "6fdded65b2c16fd3075904fb113d26cc",
        "07ece067b966ff73e2daea767c5bb0cb",
        "a78aa6d477b83b38763a017f41e9f058",
        "537cc19486d5a64fabea112f4626bea2",
        "41f0d57f568dad73e9de70dd1af75629",
        "827fce9b938f21e728a30641146be90e",
        "43105989664e6df3c885377924f962d1",
        "7a5f09a04b10d72aac90a867959529dd",
        "8aa8c62ff4f837ba1a9e682feaa3cab8",
        "062b7782e10c89cd061da121faf638c5",
        "c09f4ed72470ae6499a0df714fed70b1",
        "29e7ef59d181e810977b7cdd2ddc3813",
        "3be33ac925d8661cec1bc8f2373bcac8",
        "e3c4ed5bcc26db373d36304b05a280cf",
        "3236e524a3170acd5f80fecb13500b47",
        "8b64ed70b950fddf995645036225736f",
        "91cb9a8ca0a4b414e425fd2e2a749ad8",
        "e2b3dca6c45dace985bcfeb3dc024481",
        "3994bd514d834695d9d7d9c618940674",
        "ebd148bbe5b8f24f1aa8ec2479f9c00f",
        "4584d4c3632b39e724cadffd80c8bc2e",
        "20bfe7f746257f5772bfbaeea45cb234",
        "b63c174e94f4db7f05260900c6de1d8c",
        "5c17a1c86bb188f6aa2101c949cdc807",
        "935b21ab38f5ea60ac34d6499375e87d",
        "800f9b0fc10ba702e4fdb7dce17886c4",
        "396cd34f032b41ad0043408595ae76ec",
        "9b0ad9b3fd662b394d764bca67e67805",
        "d636c1d844f686c8021e654cc49a32e6",
        "9ceabacf944861038e1390255eb6affd",
        "1a940b344c2b555c95462677277937ed",
        "ab50d3b8a41820751a3519c7e3141da5",
        "fdfba6e353ad4890bba35ca6e81955b1",
        "8859993dd89ebf350f8e88114b475ecc",
        "e27c4686b3e051bd1963fea7094471bb",
        "07dfd5bb52faebf5ddec940f492afee2",
        "938a86739b9d126f3019c687b8a96988",
        "c6f3d773626323961a87dd857e042eda",
        "afafca6d2fd98a6204feb02e8a9613c1",
        "89ad27783eb0b3e9142eba009fbb1af8",
        "c6af21acc42e5aa605ceaba9e6850ed2",
        "37981ef8e5154a856f0e4bea5ba48a47",
        "9f1508627eebe76d2305c57e0a07d640",
        "de684c73d6f2901b5e90ad801fbab466",
        "795b758ec4f9185f378422c2aeb90f58",
        "c37b15190bbd3ee92fe98c81780b3758",
        "cf3f0ada240302524dfd60799a28f325",
        "bf93c510fba6fa361d0d46a1eaab7d4c",
        "ddd30df957ebd43f69d0bcb80b0e6702",
        "b99c70c3b63268042ef2888f2ea8ad55",
        "0526ce96e90d96d713e2a3256a106591",
        "829a5b1fd0cf995af117011b2bdf3c07",
        "4e7ed11a11c2ac8521792ab019d2b8ad",
        "7154aca101dbeb10a055757add26a1d3",
        "da77213025a90beb1fcd9bfbf201749b",
        "ce8cbd1d3e99b2fbe0c2bf12590b61df",
        "b0316162b299d0aee327fec6d8774bba",
        "e8f312deeddd71e7cd024678913d9dc4",
        "87618eaab9f0d94c406dc93b343f2490",
        "dd10a71460d110013721706f7f19056e",
        "7fec40c6f9d02f6fcad1550cc7bd7a38",
        "9e014bca6c84d14258507326619ac17a",
        "440711917a12937056f8ffe9a01c4a3b",
        "7c03eb84466144617ce0c6f87ac8257a",
        "77a4447207f1cb9c3f9ce17bc968fa25",
        "96a64fdb46a4da0ea164aed2d642e74f",
        "3bac2fc72dbd34b17a256ce29da597cc",
        "f48f894127cc2d9ab4862fe49f8783b3",
        "269c9228c5550543edf16a5a4674d86a",
        "c7dc9b4ffb67462715fdead79fea51d2",
        "514f722e8ce4e67867dadc575253cfc6",
        "93a73a4ba8df148f4874d0701050c2b9",
        "8ab2295334fef8e3ef82bf0abc12aae3",
        "0d20bb442d0cd7ec3be2a988179ed2f8",
        "49136bf679edffe4e15d207501790d4c",
        "2d0bb65aeab75c462702595131abeeb4",
        "9e3e9cded76242e39e036a937a30735b",
        "dc9b447881b009d1f3930429a09c53ff",
        "8b7dc6e9c81d18c96d6b5adc6a2bd4b7",
        "b8d55b1700020ca4e45eeb46b1920844",
        "d609ad78d952d7756aba74f6fcba28fd",
        "d02edebb7e42468f8b5a5d715a1a2ad0",
        "7f3bd53639e082345b48d42dfb9046ce",
        "8b2d2f34c58c53314fde1d0d093e4e82",
        "f06ecceae1b570cbe0c143d128e39053",
        "797ef53546284e42a9ce763840a92aba",
        "ea7f52cf74b05478d28258d503a2f8b1",
        "f2018605130d3dfc40034b5966e7a6e1",
        "0c07fca6f12fba6cd56aa643771088f6",
        "618f5df2808384479a3bd9f87fcb8192",
        "8e42ba5d79f78afb435dc7e394e0be83",
        "db3aaed0b092657cdc029ed0904b539a",
        "0e12e5ee7bf7fe538214b396e2d2159e",
        "15aec086e51c4e6faecfe3ecf9b89710",
        "6476b8d4ff6938a53b71b835e85bed14",
        "cc094f5fbfd7eb70ebeb40fae67fef6b",
        "ba386f05916eb8adfda487ab8fc17835",
        "342892949984eda928e951cd7f0c6748",
        "8e1b6e70824f39f91d1a5a88ceed1cb5",
        "b20f32dd2543639b6bbfbe8d24d2e67c",
        "c775394505157aacc615e05f5f3191d6",
        "2a20bf637d2a95f155ab93a1bb47fb35",
        "88afce05a21769ec868738213aa6472e",
        "9479fe2caf053543f3f099ea50e4b933",
        "e21d0dcc064835a7647ba5c19856a42d",
        "0afa069b05fdde19c0ce409e71259d69",
        "9b8bb7d1bc4a06e3d395a18020e33c48",
        "db2bea21e8c3df7db80d45ca07d08749",
        "92bd30912c7ecf36a439a9c21f03c6cc",
        "10b177507847c3866c6f1ff85080e10b",
        "f9598242868ee1652f03bdd8f82cdba9",
        "1fc6c6af4b07f158eee6998b6c9a1354",
        "1005825f80a420920913e8c222fc6bc7",
        "c692b2d5e0dcb73a6f5506b0a31fea61",
        "ec47715d3ff61b7d6eb68048c7624170",
        "c6d24ec4564cc0761907c4fab9043cee",
        "1e1e9d0f48ab01eaa1e7bde7da35ac98",
        "ca5317adfcf2a974611e745e6cf6c0cc",
        "25a02867ad29d482370dcaaa45940c66",
        "355d212a093ad987e8e84d85f21c6bee",
        "efbc21c7607e2580844867ba9675cbfc",
        "f341a70b550117a00e90dc87d68c68a0",
        "77466047310526fd451c471a9d0f259f",
        "d8a9190e5a773b48db05fa7d6ea5eeef",
        "05960e5f9196393d3d1a800f0a462246",
        "becd92f65215697d087df23c70888a8d",
        "c1ad46c2335d8cd53b3ac9c3bc59140e",
        "198fe3304796041a6fd4330f099d9c12",
        "7203d61a8d680a71ba6d1fc8911bece0",
        "be3d11a3c37493faa301e705498749cb",
        "80d5e3793fa001407f1e6c216b9cef15",
        "9544e210063eff81990ecc81c10f27ed",
        "8ca703776527939dc69225d635fd7a90",
        "d3566036e4035f008669dd4415fe1555",
        "57f1e8aa142b2c4903f78254256ff117",
        "d9a1ab5d908b25438fad0f9535c50207",
        "e21f2f8dd816f716cb6a4fda781328e8",
        "81f2f03ae927da33c240f4f856c5f4a8",
        "0460d70bee5fc14626ff0195e601405d",
        "b945bcf834d18813f1191bc3715341b0",
        "a32e7b60bedcf9279949806a540e3fcd",
        "15afd6bda96c9efb593cc62c52282165",
        "9da9dad787f00f40295e1dc8b2dac2c2",
        "3a415b7a1e3da1504d060984c04e5085",
        "1a16faa07a1373139da12cc2b4df336d",
        "e6d4806bd5d886b06db4d3f0d93dbbcf",
        "82e9c8eba641dc6b8e2d914cf742ace2",
        "81ebfbe85f31075c7d2c61fc6fad07c9",
        "9ef84728ce9e131852e0327695b7f959",
        "2eabc76154d4dcd1fa265b604084a776",
        "30956b8a3f0775f6f635f8b83c4cb90f",
        "32d51265cbf03e5e3a75f6225d4d0f7c",
        "4e14ac485260223817e24a50129066d3",
        "61dd2a2cff141a0ec5e78c09a5996c16",
        "05cacbf2af48063e033f5a99452d2352",
        "1a40b320e2cd1dff9f0ffcdf9adea3e9",
        "55edfb8dbf7a2393ee5f87db0934e348",
        "5c1c4c2061d2ada606ba536affab55c6",
        "ef34a2c0213a72f2a63167c98cbabce1",
        "572cb5340b036136f2a26b9a40633273",
        "5910429cff09cd9e64d500f2483e774d",
        "933db021caf33abdd780f4a1ea4302ee",
        "7e8d75ca634b5d9f6363e56d82ee7566",
        "7a69975ac358d6def38ca48334eac909",
        "3b3270a5f8eebb7bbfd59c60a9eb5d4f",
        "fd8c6444de11fb404982273be3a82369",
        "f5794e8b7bcfd27a285b561463aa9076",
        "0d6e227fda9784f466f978d681b9bde1",
        "d696fa5d6209bc854f3029fd26e0733f",
        "483a513fbb763c54360a8b40a335f28c",
        "0e931ec789fa9d6b38cf7c4238ae2990",
        "e6892d68f153b886ed7e97d3d9f43520",
        "2d833750b9457d595a82da02d68fafa0",
        "258dc14301bd7b1fdb8d192b0f87d76b",
        "edcca076ef370bedf492c1134d72f269",
        "667fcae760f32ff2573a32b2fdfdf942",
        "dc5380225685c309e084641c5ca08777",
        "9271d4fa53466ccab287a07267912911",
        "4e266af91b9a601a63a2165e0c23cbb1",
        "0f5e944dc9cbdabbffe4ba68b32a888a",
        "dbab4dfd016e9fce276b28c4dd7c3528",
        "ea906b55b438ea9bcd4daccdd3e1dca9",
        "1ca705c2acff9552d1732f18212b93c8",
        "ed83df6d87a662d85dc75be7ffd28825",
        "e7a9c88cdadf52354066fffad364217a",
        "d4b929360a7722a0687d297ce1e20197",
        "dbdacb864176b93cb3faa079e4f6664f",
        "046f1cbaaae13a0cad840c353b1b67f6",
        "d76cb64c3406f0c2dce8f2375d88a0a4",
        "dcd7d7cfdf9137877db00c79674384d5",
        "329e36a9b878be1b043b8dc3132c1384",
        "f7c9a137407fbfecf88388ff749380d9",
        "61d23a26ed2019bc51f0998ba4d57646",
        "aa5c7992702a5cecbdad3aba8b0bd890",
        "f6ca4b0d7b1157731dd8a59eac496199",
        "6b47c1aaf4432a6ee913bad0a7d59020",
        "3ff3c2c59f3ad1baadeeeeb72de8ebcc",
        "66819fa6e5892022eecc310cdd914583",
        "a0505f642fcc51bb5953dfcab3e6151a",
        "b356a1b15f398dd05687f8bf86c05439",
        "9aca335953cbe7c46847c6deb43fc728",
        "18cb73b261db7d44b4ddd7de35cf2f06",
        "06c9bcc89b7a248c694ae1e9108432e8",
        "aee50e85550d593f1e8cedf5e7c00b6c",
        "ce6dcd5640e1cfece34e827d3d94b4ef",
        "56b9fe0d46e19d86c10481fbe668979d",
        "ad7ef9ccdffaf1fdf0da944589fa02d2",
        "536aced9d622f8bc759f8d3769332164",
        "21ab14346c2b728d8dc291371d3a4a4b",
        "1e0acf18349ce60b0cb8d4dbe7607d04",
        "c8607fce7a636978fcea8f8bb486b39a",
        "143490a8465619ca61007e8624fd9b71",
        "40e96310daaafff5a4c51454eb73940b",
        "452d2efe6ce62654ac6542f28d38eb91",
        "f4620b358a20ccb432a3eb180cdf69f2",
        "ba9d44fa118f2468568afb9b10bbb384",
        "0c440cf859e29ce006ada5bd85aa38bc",
        "27ca82db681522f79688f034fa79a36a",
        "2f28d6796bb74b7b7b4f8a0f8a7e8589",
        "cb1dc86a7f0eac21f8c7ea21dcfc6c1b",
        "3b85cfd2624314faf50de5e4deffd8bd",
        "8a8b23acae6d90f2a8c740a5972f15cb",
        "167820cdf9d602234dde0e62aa403caf",
        "d27e65673b7c4e1b39bfbf3b090de528",
        "28ecf8fe9effa6358c7cd1d5189c6107",
        "03533f0c68cafeedbb1350148158cb97",
        "415193773038670791961d1995834aa0",
        "1de3d68b0622cd0ca9b98f56fdd9a4de",
        "64ca59ffdee4ea1b6f8391a4f39604c7",
        "76b1ff95c97432fca8760b275fb2529e",
        "37fcf702b81b72535fe0077037ce9b0f",
        "ce5edb27216aeef4ed67abaee267b204",
        "83f5dd75f5e4311f2972543327ed866a",
        "a44215fd8f7bdf56229ebef58ff1d9e0",
        "e4b033875f25df2d8db96aa0498eec27",
        "02b9df000745fb392dbf0eebd8719548",
        "07736e961db61517f0d7c97bd0947160",
        "d868fc0903598e62ce2d4e881d53280e",
        "70350e2922fe0e788eac761944d508cd",
        "85e66f347a8352ab3c813f39dd7aaf4b",
        "4db4f9ff307bd8f5ea5df3e6e8d45909",
        "4df030f09db83b15078c1bacf2cead42",
        "7b7a22177c6b68439aa6a0272c007251",
        "9268d3aa134f130679006c2da3868552",
        "9b6b2d018aa9ce782a2c82eed672a828",
        "8e1919afa0d740b0fc74efe587335d97",
        "eb138a2057e47522867fb4a44e9a7672",
        "3ecb95080e1aad5d2551ba6c673cf7bd",
        "fbe4d4e683cba0a73767cd9fd841199e",
        "e641343a3039cfe2c0584eb20959a8dd",
        "ac7c80db3284c0550a92289a0be34bce",
        "b23978374b53f6dad7550bf00a5fef37",
        "75a22bf8d7940c363dc09929af1475b9",
        "dcb9a67af6d4e4897afcea47f54044df",
        "9ae79b9bed10b0915834e604af5c449a",
        "87832a74ed5cbbe8c6b6e22b2a8c769f",
        "d9de2a7b86a23c81ede6bd10ad4d3679",
        "a386c6961dcaa57751c63fd58414b813",
        "98dda839ee97715cb18d244d68ff5ca6",
        "bcb06697a2b39301567dea87b8073d82",
        "a910b3113c82c3c42546937a35bf6c7d",
        "291700ab0ada97d765faf0ed5a575bcc",
        "f7ee2e2ac2ba5fa2cc5f5a1a464d09f6",
        "4c6945df5983aa98298d125c33173769",
        "0a5cd119ae93fff64462a28c0156b63d",
        "96ba45b464357df659893fa2d25ef5d3",
        "96c7968a939062e355f3cbed94f1a9f9",
        "4f680eef68bcbcdd59534343d28b7574",
        "dce5c58a691f5dfa04fce9c53d6f54bc",
        "90bc869be603f7e6d991ddc6e5e53a3a",
        "db9bae3c1e93e77188d568ff1e66548e",
        "fa2e8aab8b9144ca035e415c1b4c233c",
        "661b0abb05e4879122db0436151ef791",
        "d27ed8bb825e58bbd92c6bdf91572ffa",
        "13f4e825d0292ef35d8570e9d960fd97",
        "e94404eedd5bfad3cfd2aef012a66b83",
        "cc440b9c70aa86c1b32b94fae710ada6",
        "13146b6d46152bca07e3915f4e6123c5",
        "b02f0ca8f89ce7292aee27faa21842ed",
        "7e18090be931e29fc8241a26a4c148c4",
        "392847f52d00e3c1a2ca999a78ec300f",
        "0daa454cbd11a885ac066b27a64d19e1",
        "5f63aa9bedd426bd73e0949a6698fe0d",
        "d4e69c85639a90ddfc2ff0f5524c7446",
        "5d53e2b7b111b0f256c7f0069cf08acb",
        "953523a8e7b75c15b8d7e4306d284c53",
        "376d20301ca8bfabed81b9d9fca01dbf",
        "aca96838f38c2d640470d4a18079609b",
        "5bcf2b287c7f36ac165faf06b0dd0cc5",
        "2badc9b84e314ef36c7b6e6e8ed8fdf6",
        "ff403a63935a605c19593ac04a81fa18",
        "c7b7e6cf691a3b5c8f702e8f7c24a121",
        "8f91ea40fad506ad487c4fb95fdb8d98",
        "50b10948515ea82915f8524c1ae0e3f9",
        "ca847eee207168fe9a6ef165e41bf0ad",
        "4e4c231ec50e66f166d1cb89ad1206da",
        "8f150d983a9c597733bfae234f1c5f92",
        "399afd3da6f540c1b87a42cd1c4f39ca",
        "9ff9d35db58040fc92143422f71d4891",
        "8a02529f9bde6a7805b979fa84b5f8fa",
        "b684eb165fda0974f3b81f4a73611774",
        "2a46a8e18e80615e76292010fe253724",
        "3661f02bc5bd97f2798036ce6b754055",
        "74bcf969ab264d292f3702ed2afddbd7",
        "f6ad2b95ec7ff1b3018ae57782cf86cf",
        "28c50c4252cb8b26cee98dd8d93fdb26",
        "f31244aa7efdb605e8c6f9b0210ebe05",
        "caee676f4de2cb931ff38b7932bee953",
        "c8eefb6cc3a2d26f9f42b7625dddb85e",
        "50963ff846fd21e404994d5d414e6612",
        "93012c36052288ae5966f5a9f45ac525",
        "71f7e906aae63031cecdceaa318eb2ce",
        "ab6c549e4e9160d9ed3e4488bab2b8f7",
        "0899f3f56eed9eeebe8b4c5a28a7c723",
        "335dd68cf5f59664808dd673bcdf89c4",
        "9ff3b9cf2addde5d63dc6074a1a44c11",
        "3454e6614bf8983908d3bf4eed31bec0",
        "538b9b748abe64b0624598e6ee29a576",
        "9627c97065d81191df68057f8295fb7a",
        "7d2c4c43fde53c4fb6ee6b574769c328",
        "744f58f340e54e5e10118d8b5411e548",
        "4bbe665bd64e3b5de81c5a719302c733",
        "4531836302574af063ddc103a993b807",
        "7c44ebe3a82149e7880716afa13eb4a5",
        "6b30dd1ce01a0dd3dc705af780ef317d",
        "fb49c8713c399e9c874d7b8990a720b1",
        "f8f4ae1ea6ca8963e675b461472e247d",
        "da54f117676edbcccd72aaca0553f8e0",
        "c33d8de28a3ee484c82083d973ee9b7e",
        "387e01631b10ca26aa6c15c71c6eb9ed",
        "1cb8cfc11c9a75c585668d014434faac",
        "34ad7f86a999f44af22a77f765cf200e",
        "027507efc5639b69d03cfa774e355a1d",
        "793adefe7a1eb5c7d056fc313ea9bfc1",
        "9293c270df2306e21b13945b423d0e49",
        "ef1be1c5fe37111088ffe0e885601ce1",
        "d508327264bdf440e2fb046a5167a3f6",
        "36502e8e71e358050f49e8f9ce82c05e",
        "5fbbfaf6e8cc2dda25f8abb53020c46f",
        "d285610e7c6d7e953bd3a407dbf4af42",
        "6c64a132b9aa65d0dd4ed1fbece6bb3d",
        "7561f537b78015124ff569c7c555d1cc",
        "111e80093c0d9a283cd073e03ff35abe",
        "013b2d33d1ecb284b40891bf15d8500a",
        "06dad18a48c4a7d97b05af695948c80a",
        "7112cbcd07b8c6661044cf0d93f093e7",
        "a9d7feb3d7eefa079d2030b50896af0f",
        "25ba01358b137ddce047bafdce3b0d2d",
        "8cbaad4d2cc7ae30bfeae11955ff1ae4",
        "5ae789eb8d7aaae3cfce0acfa4fc4b55",
        "f61d2ed27fabbff23fa29e2a3775803b",
        "cb6ecbd5d316242e6e9ac223f159cc27",
        "93b885673b0fae78b5a99c3f666fff9a",
        "4fb3295bb57c7551fad0d07ee82bdaa5",
        "89f4f8ec618aa4f0b04b39b666f18239",
        "0fc982ab48364fada4dc2522eefcd018",
        "695600f7b7881d8e40c2310c0e86a40e",
        "32e4738221031a1d8b244fdeb20e0077",
        "21cad79d1af5b88c563ddd1b0592250e",
        "81ff36b0418b5dc51dd8dbd2a89d70ea",
        "d147bb63590c948a19fca2ec1f9462bd",
        "a02ee8969b2a78b7e2c98856f2cdd6ee",
        "06a11b91b971b277e17986392ad39bd7",
        "bb0fa1be996dff69b21144c65f3485ec",
        "f22887c056cf14db1bd282096bd4a300",
        "121703b9ca9475f63839c5b07a7a7298",
        "3b70d44482207323a67433ebc2c16b89",
        "9ed57de9a5430f86b6515c874df4371f",
        "129332414ecb8f7c52405e9b0fc45b32",
        "cdc985f5c71b2747b7e3bedecdd19f15",
        "d485ded980288fcfdc31c91b9b83cfd2",
        "e9d21da9d603dc26f002e55ccff61f2e",
        "32a3573e4e729b839cd26be220922bde",
        "5bec6d10fc52552916ac463b67d51b18",
        "64a8aad2adacee2fa551840c268f26a5",
        "1003d180561f500509c1c55ba1c7399e",
        "97743902620006556277dee19a1ebd26",
        "a543b42f2036017ce2885cc49b3957f4",
        "29df865ef2e08513ee0fb113f8d7fbd6",
        "f139bc6f71c559aac9cc7c1cabfe7448",
        "09103d818ed13f90cd2ba8964486bb75",
        "354499b8f8e716b6189d014ad23a88d7",
        "726feabf032b80cae4b1eabf677ddbc9",
        "4279a39ba234fbfb2019f14376b19459",
        "e891d8a2e92bd0c8f33c115b44bf65bf",
        "408f10c4603133ef73561b38cefcbe8f",
        "9e2df1433f6b67965fae1069e2c7c662",
        "554a81242acc887ccb17d0019be52e3b",
        "efa7e7df9ebf421b274cae34f78f90c2",
        "7f8a5b019e4a44273b18832618c412cb",
        "4ed4247a616da0fa65cd5fd291a0c0fb",
        "6429f0c2ec742359a0c8cb940be3690d",
        "bfb844ec09db99ec5914f3ecea57db47",
        "c3610209b323df2f0d62b169aa24485b",
        "e4934023d857eae062fbe79bd2221531",
        "3f47582818ed9dbd0c5559be094cc443",
        "e2aa6228fce4fa5168a26583f896ffa8",
        "01d83b55c905bb1f34eb537dc44be546",
        "1a30968bcd96b4eb6e5e23a163801b06",
        "a7b0098393d418359f95329781f8cd07",
        "b5e393063142fdeb237bc69d0244a371",
        "193ac8385174f4efe7756ebb94efe0f7",
        "1904c9580bbdae92c423786ca0b9661e",
        "0d46a6817a520f141d281761906e19b1",
        "7803c66d7c96999ca1b8b1638d9a5a6d",
        "256b2dbdb9bd6a9b3d8fff871a5fa98b",
        "8a9b57c0a263ab2287b4daf42ca9500f",
        "0a292693e9c6c6e25db090dbbcfc5d3a",
        "8672eb88a13d11086d6867e351000f7d",
        "715d6ce7af8cccc2b40bfd96832a8ec6",
        "372ff158811c3362afdc08abb5750541",
        "667c05311ee2eb7fa388ce81d386ee58",
        "a470fc91b2334e1005956551fefe1473",
        "e44e289bb50d71e536140bda9b1ddd68",
        "d612ba92f2b6e514e233bb3aa5ad9311",
        "8fb85070db1c237b93c618e614846fab",
        "e2b42b57d6ac503422a3ddc4a854f186",
        "9bf0ea3e8a1f76eecb972de39b75721f",
        "df10f8fc78d3a6196a8798437f25efbf",
        "7ac8f37eb1a31a9dfb8866421f87fa43",
        "cf09b90783f8a0e65cea3eae8b7dd280",
        "72b8504e286d87e094f043d35d925364",
        "dc26c4e249c20b7d6f5ee2617dad4156",
        "872d51370d1e0dd0fd1aaadc8e3200bd",
        "e09dca3b14edd4d0d280720d04286ea0",
        "0f8fd87e323fca6f87089c2a0b828ae7",
        "2b5d3c22c5d7eadfdd6082ee5e61273d",
        "974697b818bd90ea021ac688d22f942d",
        "430bb12e03092b3b25ab7c628938940a",
        "675957d55a602497ec8bfae3541ff22f",
        "a001fa2a76ad5ae391fbc1ac3704df7c",
        "d8cf65c793dccf36b41b4e6ce3e0c87d",
        "5ae4e4da295b5da232f63d0db53d991b",
        "a0a1d2eac4f31cb92bf3fcdc15aea633",
        "132a6c3dd6878461beb311b27cdeed0f",
        "492e7f29b90b5f2c8beb367a69233349",
        "78614622e18748877a369f9accc01bd8",
        "cf78071cf4fe8397de60fd6ea222649e",
        "96a9d9c64f1a59534759e76e5e247df8",
        "d49273ef3611064e4e7f3be5b4da12c6",
        "4304ff78db6aa96beb6f721ed5cb322a",
        "a170d4f6c5c782e3c60b99c4ef0ddf0e",
        "23835fdf8bf299529b3c5e0aefa84d0c",
        "a386dd90266db2c43e0daa2f005d08d7",
        "798e08ce6075f1241838f3cf40d0e5f2",
        "f5c955d11623a9fe6175ad0fd0b8e578",
        "c4e264f15b16ec33a2bb72a2a252a261",
        "2940f276fbf9aa7a5738da4084a47b10",
        "41047b8d88f14f1d6ffebbc8a260189f",
        "b6383501d3e862e19266f858e2079e35",
        "9b9b18bb45b552d28a8dbda8c6939355",
        "d1f6f3f6ad3562d40ab5a636c840a257",
        "3203ef6a2ab36f39119f5c88db331816",
        "7503544570ac96d188a79766fc4720dd",
        "a114e8892606b5913bfcb2ba8ae31792",
        "1e3e4a215724f78fd9d5ceb29767e3f8",
        "b91f5d00b723058b82b909d653799221",
        "9663d49a0a0339cc4ee9a4723519e8b1",
        "3c235377bc892138d8c202ef6f2995c5",
        "93288cf0268dc0e6c04e80a273f05d00",
        "41c6ba01f2b7dad7ba74d9a2e05cd889",
        "79281aed1df2c4206c563bc055e9e97f",
        "f353c1fdaaef1943b946b8a3059c8160",
        "eb5daf36f094733f74a1c36cb3e71a8c",
        "0b91f367b9e506f881e1f72c01db7bcb",
        "0a48ef3ee34a41d862126444ea70e968",
        "5e5419467a60562a940dbfc3fef104ff",
        "2655f400d92bbcda8a71a3a89ca8ec29",
        "9fd668c51b98caa5774da59379741406",
        "f7849f8a175fa3a29805e4498dcbc048",
        "82a7f297636ed3eecb621eb51b59a946",
        "17b3f2bfe5a6634b24ed104c29182780",
        "1c20f7599f1078819ba5bec4798df674",
        "d6f0230436ed950b24fa790846b7d145",
        "dea4a560b4bea5d7c3d0b1d6eae590ae",
        "8178814c4166b1cc4e7bb0bfca7b9aef",
        "9960cddbb7fc328ec64b27ff52ec97b2",
        "62cbf25ae4cd8f8a2daffef71fde5d7c",
        "a54432ea0da26e5e226448ed2964ad84",
        "e913a9def668e5bc8fd1a334f900c367",
        "d25217fec47e6812f38d06ad6317c9ae",
        "a8b0c2233c16b0d1280ed093b52680a0",
        "16376a8dcc4cb27b1785a58a60cb2413",
        "21742c78e1d88750d887322266397240",
        "b604183d0ab8cf0f741904803ff061a4",
        "080829ea91a09e7211fe1d744277f0ed",
        "d8bbd2fcdb966b3f57124374af45a021",
        "85a289b8cbfdbea088a7eb26ebea24f3",
        "138fc3daec9f3e9d442f05b8bd349184",
        "6016bd912cda5ea5c80c878ac304bac2",
        "a3c924c8470a45eab1246aa8be8ae95a",
        "909341a4a8bdcf7de0d0b2661d69803e",
        "a59bc543409f8a17d818bde299e0c7e5",
        "2e519828cf6704abc3d9e5e7e7261ec2",
        "7fba945136f368e5db9314ee98610840",
        "5e8e2d315b65bcb6db8c8782d69e38fd",
        "b38476b0b3d46c957dc0efa7b473774f",
        "180558ada892116f5710cec955cc1ee8",
        "df30a05a80254e91e914443de9009e5a",
        "1317083c3a42719465795ecf410ed9a6",
        "60baddd9c952f6e3b6e64de15d9596f6",
        "acfe9cba37b4f0581892c70ab9866f0c",
        "336f0061d1f7faa0834a38e98cf25390",
        "981696c5b8ce7fd21afc9469056fbafa",
        "d48ddec4e658ddedf64a9f1c03cb5b0a",
        "a0e410b35f28334a52a0cb1780a1ea62",
        "e1145db4e004afbb746ddde8d93ecfe8",
        "08c896407e5f9f1eb4811b06c2f1b55a",
        "d5a52c6476604f9053d2a527d3e16ade",
        "b21a101fcc474621d20ef0f48575491c",
        "312672c68680b89cd4bad484fe01bd95",
        "f0b7c735e3d1815afc68ade0d5f844e9",
        "9badb3d178b7ae57f6b6c152cddc5295",
        "aa2e2820fd65002743c72d73df607db6",
        "ff131b76d2744bb4efeae9afd1ccb4a8",
        "82328a5234ae35a9a47b23286188a48a",
        "a6408e1dcb66b86adec8f8c4aa31eb2b",
        "55659f0b5ff3545cd73dcb555e657c5c",
        "aefc17d363d9f326609f1db0ec8e8049",
        "ff8b9790ab512e3f5eaec8ab591cb898",
        "3b4f9b3bd797e59c36feb577d1418f97",
        "862cb17d8ffd21d27516d8806cf72424",
        "5e6e1c36d775b37689a1f403ceb5b5fb",
        "ab662f999df95a93a94a45df40d2b805",
        "2a644a7dcd30c13a633e6dfa2b0db357",
        "a21d150030044409f91ebdbf033cfd30",
        "879f907d9fef7909b036d94127b9a55e",
        "a43ef8bebf763179221917f87cdf1429",
        "d622ef4f4013824fe487f1b28f1f67c4",
        "c77c51f3afedc8a0d2a4fb3b9b7516ee",
        "1312c026223ba23f90f5dcaa69ea9a47",
        "0f3b977ef4bedb3a5e149deaa0cbb50a",
        "5f8a0df3df2778127b47258aef429de1",
        "48a1138663933cc4a03e89af0a951327",
        "d94db509c0cd70c0ca799a67e5a85c03",
        "665ccce62db84166a1a0335f00cb049c",
        "a6bcc3669c2f620fbf3464129a106e72",
        "7390f51e0942f41b73a98dfa5fbdab1b",
        "0dbc635ea1a2d6a490f08490df3956f8",
        "ea1ef3c9a5671ec36d48d78240fdbb92",
        "40b8641f4db6d6de799647b2d5537a45",
        "9190794aecc6e6886194e74d2738c608",
        "00b3a2c675507b3e60fe92b0737c37bf",
        "cfb49945d615adc8d91429a9bc1ee066",
        "028fec73040e0a910ca9fd40b357ae31",
        "de5f0cdf783161dc95aedcad8a58de85",
        "11ed4a73fe216bf8ec2e52e6e520b8bf",
        "f1e845963b94804fc80e81971253b134",
        "66ed6539be17b67cdae7d2a12ee1cf2a",
        "45141559dee2cf570d66107f5592e0da",
        "c530043d6bcc22842ae5f65707e46656",
        "8350711dd782eaac9af05808f05bcb45",
        "2fbaf3477bdebf12a417b3a390513488",
        "4b0a355484bf58d449da2b5327fd5966",
        "8d5e37f042c7fb9b673a10dceedec33b",
        "707b0f18a4bcd5106fa43e18e0837fce",
        "749fb09269e255026b2c4293be2a9257",
        "d0ab448fd17ec6559858cabaf3d8769b",
        "e70a5747da682f8c078ba9c1ac9aa18a",
        "f84940eef99b90c22500e8f03ee0e9cc",
        "93297bebb0899b0cc5409431cee7c7db",
        "3a15fbacb6030f7a5ba40202041a3bac",
        "9934100131cdef2c6b6329b677fa0763",
        "276da65247cef6ae4814a33a44cad8cc",
        "f0b0ebbba552fe1232702a1ebed7a305",
        "04c505d0836a2699e6df69a04a25595d",
        "5383883d226bb63ae9064029207080e3",
        "733e3a8b401a263d8fd805d197b421a3",
        "13f10fde69da06fe65b474221aaf1936",
        "a67434eedcaaeeb63138a2c17c7fc95b",
        "8672fef711aabcdc0e3ff2342c6df239",
        "d3706da897c7bad8a5fddb2b31dfb687",
        "4a4e5aefa77595cf58624f186ed21803",
        "b551dd4de2e0f1194b04754f1e1dae9a",
        "2c2b09fd16005a4e53c2a904ec689dda",
        "86e085478451e33750a4be93ab7fc643",
        "019866460972f247731409205eb5e35f",
        "2c45988d7063aac3bb1bfb7d2333d8a8",
        "6d5213a34f177041c94ba9bea99c39a0",
        "ee0bc51ea95cea9d5c7eda7f5b3329fc",
        "432917415aa8d2b64791b10cd5f37cc7",
        "6090b818229c419edffe361724669363",
        "47e84320a8410321e7089c3bf003fbd4",
        "d096069ab10df9cb9e4f7d84ee95c0b0",
        "f7670474db4fbe5cd36e149a73004652",
        "791cb542203fc35f5a2f38b618ce2688",
        "f371a3926369dda65273fb63616f1903",
        "b48ee048495bb03be5c562fc1e372da8",
        "eabeba07119e447abbdb5a5d1ad7b13e",
        "0118700b6cb1c2aa7988828ee1af35ed",
        "2c0e909fdd3c6048924f2ceaa4a66f8a",
        "3c8cdd62dc11faeb0d5816418c92e103",
        "3f89cb3bdda8e44e0c8a730be62b65a4",
        "11df5f7380629db398f6e3984ea5cf3f",
        "8069601fd6446badbbea2f1469140efa",
        "0a9b8631bdcc53813b229101035b8fe1",
        "0ed2489a3e3da2eacd97079576a717ec",
        "cc6c86797448a379f328436dbd2782b3",
        "7ed2c1ad1b5927151fbac4e80663f098",
        "d5cfe70d5c50fc67449f64cb9575b7f8",
        "348d043435e5b25f89943bee5d30f92e",
        "f3b4413eedea2d266819feed852c4e45",
        "57ec7e5005ca8f131008cd336620e586",
        "1e368cbdeb3a84b2da3553f48f6908c4",
        "f93ac2e1c4f35bbc59d87a71d130b6e5",
        "86ec5c7a6a0ba377ff0819b0ceae2529",
        "d4c7dc6937d571d819bd97fe2febd364",
        "788e36f08d8e10abb9bf678c9a66a5dd",
        "f0b1beffb709565e141323d150020706",
        "17b0f0348256279370c4e6497e3b7079",
        "3918af8566db2347450291d4f5c50390",
        "c81ae3145e43b11ec705476962d9890d",
        "d05247a1540529545aa46da21e342174",
        "8ddeab280a1c7b2088ef575635e6cdaa",
        "9b3ce1aa3bb6ebe8e1bbb7e84564137a",
        "48e10c7b6a58994ee8383ee2962a7a49",
        "6b1ff0145c4ada0ccd559f4e77179f64",
        "6be8d8f6b953622ca866aff538dd3fa2",
        "cf9ddaf5c69bddd18cd9849eaaa6ec2f",
        "a0f99b2a64216478b73a8c73e7a299eb",
        "7afc8cb064f79090f1b9a83298d5a0e9",
        "c28d9081cdca6a4bd4b7d1c78c78a738",
        "02e0fbf906c1d859a07a5a61c81b0fd8",
        "c2b9b9e5b34cc412affa5ccf72a75de3",
        "7859ef6cbe29f7cfd918f4d2dce3017b",
        "6197540a7bf7892d6b0e468ed7a2775a",
        "fe448cba74e1cd3478eb41d354a2ef6d",
        "29aec3eaca84c0672432309773da7716",
        "32d3c2222bd09a28d9ad76e817144ef8",
        "8825b596c5972b9942979d253540b345",
        "57fecb30b9dc1db98992c395b7cae779",
        "e7c437259761910096d595d3084bb7b4",
        "bb7e49bcd51dc50d7662d7d4ae336279",
        "73d776faf7ffd39ad668f809eb2817fa",
        "999a092bdcf2cb64e5953635fdea60ed",
        "31eba06c00879d8947dedb1ae04268eb",
        "16b69ae99687f8a02eddb578322d7938",
        "18d7e22f241bcd9ddc8362eccb40582e",
        "a5b225b6dd158f5d5c9fa0fd57dcf9a0",
        "3d62c7be7f8b97c53dd58d87430bba54",
        "e055f835a99f70e06bee4b4b426f519d",
        "17c7338d1e1faa724978b4063227d26a",
        "b77f53bf9f68f77f3f1451d1f6630ef7",
        "7ef7600669dca42bfcad940e194f3a7b",
        "d77a3078df75e57ec7a58c935d4e6c11",
        "3dbcaa891fa6111d1833920a7e1ed9be",
        "184933f15bcea481608e372620fcf2cc",
        "aec3656004f22da334d740f317969584",
        "37e1c81347fb42382dbdbc31f517cd57",
        "ac7537b288cf61df9e357b401cb261ba",
        "a1800dca5b6fee68efac245aa0449144",
        "5047bcb0980950ab5aac79b1c0d278d8",
        "7893b9e52d487381d6739506d90999b2",
        "0e9c8405a567102747dc0d56139b60cb",
        "c8f68987c3f08f77f5ce66f5cd4056f3",
        "e03f08a11d3fafd5a4864efd7ed13bbc",
        "94a3602d35d29f062ac6ca4c49573021",
        "ba8c66c146a20a467dadc4ef18a3db0d",
        "c74661a73bfc4c2a57ad86b7bcb46e27",
        "1e6edd06b60ae4f715b11471f4cf7c3b",
        "8553a3feb8e16a1e02f5835e89f89e1f",
        "e67cc5f8e5e0f64c03002b90c0cdf193",
        "6e7ddba8e3896e5d31cf00e10f61a1e0",
        "2d1e4f0d4acbf0016454ce69ed8f64bd",
        "f1c266c6933d592bfb17b112fa5524c8",
        "0b3753e8d245ff2ea700a14442ebd947",
        "f897ea92e87f5c14b5b0512b192888d0",
        "9ea86c6941ef24dabb7b7b0524a7a22f",
        "b3c06fa19a68ca3d1a5bae0a37abdb29",
        "5e7b772bc5256769508c30eeabba4bc1",
        "91b887a73e41d64eef03adc3cf6986a5",
        "8e8d989f7f9218bd7d482d930cd6d029",
        "12d2215008ef53299cc4dec129cbf70f",
        "39846d8662f268fa3e4f4672003461da",
        "4070c76eb20924618566256c1824bc89",
        "d46acd25886b664e1e97cd1e9bab6c30",
        "d886f30373c922a849c41f1232a32a22",
        "347c2e7135df52c961b8950e50b02862",
        "8b3d928da4fbcd1ef13ac60dfe649d97",
        "2d6450e6e4008ebc64f9ba5a0e04fb6c",
        "2fcb62fe1c1b282c0da9cbfbd4318da2",
        "efa59dbe562d192dbc85fa98c8c5d899",
        "e7473aa4a7a1759302832fbeea40952e",
        "f48e2be556fc4487576810e6ba773d78",
        "fdacec29cc50b5b09c9dd781c133e3c5",
        "0b95b3b1894da2944ed58d77f0ee4121",
        "f611cea23c6ad9bfc0922853201f2340",
        "6b5bfb86be8f808604a03ce9eb3d21a9",
        "3868ba4372b406b67caff3f108df8683",
        "a7817017fa9cb58310940e65fde5de76",
        "fa5ff5366f063d2f4543d675e7bea116",
        "e2a68a1277fb4a35128bfb8090313450",
        "a746402f4085b51332a5939427149653",
        "9caf5de61b753e239b8d87e3d99ff845",
        "cbde4e197c5e88e3c71374e25ef02aa1",
        "abb8c8b4fde7d4d5ac1afa21e8a77a08",
        "46c1042c49ca19e8f944b3af7c3a3198",
        "f00f6a6710c47e9d3d20815133691cb1",
        "1e12b92ad14fa8c3a4955d36d23b2b6c",
        "f20d780272f0881e29fcc6ce204243ea",
        "cf0caa57d185f002fdd6fa6112bd78ae",
        "826f9e652a76329f6c7876c5a8bf0ded",
        "9cb631633a7920dc842483e3bee4130f",
        "1ea17b90ec252f0f4635a61b95a5efb4",
        "3cac5976fb7cea4c7708267a6d8f96f5",
        "5591d35effa1cdf3bad9706bf369906b",
        "bff77de2441e4e5e2d0ecd4462073745",
        "e516208576db41ee398f5cf1fb97b8c2",
        "d8e8fa60ea1d59733348efb7f719dba7",
        "25f32f6a5b15d3997c5ba5b2ce0bc895",
        "725f53cdab36b333f2b3c61e6e3cab42",
        "41d52eeb9c9c3c0d23426ce842b1a0e4",
        "78a1e60b5ebd92318eb82f6be75b6470",
        "c65a99e5ee5528e8f0b4c5d20e708797",
        "6fe529869b3a2ae29b40c706ce4d6e31",
        "866c4d5a42d414c07c109101869f75b2",
        "4ac57bcfe70da809618713e1369f767f",
        "9396c5af078218faf6133aa7deafe3fd",
        "9b30d26ac60fd681edab927339179162",
        "2984be7fda11a6d959b1bb607ba73df9",
        "542ecaec7d2d003469385ef9aa46efb6",
        "4948b4856de5b4230139702e2798599c",
        "8b00c5a40cdf0d33efd87bd17245e4d1",
        "54f92d5b43fdfaac4c0307b350975030",
        "dbf27937faf307745179f48493b26e45",
        "6ea8dbc43b1dae19ce47bcc06c364f56",
        "0818747b43a7d1259ca0babe2b48ac17",
        "f336ea23da882f7b4fee17c26471972c",
        "23aa0e3fdcf8203f7ac285f11dbbbf6c",
        "0b2ea597d46051bf2f845ebe955f869a",
        "703950eeb219f1f96f697fc466d11e5e",
        "26e7de6ad320e752b0095c1ad2b71b4d",
        "c56601afc09931b0edbc7ac84ab0abda",
        "e11392ed5acaeca6ec2da845a593c604",
        "44e78ea5687f222ef947d19aa802cce0",
        "bf39b9bfd691a5db49293930cf568c27",
        "75fb8b5dd72f90d609b2576d8dca63fe",
        "b1ad002c5805f333a7985cec5aba9145",
        "da267a3abb735aa6bca2105234f62b30",
        "10352725b7a5377f755ce1c214c4812a",
        "32ba2f4efd1450c3a36055d8c2381ce7",
        "ef876ace4c35fa1f9adc855f7c6d824c",
        "50effa31ba204d2c5df10ca31b13d492",
        "67393fcea6ccda985837f48b342f9596",
        "f0bfe501d337186f601d9319f20d595e",
        "6b2ac595710fd8667590571fd4c1aeb8",
        "d60dbd209fb688a70160b39988dd64e1",
        "17414883961c557893926c61cacaf468",
        "65c4eb5cc8b70dd51a978fd31da0c053",
        "9020dbe5e722f9ed52c6b28bb6432d47",
        "8e65e9b6cfe36a99d898542a49417929",
        "572510279055ebf9947f8fb824e27bb5",
        "67c2e377b7dd9b56dbd89da9a891b7b5",
        "939d8213f82904d86a538f2f7bb9a369",
        "0144003ab670921c3c9dd6f46176f224",
        "5d9895026f176973c1675f30576fed2a",
        "bd35ffd5eb04f698fa2beb51f2800367",
        "a85f13a01b78393ec2147cee178409db",
        "d97a0f196931aed5d343635908e2a8a2",
        "e2aa26ba29c6d24a75e931b257147ebc",
        "5eb9bf3a5348dc092f45dc74c252d473",
        "cc6b1cb04414f779fa044d4d5ea02acb",
        "2215ecbd70ad469f43c4fd7db22f669c",
        "a54a6257311b0be06d30f6263289b3d7",
        "faf5fda32f997d39a0f52507364b60e1",
        "6d0767c41f24d704a48077616e0b98a2",
        "415771a684551c9c4aa061daea6c7610",
        "f1b8e7d690c5b05c984d1292a649492b",
        "3e0911d44ea90b062c8798d48b794f63",
        "f5601087a38d6cf31b4a549cd36d38d9",
        "7d3009298224052a513177dc2d9af1f0",
        "5cba1d093d6ee5880af17bf9dab22569",
        "69f5299a82d5866ec41bea2f915147fa",
        "9dcb8805d1247aa5f1bcdecd2227aa06",
        "3fce0a395ed3d615161b1132ceb672e4",
        "76ae6dfa68375ff136e48277e2f3ec65",
        "55d735df11f896ed2c97c8ff10bfa36d",
        "b2218283d3e0e60096cfa4d9a7881f0d",
        "ff95acf309f13e437f0ae611cd0beb7a",
        "6b23607ac1a1c2ec3ea7270671c065ac",
        "f58c9a68218911ad3570679f701fc2b2",
        "88e9f4696ba03286b8856bdbb18471dd",
        "c66e63b9572d2e83d0246377cf8e2e9d",
        "007c4e6d7ec3fa8ac5336ee4e69beb60",
        "deef020b339ef1b78b69bb7d44eb9094",
        "5c5fff809eda89d16c9e4fa4ca0cdcad",
        "6171171b91334d13b38d6ab74e5336e2",
        "a9a4d86238ff4fcd0cec1d990586971b",
        "b67b368c7e73ae224844e14a82f12320",
        "b4ec43d2b209acf69611e1bf5b37923b",
        "ad4047216dcaef67ea6ee2456face1e1",
        "4496ab74b376a74dd41a413fbc9a527a",
        "25f123be0cba9145925e29cb293d6849",
        "ac08c86b4faa2032e63ef0cdee4ceb6c",
        "1cc7cb600c6aef251ec976495aabcaf9",
        "7d23f8b7a66e82afeb827e1548e45168",
        "6271613390b4530ea64944d691a2df95",
        "832971d3637807e09f8a44e809053e9f",
        "4dadaa890230502d5ed71c388d494504",
        "757b257a2b75ab8122caaafef5b6de49",
        "01e5c1b060bf313ee2598117d5671f1f",
        "264446ee1fc38d604705d5cf1a9facc4",
        "c8eb96ff44a1978a0d555b928f1559a5",
        "feba38882d6f08d3bb6c6575bd83fe54",
        "016c175b5b4c534b42da5b71f126fb61",
        "c58b39e8801622c9379a8507fc1cd938",
        "712d8e07f5c39d7acc504e7502c7d58d",
        "56e6ce9336c6685147b04dca9370338a",
        "de5394c9543546064606b206ab94636b",
        "221b8882dc603b5b3343473655d46124",
        "5a04342a186de59431c3ba5954f30ce5",
        "924e6094047cacd859ff70284e98fe08",
        "37a9d41ff1dce3ba21e4f8212be88d16",
        "65ac5546ea1c7ebb7cdf8e58d5ac86a8",
        "d620e0e8c1548336e17b6c1b56fa8f1a",
        "ca6da8576b80007a82b59c02e2e26345",
        "ac5d648650602b072fe3e5992587b206",
        "b7e645dc9f4c31f38aa5dd331c13ac5c",
        "9a2931cc1b8a598b08e3f670d015b040",
        "f023115459e3d67ceb3bac5b437ddb63",
        "ee5b57bcfa4872e7d9ade98aee2e6bbf",
        "34452235365e0abc6824e5a79a26aeea",
        "3f5e4872dfee734e5b28c245036977f3",
        "a52cd9eaa0f1b0cbc5274bd3ba6a64e3",
        "8221c31f7dee4eb92043f413593864e6",
        "3039edd28ab8bbcd60c92bbd4ef6c2e5",
        "ea0906ca508bfb62b08f6f90db9cc045",
        "b99f673a5d7721f5c0d1b7b1da4931db",
        "89905928a6ac89567d51c8aa5658b273",
        "827aab889c0ca5c2b5293bbea51b9d10",
        "c422f170399d53753a8cd5a06f970f49",
        "e68ec1fad43b87345598e72245ea1410",
        "22b6dfd3475953e3a5d0e8355cee399f",
        "128c585dc78359b0a9c76d0fe95cdb46",
        "a8b48ad96ab0931b3559a1fb16529343",
        "1777b8623c8c0972e4efc098e3cf2979",
        "653e1906bf2c2c56fdb657f9b154365f",
        "87c769ace080ce9c5c7b401609d0411d",
        "eb25a2d242f97a408016d04227b98399",
        "d49b423c23bb5b68d3dba36789f29f90",
        "de0fa539dd68139c938716b25d622844",
        "5d8a0d991e0c539d9beb9e678c70a325",
        "3ba7770534e773ba35282d1af298b917",
        "e2c0a6b20333102cc6baf9e06961c97a",
        "5911c139d96c04f47e715652068bcccf",
        "10e5ebd78f541fcbeb9595f7c4d64503",
        "8b29e09b266add8ac4a291a349b25aee",
        "5e783a88b8d66e030763bcc678afe2ed",
        "c2fb6bb0d9b3f158a7f8ad6186042fcf",
        "81410cb57301c5d05d60d7b994a76333",
        "62d1dc8d0dbe71f5771ed05fe63c52a2",
        "800be35b01f320d5257312c4616c1c38",
        "a9803d743a1c01216562831d742238bb",
        "0562083e21ff7ff3b78543d6387e6a64",
        "a8f65f32b82aec6932cd0faf68ff3481",
        "4555935df2af0a4950e93103e47f4091",
        "d75b3b972329e67eb2edea2e81ff79aa",
        "c5ff62313be98e12ae6ea50bb53ea9c2",
        "d7c1fde062540515d257ca87fd999598",
        "7e7fcf5816c18cdb12bac917649d3638",
        "e036f5e2942395db27ad8d09044953df",
        "86d4023cbf0bdd49264b5f845639f86d",
        "5a7cb606b0671d672397c4a525f11348",
        "d051de4d97b0c0f7e6c258a61693da9a",
        "c6c470af53f9686bdd3b5ef8d643248d",
        "d887057348b56879a17752d6e852b771",
        "7014ba262c6d636aa26c7d69c12c4b2b",
        "3983846562a57423fe20fc056f82cba6",
        "9fbdae1814aed33db662644e93cfe93c",
        "e76b70c76ab4d1c2bf956db9965919e0",
        "bf133d98930de9ac37bfa4de1bbf25bd",
        "36a0da7d5f21b52f9f885765382a719b",
        "e481c59ea2b618d110e35ed02531e2eb",
        "35fda68fedad76f5e662f5b99d5e85f0",
        "5bc5a071f7a5c3d830ad468e4bf5021b",
        "87245f0e5a2e62e4867f9fd6ab1f6c00",
        "48b857926a78e665ab68f3d54b2fb474",
        "553ec539e6078a0c0bf4c31d9d548a60",
        "e203817cfce86f6d9c9d24a46763a24a",
        "9fe53744b3e53acf3ad73524cdb0c69f",
        "69ceedfc54b407c979b7b2548dfcbda8",
        "a602e04121bc23814927e42b9c74766c",
        "ed1149312eae6028b1c5e44cbdcf7ec3",
        "662774851f837a4c0427a67c888a349a",
        "7ea807cc65f48fa09787ae81b98fbda4",
        "23b94fdfe3a6f1beac41eea34e1e7468",
        "af4017d8aa0191cee3379afe4aea9a94",
        "343d0bd4f984ca647e8f39534391cf3c",
        "11c3deb285ab4342f44718e04c9b7a52",
        "032cd82a62484971ec9be22b4c00a55f",
        "63c095a625033f2b47706a5b87d724ae",
        "3ad149149dc764c29b942bc96400afb0",
        "413206170b955d75bf638b3fa32493e2",
        "728d2e6254b3ae05cdb7704fc0c8f6cf",
        "0d30379da55891feeebd297b49f25880",
        "29124a196ba7989695089b7c9814d6bc",
        "7cb837e077ce5908aba17f9d858f34d3",
        "4618ae9a59893f3737b521928e4c6b17",
        "736b654729a6f4dbd5c702f199375f51",
        "5ccb3a50f2f7523b1709410dd6657fe2",
        "1dddc776294070e5d92003736b746569",
        "57ab4832e3c1eb14792d5155751e209a",
        "1629cb4b61ca9b692b76eeb3f9a04802",
        "f75d057b668079e01b586afb26c0d95b",
        "c36bd7385064695c0afd34e86eb98f1f",
        "aef9e00ebead0d703aa3d461d7ec7b3c",
        "a293b770b2ede95915d9384675524ec7",
        "bb5b9de904c4b95867f33742cadc2bfc",
        "eb04e4bf509bd9005731eb260030e266",
        "4b4c4196dac955f1c03150df0745f1c7",
        "5e5912f5b833cac61c5733f824cf1145",
        "a2497fadc72e820d01c41be66cb66263",
        "be11cac4f8ab7ebc793d8a0a732d68fe",
        "1105f3957f6c483d81dd2c12bc103053",
        "6c813ea32198a44dd082777f104b24e3",
        "29893942cc97da88fa98a1944aa7b183",
        "9f2636038f90192cdae970adc16034e8",
        "45e8033e10b7b4728fc72b7958ad1744",
        "b31f3e0b3aefb9110d63e4ca574d8b8b",
        "debc877f7da477fdce5bb5dfc0906686",
        "7feaeb33baea20c98cdca99ab6a4eb93",
        "0fb123485d52d54653a0fa1ba96ac3ac",
        "f1c8d39450c1654840f460e0ffdbd1be",
        "d4a0bed3338254ed720f94e57d3c8ce3",
        "72656a22028d41e524d7e8f4b03ea842",
        "b1ef7afef788e36347b524a7d0e474f9",
        "926bd0e5ccfec031031b50b5b72ee9cb",
        "d61ab1f2a33f8b772be4c68f1679ae46",
        "f9ca2f28d134b22ec884de56144957e8",
        "4104a3e26d5f95fff408a0bf9762ab54",
        "ffa4a8b2d0784140a89ba35648dd6f32",
        "f0ba6cdea0495ec3403878b3d075ad0f",
        "44acde736f10fd7c7add6410b7ec4fb5",
        "e8f14dd3c9a4d1da1070256e659a279c",
        "8ce61ca4210fa95f7655088efc7a8beb",
        "a7b9aacf89dcd273fc1fd31870c47730",
        "d0d959f6b7758b290c277b18143799b2",
        "ec5e0e1e1537ef47d65c7367177136bd",
        "15ae6db9cdee6124fd798492383b6afc",
        "88d98f772361f6b03d17d708947bd09b",
        "c1f90ece6279a502a68b80888ad02aff",
        "66d228de2fb83ac38a3da31db40df5e1",
        "4afd62204628d239da0003e8ed1d853b",
        "db650fb8ec5d1f21598fd7bead8550bb",
        "72edf7433278b22d658b4981472d4675",
        "bfc203e145e7940cf405f028c75ca1b2",
        "e4890e86f7850c31d85e61d2efd322b5",
        "e7090a31103a05658cdf3f3ea7a409bf",
        "3a984d5f71cf3cee0805919b96705777",
        "53fb771579c651ab8d7813e3d697b0d7",
        "0c6e7c0b8359f025eeeb04d2b45d61e5",
        "f1682e2f7cfaab8b512bdffed6a37917",
        "4f2a89bde154df625a2aaec814c1bde4",
        "74cb5fde0eba44504a1250c2122a5109",
        "7a9b94ab6089c446236b3185e690f2ee",
        "e8d229a563fbc95d79f5a4fdd25959ad",
        "3ed7bf0deb3003796f5f4615ce4a6230",
        "faeb48e796f12e9dd721c88be8277df1",
        "c73d3f72d92b340d006283e3f0fff936",
        "1fd2ad88e66b14eb5f28a05c202f93d0",
        "b31eff7152d49579c1f57ae91ca692cc",
        "8f1ed5eac362a0487f6835fbb1196866",
        "83da9beef7af992e47376218e3be6721",
        "6636edbc9693cca5a1be7ce8d7051f29",
        "9cf129aec6ca218e05f9389aeb650a15",
        "49d55fbe7a77c789a631bdb74d4d4d3b",
        "99d7ca625fb1933aafb88912bffd786a",
        "484566e98d8676ccaf99500ccbfce9d4",
        "6c6477b695dd9724fbab08bfebf8698b",
        "81b610caa8a05e48592d1afd21a9c4f3",
        "62cb84fd41da699a5fcdc5712861e0a1",
        "b88cf3221761e592b808bdd0b53eef99",
        "43ce6c06fcf37401769f885d51ec2067",
        "d772551a04ddc0fbb69bd1d0a4d5d3e0",
        "1d2a16674e7b9c871694dd71d9c6073d",
        "8a3362d04bc1846d5d3e98615b414d5c",
        "aacccf496562f91c0419e266f49dbe58",
        "dab3e24749acf489bc631c3cde793ace",
        "64877a97bf7d4fe600ad8b05411ccd4e",
        "c7543bf05d10ea591fa55d2e5fca7e64",
        "9da823e733cca9b289f629250e48a701",
        "eb7e4bdddbebf15a980eb91515c639b5",
        "70e11d5d56e1a3f6d4b642a96fdb9b3c",
        "aa95d6f995953c8531b202992b93e257",
        "705cc62a472f799e484207dbe8681712",
        "f79616b90ea116b5d951ccb0e33e8fba",
        "f8b07041a450b2db1e8b0b066964e7bb",
        "20b5ac4d58badda2f5f0d9810b93ee56",
        "4051375cc499cae4d5e0b65347fbecb0",
        "58b17ede2cd10f2ef70b9ea509081427",
        "013ebe7e7a5a81ff61f61df4aaf7ad1f",
        "a7a0c9ba5185c37c3ca16d66824b4b9e",
        "5ea08dd3c34069125cb44490d9781fd0",
        "654bec114e71d3a35c35d983698a3bb2",
        "454c63f4484afda463dfb87523b6ed43",
        "93323c8dd1bf8177934c0f323408fa8d",
        "ed76e08b9d8657f5c958e9918b06e455",
        "a5ecda85777f92b1185e78a47ac18cf1",
        "7bcc7d47948af84ac1f03830cdf5f510",
        "f676ca14157e86caf9d9f0013c561c5e",
        "2eb24e5520185e1141e9cbe31f10e3b8",
        "2772523fec1e7251f46933bfdaffba69",
        "818b3537e3cb4eb91fe96f9ef7bb8d32",
        "45a8be8b1654a6a08eb7a7de5353a0a4",
        "e2ff94eefdc50fcb74d2415c730198ba",
        "1e3b4c5843b4edb3977301eba78f5d52",
        "aef8057b37bd3344d2f7901caf5c9fb9",
        "76af4848aaa60469191efba3f4d13d66",
        "60ed3ccebb19be3d8a2c0e4741e57d2a",
        "8fa03d4f043d4817ba6892e62bff9c8a",
        "0c0355f97e40703c02b7d89cc8292841",
        "a15c0b4f7d65e60e262ae105c3e9d086",
        "25fb3fb22dc4aa76f933ea9cafda3535",
        "5d48d3fddb3acc5ac166fe66fdfede4b",
        "19c662d2467aa188739c003415af71b2",
        "30ad8cb29e77869d56e33c68c76102af",
        "cfac591a5147e918ace849be9ee988d0",
        "df106473d2a1f9431102e6f4cbfa97ac",
        "85cefb716c24699c3d3765b79a5cf424",
        "6b899992ea00773e4d1afef3bbdfce0c",
        "507bffb30a6562fb85de6b8509f8b139",
        "e9594c2f0ee9299ee8cb5bf9d135faf1",
        "cce6a49a1d9c32cfd4f8fc84f66359b4",
        "073249adc2612e4838a678a5b0546db9",
        "b67b8b7b1b4acd36d2f6a0dbf887e7ce",
        "44a1037f22d690c72dcc6497648b7be1",
        "149978e98c0bce1af5cb5ca59ebb1233",
        "588f0502bf8155d7a5711632bbdb264a",
        "be18f5bc2c7bc46c6f02a3709e9f5b03",
        "d271c88059b4ba213e23cd68fd11513b",
        "203aca392c9d35f08606b48d0af2a144",
        "64bbf30922ff226bb27d166e06e80170",
        "18845e66faac5770831f125f561e4b04",
        "200d7f393cdeb2764dab220ee866be7f",
        "43d6874e67597e6f6fd5fd372e5288d1",
        "8362ced20d41507447badc1057a0d0e2",
        "0691576303dcbd179ceb1b5bff179f6b",
        "20077e44ebf080958da3045b806aaff8",
        "61abc3d0b7a60e3783c8d19f80d935f3",
        "c7aae8c757bcd6746fea63c8ebcd48eb",
        "c1d2b211ca58a5584f660b69624c056b",
        "925e8351c22cf4b54b1ae21399ab3db4",
        "054ba2c7b21056315b226e097ede92dc",
        "0d8cfef643818ce7af6da9fc3a305286",
        "fa51c30d3ab88100bfa8979010281083",
        "167a64c1d8329a757dded483985f6325",
        "9a5d3423edd91347c8aa1f3ddf56e5bb",
        "5086e32cf9a0a9d31ad2306804adcc93",
        "20c183ec6e139b841a87c9637325d03b",
        "2ec49ba9a62cf9e05a66bf8324e5f7db",
        "5f8718dde0516630a54342aefb0bee1b",
        "e9296f9b1e144763f72114d5207728cc",
        "cc1b85afe3617b661cd48bf43bbbfd19",
        "9f86bc380c2bb1a2b951fda05b807c48",
        "8b51315b024b7e336aaa2da433d5bb66",
        "f1b8ea1f0997b7b6b4cec537d068409e",
        "28c4918132c03f912b8ff14683053f39",
        "feda58b5ee6743f4bd6897a5283fd694",
        "15220984504d436816312e281430e2d7",
        "3c4fe0c78bb46a2d2732ce27af4e3291",
        "d2d1d10d5c0a5dbfb888eb6c9286d970",
        "11ef5b46164a5ca611c3c0aab956d6bc",
        "95e45961c775b797e841302fa5144bcd",
        "2ec41738dcce037f1a630c5abbe144b9",
        "e4d5133f4124866818651bb95d31d2a4",
        "d751ab175630bf00da5410a957c01426",
        "3edb6498934983ba7552d51d58c50d1e",
        "9b201a1901ee4dcc292c7266a69d7af3",
        "d98c4944e4558b02f2506548798f5982",
        "ee7935ce43b676da25734bbc0c85c438",
        "b189ac56fe43a35942a7b05f6b1f1617",
        "9998c9c787f720b451f18d882e7eed6e",
        "f474e8b4b4e6fcdfe052ed4cd03a5cf9",
        "3305494fabc480887e1913394da2c460",
        "c302a02846cfe80758fbb018d8dc2598",
        "af4a8300202c36bcb9c021869a25639f",
        "eaaa2cf87cdb5e7edcf21db1dd5d033a",
        "0db1e306ab87bd60b8c4fd1af57086e1",
        "615a6e6fb7cd1fae9efc67ab2c4e424f",
        "962e05c33a3650a1089416c30a8decf0",
        "46fbc68a1308a410eb4a0e89894e21d9",
        "bdbfa2fbda6f88f342c786db2a14d311",
        "381460d3db9a45abd3562f807f546805",
        "544e265a50364dd21eb4fb4839fa47f3",
        "e6f7d2f0992bcbeab24640bcbb8c92a7",
        "b7f20f71e789ed25173fe92a8e91350d",
        "fc4aed977d6544392c20e204c5bd4db1",
        "6a9390d4dadb2932c8bc520d6cdb41e5",
        "2024a0ee7b0037bd17f968bb04e17ca9",
        "877c8ba6273d24f17cd0b38f64634654",
        "55ea8cb640d972f15ee47e3d7a66ff1c",
        "5749aac277b5569308d7fb4bff90d280",
        "111e3ffcee18e33f71af7bb78e782d6c",
        "c6226a6d597e552ea17fec37e8fefaee",
        "bc4d943926f564f6c3ec2400cd7fd559",
        "1e4b2de25ca610feb33d03a9ea91d519",
        "7fe61ff7febab37a83c01195b7ea0c71",
        "5018befaec766725acabf621f765b34d",
        "7a72e273a36433c156f78662b92db440",
        "d81a9b3909049ccdb3422b7da6b55be2",
        "7b1aab851a46359aa897c131802a0e7e",
        "12b0204aedc5f9422a2b2217e053020d",
        "dec012a150d1105ed2f9a6cf2e9da3c3",
        "b99dc9e0c3b7ed7c646124b6e549f770",
        "e135aa67265b6482afb14215fd8df545",
        "ffd0300c3bf91448c9eeaa1191b83d06",
        "7a0768b0e0a27bd33779ea9bcfdf6358",
        "fb4282470cb89c23d27111dfcfd358f3",
        "3bd99cb50fa2f2c115a51220e91cce5a",
        "ff067b339fb6ed39115588c30d2e9aec",
        "f62fed0e74f52c24163527297a98e1f5",
        "638733857db42573b62d2d32542dabd9",
        "eae7088a06c4afc7f85169c723addaff",
        "09ffa97edcbfa3bf5ea06cc3808769a9",
        "2335e89f48a722cd04b43f8fcf27aed2",
        "a003637ca86566778a0e7ce60123038e",
        "1623f819cf8b7eedcee097f5ffa34752",
        "02f83070642bcb0831e197b4f4daa821",
        "99e38afc38b8f5bf6037219ed6fbf24a",
        "0d867127e81aeb8521a36f20f9a74f74",
        "6983dd119afe39340bd203ade0221505",
        "cf510eb0c9c0b1f0aec05932039b92e5",
        "bc4d1dd6ad53b2628082869c64c0a6b8",
        "b327c2e8c650302e4a77116a93a4c379",
        "e72fe04f83d28da0b5b93b8394ee50a4",
        "582ad0addcdbef7c75b4c83d6a8690c8",
        "cae60aa6db9e1cfff663676255245002",
        "8fe06993698bd019267007bdbe3a2067",
        "a17dca4afa486fd041d2051530a7b3e8",
        "b2b116503c3218fbfbc66959a03c39eb",
        "4dbfc0795861f1a7f3cc39106f81a715",
        "ffc119fb9af6ef83ee40818098b99cf5",
        "e26c0c4b6b723b52acea95a896399c20",
        "b8d802abb820d4e4ead6ee15cb703573",
        "beea5aec13e43e4ccb151051043e16d2",
        "e4a2720ddf7704a3c7c4640f04cbda4f",
        "95ab23fedd3e52ab7e61b2e027c175cb",
        "94d8100d0b3d13414a95dbbd56d2a496",
        "e0569e6380a6c53a01aab9343a9ccd11",
        "5141fb0f94d655e041f5859c6e377f23",
        "494a84c920e005a94c7b27ed88f88352",
        "978b0cb289e6da604105ef7a804f616a",
        "1b59078a61c054cf53a4ddb61a96557f",
        "71048d61765d97163c9c195fa68dd32b",
        "e480b746d9d5db6cfdeff672b4da9663",
        "c9fd01478cfe63e46a12236a93f45242",
        "2abd33758182b18ee78abb339b42f722",
        "d20d5749e71aad82fee1891e5fe44d8b",
        "c977bebaec07b8782285aa447b4864c1",
        "0f65ce0fb6d9cef1d32629872768b1cb",
        "b0c16b75b54e82f1e00a084d6ea93fd4",
        "211ed195cc27b2834ab496fc4dfae0f9",
        "93c6342321deb392ba18b7fa5b5f3474",
        "8b29d3fdb1fd70fa38f4ea7f54c46430",
        "9a2773b2a91ee2e0e38d8973b289a9da",
        "48ab960511ed30a1ab5c2f57073f66db",
        "ec44aef2953ae8961234868d03a7c851",
        "b803ae955e268d46f4fcb8bf5f05fdfe",
        "ad49dad74b72d4c11c66a1e474fef966",
        "b09dd286950fcef2e8c0cd49ff50878f",
        "df114bd21fceb22c6a1555f864abae26",
        "2f50ed7c8b7414a3eac3f99ccc8c6773",
        "9ba8563923781ba900c102fb275f14ba",
        "b14b546e21c42c87f06732f319434f7a",
        "c5322779f3bca4dd7fd446dddc295b55",
        "a62cf0de6d7ec0a560014cd18ca5ebf2",
        "69ba8b76200d6056b259f041ad31b314",
        "3293861fc456bd230c5a36e68107e4bb",
        "e050f996a3983bbd8233275222929937",
        "f8af4f7fe626407597f7a6224b9df176",
        "5175be0c660c7371003ebae0c10edbab",
        "1233044df2e3efc18d9aa366f887271d",
        "4bc91544e4f9f977abe3fc1b7b5ee9b0",
        "9b87acf98f80757d34cb65fdd30c4b67",
        "02b8bed2a4a5027f69e078ed8fa3a819",
        "5bfd96d38a59e91081d0cec6d12978bb",
        "e227d093697eec753a6ecbe6d93b67e9",
        "650a317b63d4bc60da8c9b78f2bb4e4b",
        "b1c365ccb1b1adca976dcf91c4384f59",
        "744c14012435abf0b887ebd1e8052934",
        "aaa4b121e2925039f5cbe4133a89f520",
        "1b3aa0f9e748f9bb0b755174eea165aa",
        "728f45f5ab0ad863075aad0da97eb75f",
        "b0eb04f3b3c476a522539ac71b3e7661",
        "9c722cf3b29ea7722b7113ada592004a",
        "b63df0d8f4e6a9e7ba25c991aa832ac3",
        "e90add5a189ae49b63cee15a0cfe193f",
        "297d0ebc67427433cec7b390a4745a39",
        "877895bc5bbb279c6a30d9bb9e6ea622",
        "280a4c55eee8aaa978628b526f0506ce",
        "4142c4365b442493b5bfe764a665b597",
        "f3201a441841894f12d0109094160b6e",
        "d631b3e934f93c961ff1150ce81f543b",
        "e2ab8d7296b7662d00cc5cb1a6b79787",
        "fc6dce16c6b7ef9a312d715d78d67fd2",
        "e3adae9db5997bfe0282c75291f4b610",
        "9f84b3b381987f7b6bbd24eb8f7bc05f",
        "9bdbfc3a5b5a7a94c373dc5c99218f69",
        "142810b0de8287f78ac8037d44aa6ac2",
        "869993be9876cacd26d8b580882777b6",
        "59d6dbcedca8388419814864b563d72e",
        "e22a8051aff57e667c957320db427566",
        "e873fa4106349dcea6199aab48c4ecae",
        "b5c52070eb3c0595d6beb6bb340f5cf4",
        "9beaa95299d013c12664397124e8a57a",
        "75e31b93ae94eaa204f59d0fdb0bfbfc",
        "b2011754fd7d2ee2a213f5c77df92d12",
        "0d3d4be3db2264a762d7d35779f47dcf",
        "a5f0746dda78822a3c353bb95c8cb05f",
        "14b54d769440375279c89362a0d33391",
        "cb882166491a886da132be8acc88ef2f",
        "5d83b479f36367f096e26bd1bbeb4045",
        "1a951570d027d9a8bdad926f0d84f15f",
        "ec918a61cfcddccb1f01e7e1e3709ff7",
        "4b2c1557076426e66075495f27528cb0",
        "6a8bf2ffe6d33299a15e3d2c055e7311",
        "34ca4e78ec8ba71d78cde92e6a86f3fa",
        "ce9c14135a9c662d2b3d6e374ce4bbf4",
        "78fb671fe7d388c5aa2c60afb34e280f",
        "6c6de7d153f78f68691e70676a9bc7e3",
        "c1564585aaa9ecf8a4c5e1f8be6a0721",
        "1d36f235c82fd5c285a30aff334ce8b7",
        "d60bf56f18b3ee61b5b67bf55a79bf33",
        "24eed08ff654c80acad50bc8cc7bd8ce",
        "2cb081190ced9748a22ddf244440e2bb",
        "80051aff18f088ca33b1ea4a31c0b98e",
        "d0813609e6f836be2bdb5b774f065e1c",
        "d1519efec9682ddd3d913146bfecc887",
        "6ff3d22cb79f312b9c33e67f21de7108",
        "35486af118fc2a5a568d0d801e7a8178",
        "d8292c13c6d590a43b46d15c80431cf2",
        "2c19520ee8d2a2421083132f1bdf0032",
        "2580ee8ab4532840ac53d5c55a15d2ad",
        "d76cff128b81162a27ee6fc27c75d645",
        "aa9db7d031ed31a1bdece12e593d34b0",
        "cdd23ec703718d8b1fcf0c2cfb18e0fe",
        "bb5e98aa80f3540ad9b6643feb2ef4b2",
        "04546121e9fcaea3387ce3e622db2055",
        "c768519deab63417446eb895edeee7be",
        "6973faefbdb51a08c88d3d066e29727b",
        "4fdebef52ed2fcab93983ff6587b9b04",
        "5f8d321d48ad1262a02bddd4d2ceb403",
        "2374cfe6c1f49103b30c576140411b63",
        "12956e466dfbd24952ed0ed936c05a73",
        "52e7fbadbc377089fa65b83de088b62b",
        "9f9f3f2d60d4d125f6cebee928b7311a",
        "2c54f7f27790b747f1ded570d4084017",
        "5eb6587456e33311c7264c402820da53",
        "34538a902ecb481a48cb37366ade491c",
        "d4753acc6e64cd4b46b7439004f109b4",
        "b2d2e16172c27fdfc61ec2dc10a5cc75",
        "cfd3bf2d7e2894f5fc6391fba60f3824",
        "4aaf2df3680335af113f604bfe031c8a",
        "b93178051295c974769faaa5642b2008",
        "781e33473918ffb1405486dee27df60a",
        "89890991c52e5f424bf9f7b4f9077e37",
        "92386d8cd1ce5fd634c2edaddc7a7c69",
        "3f0a0e4679b8e8d79cd873091e34457f",
        "a77d1f67d07bac87903fd8e501bf6496",
        "7bab43b68581d16f65a292788ecb31c4",
        "753cf32d82aef95db9832d0e54420f2d",
        "5784ee0c8a79e9fd77924bd2407554ec",
        "422d3f5d822903a6d5a5b2611a8e0506",
        "c6f254a127d19c396c6c860f4ddf32d3",
        "570ebfbda4befeab8d89dd7361489d6d",
        "ef6e43011bbde3983259c475016fdb2b",
        "e9b3b4a2d3642147ada0536286ad0806",
        "e49aed44d1604721d1fc0ff9705ac340",
        "4e6fae4a3d88eec532f8a64c29d81fea",
        "ffc384bea1818441ee293a83c4b1729f",
        "ce498b36e25d070c43698e9b4f440379",
        "6aceab42997dd94a068a98fc2bb6267d",
        "990efab9f0eaf901bf8eccb08253086d",
        "463d7460f54c40386385908689d362c0",
        "54a2c953a1c18502f14fe969611b0832",
        "0175da550866789221636beb438d5c21",
        "346ec3b09b53a4da9b8f12dd0c83d363",
        "3aadb8d859a82b9be4a9667c22c97c83",
        "c7698c48a121c142421f38bb11a5528f",
        "4675304f389cea1044a9bf2d09293b65",
        "a8dd4bb0a872fbb68ff66487cece1dbf",
        "a0ff446c17843334d21009ba766f7bfc",
        "963f227c808ed8cf9be51191aa984fac",
        "1343ff94861d9b58b592879b9f84d98a",
        "c64c31a73dc526896a3998e37baf3186",
        "f6d8e962911f45d7618a2fcc87c6c097",
        "a2cba7793d07242ee4e9dc6337f4227f",
        "6385e62be3855354d4fbb1a17def1df5",
        "c181696ff9ea1de7770df30e8a44891d",
        "9577bff1835670647da0889f52c27a62",
        "441f14b38de7330fbe0d46ca5475b3dc",
        "6556fa67c975c1e41f6e8bb2f257d39f",
        "0eb1c62dff63ea457e43e22111014cfa",
        "f2bebc8716a642f61b2149ae641942bb",
        "7e34eaddb0b5781da51fb80b7405dfe2",
        "5a555073cb49c478d91c5c250bde9d9f",
        "0d3b8897beb1240adfddc4286b8bc679",
        "eaf2912720bab68deba1f0d8fe5624bf",
        "20023b34d2f998717e754eaef00e7bfd",
        "299cbccd4be0540db50bf64472f892fa",
        "ac23c63f887ae137350ae8cde3354170",
        "2f71aa8adf7dab703d90c8449ab743fb",
        "7e8c8b918469a1743aa04338e0a71620",
        "e6509cfb39f56da616c06a736916c748",
        "5d2ff4d1c45b6c5b01c84802a3a9ac62",
        "593c20c38e5c070eaab3428eedb742a1",
        "8cf0fab14359eaa28773365459ed364e",
        "37e9cbd3e92fe4685fedff78e5b83816",
        "56a93afadfb89acfb1f7ca0be27ccb7f",
        "53386313443454949a40970875e09d48",
        "2c81b91f3b9dc7f25bae6fa41415b7c0",
        "4c70c57d0e2735292b7517e5521e4ab8",
        "a929932a5b04c882b658a7960372f0bd",
        "f0a2681cec2f5dfadaac158c1e58c7fc",
        "066ba353d3e17ac61a96b5a0d4c8c0de",
        "571a74f6cfeb15db25c13904513556a5",
        "c8839409716e121428d4b5a49f0bf6c4",
        "778e627368875c53bbb48e213683b6e7",
        "ffe0d9265fa79ab48c2e47719bef6736",
        "326d068caab037486809e894fc792345",
        "becf7379c446200d8536ec73810c206e",
        "cf5e8aa1a9d020f14714189b91f464b0",
        "b2d835d25d75478dbf28b6fc12c72478",
        "ceceb4c8ffb6c7a1cb60706e7e55bdc9",
        "2054425abb21242f2c3250f2f7efee80",
        "ca50203ce657e764bae59b668c93235e",
        "0b4014959a473992c1c2ff8643ea38cd",
        "9492603080e9b61352b6e9e2fdccf6bf",
        "2722bba67f299fe9e236794e7f184a27",
        "59f75ccb022ac608a934d978cd17c31d",
        "d7f71653bdc3628d949d78f7319494aa",
        "1444d7f2691942f033642bb6a593e987",
        "2851977868059f29905f6dba315e8d9b",
        "2a3905b50c09ac9a2f2e94b8f926c571",
        "17bf224b8bdb89a79b39e1e9fc4369f4",
        "0e29098bb3465a609de56f93e6f0cfd1",
        "30e0b4fcc761f4ec50336a8af9262576",
        "55d595f693f6f947d62e8b9d6f1c4a5b",
        "cf0d5112a64cf1b6843b9fec0a1c2bec",
        "d0f8ea4f2f801afe882eb3e8207f2087",
        "e55c12ac71ff56e17f86fd5cd2b6a3ae",
        "8673a2c371e951f43048386cca4b9ecd",
        "763b1c1b5c5865e036287882f15354d5",
        "ed4a0fdfed581e8e5b589fd11e8ce5d3",
        "6d1090039876be341c8ec0e2a1b414f2",
        "ea61a3961e095eca2f07cdb57af0a00a",
        "30d1c947bad4ab1ae6f2f6b2fd1ab7a5",
        "71ed6718479570b68d4150266dc97720",
        "1891e808898bd2687191d853b41868d8",
        "786aa527560cf2341f488209382f24b3",
        "2b27350ddcacd9167876a04edac48cd9",
        "42d7c0b15679dfaba6a8aaad5ae73db9",
        "2613861ceabb37b8715c8d3958288649",
        "7c51060397aa3f1d125daca16b1b9bb0",
        "41ecf41dcdc5c9315b98c088940912d5",
        "76dc710d62b26f167f599e54682b6ba3",
        "d69bb081eedaa9aff28212b245ce9088",
        "55e582c0a71e59af7ea963daa9210d89",
        "68e53725abb9085ac70e1cee5b6cd4a0",
        "e255425c03d634df2ef2497704df4591",
        "de22976130f1a12b0fef75073f3a8255",
        "f13353d0962c049cd9800142a7ad01d2",
        "fc8ee91453efc2ecf1454c6070cd6a59",
        "dfc478f1b547586439b5a21a6bc76fb2",
        "107383b87ff699ff950e7f57c6adc38c",
        "49633f5394f40e44a0047cad26e71af8",
        "97fb01b3c9ed30073719f9c8ff0bc900",
        "2f4186ecfed0d470c9854a06a9876117",
        "834e50eba3ef38b0b4d3a1af4ad24441",
        "c770d1b2970bc785fd18311f7ba1da12",
        "056b28cd54c10324d89b774039ff8159",
        "9192c4215b81ec0f71ff1e3eacc37029",
        "71ed1acb648ee4003f26f0a6e14754b8",
        "cdc30cb9a616d063ee17c34d40855f3b",
        "de9968f2c2456296c6bb23d2dfd61147",
        "e4c92c038b14a214e142b5f6a5d636bd",
        "18906967b10d800bfe7717827caa3775",
        "06796535599ce53821fcc2abe8fd592b",
        "9a00ad9a002c0a0e3a87e867a26bfeaf",
        "4cc4e6f9acae3efcae7cbe88551e21ff",
        "e13fcb28cf26d9a2cf43e5a47370dd5a",
        "c865f9eb158817c5556ddce1c13e177a",
        "03fac606063c69f86e7375518d83d069",
        "11149fca4e6f38cce288b0c405e5d6bf",
        "8bf33b2560cc965ecc5b73fd81ce12bb",
        "adca3cc99bcbdb467d235266e70f699b",
        "64e0427f6c02c934c27476cef25b97ae",
        "670650e28f4fba5f7ba383b8872cb7b3",
        "e33b0d777a0bb96cb967f4e24f1225d0",
        "03c2ca92ede7c116490c496305a2d351",
        "ba35ab559a42e772d427388755fb6724",
        "264d0262bfc8e1a1396e763d5fc3583a",
        "81f154de654d2e67e3776b4d2e9ee6a8",
        "1c8c250c2c8d712c896c24a5ad53cd3b",
        "a9f8f502d2ea3068e93e47bf1183fe7f",
        "f4c4fe61176310ca01766294538a8903",
        "a6987d065130ddcaa94af85c184794f7",
        "f4c80a8765e157fa8a1668826e79c654",
        "1e4f32e5e4297cc7b670cf035b5f3d6b",
        "f9bd11fa79a39d686d2e98f34aea95ef",
        "bd3ddff6d46efc47deb69978cdaf68f6",
        "fdd62b92ae97bb25b8a8f6dcc23ebe1e",
        "8258e0d7f2f61f06b965e270b2fa383d",
        "f9f33528342c10ce4a73ce862e6607dc",
        "931c77709278fbe723d01476ea632720",
        "ccda90deae347f1671f0b4fd082fe200",
        "07010ada4c17de288c453de6fb620736",
        "dc7859538f722834d1b5a534235d761c",
        "f9ca884ec421de3fbae61f86ffe50200",
        "0f1489f114ba4a89f316a745e0b73bb2",
        "acee38f93e88c5810ba36bfe450ad57c",
        "bdecc17885f91dfb0a9934eb6510f44b",
        "87e9314514e1292a42f58fcf33511364",
        "4cabaaf83cb43847bfd154c8e7147699",
        "5ceeed5e8bd85e1c099e860d5f207354",
        "3f7e950b54d90bc7274b68e918ba07cf",
        "7d6e3b5269bcc1990f31fc12aaa7bb29",
        "dc203c1373b50dc362f577b81a9a0a04",
        "868ec4305d55e36f0b9dae763dccf176",
        "330ed458dbfc2f03f079ffa6b5408af6",
        "705fb7084ee3824e40176ab952964ee1",
        "430c117a6b46980108c42012817b28cc",
        "c30d4e8efb176f210513dfa233fa3f61",
        "43cb7b5e57f06a5a3a3808031914d3a8",
        "b3a01b4f76296624221b39dbcb219a8f",
        "3786dbe596c624bba7e6d6189a3c3054",
        "3cb2cbca261eacb782975d4f4476ee9d",
        "46da390b3d6613ca1884e0ea547ee473",
        "f3e2ffe19024336817c1726d94cffb28",
        "0d580fae05cf134279aba9da22c08999",
        "53952860f627fdc6fa4807dd7d2dd263",
        "a4fbed6dfaf1a9608f1e560411d6804e",
        "60330e367bcb842ffcaab787847bba93",
        "d6a3cd8808c02b910e44e0187ce456db",
        "65fb57766a62923660e20faa27a066ec",
        "4d71b3fe27bf0c29a48e8817da18d122",
        "6ea88fc617219be4b8b0678b70616db7",
        "6d77db37509c7c4194b4801adbcc0d39",
        "e42ded40acff4641222a271621484c74",
        "def2d5e22fcee981c9d6026cf31e0d9e",
        "f23f6b7d0e5abdbbb7c61da8a2fc1bb2",
        "2db6a310d98a14a7ef057bae48229b6b",
        "4d32441fb6dfa48ff988e643d5cef771",
        "69615dc6cb44302171bdc266120234df",
        "33e430111fd8e072f96063a5a62886e1",
        "738f1689e10bf8ad1573465e71911c8b",
        "dc08b9374b0f01de443fa6f942f37a69",
        "de534cbbfaa377ad798c16c3da81acac",
        "15d631162ed18087863d55d8bec65297",
        "70aab86715e0e9990369a15f4eb7fc99",
        "5c3a1cd19cd80b306bb56a825f634455",
        "cd684638bdd2ac3417337405e1c99b74",
        "dab9fcb7b82f896b1a336807806d51eb",
        "2c65e5f1c22f6d367b67d1e8569cca5b",
        "21ed6ded60399d9547ddfca1d982fbdd",
        "6503a9da7dc738ad5c8cb0751c7ded43",
        "0f18f42ec55d3e31e35bf7971928a792",
        "98b1ed2af189c47bf0cb25ce4c962613",
        "0c0ec3de55f13a1cd00ddf86ca851603",
        "affafc22d4fd01052d67d68599826bb2",
        "a3d9041dee7dc876faaf0b25503007c7",
        "203a3f7a38c64e5b2405dde168ff46bf",
        "79a865a6b05d2e550631e62adfc87839",
        "91a33055c40414c3639eee85e628543d",
        "dc92583ee0fd9f762fa0d4e24bfc813e",
        "398ee0be156600dd7fa544d4c6215d66",
        "870ec80571d0cb1e1434224951ebee52",
        "549132de510c62e6f05f7c39b10d408d",
        "ce90f625c40b9a90e7af693cda997dde",
        "acb5f76a253fa9fecefea455949651c7",
        "5c17d06ac5324582466f069656add0e9",
        "a3e627dfedf8889338dbd637102ab286",
        "d64767b3205bc413d88492464fbfdc75",
        "0e0968df90a7e3339ebf038191d8fa22",
        "fca0f2d3db4f305a68e7f01e972b8f70",
        "8cacfb1578e20fc0b58c5849519da54b",
        "3d0c9a5b5c7ea62a96ed93dc76eadf81",
        "8c1ef4486a1d160f77ff940b19796dd4",
        "2d041f030a8fca5846917566712b71e7",
        "7cf3b09fcb51d77652a776a0ec9e6029",
        "d2c931780c3fd0429ee099924faffbd8",
        "22571416f23326cce6b7552eaec21834",
        "a3643d17cf2a8bb3f32f11a6ecf42649",
        "3fecaee86a59324a00004fe0bf19bb5d",
        "d6c4d1271a25ce2163f1fea7e007b710",
        "37a717e71e33fc779534d2c7eda0acee",
        "716542cebb63c1b617ab3accc4dfd8e3",
        "180ec0706dd7056f6945d299a813d233",
        "cc4469b50e7ba83b83d154fd7ee83289",
        "5cf1163eb34ba1ffbbb976d02a88d431",
        "9ee6de1477286516ae7299cbf78cc7ef",
        "49958a54fe065a14cb06966fb0a588fe",
        "b3c4d4a1446027b193c596b37a3df629",
        "2504369d674bf51b3644d48b4e52e547",
        "352c49abd23442de28bf72ef23ebfa63",
        "99f7a8a4514f1e510faff21da9f334e2",
        "18e822ceaf2f7d19ce722a8e46c38a04",
        "97e240f31f3a76feb112d1400a84add5",
        "8261d076cb4567f5a7bbc091cfe3b0fb",
        "0491a8fcab4c2b7e081906b67406d454",
        "1f50486f5c3b45e53709df1532a13309",
        "c5dbc3876b8432556f9cdf07292f0762",
        "edc495dfdd05bfe560be6bd9864a2526",
        "7521936728a1e841c6e9c18ace804adc",
        "3d82641d9640d2a655509bf83b8d943e",
        "9115a32c2d7422b9407a7bb6f7f6d90a",
        "28a4edb5e9096be11d20b4d797bd77fd",
        "2978b7375cc451190a898b9adabe352e",
        "237dd3588ebef7e3e369ff8950d11c21",
        "8b0a43b95ce79cbfc3a20ef1ee93db61",
        "0c1de57647203964716c86a97ee5567f",
        "a651337c946ffbfa6913a8d660456b3b",
        "1e1349f3b03b5bd49fa1f0799b354c4f",
        "80342dc861c99993af3890901241a786",
        "33f9d7c88476796159720057fa7f02d6",
        "15d7baca30af2dfceda5662fc0f3add4",
        "bbd247b4c795b3e6f6f94b540211f109",
        "070a4b22eb81e6e5e1791281e86ccf6b",
        "95e182c52e2949f48e80a97378071661",
        "9c11856e396b783036c9a595de85ad16",
        "68c5cd9eded9086e1e0a8b71699a7ec8",
        "d14bb2327f077c4c621b53494ed09f7f",
        "fe35ed04c493458968307a1227f14de6",
        "81ec69959a01bc32894b860b2ae78a35",
        "fcf74381a6f0cac08248239ef35b9a0c",
        "0bcdff7b3e2b096ba0a16d706ab8cb3d",
        "475b709e7e49911c63f00c290f82c431",
        "feab6f05f5500d33bc95a24510e2ea5e",
        "28c75d597fae234a7c1fae63999196ef",
        "04c610dce068e5013a1e19b864a1752c",
        "0afc70f89a55bc118b99875fe30b5c40",
        "9016c950a34bb4edfca0db346b79f1dc",
        "fe0b8529bfed67596ee74f395cbd87af",
        "f9304b1ba7217ae5445f63b3b1879727",
        "a1b23ea29254c5280b177ef5e732f680",
        "506ae101758b3dd4e076f595f7c119d8",
        "5ff14f8e9e8c4acccaa43d93acba039e",
        "baa84368483af7063278846993456912",
        "808cb4745b81df86042ee5e76fba4cea",
        "161b75b1a6e5b38884bc72f38c48ab99",
        "8095de47025a4a8ac0722b77ba04d478",
        "8572ec1cbbe4c3e80f69c99b42fac10b",
        "cd76372f4a5781842d1b2ee0f0e5256b",
        "6c9b6c1b80a9ed71c092c38b10a839b6",
        "71e618cb9383b6550538670b8e61b1da",
        "99088461ef1b8f0dce9872a753388b5f",
        "e4457ce032ef2e20ae366952e903980e",
        "470841a477671edf998afc77d1b89cb4",
        "73cb9fb54b923dbf4587694f320b14af",
        "7f4a654b3817d51698a87883319414aa",
        "ea2bb1ace11aacdd5ae527b6e31c0dc3",
        "1b131d904134ea98db2f8a57559867d7",
        "eebf5119323587aa502933b7334729e8",
        "94c3a02c603eb8c470ae0fc7256b73e4",
        "c100e3ee6ff0a472664c2c7ba49fcdad",
        "38466b03cc3d706ed36df32dec4ab21e",
        "a97f1ebf5e22a55a6dc58c19911734a6",
        "d071cd3293aee295577fa957229595b5",
        "2f72a1a6d5b15193dcc39ecc71fd37df",
        "c29bb54c4e6edfb0a04796f7c9ecb22f",
        "bed9dc0f930992c0155d43caf73fe6e5",
        "7c9917ef9302bc4e6012409f69417bbe",
        "f8a30b86366011f69b4cb1963b1b6fac",
        "6c39da06f3c46c55fbdaa8016b03e018",
        "6ddc2bb5333b2d91c33fba01a8e356c8",
        "35ad7c03b2cd5d0346c68f7b8109dffc",
        "bc160351c82fb74d5d1bd6837c9ebb9d",
        "71e769d19aedaf899bf18723c855743d",
        "46a93f6ec4cd25615a634c34b53d06f0",
        "bb838cf03574996c860fcb1757e5b6d1",
        "738f4f4edede56ddb858df82dec6ab38",
        "1f12d91be33a6ec057a18a6e11c0aa50",
        "dda5ff81408d153d174113f6d233f4c4",
        "f528626b23e2c89dd0824b40495378e9",
        "e72754f6f90c52043e8e40aa8e8667be",
        "19bc19259d57ccc352dd5334a2a991c1",
        "154fbeb06be4bd69b2b102bd3db8766e",
        "90cb028411ec0c1963367671c34a863f",
        "e05d544091d23415dd44f6f3a703dd1d",
        "bf695e0c5354342158390fb3eb84fc30",
        "af102f43e9b84cfb500fa2c477746332",
        "bb03a814092ca1212443f1bca50e81b6",
        "29b9131780fd87d364f65381c7e78da3",
        "a81ab90befbe46619180bc2e12d0b5f3",
        "9aaa694dd07d572fbfd3320eba22ce10",
        "7644c1bf5066433a205a7a75b98bbdd5",
        "942264e02fec74ce85df9dd2c54c3d8b",
        "a710ebb211ca6a88f38411833343e741",
        "dcefbd390d6d19cdccafad7ad599e101",
        "742bd4c015fd20fb0507e8dfe9e1e999",
        "1545441b90a54973b0b99b210e8743e9",
        "6ee75932128ae1d478dbb82998e3eba3",
        "676bd247cf251e725f744060f7dfb2a0",
        "026795a3ccdf86f55c21d30b7850f016",
        "cf3429d86c619987b6f3e7afe4e7b049",
        "7e53c135bf42718b839799f92742c41d",
        "9eafead424e43300984eb7ff3eff686b",
        "ceba7a304bc2a7fde1e7a12a2b942086",
        "a02ce89caf2fe7417d785a977d61c042",
        "ffd1c8689ae3370198d9844d22e5c78c",
        "632c2f71c88e0bae903c5d644152cdcd",
        "47ff7f3c749f6176f8e292d1ad9b8b4e",
        "5f864582fc4e8a4ccbd3ba9e4eed8522",
        "113d57cdaeba1da4c7428f6258ba942f",
        "936eb939563160cc64f669d3b0af072d",
        "b3b6a0f485bb4711a8a14e05e30b3fb7",
        "e88f0c53b834d93c173a365de0aa5374",
        "d20c465873260174c5bd60d6e087cf6e",
        "004f48e5fa8ddfcbdf5c509bfdf10fd7",
        "a6c01abd5a66cfa27640d914fa57a190",
        "2375d1e9aa7182729cf2e675e4b2ddf3",
        "72eb27e34cb2ccdf23ec78e6d5d16673",
        "3c70d81ad31a469e65cdcbcebcf77a34",
        "f5f4d38fcd5f9502ab52730b8c8d0f63",
        "0fabeef9a2586253a77a005f2550766f",
        "3c77cca37a5150522445b0b65cce6606",
        "0911e07021755f2e66bfbaab755ea3fd",
        "25c3e0ade029707e007271fd0233be75",
        "460100fc0d3d1f0f57a21ed18cd7e0bb",
        "c1eb0b3b113b97505eae938df29c5605",
        "cb26cc382ab02ad01013e3da38a13fdf",
        "be1dc2c12e7ff54473d4ddc224f84b66",
        "6ad79409afa667e7d51272aebc7fbfb3",
        "d59c4c110c90597647c7a255ef526592",
        "237334b3809a943636406f0f28cabef8",
        "8ad5136c78638c17d7fc41ce7e39e15a",
        "0a946ab9e09222382b73aed40db9b199",
        "843d5d522fbde0d6adb54fa0d36e2e39",
        "c1ed804470401797ad00f21bff050273",
        "d068fa57a36e701f6eb01b51852f2375",
        "e9fb63ab4f21715811bd82f4b58171a2",
        "f3f6589c2451c58e9fd8384f6e612d7c",
        "dfa8bfcd59985d13406516692411c1f8",
        "34664f0f895725d7a65130dd50bb9d71",
        "d326e10088ed200a0758a51bbbd54a63",
        "f64330231d07e9991456a5a5bc70b3dc",
        "67f8ecc9238b574acdfb3b3db17ea8a1",
        "cd67b21ce55f24a9fbec9565ec57a217",
        "b4957581a195fdd83e8ba462663476da",
        "33cfb3644579295385128b38ea32a311",
        "16ce099d1eba5d6b6a0801ecc561c4c2",
        "a09db6ae70f919b2d953181b9026f998",
        "5b64c782a0ca6a824565c25d6023604b",
        "1a2a0e4e978f3a2f808c646fb03fef05",
        "7f82d7444e82a76c1dfbfec37a78ad0f",
        "2657a0fbb50d940006850d5f111b1b1e",
        "571fcd11e953233fa326fbb513a1af33",
        "e5d1216bd94f6ee5c48dd279b4a33a99",
        "ff3ebeb2e6c39ffb1b1c659eb1d92c1a",
        "6377f7e7e66b0f3332e3aebbde309ecd",
        "f29e572547e5ff2efb3eeb3727454c79",
        "3cffc0f5bdf028c5feda8b3a2cb1bc9c",
        "137974180e35b6a26be72a9438a80cc3",
        "8e76e4cde1e4a693437253cb0a0af527",
        "b4f101962b72adf6aa20abde823724db",
        "23ffe4aea84ae7ddfe085206f45f126b",
        "a729cede3ae36a342c9b3746df96698e",
        "b99b9c8f2e3f8af9471c370b3a8d8649",
        "d276a632fcb13872876cd08e9a91f482",
        "7ea272bbb6244516a5daa1c63e43a87f",
        "299246c999dc46c8d92e133d1c200651",
        "56b8fed60a3f5d2bffa624ecacc6a3ee",
        "771964246100b1bb26b01e5711f2c80f",
        "5c6876a2c3ff184e11f8d7adf861ad40",
        "93338bb40c5fefca538e9ae1afdc8ee2",
        "d5568ae9b48262bbae1d179c755c85bd",
        "9bce321396897553008b10a8f6c64833",
        "e5db7c6d2f63b098298b2c4caa3fe27c",
        "223b377463ce6d62b21671357a510c56",
        "be87f096ba4a4df27b498e8187197b9c",
        "b784657e5ca971ee0af6006726af9985",
        "bee1604c2c630bf4e525e8cf5c5cc2b7",
        "228a79d033dbe390e34c9c0a0cb74853",
        "b1d6208246ed61eab51dcd379ecb8874",
        "79e8d778206975c8427bee27ec169ce8",
        "67f906701f0ab09713c00665c6b27fb7",
        "12e50fbdd29eceaba1b684cd0be5b229",
        "b25a75dd023f82a57468acbcd64a2f8e",
        "00a3081efa71bafbf20227c24ea3169b",
        "a816a9138dcd45eb797b5780baabc324",
        "e73051d6babe00cae68e9952e0b14103",
        "284646a6c7db5eb58d150e089514bcb6",
        "4da8fb77a68e82ed46f38854c64a17f9",
        "c6480d8e4d72ead99258698fcba2924e",
        "624d64a2e298ab5d10569c825c302d61",
        "25be3f3cdce513b7bd6b5f7ae069e859",
        "a516834e2188e213ac568ba893b18ff2",
        "1acf7e92be4e62d5bad1c0033cc32f0f",
        "cd3be0290e623fd2625c5c7880dad98a",
        "7cdd4f9d7d956c0e6681ef35fbeb89f2",
        "bd9f09420b1b46571054ce83096d3a6a",
        "11685135dee9902b22ce9fc64bbfc57d",
        "61e5cf7ca0ca3101baafe1bb9eed8e19",
        "7811326d039ea1a8495e6aa7551b6122",
        "be5e0280701fd579c06e20bc27d0e69c",
        "b056d9dde341dfbe27bb34c3139becc4",
        "dd7677e28751230ad199773fc4d81e55",
        "916127921f898ded1a1eb8039077e994",
        "2687bf209370c4061799f774909d3096",
        "f6269f0bd610e0e2c09f5b865569fcc7",
        "2525f51ed49f716cb9ee402f5297b769",
        "66939e6232d5013403251cb01575f8e1",
        "1910cc34967d749bb9a7007685b38ab8",
        "73a31f58e2a65910f67899adf802b956",
        "934ed1b2bca7174441dd8025d905a737",
        "450dee6c1c250919077d740a694366cf",
        "343e2a0e62cb717a705a8b6ddc0a074c",
        "879642e96f5dbf12036157df90925bff",
        "fe4a498fdb037199f1296a43b9c47abe",
        "70537846b0752e38e226ef6f3ea89bf3",
        "7d3b84207d48afade0dd659dccde7a5c",
        "f0d1bddba1701c231825a43b4cae7919",
        "8b750ced53b7a31012e50030f767cfcf",
        "b59029042f6d457b513c575d1257ec5d",
        "80042018770d05913b11b8016e14f0f2",
        "9173ba80f0aeb22a35efbc71d627116d",
        "25f6a930323e0dda6b56f4b3b1368198",
        "a9a9682c550eae8d7e3d5e7f92a2b503",
        "3cbbd0e6b2020a1c2cec8bb5756ee0be",
        "996bda9c00c05d10650ba9e31985feb7",
        "047223b78aa85d286df8ca7edd7d4789",
        "8da68df98b971609f0b5b7d8f03794bc",
        "47deb9bf8e6f3d3ac958301003e9d082",
        "ae3fe0d0d9e031db9a0df24ab292f390",
        "cef1080169e3fd34e1167e6ceff8d18f",
        "ebad0d6c9a6cf2f187032d0327fd7366",
        "96bb1cf09a93ee41d0d7aabe12890efa",
        "8fc570a2891a344bca47a5f27e931d55",
        "cbde7b6fe343a299b083feb377d38c57",
        "af11f630816094f7b389506cca1f0220",
        "8e944f753f71bedbbdf21a2a0048ec90",
        "332844ece471aca6ffeb9435d57af0ce",
        "13c93201bb3cad43b8a23fa7fbb6667e",
        "f834bd27906af35680128b3415d5b1c1",
        "a7d75f8ced35b65e5ae94f917820dd78",
        "4a9cf1df3ed684c2c5bf72d2901c6af6",
        "59969d3fafca318414900906927d48d1",
        "bad0e354d485456783e34673008049eb",
        "006df7a0ee5ba617420306ba25272a54",
        "a01978d301f6f66d46a027007cb23b40",
        "9fd111c184c5d404d5205223acac2912",
        "c619ff3ab07b7cf05bd579fd3edc24fc",
        "693b177d9a49b3baf3203f96ab53cb33",
        "6d2ed6e34e20879a769a52aa54c02c8d",
        "553047070d7320ab68d168e08d53fb4d",
        "84ab86e7fb59763c5d1739bc272bd054",
        "0dc93fe2c71e4e57ea89c24c6c6e1528",
        "2c64003ce7dac5e11e94e5744a74ab81",
        "6b57d9df670de208d7d3db3f6096e01a",
        "05e9e643af145373a4453278c557af12",
        "8c66a0f98a3f1b1c487d50f71480e191",
        "d24e8881c3cb642ccee8fdb5ca8685a8",
        "dfb45342f85bbed44db35e13d73d59a9",
        "ee3d14af3f1d67c6d86b1d2e1fdc1d7a",
        "b91a8a9fff0fdce5773d0cb805ae2e3a",
        "454a10fbaf6fb415c4175eae36a52d00",
        "6ff55c4ad9a88e17f6b37d763809b7b2",
        "35ab10904f2bf8ae0369889a87f2dfda",
        "aaefcb3b9be635c898edb593de73ff3f",
        "6c5c6a676fd647c671f8d327a74c2043",
        "5c155ca3bd899b83001c59a5a8d373a7",
        "eaaa70d4eb311a31abf738f28ce72e08",
        "088cdae61422333453f3d1f69f34ded8",
        "fc961cc39daca8b5ff18639d49e75226",
        "b6e8075fa75509cb378790a0b6a08c7d",
        "6c65690a67b0336e538b9138905841e6",
        "66ac23b23207cb3596658ec12cdb89f8",
        "4b3909d82c41706c7e751282d46966ef",
        "039bfd975df920553329400061657127",
        "a7e11e41991dea1d2e8a856b38382902",
        "c7281152ee9bc22d9e15b59a321de55d",
        "5a61f93569b878d5ccb9877c8b3afbb8",
        "1ea1bb5c42abf4569be1564c8f351954",
        "c01e92a9c4a65714e48ca2e3dddbeced",
        "600307d5c3d1eebd42dcb04bc4476040",
        "6ee1afd7440fef8af3ed46cf1d9ba4c3",
        "4df200cd10bb1c17a9fc81cc260d76f3",
        "24aaa1ed6cc583e652b04b307b334805",
        "cde8e9fd356a713100a1fe2b10220fce",
        "724d66c17910d05b52d3dcef2c302e22",
        "723034e358f3c1899093ab22436191d3",
        "b8242f9fb94092d5f10cfe6faae90338",
        "b33f9c9dcaacfa65fa88060d27dd0aaa",
        "ea1b22e5d4ce6a9fd5f7f7bfd71b2dee",
        "c47f9c87b2dcfc697e38ecb7087454ed",
        "56ddd7970a0506eaa4c26efc63a0dab2",
        "e583b787083da2ac997c7f25ebd4e6a5",
        "70f5457975d063d316d36b419af889e1",
        "1255558dcffce6908b0b4cff2c4b0929",
        "4c210f0db8d6ceb8e57a65b723e5c795",
        "9887484a5fe0ccd8018f0ee950de0506",
        "7ebd7d8ae28cff4d2c157ff00b548c39",
        "434f8634ecfad3b1a6c81ac75ed774fc",
        "b432074848d0607f47101b12bee515c6",
        "27bf40314b5e10ded77c741a5cdbbbfd",
        "59ed8c3378467e15ae5395c4488985e7",
        "90a7357516f251f1790ae4653514717a",
        "6586690f6c4f8a2f579063d0b572b694",
        "779c3c53a96dd5d18c17085a6351e1ce",
        "37ad2ed56ea3677dffcc2794bc550f8a",
        "0ddab547b6a30d9bbe096ea070bf0603",
        "6cacf7093c9c9cd45af6a93345569c6f",
        "9ffc0375f66dd64358d809685408db3d",
        "954503eb969b2c6491b69391b9cbea47",
        "ae9f2095aec5b0ddc4c0e9c3706b112e",
        "fb6442d614ed3fc76f202d107aec8b0d",
        "61f8ad08e4bab11f5e1c9c8fcc4719ed",
        "1fb4af16d3f00eb788789a20b1bd879b",
        "11ffbe2040c633167bc33aa0771e1b91",
        "776b7d7dc2165f4a9952ab1b5edd47bf",
        "b804c56a98967cf263cd368bff1ad197",
        "fdb8d87e65318128a9b4647441a0cd77",
        "01d53ce1a0381ebcceae6033ca70d929",
        "974eee80eb5c2e422946caca9bda47c7",
        "d233b9eb2b651d6159bcc505a981b8ff",
        "9cc42e6bc56156662ee6ee5bfc9c6e49",
        "77ea4edd4890c3d088571b3e528c8d44",
        "bb770e5a7f08f72e1d61c4c407478755",
        "238c0d32d335f962905041d9d5508e10",
        "11969221d5f9169a9fe7ce44f58a6f2a",
        "515284dc0036743a482170c489eacdfb",
        "bab1581943c0d97f987f9a66be73bc99",
        "542e9d747dc509e1f81cf42850dfb29f",
        "ffe5c7355b63abed4436d9510d8b8ac5",
        "304bd6d5ffeb07f50b0f09bc847bb440",
        "0fd0f5f492fcd4cacdab82d84a95db02",
        "14f0741f3b82e515dc553ed43faa7b1c",
        "e609403fcf6a4c809f8a6228f6d6bc26",
        "c86c1291030fd5f22d983b213a5e6fe2",
        "ffa31c0a3b94cc0d0b4ac17fe51717b1",
        "75902a83a14eaf3a73858ec2fe8c7303",
        "3268f4c6609dfc12bd663e29bb844759",
        "2f84609aefb6b7c5eca09e4cd22266ca",
        "d2bfa201692bec97b1f2ca286f27c09c",
        "9c9dd55d6cb920cc17183e6e5c2537de",
        "f23f4aa46524943f88b19038bb7dfb49",
        "c2e1c697a594738b6f13bb25624d8e81",
        "1d37df6051b16288f3cd05eea15f0218",
        "3446c335887504a814a1b9f8e6408dda",
        "d5cdd14d96003f80a827a08a75c0d28e",
        "b8c6962f3ed762686af5408903cf95ab",
        "95bcf2a1f59975b75e6eb46b23913280",
        "95b63f61ba3ebb6cf08ab03820612c79",
        "0cc0c27e41d910d3f079c1927e25a9c5",
        "1a3505980aa538181d47bd9beb9478b4",
        "4a132f34a04c656109a142ada6689254",
        "8e464fce2f46bf9b8407c7c326af8ce0",
        "aa96b56f67c7575c667bb3c1868a9a4e",
        "4d2b5f9cbe20f23ebb838b97df1b305c",
        "96954992dfa590e2cd0ae8d8950af4a9",
        "b992e41eb8e67dac39a1b30e5c5dd39f",
        "1409fea5e2d0cd7c409b6e33c9e060ea",
        "02969eed91239d70607d9a74325994ba",
        "523160b5c1b5eaf41e9b3c70389f6e98",
        "982ebe3b7347b324ab6848df5bf90620",
        "2c551a2e29e9f5f807bae28a528e2109",
        "14563dee193d73e4d58855a3b630287c",
        "44a0b4f29c38056d2aff734539ef0410",
        "86e5f652e50d38155e4ad3ba3623ac30",
        "c27de57137ebb94cb430aec4dc6bea4b",
        "2177d023e6602e3c4a41ebd933c9d585",
        "39445fdbf6faa3eb461382c1e619f37d",
        "863022e8427aed96d8a9c24ad7f01bda",
        "2acec6639eb0d0a989238aabab904d4f",
        "17851443f1f465f3d61eadd8eb6efa18",
        "89db94b47904ee6979bd23b2731c4844",
        "707726bdc003f67d62caa3a2f3b42419",
        "f3f3209850a9f4fd8363b9fb02b0ac63",
        "2e5f028384bef9826665976fa19af579",
        "f849660c259548e1eef069519a9c01d0",
        "0e63179417ed1e01a63f1abd92604c73",
        "351365b9ee45277e0f5f6b4fb1d92924",
        "dfc04084796ab1d7f6e7b3895c266e3f",
        "17b8e05f1b4deb05f24a4683455707ad",
        "556b1d3be828189fa3e8cf856ccf774a",
        "05d136e3f0900d21e221d75d3d83192b",
        "0722886aefb2ca336d7cb3cd0e68c551",
        "e14b2dcfc68b802c8b81db566e908c17",
        "15f0685959864766fd53c99423285a66",
        "62ade9a418e78918519c829fd5933aef",
        "5888fd1ff1da9e4f7ee57525ab4e486a",
        "9435ee618a1527a6f2be377f9289fa9a",
        "7e1fc21b7ac2bcf0a4a952be566354a4",
        "b6fa171d4dd88144592cd6bc10ab69d9",
        "10254d838cfad83fda3ebb888e0b1098",
        "f06a6c0071e18a92f5b6c9deea2cd911",
        "561d02ca8e392de4db576576e8f4c0fd",
        "d47987cdf8267e13b9035b70628222e8",
        "9ce248f9475de4ac01fa561c0f564a2e",
        "6bf8f4c8384183287272790f38105cd3",
        "a6e1286564f4e356a6ce27fddc2661a2",
        "e2fcf2ba23a5b21df30a15bdbfce1434",
        "90937adfcccc787b276930687da9bae3",
        "7f7043777c40fa4bae8a09c31ffc6939",
        "9075f8ee5d3cda83f73ed553e2f5abed",
        "aab2957f5007ec1f261325dc1411320f",
        "2d777f47dcbc2bb8504f45f54351c591",
        "a062a59bc3bd965e5a6959526d7271e7",
        "d565128e801e46d7f8079108c98c5ada",
        "871689580c879693f367ea95efd08ec2",
        "a758493c1ba468b141f2a0c63b4c6b02",
        "1a238c8a1240ab5437440b7c52d9d431",
        "e77893fd72a9d29fd7e9349363339ce4",
        "fead16c8d23bb6c59e0a3a97f6fb87c2",
        "cc356c34ae4b80ba01513ebf46e51ffd",
        "fd93089c7e05d1e7c17be3dfdfb417db",
        "1bf6771c006dfcc568a5936e57eec0ca",
        "ceaafc557c88fbd2754f0b2f709397c9",
        "419da6b6a9ebba63c11f1df0a6295a7a",
        "44e413ecd2e739eebe686a0c2633652e",
        "4667038b99154551fb908f8d21472d29",
        "f8015a8dba558e78a3a816c316177a9f",
        "30c87ea9b522092ea2b72195cea6f3ce",
        "ea11f81d1e6f72706b69b6cf44cd32f8",
        "50715d721308e9f2b1ecd73c6dff49ef",
        "23ce8f52182633810f3b4d19e0b10231",
        "bffbd96373a58cc55d6cfeca7d723f5e",
        "f30e458ab82d538c77d231481e6b9522",
        "b323fbde6e72c4bb282245087753e3a8",
        "fbb9120b26c3c3e06d391b0512fed94e",
        "1cf2ce9c8091ba48452cd97b11269709",
        "f634a5cc6c5106298b5626f8f6ea7210",
        "c67f055887bab863038d210a1ceecf86",
        "37a1794717ef75d659507c197f40116c",
        "13b6fcb1791b52b2bb2fdf8ef4b6e565",
        "c24ccb259f17a8df3710d72821b5bb1c",
        "fe4ce78b24a5bfb642b555d801087593",
        "6adc5d25f5d4a5810253c6ec1ef0074e",
        "6ff534383d1dc9e395f5f9d1c299a093",
        "a9484043c33319fd714bc26bea597b30",
        "280e05c4d1e82921c0cb331d2e6a903b",
        "277a3aa1ce05134aae9bedab04b2b7f1",
        "990ff1a99e0d139d92145c5896bc1d52",
        "8b79805d5871b105178872dc29fbe812",
        "2d4f6eec1440c99bd940bb5324e8d135",
        "773d1e149e733c1e9a38243a55b4ea2a",
        "0ecaad06136077804191febec259ce55",
        "63ee0fdeb256f323504aa08921d1b78b",
        "683fc4377b12261ffcfb992b419129f3",
        "0e41b47560f80bd676151f61b2e35ea2",
        "2ffc74b379614e0e6fa95a87471fa790",
        "efee37b0452631890dfcefcce01063fe",
        "a33a1ca0cc88a65bc1ad84d277ac698e",
        "888244ccf86a6128bd51fcf7be8ac003",
        "3acc08d1d511b8149fe5f373904f78b1",
        "04cbdb1929c2470aa5860a691319c458",
        "a304a3303527a3d86c94677d3ce8a3dd",
        "2be57e39027c5e221bb5ae4fadbc650d",
        "6fe51ab0784ab48491e864711bff5fe7",
        "c40b4eca7830a724f3aad35da3fe7bee",
        "ddd1e5da75c78b72fe442bb0a1bb7349",
        "8d75a3395ed99084f76e61588b68d431",
        "057850068f4dcb9b50261a83a31bf6fd",
        "76f80cf46a05bd74ac8c6d2b0e5ef5d8",
        "b48598098b92a22a5c38cdae5541c3a9",
        "e166629b21929182c28099ed8a599593",
        "bba6783a7b8c1abdcaa1d35bb522ebd3",
        "36f1b7c3f78b6d8ab6de5cf31a0dc032",
        "e7a64fb73ab3a34d9baf4bcd95e3b5ac",
        "9f0de6a591a57fad4d10e142df0c83e4",
        "c51adfb4a406f593ac118b78ad29d417",
        "5c205f14e5b36233bf86d3e67e3c027f",
        "28d937402d909b418b6cc6b1a48abbe5",
        "938cfbde2b845f765cef5d3db5c5c166",
        "9d0e362d9aba7d074f788754ea46d27c",
        "15eaacd0552196409dd9891b098111f0",
        "99027ac85a782ff95eb45d3bfde0e29e",
        "d0ede5acdd933acdcff491e60ec17036",
        "0dd831d1022055be5cde72c0a661c860",
        "6bc172d0abb20b023102d5a7f9661c78",
        "a533ca4274de351440aa0361dcab61ff",
        "22c3fbd7a37918ee140033aaf1029698",
        "f9bc1301dd425fc71a5282410ffb43c2",
        "6b8f3e19715c75369ca94d0faeab960f",
        "27adb0fcca071e71bbb230ee42b5fac9",
        "1af5288c3a580d476443698bf81a702c",
        "f1f208aa465a91cfc5190ca93ee0e947",
        "bad252c032b41bbd485b66740dc2e2f8",
        "558066b694c456d04095e1426a006b99",
        "173e33da3a08ce34087ab94657d98328",
        "b2f4ce494d5f43239208ac197516c04f",
        "93e3c1eafae9a518b809612d352bb317",
        "41259c1d615565494413f796c7dbf97c",
        "3d29c15428c37d8cdaca65b03008a019",
        "bd910bb22c35ca32eb519ec37cbe54ca",
        "0db7bcfd79f6e89f1c724c28908a5073",
        "77816c90b041841a1bac54815988ac24",
        "b196e48f6dee0058a8571bd23a772b6b",
        "55f69b22a10bcb4998fa0574cf41aa3d",
        "6954c556d83e49be73a578aaebd63920",
        "a05b5021e5a97051902533d520b308cc",
        "99d9468bce0ee225862f8237ec32c7ab",
        "25d09d758376c1e830a1ec1f2c37c85e",
        "a4d6399e465922f977f0810de7744698",
        "2e236753f5acb4629cd31c3a28e00316",
        "cbb75231cdd477155c17183585c18d62",
        "2927644fe3c0b4b54559e3fef0835603",
        "16d648936412b994531bac7cfc9d83e0",
        "ebf5a8176617cf6452141e0e1c4ab3dc",
        "845dbe848ebd9781b6eb13a747f3fdaf",
        "8e28a119d2130d40f30f0b34fdc9d782",
        "52b06092b5de4a02b8d58f265586a540",
        "e908d44bf91409d39d5d848a85bd39b8",
        "d8deeb65888654e0b801fa674cd8254d",
        "b42a4319932c9ee45c54b3109e2ada59",
        "69d4a615a55b946e804307368c0b3ecc",
        "a387eaf2431142f13aee52d3d86ce9f7",
        "01e0e77602d19cbc023c8f78971ba3a2",
        "9d1b14245216c8562fc2800b3bf956f6",
        "39d07df0ebb0b88b3b7f7e6450c18831",
        "d74e5e6053c708011bec6075ac46ab76",
        "3b4a7975dd15d215e707a061737e3403",
        "dc99fc66ea54e48d95cd02941456363e",
        "3db589f626d33c28254cf53615627a17",
        "993d0900937e941c3d975916291a48ee",
        "da53a21ccaa3a5e693de5bbf6427aac9",
        "4699575251f30fab091df7b685f5a588",
        "7eb1d3f2b0d4fc7869bcf440cef5a700",
        "4ce6bd1e2c947b5b0e46452ceae67a6d",
        "75a8eb5bc13fde13ba8c2694748fbc4f",
        "7e73a763c023a7b2b5842e07707591b6",
        "3cd07715ec3928e5165108d5ccc6e81c",
        "858dd72fa2a4611307e3ec81a8b4ae83",
        "2d06c484bb0cf191ee01f898a446563b",
        "e939b8434e587046aa3408afc11cbf85",
        "e8dc4802a5ad4b30d12e07d68073cb69",
        "c9038c7cc075f2d08f5d9f714debb8d0",
        "ccee152bb78427c07442c35560cfcaa7",
        "5f6b574c10a068e9a2d3c6c549fa0971",
        "605898c7c25efc4af8c634fd621a468e",
        "4afa6286ac5703e42edb58bbb7e73d48",
        "edef9350314a68eb7236ffb54ce74b4f",
        "893e9aa86222546c1a619a282026a5e1",
        "22a7534e4c57dd07dfa945bc009f75ec",
        "baf72ac4aa7069e8e7a0289f5de017f8",
        "d456fef6e0adee78a448cb02be43facd",
        "9736b7ecfc0d3ad9022bb9ad5f998ec7",
        "f1e6e4c9e7ae1f248508c9d76134cda7",
        "5f81d5794d85efe6ca3a0cc2d9d0f781",
        "eee842a61f998a7bacbbc562c6dffedb",
        "de93ac97202c3ebe4f0ac54d1c49e512",
        "b8a42ad99b5bf3b456a1e62b29b4c7e0",
        "3103f2978b7c8cd06f234086f3322ec2",
        "71bc2a3616fb2328ffa60da356d67c4f",
        "1982663b3dbf6cfef37042028667dc0d",
        "d8ac7a3181edd93be56ac3ee33fcccbe",
        "9014526621bdb9b4fe34f6f07bae2739",
        "676e626b0cd7a0f4abbcd4eb7276911e",
        "fd6085b08275369b0e0fb62edd62e8a6",
        "2619a51959800efa42c6be7532abf3e2",
        "095ea866a8335d572c9a700684a0f7d0",
        "c2867f043186cad4b47a06a28cdbb277",
        "971db6c2f6daa04eced6fe29d553963a",
        "c6cf28e9ec325fe4f6715526c61d812d",
        "c8658e34a775192166673c137f98493e",
        "b217692e7e22c2796aa36f1976494bac",
        "a2625c5d643b60455a232eb968b79428",
        "4e05f41c2d1b2b7b4e164422a7d0d0dd",
        "87a0ccc56ab9c36b811c04301c0a6680",
        "ee0b9bbd24cd7ae47cfa90cf37a68ec4",
        "fc5e1fb3ae6310f3a9f6d17f898a40b6",
        "b271f43c19ef8ec635fc865284f1a917",
        "91d20c9909785879a7b437dd3c6545b0",
        "d66f44c3a191588b784655a3f93d074f",
        "710994b93521e09bde5cc99c0db206e0",
        "0be10ae4986ba6b82609ed6dd1c5e6bf",
        "ba13dd24721047291bbfb581a5353197",
        "08b88320f901e2f313eb269022e39912",
        "81add4ef947b871fe296499218c4e8b8",
        "09e842ff71baba803c8dc7968c036349",
        "b75c539a011239db2ee62780b4a579e1",
        "f184a7a5b838c23752eb9dd82640d339",
        "08cf93b279cc96f72ff6192dd925e7a7",
        "5f79fdb797cfd199286b270d2585668e",
        "752f1887cceaaad1bcc88374fb82f315",
        "f9748eb7d337cb7571ac8040cfe90d34",
        "e677e54b1f00ad8467bc3da9f91bcd41",
        "ee65345c4be4ae44de36b0fe655f9757",
        "da6f6800a7c8be7b55c3d5e2ed6fd087",
        "21bd3550a7b72b5d5385547c8e07f9c5",
        "fd44cace91c1246822515ff1c1a4f08e",
        "acaff5b55e2240a10d719a48d93fe0bd",
        "1ae555a95043b8a5f394886236d0f991",
        "8efcc97a5b2d43183e4e0e1b9f747b15",
        "7b05e3ade0b5e48b3ed4c4b7404790bc",
        "dbb452690b9beafa3cf599bc95d4c09d",
        "de6aa1b79cfea70ec38fded53c07d744",
        "d80d4927412069a994304cf3a9e94e67",
        "0e95c1daaf786a063b32940adfef2580",
        "6d09d5c4605d1733a9974e1a1428590e",
        "e59aac9cf333fd6bb1f79483f71b8093",
        "0765dd929e7f4da1d35cedc7581ef4f5",
        "e20d4d72d32240109520045ebb3296ab",
        "2594d92e0ea1a63ef356ca07ae9bdbb8",
        "b802c8f04c242659a5b0da35554564a4",
        "056dc68b0208dba3a50dd1fadb4ab25f",
        "9ff245754c263358adc1683afb904fa8",
        "c3b9ca8933f45a1092c61f31103bc623",
        "10e2828a08bd7ce657d6970f1b4b7de7",
        "0b2fd9658b9e0881b75705e9b6a82d0a",
        "27dac03db75a05637e6b864369e58f4b",
        "21fd52480b0070e5a110b5560340e6f9",
        "fc951a8be14d891399401b9daafbe723",
        "ac3ff783b577caf7cdf2cfade3c1bd80",
        "d42af680785114009538d927fcd00490",
        "80aca7419e8bcfc0dd74cbec3c78b562",
        "b930f039e56f33dd02eff7374f13b011",
        "e3b99f118449b2ab784a77ec37b0ac24",
        "bc50bd58a9f6e358d8e9a00b993124c9",
        "5ab1811343d97c508e1ce3bf2be2efac",
        "89001808a30fc219c06aedc463872a74",
        "a01f92794618eb42f18cdd5402b7ce4f",
        "41cd51c772fe26ef982aecabec69275c",
        "18398ccbc3cdb139901a73dec7ee4801",
        "af31eaa25254c8fc8077c2e65e5aed8e",
        "ba703344c068a2bd6421710bde01414e",
        "f0b764f9304b46f5dfe56e184cc856bc",
        "304bc337a44fc2826a8582ada8b4507c",
        "344d48304ec5f747a1c9cc4d828518f3",
        "b72910cfa7934d3c8f0772879418f433",
        "4030ff99d63288a56e6b946f6ae6c462",
        "c70257d7377a94e03fbd22eb3c8be14a",
        "4c67af67ca0086fcf1bc8ea5e5942fa6",
        "e42290ee8b41b5a764a744d85c464ab9",
        "2d0e06761da4a0ff5b679c8b2abfcc72",
        "0b919e797e461ab6c9f47a0e93d6d209",
        "85250a94199df06483b2e3d7fddf346f",
        "1af8de69cb699dd359397b377b19f0f8",
        "971dd00421a7fa8564353f78fa733d04",
        "3747d42c6b571f434b264577572cc128",
        "c96fc8b3e8ad09c14ca8d9023b65d27a",
        "7f066b54f43625ef5a7473c61bc68ef6",
        "47d61de573e153662aced0c88804e1c5",
        "ec78dc9d1b3f26b159e2a0d366b5d790",
        "d00fc9b7bbbe0e90e3e415cf40c0251f",
        "ca500ccf8bc1069aab47bc47aa060a2a",
        "410eec991a7556adaa251ec6fc1289b8",
        "0b0bd29b8fa95912677e6466742881bf",
        "cd380e89035a1176184639cb57b7e296",
        "41eb08da174e3fdb96c0943cef26a7b2",
        "bedd75d7c3813048053e1234529a7798",
        "472726f27a30e82e809a5e0840345805",
        "2754a507e8c6db30eb67bb956eec7672",
        "c33d5403fa17459f01871667547a1a03",
        "ff4337e8c79d6b7b97761a90896d86ad",
        "f90e690629b13cbe4e334a2cb647aa56",
        "e9a080a28989e28696e33deac5df2f82",
        "b7986c97cc58691be0eb7cd3bafe57a2",
        "e9e5107e11fa4559d983258bf773aaa7",
        "dc1a6743affea826d6eb038e43e6d186",
        "936c1bf9a151bd379e4392878626e890",
        "7f096fa4981cbb3ca0a3845c7961fd09",
        "743cc4354e1fc8dacfec1f9268cef168",
        "89a2ac5d9f41161bee374877b41f7bc1",
        "6e898e636155162c524bd8ecf30d6ffe",
        "67b988ec13a157ccb51f5622e897db63",
        "38277108322d5f08d4a1c36edc6f02c7",
        "8d23f7ea1f5e30ab5e254e8da0537ef2",
        "621613c8a149cf8bd43876c33814f7a0",
        "f7e6f294e257e137821c58f39c7b3813",
        "54390cbca24f8197af9660573e750608",
        "adf985536f31f25396df8b605604cdcf",
        "2fbb9ebc90a1401e2a038543f000e11a",
        "0b069d4a1bf1101c8bb5e340e75630cd",
        "aca71dfdfdc0efadfe0999b53b93f9ab",
        "c8f9ac14b6a80969773eb20767acb1d7",
        "16ae21eacdd08e6e3c9457a24a7ab472",
        "5ac7331067baeb6668bee1cc9a69f772",
        "b57ed0c361834a48f52f6667ae935b68",
        "7d32de3f8ddfb84f7803affd9196e67e",
        "de1e4ff798014116df5bf2e7908e67fe",
        "ff3686f013c296c77f38c835c2f33374",
        "a8fbe677133900870a68424995821a1a",
        "835b6948ccad7d4b4da69f8396213eb1",
        "390e61349d41b696a816004a13c8f43f",
        "834ab66fbe8add353775090c1c5f1015",
        "38eee92692564095522521791b132796",
        "3d196947b12e2c57c9301610500166b4",
        "01ff79a25c413a1cc11d64d4b6993b37",
        "2145e67a02c7480c0227098aaddf2b3c",
        "513653d4f2f22457a24378e3e9e5383c",
        "995a66eb091d430878553104e84e9b53",
        "0845024dde7b54250a7cc15500ff9176",
        "2584651a6779b1616ded162786460748",
        "285a5ce2460ec435279827ad2cc94ca4",
        "4f96469f8e2de9f259fd12a122e82156",
        "6f7ef1e472043eb53140c8d5aed1ebb2",
        "00ba5576d96f6f4963f2dbb3adb103a1",
        "874b2b37dc8c64503953e3c56ae3511d",
        "262ce36af95f5e7c276f5c1782e7cd3c",
        "0fe7632f4f4ce3d71d022425dbad4f17",
        "bad9d57232ab74f5a218371018641726",
        "26f2def1c9df58ab8972f60abeff9394",
        "a6b53a059c938862ae152008b033cf74",
        "a53bcb03e9e7165bc1581f90734df9f2",
        "851c534905b2555ff99e1cbc628fb6d7",
        "67061eedcfa5b8f23718bd8691727b1f",
        "223a4269120442ad38a250b57c9579e5",
        "c656623e9cd53e49c520591b994979c2",
        "6c1e96d99c6ad5c43b70d128f117055a",
        "2beb4aa42d71c8a2569fa1967bfe72f1",
        "a567343baa6d2b59db3a73afc20c544a",
        "0f517cdec2274cf50ade587da897cd44",
        "abc00282ae7477044e4a0197b1696b58",
        "eebc988b3e3f45f37a8b6c88b668f5fc",
        "ea5cf991f6be3a3762a5c37fdea9c489",
        "b2623dc43e9609d52cc676ad48aa25ba",
        "cf592c9e06b0009745680b2fa6f99e63",
        "fcf34ca1cd80ab5a766969a18986b796",
        "4a03af24fb1e11613f84154b9b2dbd4b",
        "1239f3861354f993fc9df3b6ac776b64",
        "ac8bf7d8beadda53136cfda213f22602",
        "760b269cf5191ba36d68ff35f11daecc",
        "38a1ff41ca49b3318bf770f657e12db3",
        "ebf6d5843f7f12ed533241676b8795e0",
        "4784a84649703733960b7949bc2aaa13",
        "f144a41927e07095766b8f7237eda8e9",
        "9bc23af10430da347d3bf8399a668839",
        "e62ed2f359753041bf14a4ad5a2ddd0f",
        "44f546cdab5d9efc5675f6e23237da9f",
        "6f0bc9bfee2309a13be30b4e9ad270fa",
        "44201a197f4dedffee5bb2ef536268c8",
        "e320c6795e8521e36bf027e2fb967dd9",
        "6d6abb3032938fa0801508f6ec49f141",
        "fcf97553ba1c1f23fefce4769abcb4d6",
        "1aff0a319e0a8b40e242a193eb2a82b8",
        "ed8ba11c86f5a096c187e51de01d524c",
        "abfc49706060bb8d72dedb4205b75d2f",
        "41c8423274cea8a37d5aba7a498f6996",
        "0f0832a5c3249e7eaf0a1289cbb4c2d2",
        "ace0da789bae5d71b800eaa1d9cae33d",
        "efca00fbd0c8be637ac319872f5fe5dd",
        "63fc335cc420b41121438839a9b4a439",
        "3f84e6f705de5ac2841bb1baf91d81ef",
        "2a0d55082cb314539c7d8c77ecf5d8d0",
        "258b90f0a48596352b663ba3aa621c25",
        "11d8286986f8e2aeed39cd6628b99021",
        "c495b98ee21b8754b7772065b6c5cc87",
        "2fbce160d9fb129603854a572b7ad332",
        "b33ce974830b4314dd07fe5b869da10d",
        "6c61fb863396fbf84dc7435063b485a1",
        "d3bc378071a51df821658162f8ff6bef",
        "5407f71c8bc4f35788a05f478cfcd1ba",
        "a7be4e3e222c8e1b481403ea724d91d2",
        "6f716afd530b79d4f93c62dc1d62862e",
        "0647d8c9928ca70f06f2f91e71ffa938",
        "8711f01881e4de740418ec6d35d0a61f",
        "ca2179c4b01de57b1fd5bcb2b3406d19",
        "ed6e533fa08cd06f19e01ae701f5f0a8",
        "8b78e07c366c3d6355679d5757f5ceb6",
        "efe039c110c65715eda733265deb0fa1",
        "9ef020ab7fb2cdd68038e288defc47ed",
        "68691eec797061fd83ab4939bbb62bf2",
        "f2b4d2dcb5eba76256ca91e222c5d0fc",
        "ea9a5de888165925b353ddf380604593",
        "5970912fa27589c70f486fb3d1dbbf64",
        "aeb1c9f4bdd57967557d5dbc8dcc6d0e",
        "bf30cd22cb1fdff22cbdb71f124ca461",
        "090fa9eb8f186908f02a28d1dacbd33e",
        "d5257a0a847c2f43d8dad549bd07b362",
        "74290a01745c828eaced7eabb087fe68",
        "4201cbaec52ef7c5fc158fa07596606c",
        "45c62a16642300e70a14e7fe10ad45b6",
        "2ef7fba9ac2c84937978edb936751bb3",
        "ff77bebd3c7a89f0186b7af56c715036",
        "0655f521eab75613fb0b3ce0e46950ef",
        "79c2375593324fd36d9eec86c8fe3965",
        "5d150b41f04ad39f7646ef349c8df15b",
        "204500949d8fa86226160ff16791e2fe",
        "fcb4499b03d31494cc06a3dc511c7eac",
        "6d1c0f85e81c94ddc122e895ffb460c2",
        "9ea4be36a690f99a04c2475728074d8e",
        "67a1b1522361ce8092aaf25f6191365c",
        "573f7e076270d07dbe2e2279631188e6",
        "5f8d80535ce44a39af2933514c5534b1",
        "7377416382f455517bbde87e191f1e5d",
        "0f15e5d3fe3558f8854e63a130654491",
        "d70253d31b8a25f91a3057d5b3c49141",
        "b6045e08d755b7b8995abf803fafb29f",
        "aa5ab5b3afea28b43b4fe757a9b2d60e",
        "5e1c3dd36d7f3ba6ef3723c40193e796",
        "89fcf77beaf28a1ac4c224c4d1f623f7",
        "1bd7a48800f6ddcf98e57f2416cbf55f",
        "e56672afb4f966763e987c8d5c0f06dd",
        "56651be2f8404a2cfa1fc7537704a6bf",
        "786abe3801a70c17fb23f31fba961371",
        "8e0c29393fcaa3c6dc0f7fafd41ed66b",
        "84eca25950834abec4cf603714a2bd57",
        "813237b99796efab0449a8fa15d84c6d",
        "fda0bc0e618b0e46f682d4d762805778",
        "1c114c02f26890c383a2d6f0bf1f68ef",
        "7c66e03ff726cd268420142c109994ad",
        "20120cab1420b965c5bab86af514e47c",
        "70cf07c31649ca1aba7f05c83a69dc7b",
        "1b949b0405290a0a824d02061baef987",
        "0e09f3ea333d2cad5e86f8a3e09884a6",
        "d13b6b64be6f63eef65d3b901da3f9b0",
        "b46e2bc70eabc919098a887d303a060f",
        "16f79f1f2bc0d48a27dfb300432ac7dd",
        "ccba1f59534f6cd871a0600a3afb1ed1",
        "7328ca3d38b87dafcfb7c6e94ea28658",
        "70c865e897c31798e3223d48ed2c147f",
        "526bd14f2a370094d337d30a274ac203",
        "3aac4295b55c7c3c2b9f5ceb278582f8",
        "6166153d7e135bb829d3dd696acd847c",
        "ad71ba8eea61decfca22c3bbea064b1d",
        "1dc9d6651ffffa9e91225527d072c450",
        "256492701d0f992af3417c94c8767fed",
        "61b70ea1d897e9a15c9e56db8509e05c",
        "b4cbaa70d6b457e6dc82da0d9f5399fa",
        "d8812e06aa4720a85fc8969394172288",
        "928124e63ddea5c51071cac9f5e2d958",
        "0050bbadc788c910bbc566150d847021",
        "229aa7b211fbd0b00080af675c13426d",
        "e72a0f55159f1e711619bb2102076cc0",
        "b48a91ba5cc862b60ab68852cc4d7913",
        "33edf14fc04e41fbde13bb24659e8823",
        "749d14b79d45259f26fecdc3c245bd1d",
        "7d9c3abf1e4476525bf4d228d065a076",
        "3906400a1bc9d05757d54bf0e8cacabf",
        "42f9f05ddaa456c2fafc832638cbbf57",
        "493ef797255864cd1f1962f065a572c3",
        "58faeb271954482a75a7da18a54342b5",
        "b9e5bb742c92488a0512509f14db9d35",
        "f1b80d46f2f2c4d7ac3cad028f656650",
        "bcf5dee4bfa38f46275efc7611ea80f5",
        "93f7868ded7d0a8b2ee5487e017e8ec6",
        "b8defd601ee7b31b3b1f888d67e0399e",
        "c7d10facc4e9eb5265fd3383b8251f20",
        "7b971dd3977f905f159f51aa5681beb9",
        "552ed97624cb72c8991e6ee8f82fb612",
        "35f3e190cf8ff3a399134bfcfec41d19",
        "9e157bb24c5954bac01aa0d20d015809",
        "a914e8dbc6ed26bdb996a39e007e74e0",
        "157d9200a43466d0a5ebf28b42d9d36b",
        "a8ca1f14a2ca83c27bd74172a40336ae",
        "2700c7ea35c40f56ae00068c31b47f6d",
        "80a3b28d2f3cd710148a3ae8fad8efe6",
        "1327f6bde823f2743bd272678cc3d548",
        "7e4385f2292130a3dacf28c90abc5416",
        "59db5e40fe710b6c93a304b75496e424",
        "821c04a9480c555184da22fced2f9107",
        "5b211639ad06c3f01fdd83232fea6f2a",
        "eed877df90517668201c7a0be68a8e7a",
        "b60234184988de90767ca4a6c42bdba1",
        "1df90be60c4ec68c8883fe926250f535",
        "69733b73c4c9b746ea5f1450c6eecbbb",
        "048856330b7418769ef74ecbf306e785",
        "c31318abf7d4fab38c4d82590a041b6d",
        "5a7771307d1f7f0eb67d93f7b1e27c41",
        "b4de4fff566aea613c544071d89304bd",
        "036c682f0a9a4356a85f6ae957e9976e",
        "ba18d050287a0c0b3990d64b56bc6ce7",
        "67e55ea060a441b2048cc9ff031217cb",
        "271f9a40f7b5259abfd7494044238cb4",
        "54d2199910696af0d856a1b0a0597958",
        "432c39ad78c751779548bfb58132c02a",
        "27296073c7afc8bc86021c31962f5cec",
        "2dc08c6aedaabd4a35cdef390543ca20",
        "f8c0365ec258c45a4ad3c533f2b4d1f0",
        "d0162c37a24d7f32697544ba7a23125f",
        "f2f0b1d763e7b71b9610b8f40a34dcae",
        "bf272273c634e3d23d027e695d604b1b",
        "6626e73607357bc34638631927797f0e",
        "1d5fce2bfc9006ab5648ec219dec9962",
        "afc6090c7138f6e56cb290eb03960954",
        "6afebce9330cdcc858eefc2d2454a361",
        "2c390d778febd740a659c128df95d97b",
        "6e857db7ae2fbf03f61882bd1e40d6b4",
        "58e1cef96ddf4167acb5f429dc16a5d9",
        "4743b0bf5153169c3e96b197836cb2bb",
        "af3d65ce2d4762c10c6c041be01f9639",
        "8c0b6172e4c61ef1f19035e3092a6971",
        "dee9fa6d7e956815e1b5ba931109a887",
        "21f6e76ce00a452936d751cbf30cea14",
        "6e88d0c06962aef840d616bf97a98851",
        "71fbd55de568bea76191c41398ee99c8",
        "6a212e2c1a07309fdb84f14ebd6009f9",
        "7547d4dadf1689dc97a88e6b95fa1d3b",
        "5f8181a41f08efc43c557d568c93b738",
        "42e8298f132c54f6d4682fb11fb7e90e",
        "284bd163f9bb8a013c01555707271a6e",
        "6fec6d8821c6d2cfe6fe4065d5340c2f",
        "3eb2cc804ab8a15e9d9826ff28e82509",
        "5c364a346652d99849984942a1db9e39",
        "10a62578f49f42f644fbd748509b8f7a",
        "ac2d7297cd2b62d34e9c8f7dcc6b4af9",
        "2849f6ab0cbccb87255f7a28933415ff",
        "68dc317d2d6d5444594750d6d21e014f",
        "332ebd70b6353c4ab6dce0e4f8eae0a8",
        "eebbb1fbc4486cb7894ac18478318437",
        "d6cd59d36f501e908fddf19109a62f68",
        "d0b2c7bf5d876fc94f49797a40c83e9a",
        "5d42386e9b19d9ebedaa0a4803126599",
        "86f34cfd486fedbe1994037d4c97d8ad",
        "f7ba398834c56a6c8eb692d53b4f8421",
        "9943519141ff8cbe613d3704dd5a720a",
        "e5aee6b6dc5611f466ec35165f7676ee",
        "b78d18f894f29faede91801b39524642",
        "d39b422f0c5d6e25d6089e3a8ced1450",
        "22c82ad92f24a616292ceac69a36dab5",
        "67d4f886f476e9c05cc8851bbfa8ceef",
        "2611d2c99df509c13a7c2982cccad180",
        "80f50335b9e399c33c68e4d0a517f82f",
        "07c5f986ac165a99a24650f10cefd7cb",
        "ebaa516acf67005c9c00d233cd95fd43",
        "b590d7cf428f5a43e846ea7b61987dfa",
        "f6b167504431fb916c1a6a93d0fe9ac3",
        "bcc8d8333de312dc732cda43e5f2ed0c",
        "3fc674635efeaf1be356f777cf3ee8d1",
        "b6aa756f7de72a985a1d2686d22808d3",
        "60bcd6ce9cb0f7ae8596481c0dafd380",
        "b361c71ea3206df641c279b5ccfa13c8",
        "9960985abbe91b8acbeca5ccdc74a189",
        "bfc7089331e5fdf9150e10724b5595e8",
        "abfb3b3f062436b244b8d7fd3b83346a",
        "24f70fe601bdadd48bb0c82686bf3faa",
        "b148b2d44e1e3c600e8e2e396bf51de4",
        "077eae671d68c8424b1709fd6b50f5c5",
        "3d7b7f4ae06fad6e5ed15aba24da577c",
        "aeeed96c95a42e1972dc016c33399ffd",
        "4f9b7179145e5ca288dd216df359bbd2",
        "bc8e0d70213c064f4586d35a1e23a18d",
        "4f6ae8230fe9b4830f24ab36f17c4bf3",
        "f594ec726ae7d159bfd4b906280b034d",
        "2dc557a1719384433c1099c3c242d3ba",
        "7d453043202d6f99b57d3722f100524a",
        "48376dc56a66e90dc111b1c028858e26",
        "e0e4faae39cfc0ddfa158eeb36fc5ca0",
        "86f99fc4dbfbe31f7a26df8aa6b3274e",
        "d8bf8afa2aa3b1e724c74a85deb319df",
        "7ab08a1af0d593dec44c4a87c5194790",
        "85010ec68c630f75eeef862a518ca720",
        "134bad3b67bf61ec4eb70ae7dea95941",
        "fc87526cc52738dd6f0b221c8caf69f6",
        "f50e8f882efb0f98780e2ba1472b0ef2",
        "e6ee3f761b458d5465f37ac7357e2c8a",
        "18bee7890f3a13d385ec65bc1c3557de",
        "85daf962ca8130c1af35f5738f8c1980",
        "a5330336dc368d3c054ba2ba0a62c39a",
        "e7d8d1e4c65245f7e9d47f0fffb4fcda",
        "7fa257adb7deb4dac0e8692422d27908",
        "04fce5e6e4513e5ed06204e78689ea12",
        "2fec97eae5b7b01f33536ebe89ddcec6",
        "5234adbd72f2fa7459ccd62cfdb36c13",
        "dfd57f4798febd21e7563c3104b40443",
        "c199eea2f63ce1f3edb1d2cc03d2a5a0",
        "b708b2d37d88d805bea53d74ebca3a62",
        "0daaccc301af821de8d7528132a7fd5f",
        "90d61d7d3ebf55adf0b809bf58e4a2dd",
        "d65c94c3ed690ad4cf1ccfebd0f30118",
        "9d3e85991bbd59501c4a766bb857d136",
        "385feba312af3cfcc044f63d80f54e26",
        "90ecfd8d17e0fa9dd21830471fd2b146",
        "f91f19148ec058e154a025b4ac0820b5",
        "2c6a031f0b13c767ad62d18d720c8b75",
        "93d0b1a8cb8898331101bfdbf32ce5dd",
        "6cc33eff90db8c6bb175027c298aa0de",
        "1a33d39fbd64b0903c1cc3527cf3f643",
        "0387b0e937dab9620adb2e69be7ed1f6",
        "c96b89705c259d3bb01c99b8296dbb3e",
        "0ee5a55b37b7872d16c812e97877ebcb",
        "ca3d9d8995a979af13f9fa4e6906d829",
        "75a894390a5605bebdac942ae1106907",
        "efc8f38cd10701d82823489fee31c566",
        "b4087ec90f7240ace8d24f71958c596c",
        "e9ca8d93b1161a704afe6c22d724fe18",
        "f03df8531a071eb9ae47fe2f2009f209",
        "2e410aa1dff03d89a174b043c3ee1699",
        "1faa238ce0c8ae04477d10329b2fa1e3",
        "c445a50b6400a004454759c393ab43c1",
        "f164772b9c1a11eaaaa9a0cc355a97e9",
        "f8cb616eea6da4984a12b14ad19b690f",
        "7bd02d1d4ab97ccf26f28b0088a4d2c5",
        "f022466c7d3f98ab9bda61b27dc35e1a",
        "1fa5f9eab932a265e74c7200d41bcc23",
        "6aa3c4526d5f16b6f523d7f408338207",
        "ac37c1ff449901881bfc81061ee3db68",
        "170925562a2c4c47d57eb57ae36a686c",
        "cbcdb68961c2a8192c15f331c0477019",
        "d24c35c35fa2fc8ace3e925dfc30efda",
        "c31991a7428eb0d03eebf6c040901428",
        "b38882e8026dbb521c5d573f0ad91d29",
        "38f6c5e17f235353c548208b758e1e1c",
        "73bd392d3f5ac6c9a47ab7e774213a1a",
        "91da12857b09cf27b45bfd9e250cedff",
        "2c588ab099e31a166fe505559838c754",
        "0c40f881393f3c4fe141543781bd56f4",
        "48733407fa94505badc81380f1d0c941",
        "ee37a62b144fee5c0fa90919c6dc6061",
        "d59aaa8e94c43a48070fbcadc88ffa29",
        "19a91362cd970d20d78049f0984e9cd8",
        "9b3287184a4cc9d13a32991bbd0a9f4a",
        "38feed187286702eabf66a594687b83e",
        "67bb86a0e7338c503686c5cb61dc5fc1",
        "c87f0bef1fef791083884f9b50f0d5fc",
        "43d4b5839b0d1a89fa082ff08998b8fe",
        "f9415013d45468a9994f410226e369e0",
        "dc5596c8569b526c9260915d4b289c97",
        "de6af9955206f4d28ac5de9be7b8cba8",
        "42562c33f114f307c9be97e0cdb85103",
        "d66c7e9389572d6ef7ec16b678f0ca62",
        "6d0f1e71941a55ff415c5518765ad1f3",
        "a96487e0cec8f73ad01569822084ea8b",
        "df71df12d194f3257144c6a7745218d1",
        "28807122d6fe70c839a6062c8ff3d99c",
        "b9de3062f8966fc5262b1a086ec2edf3",
        "8ae3004c00242131ea63154a1cc2a738",
        "ad33a5f03a72c35c6bb4468aa2b371fc",
        "581a44610673022179c9e1e8d49511f4",
        "fe16f7c34a548f127850f38cedb3f85d",
        "a6f25ae56a01f082429d4c63b04e580c",
        "23d4a22bc01252ca4d00b14426e2844c",
        "d4c3c0e351d952232fc41a881a68fd55",
        "d350fbb55871b5b7491735db6df475fe",
        "690113713b26883eb732c4b4177f0fc2",
        "05e25db2050113bc9c8b36942d07c6dc",
        "44233d6d69a94d280414ffc33ada82e6",
        "9f955c578e92e9c3122abc341cffe043",
        "c1e6d932a56e93b2850c6a32bba1bcd6",
        "dea641cc0f4492ff430ef4b3611245cf",
        "32aa142494618a969ecd7f648d60c12e",
        "129adb473459eb97b06f195dfb3e1ebe",
        "d97000ce447904d50aaa634f8c3ef52c",
        "90b52a49f55dcadde21f6b66c73035e8",
        "e887c934c18d66c46ecfb532e65f2aad",
        "10a857f5ad2b74f9bfbd970a93422ca5",
        "b9a19e77057382bcf8090c40cfdab93b",
        "2a50392d97748d8f9bc692cb814c036c",
        "c09b8d873b0e6b08492854d2a7860dbf",
        "6134fffa6a4420fad2d3669b56d09777",
        "7db15b34fabb28a8dcc71752f5a2cfd5",
        "429a1d8071be842cddb49bffe3f5287a",
        "2a7f00c6fccc9709b8abbaff3d9c1ce4",
        "d09a53b7cbe6abe1dc9894458ed956a1",
        "69516fda6440347a1f9be59a15b5a304",
        "c99934add9dcd1b27308f6e1f9486a40",
        "d7e642306c2345481350285d40a3e91c",
        "8cc2522441295ec6b2c1c0c670539721",
        "2c4d072adc85de01470a1f903ac29c84",
        "3f5b552516b3cc90ffac2b3bb86fb755",
        "150abc6c3225617dc8efd05b82ae015c",
        "48340ea092758f86d7a69f439928a099",
        "7baefcec9cf0ee9f4ad6af46a50138cf",
        "5db8bd75d306ba4b12a774e646b44f9a",
        "7f4cfe76125ced657caaa6f5ca91093a",
        "0dee8456cef299e49dbe8378e3b53c31",
        "c3405d4d48a9df7fca71a53d743e44a9",
        "d3b4f8f668c1c365f56a1384eb99847e",
        "97c75c03f37efe01d99edd77b5eb538a",
        "053962b5efd6754348e90780ce606734",
        "b5322a39e5029df90f5cf392d2a32aba",
        "70ca9aee508dd779b41f24cfd50bcb13",
        "39408948dfd1f14afd1ffbf0ff2fb3aa",
        "ba8219bf5e86ec23b98ca8df5784a812",
        "9af8a5ce1b2519bb86de2645cc627b79",
        "677ade8b74979e9082f860798f5f6e68",
        "35e06dd4f3b48f7aaa29155286832154",
        "aacdf010f1f12b6af08e475d3a76d75d",
        "43b1041ab39cdfd8b28c1636be9edb75",
        "b8db5f4c0799cbc8961c950f00027ae5",
        "d4d6c82e881a8bb28ab98910d3e83e26",
        "f45c00d452735366ea63c03aed77947f",
        "1415e30a4e7bacbe8431705ddd823a29",
        "a24f4fab529513630bdfe0b118c548f1",
        "bea3795f8ea358176c1a2077f6bf9be9",
        "a75c84e5801a9f00c466ab67545af6df",
        "a7638d8685922fe9f4afb23df7a10e4c",
        "2329ac8d189b821aa30c87a1d3be23ac",
        "fae20517876e374fba19b5a57f690245",
        "3de418ac4eb13510a11bc406c4afcc9d",
        "5128968e4428223a6ed3825bf250e801",
        "6f78bf4af4a6f96b57bcbfec353668e1",
        "71101db4c6ee18eb83f0dfc2b05f6343",
        "1b774fe0ec8ff4cd3291eb6571fc2cc0",
        "471548f042ae4db1a8afd82a49b18bf1",
        "1e426ca751c8fdbb4f7ffa791df2d0c8",
        "03604a659e63a498fafb98e365a67806",
        "19d42c77f7386c43a8445497ea9f12c8",
        "9d700ef996c334778737f2b6fd14a37d",
        "a3eaf55c567451cb55a57b16858fc362",
        "f0f271b83c58744cc052558aabb83f15",
        "dd145fa6ebee742654c2d12a367139c9",
        "447fe7056e03864ae2c9344c297b44ea",
        "11d6790302faae23ac4f2fd585be0148",
        "97439868ce5a1b9f2493f443a1abf27b",
        "e3a40f01238cdf0e1cc67cb023452f66",
        "9a97bb42f9695b8e910da8b383ea4987",
        "5d3c6ff24ad9034faa05ccdc90acb2d7",
        "4dd4d4164189a28816b2846bd9eea7f6",
        "89d8a89facf276a20104fff70ab503f4",
        "3b0eb38ffb85ea31343b5fa0a6cf6b79",
        "9fe7d48b97115b6ac0d90402ca6efdc6",
        "b419e2b88e6627915bf26a5560f1227b",
        "3713cc8501a061cea955d0d13a4598f1",
        "2a4a8d98d1476d326c8b98a64f5f6831",
        "418c8889802aaf6d30a99520105ab842",
        "f752e9dacbae7b7fc9a7a52b7ec7e582",
        "2fcab5cb2015e5b08228bcb20a07c8bb",
        "596fd1fa6af8e50023f260403a63c910",
        "15be2008e9901266c554a65defeddd5d",
        "7d65601d8f8763b39252b2a5ce1612ef",
        "33f32a70be93b97d85f97de61f3a37fe",
        "30ef0e285269dad2693d82277fef0892",
        "322fdd54a5628792c5437e5507a9e06e",
        "991a40ecda98c3a59607585989c5390e",
        "7d6d81916d8664bfa6309634d60ff591",
        "2eeba07dea756e56947ae0ed09c0d983",
        "b7d24c1f69292e60c6f6bde23b04c78f",
        "b2baef4fdc3c3e32421ca67752e27931",
        "7945c8b8e9fd8c59066a8b45ee2d67d8",
        "26ed8c372c995c634385bd8196e00c95",
        "cb734a50cc897b2ce414f5791f7676ba",
        "fd11e01367baf584deac829407b1340b",
        "62964bc575812dd66d3602486ebe9cdf",
        "f31fbf5707e278a93c2a610d6c991929",
        "372e043a6a75684bbe47a122e546c85b",
        "a0e330032f00a843532c04b79db98c5f",
        "fc83700e6f81919621240a9544979953",
        "b6db5e6331c377d477d4560420c49f2f",
        "2363076a45ebe722b2eefb243018c350",
        "c16f54e26d8a17abd3b0e3b060bd51a1",
        "996a802afaa44be8644b3ecf25811974",
        "2debeda11d0b77077d00101fb5e7e39c",
        "e8dca08a6ae78162f93885cbc82d8029",
        "d4d42a8c5742badfc26b0599db74319c",
        "0ba4b2655c7d2b92e88e0cc2dfa5de67",
        "843bc1069b5f03701b074c9951f272e3",
        "7eeafd5fe732f356255d138d170fae45",
        "71564e7cb044c2b2a353cd114a90c1a1",
        "ec4f2709e714b7b46525e3c1da41491c",
        "210d3ac55de38fd8e221d7e59f3c459b",
        "4e56034115c73c9946a9e5e3c39e19cb",
        "3050471b5957b6ba49c874fc759919a9",
        "363bb2a2788a0138e63385559f3add00",
        "d02664c489e9bc9684ee14f8183506df",
        "1d0b23c599bdf5585c8cd7f47b69e474",
        "35b98e80d49365e7e5b720617294f7e0",
        "036a381658ab3524ec0fcd4e8981b043",
        "94bbdec48c1126bb7676d0ec912f4b97",
        "1a7badc9637268e0573ce7f644b2392a",
        "e19c43f42fcd5e783b5ff24309e13f5d",
        "2389d3851fdeb7d6e3254081615636d5",
        "627a57a9fa11630c9c366dd802a4ce45",
        "0922b739995f3e020aa8dcdc3d5b2399",
        "8325c5feb73c7fb09bc715848120d90b",
        "2bf15e6e2310c81a8096c7078679f93d",
        "bdbbecbab496e7f2d63cfe0b5e3d3d4f",
        "9b690d96dda562a9bfc209d2edf3f893",
        "32b0960ce2f7bf4a247bdd531c44fb85",
        "a54a7a5b0b5db3fdc91e55623afc1743",
        "777d8e3a67a82fad89c2e1fc787f885d",
        "96b3ee062db83eb0fd302b8e10f6d32f",
        "d3d579e680f85a5b45e9b96fc3cbbd16",
        "8f5ed7fc851ef3f8a6ab79d76beac237",
        "d8bdfd7d0624e9255d4f62e02f96c69f",
        "fde8a3137aeec59ad923e337cd1e4f7c",
        "eda449e73a9dac2a10ac93b9edd52e32",
        "4871b81a5f5d1b658278198a72a61b90",
        "e564c07284197db5b797098a5a235a4b",
        "eaf85ef53632cbbf6e091f7a89ff9251",
        "38b3045e3c31002fcf890837bf09da6f",
        "398cbb6d23ca9c09af17bc976fabe3cf",
        "5872a7f68927a3bab12768267bd72310",
        "d7edd39ae53391689ae37065f1295170",
        "800f913351b699cb65e8c79283611da0",
        "550930d33a1699e1fa136146df73976a",
        "2aa625fc980aa87be30d9b77b21ccc81",
        "9c6e5e039940f13b629358a4c9478624",
        "249b6bc940a646cdb740d147d387708d",
        "bfe8a0f8e9aa2aefccc33ed76c95bb82",
        "1a8a44f283613dbc651e0602313cdd54",
        "d12eb787d219be2e957798fda4ef2daa",
        "d517ccb3430dcec5a6b29c6aa64380a8",
        "a70476986f0d337a2536cddd0df7d690",
        "c85e72cc19dbece2e6be885220a59e98",
        "8f048e50ff5e89e0c55dfbcc9c457653",
        "5ac3dd5c998200e11f57d7effe320bf4",
        "d6a87340a10dc0c47ae7befab4a2b798",
        "7eb3299d0c19b7d7580e3d68b895fe46",
        "16f0a4436badbd9e42362836aae3579f",
        "c5b9912410ebc7228d44dbe0f0f69327",
        "69bef5556df9f87e2b7011fd841a7697",
        "7a754057ca094f8c2ab134055c581930",
        "55723f073d1b1a66bcb8da14a060e8ec",
        "c1ed867e853dd7ba3fb45f1757f6ba20",
        "a108391b39e5a9d48dbac3fff156d7df",
        "a39f0322884a44f011ebfcd2ef9b1b37",
        "10ec3e049573ccfce7695c51ac788825",
        "c9cda8ebb83d8c42ec88927f310235b0",
        "7c4117148dafbb0e121f904ead1fd865",
        "f933540fdeea1f150549949671b7cbcd",
        "af5e78a06bea632b480213d2f6778c1d",
        "559ebf6fd3145b11bc977c5f958ff4f9",
        "eb97e7db6d0d77db5a1adc02b99da0d3",
        "81b0dd78465d3858449b000eac2f9b22",
        "93f8b0ac34d6eea43e87215f8135f18e",
        "ad86f24617a3a0e6bac6db7f570df09a",
        "444190b6bdb2af1969df77f93cc7d02a",
        "1d19b1397af85345dd234872e46a37a5",
        "c47ee98a172ed544b5c5244ae47bfac5",
        "c512f9df911546f4e30e2b3754438f03",
        "d4b841f062379a9bfbf7cf6222385ca8",
        "71eb3479923022735a86c94e509ccc4e",
        "1b6b2e1bdba15791bc8ffe800db2b0ba",
        "89e2d44588efa4ea08c61be28cbf3fde",
        "3c00dcd6c1af6eb3f76af97fd0dc328d",
        "1ca8e7c08d5f26eac1e8ee9e24bd5189",
        "ed095c714c5a838aff1614bb33653070",
        "3db65d76d5388c856076494a87fd31a4",
        "1be938342d2f26a9d3f445dd01bf7297",
        "ed9ff26869fbcd40d91a6a650aa9cab7",
        "830704172ea9830fbd57218ce54b8e67",
        "f6944392e04185df3134491c6afb6f70",
        "5b69d64d78bb6d5060473d7afddd08f3",
        "2ead304c3cb6f85f3d8a5274aed36393",
        "c5c284b1538db7f7352f4cb7cec2e4e8",
        "4330f0a550e64b7bbdcf4c5c9d23fa4c",
        "bde2c92ac6d731e8dded10d87d684172",
        "ef45532cfad96eebae34a6fab7d5608e",
        "764289f1eb6633d5c8bfd2bfcc8e8d23",
        "d53c6719c019cf7e4cf91cf0e2f2e9d7",
        "626236c51b9b113ce02322e8829f71df",
        "4b6f2dc0857e9cb1dff027200962d3b7",
        "8d1fa844546bf747ff761e2b35136427",
        "996b781baa1e138ba6e24ff8abdcc4d7",
        "f16fa0069bad1619c34f3974b5b13e4c",
        "fb1b4daaf36745eee8b3229c3cc5b22e",
        "332a0ef98895fdc4788c03f7f21b9270",
        "36f7a395ae0e4f1ff5865b65a1df50c8",
        "299bd80cca4ea729832d77ce43def0b7",
        "f311903206cac02d0bc88c9db2df0cc8",
        "a5cde8b95e86cf95afa5e9c897b1c9cd",
        "ab992d73cf61e9e8c6c62033b469d27c",
        "46411ff63dddceeb48f9c00429b2f3bf",
        "e625033d1ff2e3e39662dc926ba029c9",
        "d2ece935c925900ed81614f0afd66618",
        "2707a1d4795ce9f010c9c5da1cf32b90",
        "25b7e822ee3cdb6f405c4004f73d9f72",
        "5bf027675d6b489d1f533557675d6e85",
        "ed269f1af9fac42b8a24cb289baf1124",
        "a3663ed49e5f43fd464ca13399f5726b",
        "2b30bdef09a3c8fefeca550e9732bdd6",
        "b630272615c838ecf80fb2e6e5bb5eb1",
        "c8cdb12dbf5cae1d89e70029dab75f38",
        "e4ea604c58c1058ee0dda2767384b163",
        "296476081e3b8803077bc86a4dd925ba",
        "aa350196ce2f8bb008562cf16ebd8d69",
        "82167f08563c7b7e376c49f217da348e",
        "ae8a23bb56334bb0856b9392328c3e96",
        "0d68884a0d1adaf4966cc19d98021f44",
        "4c51e3e2210c0e0b8040c2afb634f042",
        "051e25d4f28a73ca9a7ebe6b4deb21c7",
        "9599bae5cf641c6ee4eec075c803e509",
        "85e99ee17df57b0aabfedb9561293d6a",
        "7f6c150be29343b7ab6cf62d5d70032c",
        "ea6a8c6da07191c8d905e8c6d0d6bb2a",
        "065b32e96b396c0cc153b3a8d9d6d312",
        "85f66738cc22fba7ae0d4fefd34de70b",
        "9ccbdd89e89785f4656e54a07b3c65f0",
        "99ab6052a52e656a312598d529aac47f",
        "16aef5d94a7299ba0f8438d00548fa95",
        "a9eb630886c0922a8eb23acca2ebdf7f",
        "71c4ab33d03715d1f397ea84a3dd2d13",
        "89d6232b2d77b062168db8fadf638e1b",
        "3c6636a8f859836ac3d5d47e01aa674f",
        "b7053384154fec3d9d23e761670c0227",
        "de33ee97d960a8b14865fde871aa2e6d",
        "5a5966c4b8a33b90f48f275e23089b79",
        "2a76bfc91b00c35b2f4a818af651cc91",
        "b6c6784cd88cc23dbd419347eccf8ed0",
        "f5d4b80d000a0cac048b878a4649006d",
        "b3fd92481d4c82e6198b42bfaee623af",
        "848a1c5487cb66409794f47f7361ffee",
        "899773933aaef2f46361639f43b25ca8",
        "7a62dd74c58efa704e7e4e908df740b8",
        "996f8f4450aa490a6a7d7351cd4a3304",
        "3149aa16aea68d316cb37809068628ca",
        "082268541ac416696d2a4832bebde91d",
        "a674a5da60f8b877d1ed282ac667c231",
        "b9d9d6869283dbd9b4b9cdfe08fcb01f",
        "56c0870ae41b1c87f3a74de600659492",
        "f6c9851de9928f8fd17a73ce1ce899da",
        "94a14a62be4005ef9299d1e8f6511e5c",
        "10990e4088db6e7c5005675fe90ae399",
        "0b61282af0557ab30efd160b38e4f08d",
        "25e15072f979eba9ea0926dfe6d946a3",
        "ce2983ca421abfa68c2484a486654679",
        "630111f920be607971114cacae6ca71d",
        "91e6400aa04aa520f0f22a7a589828fb",
        "2ceb51ae260a666357fd45889b7e3b91",
        "e38994444c2432d532b38b8b0ee5fa82",
        "c8fb927f253445aff5b13a1d8b92af0b",
        "94794da168f5100cc713575b8b68aa35",
        "68b7a902e3edb95263043492f3ea3336",
        "0facde72374bf79449e5b80187232d32",
        "2dfd52b83680bbd21fb016904c9430a0",
        "8c3ce6d7c981074b418f42f1cc6b4477",
        "4c29963c8d430e5070147aba25903027",
        "6a919f23a415a1fc99705f1eb952e1a7",
        "5bde6edd7fdf997d50e3055730b655b6",
        "d22836eac2ec5b552db6c22c70f75f07",
        "b9f07c27266e2f222799b980cd399fed",
        "299c374a20b2d4b0c9f1a7eca94f21fc",
        "1584041a8366820effc243f16ac6548c",
        "5bb06ceb49aa112179aa662d782ceb49",
        "b27fde0141d500d134d366349c0222fb",
        "810ed8834206e997939b3c808323fd05",
        "83e201347617ed4935f68b2cf588f113",
        "21863ec55f82f2c77f1b5f9e6520966f",
        "6c48404d6eb3fa957237dc42783f9318",
        "163d3cb5e10773f0c1a79045b64f633b",
        "bcc20fa163d0ff0376e4cd5ff99cd636",
        "306389128fa53f68f5a9ceae0be6c008",
        "1f25f601e45f958bd7a8529a105a0912",
        "fd1335f3da5f9b10727c1d6b39327a5b",
        "793c3a9c1f124972c2e872dd2b4fdbc6",
        "29c84c3b020c5b4d15c1bfcf8875a436",
        "b3678ea099d7a80376efa280da2a5648",
        "dffeccb1d7c40b9e4ae6883827e2f96e",
        "feb8a6b73e2dcf4d98f1592de9c94900",
        "fae1fedab850c302cd194e67c3c9cc05",
        "a6302efd949306eef9760f09585e45a5",
        "893890a0d3fe711a79f89e7e8e3a687a",
        "ee22aa1b749106aa13b21e6423849880",
        "28ed3396845a8963568036e806f2827f",
        "5c4aaad95703da2e44cabee1029c16ea",
        "deb73c092c2ae2da84d331b2fea87cf1",
        "876efb8510f7d84797bf6aa0b76283ca",
        "8c0f0ed2dcdc8456bb31faa6a636356a",
        "afbe186376ce3cec5ecc4701def6f7f4",
        "089667899cd6261159e3afb6fef9ed51",
        "55168bd761fcc562248784b37de2507c",
        "0e8726f3bc263aa7b8292c9caa634dc3",
        "0f73270d0b4e0ff04bc450f27a3a2661",
        "d1312e85c8245f5c08643a6b0684a6aa",
        "bfe3d60a33e192df7fd96718e7e38de2",
        "c73532c1a7a3d6ba0056a1a6a1a7130a",
        "c9d7ea0ffdeafb453f0dabede3e3b8b8",
        "9343416fd422baad1e0c48436ba7de82",
        "921c7cd56081e4244c0b561cf53f40e5",
        "e23c5a4f5d042b07d0d5f96183d78086",
        "67334fb0a5812bbbb1eb30cddd66fc00",
        "cb1b55030f2303bf968c42dc09ad3cf0",
        "232111fc77b41e30a5855c73df367bff",
        "6bc3f8422ea83b1c1e543d2323370dc8",
        "9d4c632b4cf68cd2d94f25a80924e03d",
        "1d3e25bfd675304c7da76d20a5b976fd",
        "8afa8357e967b66b032c31ba8d199115",
        "ad2d0dd9ac8b0531cfb3e72f1a2aa8ee",
        "6ae79015db2cb59cf68d9e0ee6431480",
        "c050d00e08f818bc38371a6c0b03a2e5",
        "546e8417a9c31325a8ec5980662f0d7d",
        "7ea115bf50dc7620b3ecc17500152735",
        "51f9e7f04b9bdb8071c31c336fd67e7c",
        "7285be4131708e4545c319f7d1f9dc76",
        "30f0f4cbea36b55ceeb2f773fc9f1bf8",
        "1ab1f00d590e365187e4b8d6c6ed0c7b",
        "1572695514b3cfa16513219567c935f9",
        "2416f3acdfa00bfad02766d0150f783b",
        "67b052fcddeb95f54e9329e254aa410f",
        "f9bb638a9cb9f16921a3904322abb402",
        "c5514440680264f3aaceafb93edc999b",
        "ffc2d7597e026636fb14fe42bca06c1d",
        "0bc2a3c53c41446c592132e5dbdc9ef5",
        "10ecf5a95ea5421ed534133c76a4ac41",
        "4d43c87e32286f4ce54355b59bf30e77",
        "302bd1b4513ed87be1e2a1c40a548191",
        "d3fe5d2b04b2362dac241cd2cb7fa213",
        "666994a5fd736bf1a5e2ad2f513c67b8",
        "0365798d2c36ab3c7ac0fce15fb632df",
        "5d109f294c002b1a476c268bb4f10e84",
        "ac4d6ff77e8304da68af0fe45ae5a0cb",
        "802b446082604d23067abf846a76c252",
        "0c30c920552075c2530da52313929990",
        "db378ec76505ec95eaf175361be60e83",
        "37d3e8fde5c487e294241587175b93ac",
        "27e500dce6cd744f0828d2d491e0d0c7",
        "8647bad1c0637860fcc6f567ae364aa6",
        "7b786eb057f27c79c0aeb1fbdb7a7edc",
        "f32b1e705bb384d4f7238c5268cf1eda",
        "ff312e3b08b6e37a1d08be8c3f1ec2a5",
        "f4710b8d5741a9a9a274343bf38f1d1b",
        "e011da467a9d5993bf06ed910dc619b4",
        "299b7536371b523e7e99343ec53dc09a",
        "73573c4e67237205593e8cafd53121ea",
        "14f4b8b789340c03cb84467c84d9aa7a",
        "7be96b1610275359d3b4b639cb4e765b",
        "89fa0ae38471cbff21e435dd76560ba7",
        "314aed0e30f9b5d7b912e886be1319d8",
        "d0942a2246e7b2ea726d4fbde70821f2",
        "a8c28cd4979e9abc4b393c440e0b8b57",
        "86971b198a3f0ea4c5d793191c6c8fcd",
        "591f5b12aa564c52bd6be5dd86874a64",
        "9d4b864ec51a6f2efc05cfd56657cf1a",
        "86d25a217fe9b6f0b34f75cdab81b1b0",
        "cc29218e27ed042b8fdacc76eb0ebbbf",
        "3f2e1791288d6858f0cf3af1a575b02f",
        "7baa597a6d59a025d68d71c787694d1b",
        "e2642a7732c5ffa81006b4a910602568",
        "4144b2ec0915ec033ee407fc2669da70",
        "4b2fccd75c2dbcf6e91ae2e1e100049b",
        "6ad7330b7e199f4669442cb51cb9dbac",
        "dd17e42de8ab7deb9126945f5e2418c2",
        "4d69b46eaab0fe356ded4f6487915080",
        "9ced2fa1b508a54701a9e16a9915bdbc",
        "70901768eac3fbdd471daa17bcaef121",
        "f6d1bf2e9a984db7603bd0d1792c80b7",
        "e868139fde19ab2a874e2344a40e213d",
        "e34010a1c700a717b4615b906610ff4c",
        "3f67d611b91983c30aea9791a7bcc345",
        "24647dde763090e672eabca8713f1386",
        "15a67fa1e9fab52b30386674d7fa87bc",
        "c06ad75382fee4cc5c14239c01de941e",
        "250aa96c5ef5d5da64a07f747758fb4a",
        "d3ee233b06c7148c8ea5437239aadd6a",
        "0628587ce0b0569b2a97d27324211410",
        "6495bddae7fe6dfd143cb361e01c2ecb",
        "1a2cf3a90dd28264c8d7d7dc6c3967a4",
        "bf14107f5eef79cac4c38038610eaad5",
        "2039c93830cd8fc7f9a985d59985a982",
        "0cc6b13c16847b80862e227e7075c170",
        "0597e2de64cf9b45376a04fc0bdda517",
        "72099014cd27b76147eb836d83cb4798",
        "4a65e2e28d493823629fdfbbdde33ba2",
        "159c2670b6d6b760cb32f12d6f6c2cf1",
        "5c4775329ca3a9c1306909df38eac0b1",
        "c7c0f316d400925dcdd312e4b6953c63",
        "b86b7981d7bc22b96d0c927a5625f3cd",
        "6f15ea4f1d96ad10dd0ec06a10c59a17",
        "b19fe89a4b38d29f524e91a434efac5f",
        "51b21e6d750513216c777c24a3b5f03b",
        "27f6ee13676202b8e5fef85a2c48aac1",
        "44f4ec61596743abdfb9d1c954f7ed95",
        "f6ee6193dbf2b354b788e756806cfa14",
        "2990f0d6b3661ed1bd8481ab3785a19f",
        "599291c5bde7b47aeee7b503272be29b",
        "1951b53ad18741f57b3b4c90edc166c4",
        "eb7e37e4d0fcf3a9cc070c6b5cad84be",
        "9708ae4fa328b35106410b914ba75406",
        "e1d432c86b03dd0e2b6c0b0089950641",
        "2cdbccface049d7bd68143e0a5fa5c33",
        "77a9d452a6fe1782edd25fe3f7c0bc50",
        "c9f2ee5b872e921a2694ec1dec038510",
        "12263cde39c0b70a3945112ed0d56f92",
        "279b9a0262b65bea9b03bb49545e944d",
        "2f6c8f9c4c19891af5e16adbade54c09",
        "d7c59ab859c83051bf0e12bcf1d8057e",
        "d741ad6bc45835cc6202b292073f7263",
        "da3473f14c2f0689694d9f69e104e8a9",
        "a7f7f931d09a25da6f52b48a73a45484",
        "651415c67cbad2b0dee0d0f1196df5d8",
        "eaed540e3c6784af09fb09dc0695c242",
        "e501da55b08387093f024f4ad7dfe3a1",
        "9a0b3466dd625415a0456dabb0936910",
        "01d5479e4838f7eb8049ef74d1a73be3",
        "500d6cd517b9f32e4da73de6410c8773",
        "7b3ed3bc9b14ba7226c9b86faa54e6b7",
        "168a212fb3345b1af163f5b630f18e59",
        "2f9dc7784eecba51af47d248ded2bd46",
        "36e630fda6d23bf92a1ae7eae8f908a0",
        "2f658cf81f6e57ec838203e13463a492",
        "0921c3ff4864880637ca10613c8310d9",
        "f6ab92d0ed21bc93940f941b892600ca",
        "e293e8d2ee7f6f8b119d97b15209099b",
        "32c41e42a34970baa7c247793695ea0f",
        "72b1bd8da61a477513bddca0d2c5d1be",
        "81ed083ff51b3264194b2575efee2d0c",
        "5284171f4c57a822a8a9005198078f23",
        "2658c06a80d94cddeb1efdd86c360a76",
        "051cfbef143178d6ec5c1aaf2acfa2dd",
        "6b7b58ed85cb22bc5f3abc88c606ed58",
        "438a3b4d9189d77b44b72fcca4b363ca",
        "98bd0d5bac8a52a6fef43bee1df7cb7f",
        "bf065719cc28ca5e51eb66642836ce95",
        "ec3c035aeceb6c8e5a139a6de002c78d",
        "5c358ad0768b1267e63e0ed338feb04e",
        "5c5679df7dd7400343d28dcbe4b64935",
        "94e6dc29aba6e416a57e95c224950e9a",
        "0025d72749d6a98638ecca82b567492e",
        "0e16bddf1917990e6a4ab890e3c59618",
        "23de221fbe5145ab878419991dd6f773",
        "e7c451e7308a4151650e09b72df493d1",
        "c028d59f94a33847c4838efbaad94929",
        "82f68f78113fe1107e7a223b50a70767",
        "ea116f9a0ef3a34f7f2890884656c07a",
        "cf40c7ee3c818537fc6d9b55cb4a5f37",
        "67b9e149dc135c8bb4eeab7da8ad80fb",
        "a7a9da9d76918e3078182454b0867e6b",
        "d9f66f94eef983d0920201dc55f19a99",
        "f8c77b4d3686012b031ce8af8d675cc2",
        "964a747af0597881fa7ff889e719cd68",
        "490068689682540b6e4d4e2d7d82f186",
        "c8e2855c7ab73980c3d6aa76b98484ca",
        "eb1001b0ae4e6bf9ca5316464be638ae",
        "f0c5feba33b550e253a5624f3b06b023",
        "a59433662125490dcdfc09e6564654f4",
        "d5743d0c4008aeecbd2bfa0b709df81f",
        "ec9dfb49613ec4f156423b0861c628d9",
        "89500cc7adf4113b0e9e80d9bacf989f",
        "ea069fade2ffa655b14c47ededb70b5d",
        "afefbee1774a2d0a378e47d9d2fea635",
        "9f8197a788e11408caee3e299b57b6d5",
        "ab9fa9456bf92a8b44b472593912b313",
        "c20a9555f741cf597c92abed6aaa9b4d",
        "ee12a63bb99b680e3ddce75ba31a1f86",
        "db2809fe5b746990835dbfce5f66cb55",
        "b77727383f1027b7cffccfd273919762",
        "bf0056986187e968080490d8044e5dea",
        "0b50ce16a78021c390a019318be2b86d",
        "489607f596d9e96dd4f037fd7204b7f9",
        "cdaaff2249d15c0912e58a89b1804aff",
        "8955e054c7760981d2197e7c8ddcc9aa",
        "f5eaf9e4da0d4f9d7e93ef3772a21d3f",
        "80ecf858aa52b9c58b6aa9e776a9ccad",
        "982706b82ad19d96f08216453f9084e9",
        "9429b1e75c5bb7b41cb7ba473b5634f4",
        "007c527320deb9a654510f5ef86388e3",
        "79549578e5dfe3bf0e3e50b3ff87cdc5",
        "0b83ece5b988f5a5fa2e4d17fa725a46",
        "32278e478fa0819bd1f877ca7f50ade9",
        "b124ce0e8be14f54bea83b2708d66df8",
        "bbec607f6f6d854afcd5922fe2739f51",
        "03b4e5659f312a29ffb1c3bc34fd2ce1",
        "c48e9aff068c30aa660e440b8d480236",
        "e12039b509d4db8840ec65cf5ee573fa",
        "411f855aa0ceafb4cdffab4ded519f6d",
        "078ba322d914de1e155d4410d38e5658",
        "29b4722957e30fe78dfe3d402e74f22d",
        "9e53ed6cf00123f566024e379fd2debd",
        "5c9c0783cb4d770ef5c06428aafd46c4",
        "74907b99699397014dc7fff5a84adef8",
        "acc85782cca8f5223c79cd8fa53ecb8d",
        "f7dc22f839fa09459ed3099722854b15",
        "28abec1b34ebae1cd2752d9855048925",
        "a11d4ca69100041b6d7cad5770c9a7ea",
        "d65ab5143fb6cd521cc9f45babd9d99d",
        "4eaf4c5b41f70647038a814999b82c73",
        "29b76b90eeb15d3aa4bea35ff416ae89",
        "f91b27297c6f72577fdf02016e35d0b9",
        "9b59b60aaabfce4033ba2b5810b3f445",
        "e4c6acd93eb4f3b7819b2937bf8b0f5b",
        "1590f8cbc343347fabd9e957a2315c75",
        "d07f34e40f264f0d787a49dbee0695bf",
        "8a909613721ca45aa2016acce68445f9",
        "a113960836c153005ee0d7a1d4191cbb",
        "8ffcb3a6d45893155ea8c75c43f5f624",
        "57fd0245e18fd793a7ccfb471e548ec6",
        "bafaae7a692ec3db01d5b24420e5c9b9",
        "0df654acd0f684386dffb72da4b535e4",
        "aa0d60cc19111422f85c4585ebfda087",
        "1d54859969d0a1084bb833aa389af90a",
        "892aac1b87defa74c6b372116e5aeaee",
        "5217b01685bddc1c59f7a57eb64edbdd",
        "6ac1464fbf6b7b2e221c7edc40e49889",
        "111563dd89c8d2b7466e32855c612c8f",
        "0051ac9b8c269ca44bcdce8adcee6ca1",
        "ee014ef09c5be38ae972148532c9deae",
        "a391757377933896b0f1d13ae9dfc879",
        "217511f9b68364ef757e846fde5a9327",
        "c5aada8fdd80cb37fb91539629c4dd5c",
        "d98a473382daebdb8610b7b441a007b1",
        "15132da5b6ff4ce22040026f3ef09a77",
        "f5f4f3b8d6cf7f621712fe5fe62ad007",
        "3e39e6d00785b2b1ccedd735bc774ec0",
        "093a7216a657d75cc54733367180fa4c",
        "ed82e12742ab805d0125b551b4fc5eec",
        "7bbda302ce1999922d7003a7786c8346",
        "6c4f4bb1e2f6c8d0eaa642e515c9e902",
        "c92d2c0db82e67deaceab4a23c756755",
        "94d2c07084b4856a0f3be5b6740f19f1",
        "07a232d871290d16553d531790c508fb",
        "2178ea13e8f5749ce9c5e90687edc306",
        "3a6f3ace5961c64d4fbe6b949cbd3ad7",
        "fb247e97332d2db64f452dd05549b91a",
        "6fe853958f7ff6bdc5d61fd1f385b14f",
        "12f004b4f8acfc3a56b538518b746f3f",
        "4fad7ad3b672f3d5b27283a3eafdf63d",
        "ae15e082e6b3e2ee556cb9475726b3e2",
        "6cd62e8e51b666e3ddd30f30d7c3b91d",
        "361230488029937bd585fedcdba2cf95",
        "7c4da744d33b0d21ff085730eedc2087",
        "be5d1417adf40abbe97adb09e1fb0084",
        "2bcc254513f36e08b3e8dbb37b525235",
        "23ba20094be9fda5bd5c8606191ce42a",
        "ed087d2d34eceef77f5c902ff23127fd",
        "91ee1be4effc762fea85a9e2fadaad4a",
        "ace90c0214161c90e1506a397d4abadf",
        "578e096545d39ab823203190386b2a8c",
        "ce1d804c19abed1721d9db8cacc2f2f3",
        "cf51db2b4040d37c6bd210a745f28000",
        "c5e5037e8e9a0f0096fe402955e233d4",
        "c4188fa46162d4543ee78e4ab4c72767",
        "523fdde71da5d14b70ad701000a744f9",
        "5b799688dd7764cb1769a8c7cf0e52cd",
        "09e76fe1132b7a16919d0f5981ac9429",
        "1927dabc7188999a844e260d45a176be",
        "599c384b90b1639d450ece0ee22743a1",
        "f3a047297ad078b9ad90e76ea02c9a03",
        "7e404937c7b0b55f66fe75c4596973a6",
        "a58702953e4bdc324b9b4a6f45b4c5df",
        "3d3e19d35e7b2fbf5c50ef35dc5089f4",
        "a0f3bcb67fce5508278dba1326a96d9b",
        "dcc6c4e211cd1fe8b8eb00e4e9470baf",
        "ab2c6375aa7da89a0af89d42c4d7f6f1",
        "e75e600b8257dcb5526ed7b163c5d8c6",
        "e07f09b6f6ad1bc81a7d639482bdf885",
        "a89782b0783fde3bffa8fabaae84f458",
        "b9e788d4187fb919b79b3dafcbffea78",
        "5c9aa3804956806dca4c8eb3d2a784aa",
        "0b01161632a1fd5c8f2d1d7be965cf9b",
        "7929fb9e99b291476bac3f538fb5ecb0",
        "e870a5018c902f15cc0936d77d0bf7e7",
        "1fd1f2f4385f097d5355236a143f70cf",
        "87de8eec0a89341fd3fd592c4e613326",
        "1f4f3fafc0fdd9c7ac1bb610251de741",
        "a57ddb1a74292b686d41f701dfc033c2",
        "30452df9145ef64c459127e0829f684b",
        "f8e331903270fbefe44d63e78144409f",
        "27c6cb3097acfac1f2ba834cbca823ab",
        "2f806bd0ccf0d57234d7866ce076f52e",
        "0bb4e6f0423980a31f397c6e78cd0d8b",
        "8cd4a14ce77a20edc4a36a2d401972ef",
        "7e6873a350488233e87ec9b4fa666e93",
        "5e065686cd374b6e412383c8eb5a323c",
        "24ad10824ed6829b2f334159331dea74",
        "b16f38d1b7eaa3946bcdcdaacb35ed8e",
        "1220890e8a7f57ce1d251a6514ea042d",
        "46c5dccf7cd241a446aa73a29fd3346c",
        "f1deef725b643fc588c3a51a321730f7",
        "f243c27dc9ce705c3bbacb3c8077c328",
        "4f1db78ac345fb6478d258b7ed18b47c",
        "beaa2f4d88d529fdd09595b0f198854f",
        "5c5c7528b4dcbd7a3303216fdd4a9cf8",
        "2a423c71ab52c621bc22d5b1ab3146c0",
        "ab8d82e4a3ce1a8ebbef6c493c643693",
        "cef395ef1ee7ea1538682d17e9049eed",
        "d8ccecf71914b9e357b6633209088418",
        "3cf9017744dce4feeb978f77f8b79f34",
        "97c5bb2acc47339fb34fd4edb40e106d",
        "d4b1e476e69015b81ffc4af53d924532",
        "fcdab8b72e19b33803d9611b60850e8e",
        "2390ffa5b6a2214579ca54fd54cfb319",
        "2b35649617fdb0a2e7089e3201688a7e",
        "31766bf037b51bf0ad04e65134b54a6c",
        "fc4cf6170a7a209592b6aa10bf34409a",
        "28341b2b5ff687f4d9ed9ed0e860598a",
        "ce82835e780a4af0436fe0f31e4cef0f",
        "116ede6dccc038b1dae0d0215c2f01f3",
        "f3e1b14a57d536db50f7b7488ffac92d",
        "7b4dfad80598327fab84f4aec7bae264",
        "a708bbbbe1befa93f4708918a5620e83",
        "0770143609cbd1359cf34a1df7105636",
        "7d6a37176d333485330626f0f9e9ebc9",
        "d698aa3724b0acb71a53c742208ca4c2",
        "343ce027548c50787d9612ce5664a636",
        "bc60d6b14a60933043d20ec4908848fb",
        "71e046b22392b41773a7c495aff3c37c",
        "6cc5afa6c66331c54e8b1853eba4de1e",
        "7ca6917ebadb5e35e1be33e97a2295b4",
        "2bd8d2117063d837b78e356ec7c1cd11",
        "b23e8b4583eb70bf2c8252a852511222",
        "ef166c4453367f8bd05a542c14ba6c76",
        "6d5472bb62e329d51c695974a0a3eb12",
        "645b665eabfc161a76c6f0b4e2eac5a2",
        "929be0662f214039a230d41fc5d8cec8",
        "76a06fd77a88c60429f6990ef219d102",
        "a90c6d6c7a428e69b65589fcd680dc8e",
        "4c5470f2be9c23c9598a365046b2f641",
        "77df9144fd725ccc1ad27bd94bbdd5c2",
        "e710557a4788c677cb5d75663f7d60d6",
        "fd3b0d2e7486514e77b98bff3d139f14",
        "d33649c1a2bd06bba9c1dee2832f37d0",
        "a81fe7350f4b58864de3cf53a68f5609",
        "a9fc04e6579c85a5debb6ed7459c8499",
        "589e2e72a97ca83b56855232d1ded1df",
        "a646708c9c1a1390c18fb35d426bc317",
        "4858a5cec559dd24b5c73cc83a961858",
        "b74a464ff0569d553342f7a826290af4",
        "f373c186563183870f6ea038f342a403",
        "236b76e3c37a6fc7b2c3cddcbf061583",
        "4a23428ab74df10b9608d7deede45a2b",
        "710eb9bf4845bfbf74bd8ed9c240cafd",
        "49999e95b3566be17b801dbffc4d6949",
        "b1b8ccd1ca31b215727c7773713f6fac",
        "1350ba095e6e7fecf7fed7b87d4c279c",
        "a38a9b5e6900ebf68e75703fd1449aa9",
        "5e154be040a8eadd8c54924d496433c1",
        "ee49b1b9cba8f731e3e04f7552b47f47",
        "8e3d7965b243eadef0f60e3330300cde",
        "c15adf41caa534693085107babbd4d74",
        "303b361788f4bba7bb3403759fdad2e3",
        "2e0bf01fd7986f0ddc4421b18241e152",
        "d77d55f3a55cef589c647cfc870fe4fa",
        "4d46b9a796f368e8a43625400449c69d",
        "07e9f9bdfdf9d855f4ff7b86931be60f",
        "2252c3292f63f9e78d40ae2f108761fc",
        "b4ad38e73e30aea7a380bec11b821a73",
        "ab6c3fd5ef4fd83f5521eef33ff27e30",
        "72e5ace19af9766f831dca902d06508c",
        "dafafe00473306eb4bc5a9bfea35d54f",
        "08e73624efe459c635611b262508213e",
        "674c961bca38395081c81d66483f59d4",
        "805bb4873b8944f264609d6444dd4c2c",
        "79927cc0c026756326fd4136ac0c006f",
        "b1e93507c01f387a776fe3fb6e836224",
        "6ec96e2a3457c8c1e3494c6b79488268",
        "9fa235e8cf231f90761373e42735f655",
        "c7454bf412139312faf875ea8688439d",
        "985939abd1d7e05b4e545388cec40920",
        "cfb6b9734cc16c01a2367f889a4f627a",
        "9fb44985ef0697f94a2c489305ea6ae0",
        "4ab57e0dfe43ce4d55308a2933f01c8e",
        "1852c03076d524db7d2ecd4183a2c6bc",
        "86c97424acd81efccf7c65ce1f448157",
        "a09263e032a3e8e6b6319265c4170c73",
        "94108d865e373b704fc09fd18b545746",
        "20ca89fbb248c3c05b4d95f9c0033979",
        "d2cec5161bfe70541b1467673ee03519",
        "9cf0efbadfb560878e3a0709c1cd2f2a",
        "62fc12a7a82e51aab4514491244797b5",
        "226ae267b8adde2f41fd5799d842542a",
        "3fc17b83753f22b1d4115b6493b0b612",
        "ae128aba1dbd4687e2e9adb016cb65cc",
        "4664eda3948d6617f62d851e3f61f386",
        "9424ea088c57351665884b479a282a02",
        "6906b39a664692fa620c7dcf072cf05a",
        "b5cbd0d303fd4027cf99b146d1932d33",
        "d4c4eff1d0dd5cac8bb71b878ad979e9",
        "fb18585354989cfc075b5839b3fac23f",
        "5f7d2d09f1a98ce43e6176bdff07633a",
        "068b16b81301c73e7e62375540c38064",
        "b80e75b691dd31bb35b3f36d481b05fb",
        "92b42e9deded70db75ebb7dbf183b144",
        "d1e015312ce70d36583f994daeedaaa0",
        "c6acb36ad53d1883b539e94dba0782d4",
        "878f943e138e134f1e264a138aa48cf5",
        "06dfb9ce36a9463e55c357c45e98561d",
        "09a69d6df1590e382d8af8d333456977",
        "af066205c5388d4381cc288976030d69",
        "c3d63416d00c58d25fff747af11e6514",
        "c102da6780d3f47649eaa76666b28893",
        "2c8485f47ecbbb119a9bf3690b2f855e",
        "7e11a286096bd9ec370116d3d9c42e33",
        "1174e4f150cf998dc374003149dd0651",
        "ecb183ce3f7627f5d1589bb1de7d39b4",
        "1314a8feb3a56179634f2f706783f304",
        "24d091ddf8a4e40b6751a3cc7cc0be3e",
        "54747097e0484f2bc0c2413e47eac52e",
        "183670b00365651ac2e576a01b16d805",
        "1d7596f857ab0be8a621f8935b8c0242",
        "0dec39d2ff5b2ecb0bde18ced6c014ca",
        "9c7127142623b1683a0991387d8f18d9",
        "c1074d4ab8b8fcc320f23e895ab32416",
        "24e20854263440909310b31aa558b8a7",
        "b647ed1c16e4ce8b5905f326585b9648",
        "79133d60e2d3fde425cf8458c5fc27e0",
        "ad776c3c93c2a390949a667f961cbb7f",
        "b69fcd7f419795f56f679aa345ac8ef6",
        "3a6d21b7daab55a0dae3f14db0f0c33a",
        "9f71d5742a5414c32afa8844a3f54a3b",
        "11dabe873f883ad906bc783a8c8ffda2",
        "a7e29facedd305b9ff5f2e580ae0ef40",
        "1f7b7145984aacce509144b1debb1958",
        "b8b5b2e10670fe8a06090a4321929c52",
        "aeb291eae42a26ab884cca96102c7a2d",
        "3f44b8fb5bf99a8b25cd4b6273ac1814",
        "de3ad8158e534a533b1865bb8ddff822",
        "eda3d89a115a1fdf947aba4e6c9e43c8",
        "c453d8a0be66b82d453c5d9fca50bb03",
        "0a41edef5e4fcfcffa7ed6389ac46caf",
        "5677e879889435f6b3842cfc4d5ab9e8",
        "3d05fbed90a798608020f420bf4d19b2",
        "4cb080a60ced2dea033aff7fae890fc2",
        "d7f050f7c7b7b4976ec87de57ed0e52d",
        "cfc932dd1745b51831ae7d556bd27bae",
        "72d41ded6515b45b1c562a42159bedd5",
        "d4be57ca5abeb327368b851e5d7636e1",
        "a7ef2d56a8daaf66d213e15b16bc67e4",
        "6a966701a07b4e9c14f7fb191b3c4bb6",
        "f8f47bafa8a6d8a80427ba0bf3a857c8",
        "d8b52e1634ad7ff7a64c460d9d248189",
        "7201674020ef79e8a34ddd361b0f2b76",
        "c03b8f30c13714b6168bcb3f56b09a6b",
        "3e7d25fba914fb5f3bb5accb830379d0"
      ]
    },
    "C": {
      "count": 1375,
      "ids": [
        "72b5216624d4ff4fbf28d022fbf1dcb7",
        "8924accfe7ff514524472339815c04b4",
        "91abb3911eb8cbf25946a4ae4b3a7993",
        "7ee1118db4a26a994f64630449003478",
        "8c33e459208a17f086102b5147d1ec78",
        "555121ab60501803606a56ca07bd552e",
        "fcbad849b33212ac3c517bb0f7859b8c",
        "2ade106204f7ec23f0d3274622ebde0f",
        "303d09e63768206ddd97dd4c25b9336e",
        "e62549b14685db3321871fe505fa8813",
        "ae5c0c8af2c74f2abfcfda9cb2fc8b58",
        "f29f96117ba41a267e070aaacfdec114",
        "95c18bf6745da9a2227bf21d24528cf5",
        "e012e1002b27139ba6259361e7541884",
        "62da1fe9fbe5e197fd429c7e35110951",
        "0c8ec3f6ce6e68153c24105aaf6dfe5a",
        "e20e1fa5572ac7830313ea4beebdfe05",
        "72acecc68cc06340b5250ed600f35250",
        "357f5cf4c652cbd0ae4b05060e93c280",
        "1dc23697da05da4a64b11a447a32f731",
        "280794cc600aa563414a63e9fbb8313e",
        "42bc43e92c830b86f0fb52203047702a",
        "8175e731f73e0e6d91e23e3716410952",
        "5b1612aa19d40c732bb1be2525eb1748",
        "00afed09943bf665600df641c409aa99",
        "e695f16ba4a318059f6b28a079386c2d",
        "86e4991caf1e071a19d116701d99e706",
        "9fbfa00d56e32f5f8177ca539b457e2b",
        "80a73329506f56145c0f5a171e2e7a66",
        "488aa02e04bf12da25338c4c2309559e",
        "2c39d75c7c6ecbd5e8582857b2ae772b",
        "1b0f1c1c51b7f0cdd9e0508840ec0f47",
        "9fdb067a24041dc6f97335645bb148e1",
        "b11a47358c570e115e3ea1cd7fe52a32",
        "08cf4306f9a54736aa7a6e84da3e2442",
        "2a3545fc9f4358c0bb0d453bd73ac36a",
        "17c2cd4f5354b5650609538b2cbbf91f",
        "78d27b7ee103d2ce383cad67d6ba1593",
        "7fa4aa440cfda677dc8f2ea7e292181d",
        "65926377e9a903ef5f59488b3b048eba",
        "ca77dbe5de5abefea271249213cc2468",
        "b0eaa3c757c8ad35d7fb51939d0a797a",
        "377dc467f1f90736f71973dd7b4d7b7e",
        "82a566fcda3ff489af622f65830471a3",
        "caa2320f0ecc635364ead0d1df8ac0a8",
        "6d6258c34650b451a2ac0bde59cb5a28",
        "f86b8bcf435a7d0fa4be4bb882e9bf7e",
        "9ec0d4ce85f41c0d6ebb644d36da8552",
        "edbb18a4efb9aeccd82015496d86c45d",
        "30f02f903c57567b1bde9bb89f769f2a",
        "0a108e3716c05b10c1c8198a78cf0254",
        "6e4ffaa1bfba7a4d0d7a0f1f22e70495",
        "b1e1a87b35a3e91c225d45157af01c47",
        "00671cab97bcd7dc6d8d6388c6980cc7",
        "eda7d8f54688ad21b3adb39954310d11",
        "243d1bb3a061ff6fc769f961578474a5",
        "5b14f2cbab716045587c60fab3fe7455",
        "6b1fabd1edc4debcce5b1661544be7a2",
        "14d03ad74b243aea101341c99112c3cc",
        "3039c46ab771d769ad4eff557849bdb0",
        "195572815c62bd1731c78118e4f841d9",
        "5ec205c8c57c5642e2b576c774b8f410",
        "d748b44740bf5984c5a55da97f4ddc13",
        "1a6910f4f9def8bcb63b592e794f1205",
        "d4ddf68fa8630c0680434c94f8284302",
        "eded43cb436b92fea0be5f36a253ee10",
        "531b319d81d697c2336282e9e7d5ff34",
        "2e36f187f3768db3793cf6338a8eba66",
        "1b9f4e416a1fb1748738da9de33fcc6a",
        "e9bab64f635d60c2cf1f54870047fcd2",
        "cc13c491df98d2f704c4da60346a3189",
        "e405b0b0b5a30bdca4dc0aee252108dc",
        "0b1b2bbe014c110d815d3d5fc5defba7",
        "8d3e422a605509acccbf51018a004c05",
        "ae9c97ec80809e1be38e17c39be8b397",
        "120607fb810a0bf6c4229b48e2ed3598",
        "9c7af1fb8611ec2b5a70696bfd7f203e",
        "0e82ad20b0f9151658fc12f7ce269d87",
        "96fa84c21cf9e2283c79f3b352e06795",
        "8754c8c4b0c4e0c939e72863c7945b46",
        "e89387e438793c89e2d9573e6fa73df8",
        "3f04bdb019d6d47050f250f1d0118384",
        "4035e6cb5eae10b8ef4285dbab4ec35d",
        "8e603cbb72cfb5b1580e32ad59848436",
        "68d43711c83b257276d5d3878846c676",
        "ef4eaa981e7a520128482c0519330acd",
        "1d5f3a2f13120789f94e08d13966ec0c",
        "59fc00ba17bc6f7f0701096d1abba058",
        "1064f4c92924f57c1008c27be21b2994",
        "f9ea65c11456eb5ca289e979f44ffb09",
        "3eb10d91e041fbf6332bffaac9d2a164",
        "2dad9d2285cd61ec8464550a3bff10d3",
        "5a81b7a59af37a5a5171e0260448c527",
        "7275dabc5f94cc813ae0c2af6016f5dd",
        "4eca850265e6b7304a2361a0ae2eeb63",
        "f267835a15e5ee0edb3a180967d23ae0",
        "82f462772ed16082fc79c3ef4ffec863",
        "ff5b2df9e3d7ba91373cbf83ace968a3",
        "4f60b180b590254768c1efdc6fc7e115",
        "f56abd059a454b2128cede6a19a3c0a9",
        "1a468d34b2ceef34a2b203bcd65a24ed",
        "5cf6dbe41151b29ea60851b1bebc9379",
        "0c1ff263b04b956749a6ca8746f1d2fe",
        "6d26d59814ae3682a61fe8e272cdce4c",
        "8b200ee0c90ea41612a217fbda23eed9",
        "4219581f5fa93723a2e71ca4eb41cb36",
        "918349ea8f7c8dcbee86c9a75b163342",
        "f0298abb1a865ccedc52412e61037f1d",
        "3b88d36a7069cfcc2d40c206714d37c4",
        "dd273c69684795909e0c06b056b95b99",
        "52b1ce720a153bf6e38df4a94157ccc9",
        "3b7d0886fee5a8807e89156f42243d3e",
        "258290fac8bbc041aaa0b8dc47ae1720",
        "111792882d00a45dffb3c9d4e5281323",
        "1f49ed0a6981faa12b6cb622787941d9",
        "62d2534e6665ff3f7eaf2ae3c0569e12",
        "19f8650f4f80be3d018e9a30c2275dd3",
        "b89d416ccc7e1194f0b6072a1b864fda",
        "1b10ea9fa5fdb2cd255539019df61292",
        "4d4fa40bfcd32fdac8001ac8c98aba8d",
        "fe3009a48eabd41b8fad1fd3c8fd73ef",
        "285797e63a56ead099b8d30571d9a606",
        "c67157d535548bfff89ce84bbb6b47f8",
        "64237bed49ba067a71fecfc5908425c1",
        "cd5b297a034f448f2feac0d38c92f854",
        "2669ff0cde3645b5b2f4fbdb136e0043",
        "a1523a7bf7a6b299f7d7520b3d68dc79",
        "12b0c58fb7d78405212e98bb5f63cc8b",
        "5a74ff3b7db0e1b51703ddb753b8afe4",
        "997a47b6b3516d3f2938d423d83de06d",
        "5d819f28ba7002678fbfd87f9b21303f",
        "338edf175eb52d4c047bcd7c2a4cb489",
        "75f27ca66fd73e17cb9a8694ddc36f12",
        "6910748a761d904a07b70508df86dd2f",
        "91fa65f19202e5c6308a105187297e74",
        "e50220558ade0cb8c158713096b277f1",
        "ca624badb16a9112085f4d755a3bfd21",
        "4aeabf0a7c1e5d401a4f351fa820fbd0",
        "8248c5d43a00dc7d86ee03859745c185",
        "266a0756fe09b5ca123f35cb06aee50f",
        "9930ffc1998a31dc6bd298116f509645",
        "e5cddb9bd54f2a4c0f730856f0e3550e",
        "2fe3a6d4a79619717abb649600159c0d",
        "218909fa95bcc10df5f534442d63cfa4",
        "cdc88eaf2b5b3f56b61335d04124a7a4",
        "2665774613c80b6d1aa496006d43a51c",
        "a284274dcb72d0c5c9ea64ca52b612d9",
        "4a95f2597dbc790f375b5fcdbf883ff8",
        "a6c5dc4af96ba2132a6c299bd12de6e4",
        "01b3267572e210aea84c1cc0567e2956",
        "0aa53ca5de496ee9f3e11cd94a2a6f98",
        "783db9c442a30be1237329b828bab245",
        "c253c83142d5d354161808cc9081f7d4",
        "8ce3a1eaefd78d8bec3e78bc68d94f63",
        "d8aca17ba2c71b1e6c381ae20878f0d2",
        "ee9f2ddda47cac12d92374da937ed195",
        "18c56c6c148660e101fe30d7665bef91",
        "e9e39c1b3c00e7880b389026768e4568",
        "662b064b1bbfafd6ea2e093322403730",
        "a59a81b1715930bfb862665c7e470a76",
        "212832d6f15056893b76a37646e8868b",
        "2ea165ca7f95b1053c29939bcafbc8c4",
        "455a70b8e1b18a9f04dad8ea9a8aaca0",
        "f141fca899fb3e36d4f348fde9db4c84",
        "fcacb4add6cd9c29bfbdd61dfa5f6387",
        "ec0f51143946123c568121aa028b7afd",
        "b4706f691040de3357e046cfcba4d716",
        "6a4be448c457c9d72f6bc378c726a2ac",
        "e4095ce8389643e7af3eec439516a6c1",
        "5e5dfb41fb887955ad3ca12a60b01356",
        "3e03f255912fb117be0b3c10df516c54",
        "56f632a542a87ca1b85f58bc8bf7c098",
        "22796d09bf2b33bded8f73bbc0bc7878",
        "e345d0a78beb4f2d3d46f8a2ac28355f",
        "37c472100e3cac8b6d2edd89ce4ed810",
        "c7c03ddf9b59cc0c4bcf70642ba8e7b4",
        "bec23481b02866192dffd860a2962cbe",
        "cdd39a64b5c2c53e0e226dbf3d5c6704",
        "796cd4d44fbdcf6f0d7c04dd1bda124c",
        "99b5d7440ed67d3b504e37cf4146a349",
        "ea9b0f92b3ec82df1cd1c80fd63b4d1e",
        "377144b6c908f057b5028a25e3c86029",
        "adea8ad1da45b846a620cc684c21959f",
        "329e98f1c1cbd69e2f9613f770c816c4",
        "befb7ec295714c5a039192e94ab4bcfb",
        "b6adb5a87398306d186283bc032cf716",
        "0fc341e460df88dda3c705e1fb320900",
        "acf1f304a8a10fde87ee1ede9963d9b0",
        "2aa212eb12217a1306f855ff1256a979",
        "8c8ecad500ce185aab7f49f70b31a368",
        "47a22fa911712a1a2a1b7c7f9707cf1a",
        "31728989c28401bd01c9ff6cd44b07b5",
        "716cacc7558e742f8e84390ed970c5d1",
        "bcb28e29f0752ada0a354361dd47a5c2",
        "cf60dc934588ea9fc2d3ff88ea092f22",
        "2483be04da9f735d8eef3a4222535fff",
        "4e681425d8ec08f094e83b2f03b004d8",
        "90c07c6e3ab2e50a4b5ed6bce644e28b",
        "a33f85fbeebf1bba9387ca5b7123513f",
        "d081be6f16c9dcec9dc3d363bedc37b4",
        "2812f20a00bd120b46eafe7b216c6d1c",
        "038288d015e3e6cddba723a8c50416c6",
        "fb34441353afe5f684f47ed030763979",
        "e7814785ac8aeae31ecde9b491ba73b9",
        "fd6a4a14ac33c548960771486a217a1e",
        "51ec01ffe57cc162ed5b4fc1ee33d13b",
        "1faa081097385be7bf06a3994590e3fa",
        "56296b0711612cc38dac2b28a7e00cd3",
        "7a0a8ad3a348feef216acc842112404c",
        "b15af40d513cb2772ed9eaf876bf0d2e",
        "2bf060b9b784c124a80c9b9e85142db7",
        "0244595a63f37c60029cfcd5af0300b3",
        "cb15288e2438764ff1d23ef93d7f1d5d",
        "cee6825497c3bc8619eed3d2543d1df9",
        "e7e05580b55f85a2ea69166199791259",
        "5f1904bab40c1aa5c4b9066ea59113ac",
        "4a5f891275734e5662e3801acd57a493",
        "a6e977e32df2fa4cf3ae6239030a4014",
        "07575b125e9f87f5cf6b7c450b0bdbb0",
        "a4c5bd77b317246670b4a729bd978be7",
        "f4d4c222e7a274bc0f3e333186201c50",
        "5eaa29342322bfa148945bd0a71f31cf",
        "65749323dd1f32775a2cc5a7d600302f",
        "57694468b5a27ae7d9511df4578b67cf",
        "9e211fe665c9947fbd7301a550553d09",
        "095033de8cb4fb7a24570374ae286f46",
        "206fb01d3475aa8df9279696d31ebdb2",
        "3f249a0b9e72bb3195236a6286fcaa31",
        "33569510e971b149257b2ab2567ba9a6",
        "2a5794e1ea93b2b34dbe8183da7fca82",
        "1a076c9e9a8d1e6f979436d9e941363c",
        "194f38b20c7386c448cf97752ef17fde",
        "de8a66243addc3e3be4f38f7fbb526c3",
        "76e00c16673d9f054082ce440d0f5a1c",
        "cc6371f74b7d20faf6e600879307b0b5",
        "28ed16e008af5f70586389c304a8ba1f",
        "16c2c71fedd15764d96fabcc8f57a04b",
        "16386b40c311e7166490819cd1459088",
        "6351fc310549fe3b8e9d0ac6c5f1f33b",
        "7430aa69585622cfa19b055ff539eaf2",
        "73568075d0536cf3490955a9a79aacb8",
        "41bb5f86d43dd6f0d5b0e5ef80b84049",
        "4e34206dda1ddf6c26e1d169b21c1af9",
        "f75de3e805867d9224480e9eca108a72",
        "65f19a82ba9b93065fc491b83da62153",
        "30bc71315f9641ec78c39bd509e7e747",
        "fc0952b20fa2ea3d6d99adc556efc311",
        "09f4cbd11ffdcc115f396747e92f606f",
        "35e7c56f9cbff3078869d79b6df93feb",
        "381de5682ac7eceb19c5d2e94f280e90",
        "fe6769330476f5472e62d2c7cff6437c",
        "2f9ce8bcac0f88b646f1d8fa939cf5e2",
        "db490f9e0ac4768c84e1671ff1013407",
        "7fc688847c29a5b98079382e274ca9a0",
        "d0a223c0a70fb782b866bffe4db2d873",
        "5468557bf5551c51507de5afc7c3abe6",
        "78056a98ed0215cc496f48a3d5b38938",
        "8da4ecb77a2f3b767167ab30971b814e",
        "7d3bb56a7c19b383ae9021bd7173fddf",
        "320e9cc439fc802672a81d2a0bbb2630",
        "ac316d57f11fbdd5e91edd1a5d968119",
        "96ee76507adc19e5953983dc6987ba3e",
        "371e61b8e57348df8b8b32c07d59e25c",
        "0904add515f0f7a05bee473aef60fdc0",
        "f79d2cf7adc0a32b79c4b8f0fdf16d80",
        "6ad3c157b85711991b4914ffcb0e9034",
        "fb8bb51f4d531046b2025d6c8bc1cc1b",
        "f850bb1df91f08925f292e6822374e25",
        "25be01a66bb53a144247718b86693b00",
        "a3ebf9be1c12e4e20948d7c6bbed0e09",
        "3cdf5c4646bd81e85d60429af20dc582",
        "9e74550eab62826b88001314381239d3",
        "ae2416568dddd563c13a4c2556336d84",
        "b940a75ad76c4c15fc483ac3fb2d6afa",
        "97c845276dd6498a1606fc3cb1adaf94",
        "afb24f897fec034d3c751d693451a41d",
        "d1c1595d661ed18f1f9d52e87806eaf2",
        "7e685d3fe3a2f8d02c8f973c25750be9",
        "a1277f9d07f0ca37c3587fe4e50239e2",
        "98e868f9b587b081057c589f51166b51",
        "6bb7f24aeb9f8cfb10d5de5201e1ec7f",
        "a033a06136b5286555d856b2c632a04e",
        "820a1896bf62fc9036a66c0d56e4a7b4",
        "3a8f9486d9ddc7af26c9d765f8d2fb5f",
        "41f213846fbf4d05a24aa7c67481ebd5",
        "578acf4cd0e673bfc10b4d8be81251ee",
        "1ca73f795674d7993895080a20bb1bf0",
        "60bf71c3fc1b3666dc66ccc88ed3d533",
        "22d45f5b5db0de5be793024da852681a",
        "70f77d3df1dd7f33901e4c6131c1534e",
        "b0528e9448968de8eedbc48298702370",
        "d42e9743eaf6c9cc80a3464960a7ab9c",
        "e50c969ab4b892d786f5e5cb428b8cd4",
        "af87afe5569890f0a7fc7b8b701c7660",
        "65c6d41bf6cde411a0db518d15d7de6d",
        "4372f0fd634b3b54f939b4b0656aa872",
        "95e59a7e030209dc78774f3309437605",
        "fcadc4aed200a836674ca3d6308894b2",
        "fe6d313e344e7c99cc7f5ed0e8b79057",
        "d7ee6e7e1e8f3e2526a1e06964f6daa1",
        "2324ee5be9913ef76e56060e140ed45f",
        "f7254a89067ce55f60e5f7cbba1f859a",
        "87553a00586ea99d47e64f89bcffcf3e",
        "1fdb33f411613c5c8c52d3a7aa706439",
        "dee987fb47d19bbdaba308cbfee91b7d",
        "e18f8394eaa29ad1ac2606f479895874",
        "967a03f801b061a55d70eca165785257",
        "ff9016bea5f2494b479a1e4b511e5e88",
        "ca52e696b3eb4e3f5c37e4cd992f9f0d",
        "221dca4f42998c39190515d5ced11009",
        "88277fffbaef80ed7b0bc6fdf1e4e66d",
        "3a7f98666663bfe88f6a503d63cf5031",
        "900235722850463f8a57917b21bfe8a4",
        "9319dc084c5c1c5788e956af42e2b011",
        "33a9781a12b1d2229e1bdbc19fbce607",
        "c82a78ba1412637e54083611264c9574",
        "30feffec5184a1c787d8352b221fe40a",
        "05c828d7b15f8a7e2c2f1cde69508bab",
        "d96f85b1c92cf786331027456bfaf0cf",
        "034979d5fe12ab25520759914ce30b4e",
        "845fac173c039bee2de4025ce6cfab6e",
        "abf6e4741235a4d3189afa719674f172",
        "e883292944af736bc739fc966347acdf",
        "ac377fa0d85784a1683110e17a85232c",
        "b1b797724f588fdceb3cc630e8a6ae3b",
        "53e5ae3e8534bece6a6b18eba5979602",
        "d1128fccde16fd1c77c2d38c1a250e62",
        "4aff9f741c5b4fe899f9cb201e5abdd4",
        "3ecedd95c8d0b2a0b2f8e58cb72d204f",
        "7f18deaa4e343abd217adb913a76f780",
        "87bbae84319619709872e4f94353fea9",
        "4e8eb43553226d57dbf730ced45fec3e",
        "41f88640f20336abfa9f558a998ec0ab",
        "f0d4fbcb5a21ceb795de489a32dee134",
        "b364dcec5e49e6ce1e52d178a93dc21d",
        "7b4c01cc02574d776c08af7a0e40d2b3",
        "e50c68c0bceaed464830f57cdff3d518",
        "e627cc1ca064017cf9370c9029321703",
        "c80db4a45371eccafc31e79bbec0fd1e",
        "6067921cdae34b550f9ebff46e6b885e",
        "3b94b00f0ce9635da481d47a90834d7c",
        "62d9e59f035496b184005fb86feb29e5",
        "a88eb6ff85cc195f96daa1007d8ad45b",
        "0606d718a0b8bc03cfb77b195b0282fe",
        "a2f63c0dee0b62c37a5228e31d6c6cf7",
        "de34a6df9bda0c8756d7d12bf6059d9c",
        "2e3a1436b9ac0868d5832d8f26439374",
        "23ddbeccb2c3691cb1e6040e32861ecf",
        "ed9d7785ca76a9e9a76974c5ae574f86",
        "fb939f8d2b79381c8d207acd51696300",
        "013d3ad2c1b71ce7f97d89241faf5ee9",
        "a5e3b6c8e8b42f2a6dbbda17b4004b9b",
        "59d94302b18846bc20d470cbb79704b4",
        "b97cdaff85afc936c7cf2093f21f1793",
        "2accd92473a2e3cb836dcd39a5177ea8",
        "b81dab6e589e6a7bf61279cea0aed201",
        "e13134cc76f47f65dd9172a39f55151c",
        "d3830ff8a972d58cf1ad71fed404b656",
        "1186b65620012eb6690ffe0aa3274b02",
        "9a99baa0350682fc7ca6b7421edd9ca9",
        "62450a433e5df301fc37dda766090d88",
        "d462010f5e3c62a0c00cf9bea37161ab",
        "23cc0468747edb6db46f1bf13cf4266a",
        "dd321185a6ba12c4b4958cf6090680f1",
        "2c74fca229f72b4df614f656cc3399e4",
        "200176051dc36e3329fdc0a5948558cd",
        "00f5cdd06f232ba3cdba0649cfc07c88",
        "24462c8df5673df0f98760b076f64796",
        "463ccb99b105006c10c652ba5593299c",
        "37a3bb6fa6ac3aa16a6cd29feb9f870b",
        "61517e12a3b06e959801e44ef94e4a83",
        "82a687eda8604ec09757c95f47df6ba0",
        "8ab87e0a23697bfd845a6d95d18ed67e",
        "d77a0692eca7e9dbb300d89cf9faf1ac",
        "847ae8f500e86faf34db664240c5c00b",
        "467683bce5140c5fcda05f08499f973c",
        "9cc5d74589261014dba194ebacff1088",
        "4dcc94c361bcee20c098753d6b77b78d",
        "d0f7cd421ddae4094fd110acc6002f70",
        "ca8bb5179187b5edb889de1a1b8453f4",
        "052d1f79829536e242ed93773e5ecae0",
        "ac8793c0f209192cc87e536d88f3bbf4",
        "789f1704a3eee3865cd14303a45c218d",
        "df2eb83bd5719027143efc2a41cbbd7b",
        "0d403074025f84e666d74b216cb3f093",
        "5f9b18b249a84d0c200bf8e27b2a4701",
        "e8c736368f285041cf442bbcb164dec9",
        "cc612c188373036f95e0e0718e7f1b4e",
        "c4bbec06fbfe83092e49b09dbe1630e8",
        "6481f90d1d72040ec92bf40a8404d866",
        "bc51b557c9041c46dec4c91aa5328339",
        "c93cfc6d18ea81ce346f107fc588de2d",
        "fb20c5b274f69a56ac09005b1ad00c92",
        "87c2007ca20d4e6e80989d4abe181c60",
        "6558514f051616c726c57571780185b1",
        "2513e985312d785da5499502e5cff2f9",
        "1887b39dfff746fae43de741a766a4ac",
        "f59d806c1a398b07f47958b3e02c0660",
        "12a33366c0c640e25062a34b63db24ed",
        "63689d25b069288864779724522c81aa",
        "6af5feb95ccd1905152a0690e30fed8f",
        "0ccba3c8ec1dc55f520cff49b5503c21",
        "acca0a3382a7a6a2b031a11e6fe91560",
        "50db0039ad76f68a172313943f091449",
        "0cfdc33a14b474c0f2a0653fdd6369c3",
        "ef32bf7ffb15adc5f45aab1df6300604",
        "e3572c0305dfad45cb4f59ecbf5ec31b",
        "8eda692ab8e39b17de6cb807f7eb1a11",
        "21da9cd5767e53789279611dc9b0123e",
        "505ed5b86ac79ea440390c66f6f70d35",
        "73466dfce17230ea3b30601701bc8318",
        "cf3425078b7e84ef7fc85e8972effd24",
        "b1273e2497513488efc3672042d45521",
        "75cb3ced44e74b024b660bfa91c6177d",
        "cc347121d41982610c1643184d25004f",
        "6c3d2e7e9647ffd17dd1d130b37c88cf",
        "1d636de97b91b886d82777610730561c",
        "ed9bde06f3ed5b705e2ff4f40907c2d9",
        "63f337b8fcc5bf13394841efcf4f9272",
        "8ff12f4a6cdbd53e2e2c1aa406b3d1d1",
        "aa5b9a9929f4fd4bcbb1edd241ca8c4d",
        "d7069b8522e7d186e372df3abd3c84f7",
        "2dbff511b0cbfcb6216f4dbd23edc694",
        "4ac9b72ebbe5cc049c89aa760512d92b",
        "33e67dd5d5e5ddd873bb4750568d92e7",
        "6d18457efc695a14ded35f684e4fa897",
        "2fb00b2083c207b9860c9e94c262d15c",
        "1b5270bd2fce212eeaa5795b77a7eb6b",
        "07d210df71a427b21372a6d5b352fed8",
        "26330f509eedb89049af64d045f3ecc3",
        "3944390cb1cee4faaf51742eb1cff6b2",
        "25634187897ac76be2c8838a46d3b4a7",
        "6657abc65d7c228106495975cb54d910",
        "f07e44723311c2698ff47dc3c912b507",
        "8df2e4dfa3338e222785e30dd91e7ac8",
        "b13ade2d4ade29affff6e6de8fde2933",
        "e140803539a35f7e98df69774a59fb06",
        "28a9031124d0a9bbcf98a904dae01cfe",
        "832f9f4258dc6f447fdc42a03706cd15",
        "d24150b93a61a996de5a91aa8d2aeaf1",
        "3bb43fc45b5b788fdd9b1b372599e1db",
        "a7beb181892e26ecb650675333907901",
        "76bb78ee4d3a81c3782d82e179cd8184",
        "a3abfddd8e3206e48b3eedf4679a5956",
        "eeda48074a23045aed02451e58d43311",
        "e9a5527bbf29e6ea708548932af718a2",
        "1a28ac5ef75b24190d31474395509030",
        "a89e7d105507c8db32e9a2f5310fca22",
        "49361b7a13b2c0d261823e365b28ff1a",
        "ac93410857e0fefcbc29def53de3ecf5",
        "0ba7777b873af8b9a65901ab2248f4d0",
        "4730b729bf4d9d0b57913f3043087a8b",
        "fb13f936a1256d136ae7269a76188c6e",
        "c4ca19668e0a7f7d85a4ddc8145b0c38",
        "70bfa4db8b594316ac3471b740a3ec40",
        "e799ca6cc64f799352c37d70e87ad752",
        "8f2d53a8a6389f4d9de7a0f576abe599",
        "c2271184acc62af1153bafe25d2b3631",
        "7013a589f5c02e24bce0fe532902ba29",
        "c9f4d91caf3e7bced128f2ceb2ad6f93",
        "3dbdb8726847c6abcd6d7fba7f867ae4",
        "6a835cf7c85f3d0eccb81ce709ee0edb",
        "5e83c3b4c9dcbd4386abec1fa3df9976",
        "84b4ba281839ab60568966055f6ed0da",
        "3aab24edba6ebc2494834ffda04fd851",
        "87d76101f5e42e94e95e3feaef0981a0",
        "96ae41e12710cbbfda44c1ab8395677d",
        "f42c1c55c1518c8d8028368f62819023",
        "0b7879487d77a9479d6d3ed65d2dee7f",
        "2b6d29a9953d47f239c92c15ce48a245",
        "83f1ecea4da5ea62bea9a1922c0e0fca",
        "f428b830062868cb824af8243769db87",
        "a6dbedc3b51015f9d4d292b4023872e4",
        "0b5d521d8da132120ce63893b6fb832a",
        "faeeac705be66972eab9675dffd3e73d",
        "9c8ce06aba37bd28b9ff53b7e2729c8d",
        "941241ba801daf81c53938e1412c672f",
        "7ef73ab62b72b86fb59070538ee3ac28",
        "144bde86d3c7a40e0572e146ee05d62f",
        "d62afb9eae079cb387080b627743ddb8",
        "f42ec52a78acd06ebc040b0e84d7800b",
        "857cc23f0d4f1d361420ab1c2495d584",
        "e5d5c9d01979735e90db77933d92eefe",
        "e20b5d01ebed60ae34be36bcf28ac709",
        "970331ebf0491707f6484ce5fbbaaf28",
        "7f962653d2d050bec16103fcf622853a",
        "dd2ac2547fe17c3d03baeb6c39dab7a7",
        "f46beb37a868d23f4d3ba0d0dc07e9f0",
        "a48ad27840aee84282ee97b58f9333ff",
        "733ec65e5454c1e8309f1e67e54717bb",
        "216f4edb2a8924ebf38ccb931438caa7",
        "8832c1e5a53de27b3a1eb00f1d822acf",
        "2f195701b66f6be9fd20d0a58b631a8d",
        "2660e06a0ca5d6e56b3a6fb7a0f602f6",
        "b6bf8f7220ee665ddd7258914444dd89",
        "d429f33846e4b29dfbb749982678f0f2",
        "78e99edf02a73319a000825edbb04c21",
        "eacc77b6f5b0335a607d4807444a7aac",
        "fdb7ae1f1ba2ebe9bfd4b2ffdafe3178",
        "11bcefcf60c12ba8cff61dcaf2413acc",
        "1f76304b255abb8abf77e2727e6d7ecf",
        "80a719659fff92bb03b1a3fc9160ab1f",
        "982e7ac3990a6d599cd7744b2271e41e",
        "156b734a71748aae357920f4f4058933",
        "c23b3864c9d0747df0400692aafaead9",
        "976f6b5789d0373e6af497cfbc07675c",
        "b8dfc00fb14a5180bb1a2ef20c62dc06",
        "dbd8995d3146fdbbadcf65745c57098a",
        "fc8c198008f48b1296b1bad4e767ae79",
        "ee5884c0f74544477d10a599d6c59be4",
        "18b1ddf33b4528dfcab5ea4db501d967",
        "4318455f866f646d00ce4d7cbd049b3f",
        "810326a9501ce0a25cca93636430417f",
        "528e29535e956211505de3ebf0d01c64",
        "66983d44fbb822d53faa4724298d9f59",
        "fd0b98ceb50aa8d60398d779ddee3420",
        "609c85321c99e2bfba42a9d6f9989edb",
        "ee648ad801e1e06da4919f9634d938de",
        "25a311ca3c2d8f7f99a51fa68f1e6e9a",
        "68b4c09a63da6d56e603f8e20dd0f2d7",
        "de1102ea0930d2722b0fef9c86474e4b",
        "c815e3ff1a1889541a1718f012c26954",
        "e1aa56407694d2ac0db3fffb104dbb25",
        "8acf33d2380790fff8f69ac31b9c3484",
        "1f5f381cd6ceecd713fd226c9c533694",
        "fe3d1e0d3e4a4d881c0a07497202144e",
        "2bb7258dd0b25bf934089f5c2285c5db",
        "0b3e077c607ad0fb76edfae37f649579",
        "cabddcc53d08fd574a7cf77ddfa6db41",
        "27d19ae1dae52b52d5a44c8c5a8973c8",
        "a295f81e63646898ceddc416c446948e",
        "c09f1f5840eae066924dc47e1cd69a78",
        "43870b9fef1c8060f1e0c36f145c1d67",
        "1d1e3a4216636ea7c33201c62a06d2de",
        "5885a784fa688622232a2472e123dc2a",
        "0a1d8fa4fa38118893f8d8e3fcd9d16b",
        "67c542a04c49e06577cdee77e07b62f5",
        "f51f0c77ae2afd21782eca0743a82b05",
        "969e7a7e469896dc7bc60d5f91b5da48",
        "4a47ca5804c822433dd93077178de76d",
        "fae2ce37bac957aee967d98c2123c052",
        "0e7733eace7e56beb3ec5ca2042539e9",
        "5cd3d2485efdacdfe2ad632c56062e93",
        "717a2f0b8d9200b7573d2462b05ad188",
        "1c183adf44604e0b170728485569cf9c",
        "e1e5c83cf3be73e953c80bdc9c2fb06a",
        "2b0a4cd24eccb8c353a158690ab59ccc",
        "4ca7f87b6b006d223f3b01b52ec69456",
        "f04be84afff6c3e84fdff6fc642a607b",
        "f485a514a52a2b3f2ee39931a3184329",
        "e9248e7f9aa1bdebdc8f2a6eefa8f43d",
        "839f8f9343502e084029834ad62985eb",
        "57e61a9786c4e69c8de7293788f55279",
        "5cbc983af2fb083c7bf991d15c39dd99",
        "240e719622beff6546d31db898a6900e",
        "d2abd48af7ff921dd54935a8cd467702",
        "a2e6a73f0dbbe4531966318d30af4bb7",
        "fa87c35a1c7d773960e82257fc3d1014",
        "3065d365e231dcdbec68f1e98c1c0129",
        "1fc5dfa2ba9d85883debaa49fc277cfc",
        "e963bddb4976e0693af656a12fd3b2c1",
        "aedccf3c4639e56322416b3e69081193",
        "eddf146484b1aa41b6357d28eeab45d3",
        "7b2783288ee94744902a35baeb1eec66",
        "31a7ee83c8cb277a65d3e43663f33d2d",
        "783937354dd690e38bd4e63749f4bde4",
        "b52863ed9172d200b3d6515f4ccc8b0f",
        "7deabd3ce5c47e9f47002e07ddf7e0e8",
        "67d2e3da05a831ec8fa89805c67ae442",
        "8131128b0082f7e80da8dce293d5a4ff",
        "f0708a1a5b581ab4dad3d488dbffe47f",
        "eb41b3fd2ca5e7473ff92585400f662c",
        "56fb181d99a24bca57b1ed81c16aa4b6",
        "a87f9e94f128703befccf693e14b7dc3",
        "63a98472df5ed544319cddb89c940a78",
        "4963f8f40345fa96a23b1661d827be81",
        "0c7c867a12f3876e97ee045e91332aa0",
        "1caa328e127fd9b97e6372353377aa7b",
        "4647e014fff570a24a7c64428b539a40",
        "0c3053e546573e9645dd192cc05e0293",
        "a5ac8adae471d5abecf9173be8950a1f",
        "0954595c8564204dc6e9858d7601314f",
        "cf9f0b8154033bfa19ce3a779216c6a4",
        "bad44676d0cb4c870127cd28568336ac",
        "0efe640cf5669b334fe98202942a2ebc",
        "3190703f3e32ea5cc965d23078c7864f",
        "ee44202da3f9e5ace99a5893e586155f",
        "7b481694edb2deac5635fda49b0fb93d",
        "1c6a42614271e66892cb11e7756f1b6b",
        "215a5bbdf4add281dcd2e95c8d701824",
        "d0bc45f2c5549937875ec5c39b99d414",
        "dcfad2dd52e49887a63bf14f2da0c249",
        "d2f1bc17d3ad7b611ce9fc6c21dcb7f1",
        "749e3cc98ca5cd8d75e7e3eb4b703225",
        "e15e8ea49201de13e65bcd3eee7e1167",
        "c88f382b6d35413b5e6993ebc833b294",
        "3122d393f487f07e50c2fcf02b3d7989",
        "39ee64a4685bc803aef153b5b5cf8f33",
        "4e116f76debe8b19c683ab310960499a",
        "0f505ba6e61301f6cf8b4ae89409fe9b",
        "9572367e0dafadcc915bdb6381ca0bc8",
        "85d775329177e93ee2057094eaafebb4",
        "296bb68c16f9549ff035f81f73f05237",
        "c19ab122fc3ad300f8644d0a278147d4",
        "905717bf94f83dc4af07a5d1e786b7ca",
        "bdba2b35d229af85e84824a8ea58651c",
        "2c6385f2e68a641dbb5e9151cdd11a77",
        "f96dda7ccdc9cc5619a9c027e98b6b48",
        "c5a64942a948d45d7c0420ad270edd47",
        "0982b5a483c49a827888ecaef17fc8d5",
        "c413eac88fa5d7b70e0a31ffa88aa939",
        "87f535e0494ad38b80e390a2efce6943",
        "13bb7f33512871f83e8cf2ef3599566c",
        "c296a08aab49dc239df65b809366ecd8",
        "6033a5a574f332cff86e0c14c867247b",
        "be9977630d4b376e623b22c29a8aaeb0",
        "6752fa49dbdcc143bb6d09fb4eec8148",
        "b04d3c14efd104f74ff0fde1ef0f8555",
        "e6738787ab4cd520aae5caaa5ce78374",
        "369112ecfe845a67ada25a3784a427ee",
        "689d99b305dcfe81bb072435f810c86d",
        "f4241fd16fc158dad81112c764985fe3",
        "53cbe781a99c9c3ef9b0f27b9910401d",
        "e5aef18925c4edb3241b1f5ed25bd501",
        "4bee272ab84b551b1d185e0f6aa109ec",
        "135e223b49c87b9e132e5daac8fcc34f",
        "fbb3d8afbee0c75455ba0d5a77691968",
        "df816ff0fc5eb333ec86da9816f9b402",
        "9c4d1fca3606525f7854c5a4d714e420",
        "f0fc42e9248f19bd75745f8db023734b",
        "6e97a5c038c60906c9abe3496bcec8fe",
        "37810c074d4fe8a04e54e7160341852a",
        "a66f3ec541dbb533cb3f05962af6e7f7",
        "4fae3a465094a6cc0b2160a0670e378f",
        "fc9b95046e4b08ce4271eb5cc4b7529f",
        "04936444764946db60b4c959e88ed800",
        "6ec92b74eb17517925fe60eb0ec588d1",
        "a70e945b2a38252ed79979a97acacc7a",
        "17f89cfc63d012461e50d96c17c96d92",
        "3eb96459b71b20cd877561b5c39ae8ec",
        "93f761ad4c8cd718a904d781d9e66747",
        "341dd56b02a94c68a9844fc4e201f746",
        "3158a0348d850f0ba60877ce6f9e9abe",
        "a62d6e01e8a4385554fa5674f1d7cff2",
        "3782f7c7c4ee2ae138f65f8be99020c7",
        "19683a8e873cc075111830b9afc841bf",
        "a7ecbf8c8d9d47f2ea9f4e82512f0d92",
        "c018154eca799da2dd72781165fb9125",
        "f684e0f80edd614d46f7f8c2d6d50576",
        "f8030d7dd91c1dd00651d26971c5edba",
        "5fa51de17d24974124201dbf9086b3d3",
        "301fd76fbc87ce1c74fe0c8f45a6c379",
        "29219384b1bbf0d46c7a65adc47774c8",
        "04cecd352ed5faa55223b9f966941e42",
        "67248b7005739be8e86f62839914bf97",
        "e61aff2931dfe4c65a332dcda1030165",
        "254923a0c4dcc6a7aaa0db614dc52d06",
        "d7c33f8f98f4aca4e7d987d9ebc45cf5",
        "3195b924f6663d6adbb0faaf17eaccd7",
        "f988123b1e6041751d95986d8dab0ab1",
        "1cb8e37ad93aec26bcd8f4dea8597422",
        "d5a310736ae426e9ad28aed2a45333dc",
        "9380211ed195b42ac9123aedda7421ad",
        "b34e6f0c408c9fa051b6aab9eefdc697",
        "d7f2de11cf1666119a034f14d2aeea3e",
        "1c5bb444cb79146fd721d742544192a9",
        "1357b611eebdbbc5e277af7b44026173",
        "fcee81ed5954c9d933a226425c9449a2",
        "a7123ce783b6d01a699cad25425c837c",
        "2bc28fe516edb6cd60e8d666289da23d",
        "233ca6a37dcb295c906039acc13eb08f",
        "1da70c1b3fd555656bc0dba8fa5f3625",
        "ca2c8a18d1325bc87ef92f9187a904bd",
        "4a250321c618c5c3e4da80ca09921cd7",
        "b16c845957671ed449cf484ef37d6f49",
        "17bb95471cd6cf1c241995600803d387",
        "80b9fd4aa5906a39aabd5b99f77701f3",
        "8713de0a69d40197bd1f9a85eff264c1",
        "93e658ae608d3f36547cc4c7a518edde",
        "bbbaab6e4fb2e93c9beb406809b10ccc",
        "eb554ef034e742f025c2cc96b6caf9fe",
        "8530462b3f9d7136bc1ca6f6f163c667",
        "982a7dcee4386daca91506f8fb6fe2a1",
        "2f6de174927b2a2c515d0f1ac2c43313",
        "b4bd1026ac6b5af2f9c4059a1748d0f2",
        "3cfb7a936283b56e6cc4e7fcf75dfb9d",
        "6146add9f9058b02f67ce48f2b008cd3",
        "e7d82cb09d8c05f6329fa81adf940721",
        "b8bcb693d4eb6d558bef7207d17aa07d",
        "db82b303faa2affb5715e0d6f967ae6f",
        "a9de806385698cf097d814b75f55e46c",
        "e1bb5671ee7c1d0eaced9ce6e3835510",
        "9f619e35bab97815507272c59cc9b469",
        "a20b51a4fc5dcd553cdbf79a863602c6",
        "f04bf64b3fb1b2d7e1d876949b696ae7",
        "41701403ec7660ad2d585d81db453ddc",
        "3d8b9c7442573fdd8fcaa9efa9b78c2a",
        "02b6c19513827d14a76d32782403d112",
        "446a7dfb1bc301dc42970695ef9680e8",
        "554f66b98dde048abe1de252c16cca4f",
        "c0e42fe2029f17703d4419304218687c",
        "74fd59104ccbc62373244b833bac5870",
        "9a103121a1330127df147bf81375b18f",
        "0f2f64e2070a66dc5d9c5577762fab5d",
        "9ab87336125155a08677e62d1349df5f",
        "06470a1138029c048dfc21959ef2ef1e",
        "7d5a429f7978e5aa6f50e89b8ad620f7",
        "41fa465d91e2c6755fb85a714dca9ead",
        "ed00047ae4b26a04d87cf03aa9b18b04",
        "a6e74b053b7c9b4a823a01c56f8c7cb9",
        "b92ab9ddea1dec0d72852f78e5a98549",
        "bf72c7081e396d658ce24aa2facb0723",
        "92cf10f95f846c95cdf1da5fb5fafdef",
        "50e66097a737fa60ed4be7ae738dc470",
        "962f4128c9e46d612d9ec76b225de0b9",
        "aa951e3041b28a24a6e5db974faf60ff",
        "8ac41166e253bc717e55785e9c83c2c9",
        "991b0dbe679808c4e3f4de7ec9e57b18",
        "87c299795b3d3790b32eab9c42ab8ecb",
        "c89980d56dd74f786ac61588cb6ff2d9",
        "b50444cb80a28f5700a738a155a6c375",
        "b682b03d4cc3f6712b685fa589fdc406",
        "68155fd44f7feb998fd6a4830024612a",
        "65b251c269f75b3f8353b754ad68fe79",
        "e2b17706a66aadd790b8e268e2e3ceee",
        "dcfda9f6730a2982691ae667fa2d237e",
        "5d3ef7efef1f147879d78575586747b2",
        "47a008ee8ffd36402d5ade7b530fec21",
        "61604b44b2afac7d0a578fce32f1110c",
        "bd1e35b8ee6970ab03262bf08d765c22",
        "1e56ad4d0de7201aef733cb34340d208",
        "894d68979ecb67f926ea0688832bf629",
        "539f24ad9be4c3b200055a561134f0a8",
        "1503866b631a1866b8ab1c4022617458",
        "0567a16707aafb49f4c7dfdc545c1196",
        "25e907cba40c4ca9f4bf95c9130ecdea",
        "5c2915e9ae7f3e9ca322c3696f6c3629",
        "28569850cdc23d218a39ceff54aa4bb4",
        "451b969cde248da685dfe0a4131719ae",
        "e85293d2afd98e69e243db5b6b6e6a5d",
        "4ca031244ac960cf3c1ac6122d510211",
        "e5570ccd5cb7d672c0d5d7651e6a2042",
        "88165f9767266cb3f99af112dafff6e2",
        "70fb93d8d6814211cbf88171f025bdd8",
        "8af9342c6651be0b47b7b6b71d4f3b31",
        "c4b0215bf5c455f49c31f361b97a439c",
        "39d0cd1eb9f0a6f78a67b35d1886d9ca",
        "0b76a03944e3ed5e85756a1e3bf8e56a",
        "10e4dd3cbafeb2e893331ddf86897e91",
        "79e13add93fbeff3c4ece9ed902ed17e",
        "4415a6ce401f8c2fbeec0ccee77be218",
        "7faddd0e31fbae77baf0132a2fedb2bb",
        "aa290acf1a526425023757298c1bd3a4",
        "2a9624909d5cb6a937cf7f38ee655f84",
        "a32366986cbae665f9e3d6cdddc29ab9",
        "1b63ce0c7e5a524f0fd5ca6b5c462748",
        "4e524770f6f4f776fb29cd515278b4a0",
        "c63653bdbcfa79dbdf1c963b6b07ec7b",
        "cf13b2b9f2275c1318247ccd85852712",
        "58becf231d81cedfd92be1ec453835b8",
        "2c4a4ef5f8298fb26e1915c925deb01a",
        "fa2e9759f863a63844ad2dab8005599e",
        "34beac39f8daca86244fede8948aca47",
        "ade7a5555a9bc4dd8b8cdabb194702e8",
        "2bb443a42caf659a6dfa49658f717af8",
        "a335a81c14dd81e283a98409f0fec028",
        "93cd17f8c29da386f4ad450aa3033aaa",
        "580e452f7f596c244ffd15c43bde332d",
        "81f9558c664009f31b623cc14e6b777b",
        "cc6324064918370ff90dfb4d6078b491",
        "5274bf8eea399fe8c76d45238765159b",
        "e093ea8e8099e42a76282f020b546b9d",
        "a674d9ee1dbf42284d4eb96f0d146b52",
        "60e0adeaceefa9d773ee2b2bbdfe55cc",
        "3da2cf3335175cd571ae8f9b64aad8e2",
        "0e51be41c777b35d0eb2602022a9dc73",
        "290163a0574037fe135f4e8a5707c5d5",
        "c206b1deeafe4dca8090b73bcd1ee9bf",
        "bf607e27cdec012990801475459d116e",
        "a3c5f63cc49b5adab3b2838ac68da3ab",
        "8093b3d73a18f361f3d24bedd5575ae7",
        "13e3cd07a87b9e50006614049858fb6e",
        "800b1ce361124d2c9d1e3483f99f6e79",
        "3cd5b235dabea65a869fae4546478d8e",
        "ea9302551a081da061b119f73a769219",
        "1e46b5912df1eb1f6b56da82e15c0e10",
        "bab9a6b0bc6156f79d2235c500f20d15",
        "fe16cd9b08f98be5560b23fb23b1b74e",
        "ba35dfaab9b5108c47d3ac040b7be789",
        "50b84032120bcd6c91f6fcbd64539965",
        "763b1d38c4e48afafa6b3ce1258c98b9",
        "0886d1723e35d02efd008f166df3d040",
        "9cd7c2e54e9468e70a41b4b265ebb817",
        "712128cae60dd9279fe1bada1c210a96",
        "892d3aa69a1a78df717478752f4f5352",
        "fd72c63656c0845f9633718b767eb1cf",
        "37a2ce86e6acd4272a175e0989fff6b1",
        "91f2a34c7c33ba166ecc6b5c6c648573",
        "184e0fbce9709825326a23b65fee4f64",
        "a2478c78ec0620b2ddf8b756d8bc5ab4",
        "2fc0cf29aad0d9be0ed89aed6054fb4e",
        "b606ef0ba3ef6b105a916f280bedc712",
        "d9cdde45ba014f8fa19525f7194921cf",
        "f54b1ebffb09499b3298fa5c1c7552f0",
        "6c703486d31795be26ca639984e34da0",
        "a1b2452cbbdfeda8bd9d0bb22d5ed61e",
        "1236d048bf5300d98ee6fe05d3b8e9b5",
        "1826117f6c3b836d9875b36fa1dabe67",
        "46f6d102c2a7e1722439babc712c132a",
        "b32d1589892a36848a503c17daad580a",
        "d15d1952402004d9af62c9a4a76d4bb2",
        "4bca413193e3321caceb0311f52874be",
        "2e608f86771e18da9adcfa5f3003be95",
        "359fb797e49378273ebd5715934daf3a",
        "348b8e60f1aae6ce75aafe0290a0958b",
        "fa8aee9cb6a0b596f6eedfb2baba3b23",
        "930b9d7bf806616706064b2841d0da38",
        "e7d62ed981d981790dc9f980c6fa3403",
        "4a3e35fa16eacddebd271ca63b28e9fa",
        "79850f2d62e85955713f966eb1dd9aee",
        "00aab6ab0ce3350ca739d2c736776777",
        "15ab887a1a43fab83d37b123ff8775e5",
        "deb6898a59c8ad40d2baa730043f1f7f",
        "a0fd7ed0f374b93054542a9d69479f3d",
        "65f7194d98697eb2283e155331105691",
        "106c2d29937f68b3b7900e77f373b0b1",
        "d5bd8b928c9904054a4cdac408c99916",
        "e95986c14db43d74789d5a6bc5e9507e",
        "ce34b5d40945b52f60677c57641961df",
        "00d6692a20b13eb5d78d401735a51c30",
        "a54598a4e3d58064f2bb0cf2a687cc70",
        "63a440062094a7041e30f5b4ff043677",
        "a10f8d9e1ddf5fb0cee6d72604dda01a",
        "51d0da7b4085b0bfed06afcfda781048",
        "e375a575f2b33ef6bebdff1532fd03e1",
        "87d01f80de1a0a0b42b494f99025a175",
        "1539d5362b425e34b80197745b32ce2c",
        "a213898c18c61bc00ab5c44ac9ff7993",
        "9e6fe0b2b0c6ea84e16cc27d9b043285",
        "66591591fdce3bab4e95b2ec7b96ab00",
        "c1548568d3dbc805cc6fe64112a8c187",
        "d6b293527882c0af902505c903db1c28",
        "692ba07c36bf5f0f8c88e6b54d7ec0e4",
        "bff61eb38b1ff19838a2dac6d2cb14bd",
        "8d2cb7be260bdb19c9ba1ef7bac9f6ba",
        "af9bc7f23310738542520599559d1f9e",
        "1c8aece7423cffa4161397674349fb2f",
        "7ff0fbb3f2ba1f5bc929b42bca6c972b",
        "5f42e0ef3a3469be45aee7654d1f9c7e",
        "2f2ebf8d58e919750cb46d674e098c9c",
        "8f2250dc033385959c471b4fc635626f",
        "18e5575b5f997bc029c5f60bb20f7c4c",
        "59228d9ddcd0dd30543a7cbbbb1f1449",
        "cbf72ce8cc1fd4a71f6d997385eaeac8",
        "a9c593a27ff2b2450e43719f45f1d447",
        "0c387ed6c508c7d2a89a667e3b5f7459",
        "22f54a242bd0fef0de2b180dcfad3872",
        "33a7a80c70a33634077842e4b95010f5",
        "9c3392fad7497c19a67ed6229b8d0ef2",
        "653e4bbf6229713df86a2057caa11d72",
        "9f078f378a54f1ac82a5c2c99938ada4",
        "7d3a9a4af4e6fdfc33431327b792f1bd",
        "d0e814c152b826879d42743d94c1f5d9",
        "9bb3c04f09ecb0ede0f31685fafeb3e6",
        "f2188dd31950f3bf4f2aedde83b8f949",
        "dad30abb263c6dd886db332a13b871e2",
        "c26a72f989c80bf35943109db323c792",
        "6f59771d7d4477ff7b313f0d89a4a90a",
        "6395437aeff806c52fda3b70dd50fb13",
        "e9d1e1004d46fab3cba6202c94619a0b",
        "d76ac7f95e5fbf309e1e86db724f11ae",
        "f2725b4ca58d146e6c8e2b3bff2f758f",
        "7f98e5321fac38a737130f5d8f402e49",
        "de060d84d2a1c6c8b830f82e634e18a8",
        "32c40b4574c09f8d32c38f6fbf5c5261",
        "be1e2f23caaa40da742dfd93aba30c81",
        "c6a6806e17191b7667b01a2c234fede8",
        "9147cbd78cb48ca7fd94ed9670cf0fc2",
        "98d03704c554a5a531c1f344384e7a8e",
        "6318ea7a7678638660328eb86f7bfdb7",
        "c98f16b102ca107cd0331a51cec89fe3",
        "c77564ab142335822e81307f2ee9079b",
        "e115b9b0b03fb582b00479addc7f4d2c",
        "d6b329bf48328944e36018001fce9098",
        "aa26fc5151810de13f92e77bd45fdcc6",
        "930e3f050e539b366b1dc225c03cb22b",
        "6e28e943db9e2d2c8258c02310ffe4ab",
        "7c07e20057ddb0200bcbeebfd46294cc",
        "b8196edc1988ee6347d91b6ad194e686",
        "fa6fb1543c3eff7232e4b6ce25d46023",
        "7cb35f71d5755d5413b908739b4161fc",
        "1e9eb705bbc526383cb42d44be54a75d",
        "938204689d389975d5e567321ee0ed2d",
        "0b1fe2f044052f066c736d3e0386b3de",
        "6d3c00eae75c36ef4c0c826858a8a732",
        "7a2eeb67972f892ad65a34bdea35fd15",
        "c3fdf9a42b063c2f6dd7b7b17eae80c3",
        "0db072246f82b927555b8b573116304b",
        "edac1016c296d9ace21f8ef49cfe8865",
        "872a7b969dedb90d60887d421b9dde5d",
        "2c2d3b3452984950de7cdc5ac5f4d663",
        "96e2e1c2cf900c89031a4edc54ac2815",
        "eaf02c69b781dd25607ddcd8a7877f73",
        "5cf804e525954b1129026e634f960056",
        "30ed827303c94555448be23401648896",
        "36e196d7f09a7b747064af190a8c63f3",
        "1d01d2007316e29bfac4da81f2b41a5e",
        "78afd07e0ded61af61d83cbfc2b30507",
        "90e99e26e89789426c7b3b73e62e2e9b",
        "80e725263ab0963410f0a86a7bc24dc8",
        "273b94540d46580bdf15f6fcc0a14d52",
        "b06c1b3e0632b00fca88d011088e4bae",
        "b33dc174da7887282a88f14635a48e3e",
        "44da3a242fa4d109663b1ea7ba1e5ddc",
        "5965913fa09f30e599885b00432f3a8b",
        "e78baa40131a10f0ce7f740483a05fa5",
        "52b8804c4cac3f53a087119675bb746f",
        "339cfd1bd2f96059d852717a10110ac9",
        "7267ef18630e79d6cba370c265d26727",
        "96a2a9ea70c92fcd05a65ca96d8d6322",
        "688a163e70abc2f37778662eb0e71d5f",
        "accc40af0eb3d03f7a534a1aca728076",
        "d750d5986996adaaaa360ebc8d4730e1",
        "ffc6eff876fbaf6b5e23146abb41485f",
        "1fbdffd000b2c7aac6bf256086e9de87",
        "bda2db145577c11c28f1be270eef68d4",
        "c4b3c35be9429c261c8a556b45eebda1",
        "1fd93cd2059133d7f70b7f9a8ba7176a",
        "52f0959a3958479fefda17b6f36569dc",
        "6fe22bd45e80b0eaca654846931aedeb",
        "525649e70f12346034e3459445fff056",
        "038abd16e10e0148067ac38afc57f887",
        "289739fc9f7908ee4330df1504d0ea65",
        "7509ee85331bb1184d8cc55a8392c7f9",
        "ac4359c3c775da62d2799deea4f7872e",
        "308bdf1e2ea0085db4caeb20409f4a39",
        "4d0ac3bac6ac42e2fd6df925fc7fa3bd",
        "b13118be71edee4b4b8f9559e647156f",
        "957c29e9358e9920af6e78ba835d10a4",
        "c33a3c8da76d4227ee73175b4d30e8d6",
        "92e5cd7baca10c7d9a1645dbd5f704c3",
        "7c9e815881c3ced0544120bd6971a86a",
        "1b76599b7ecb467bc0adf5f5f3508056",
        "f5cbb5314dbd1aa443c1006e084f9581",
        "e80ef5c87bd9b2206d407f0a436ab55c",
        "e2041e768b1645cce0ed0af83385b13d",
        "d4ba6fd233f1d2030854bfc7a8b1677e",
        "b8163d92c05000fce3ca06c344404271",
        "fc00bd6a8a697a566a55831d45f062f0",
        "39113bda18646bd91c4297daa74a4e7e",
        "a7acc4a6d208ba0adb0aa39d09732424",
        "2a4ad8fcc9adb3c23a553a53a9f86ae1",
        "1d2ef374ddc84cc4302e194c58a07cab",
        "25bfbc766e72a5ee3e9a49695e62f31d",
        "249a6e639c5f4592e0847c61ce8e5b8a",
        "c90c4c241cd9dbfdf505b3d0c57a8d54",
        "679dd61a8dc1e6ff9baa5a2434ad05bc",
        "760fc8d7d7ae7efa9aa0ee45221f83c3",
        "2ec18501dc0807f9b21e23a7523c9256",
        "acdf9180892fca7c34b0fc398d84bd4a",
        "43831962f3c01a805595e194e3f226de",
        "6f31eea232a7588aeabb8c06152f8c99",
        "7855ba718cde0d4cee74cfb71b79553d",
        "46d28cd63fcc4b2223525eee858e2fab",
        "af645c7a90877460fdbfde6085c88b2e",
        "ea712ca3110b1f5e620d404c2a34775e",
        "afcbf52f516521f453644ef109f4da40",
        "5392102022c36eb2367143e1226562b7",
        "091b5ad75e21cd023c64813ce139c108",
        "120109a5e305e2c66f0cf214c48b9902",
        "54721af092c379be511154a73e80fe61",
        "9500f2062e8f42e6ec4c17b378dd5443",
        "e2b85df0abd31c196716efe5c299f7e6",
        "f4dea7dc7d1c6a6bfd28371746dec6f5",
        "a760816341679ad95e11fab74eae6cfa",
        "49b99fa79e576ed9f4e5b825fa13fa3d",
        "3671ec69e79a213222e05f6d8dd5ac18",
        "3a38a6d642691f4532611f512644212a",
        "9340ee2a3ed2db9e270254c8ad5518d6",
        "c39c7f833188bf88f132f16107cca9c1",
        "9f7271efc034896d2fc05a884ff46931",
        "46ba54d4cb3e3cdd96f283353a614526",
        "84cfb7735f043bc6cc75516a5e351d42",
        "adbca451539bffd3eb4ad59f84ac9c83",
        "0a0614f82cfda66670c853d665f97137",
        "8715d5b2ab473463fa6d60ab7d21670b",
        "9695d496416f6ab3c07f821955587c8d",
        "0b8e432fb12f5a8956e742f3197af583",
        "34d8f8101a90969ae59b2c1b809540ac",
        "9f65e0d1a748964b23cb9c227ce8ca58",
        "d39ef573893d88240dfdf9fc30b7ad5a",
        "71ad91fa453c1baf0c3c9d06babcd5a1",
        "ffc680ce1f24e5fdbca8cbf603a0eca7",
        "7e900cc761c0070e16650a5d8724e82c",
        "32b10903c95cfba4f1f0b718e1de7bb0",
        "41ab6850d99f9b22b85b1aca1169ba5d",
        "ed25db70245bebdbb949405c18172627",
        "948c788e1b99b6b34808bb5cd2790d9c",
        "a9fcff33ee980e3dac2b3a3ddbab567d",
        "3ace9a2488106a310d55dd47adac466d",
        "85f759c9c01ff1d05452e3738de08bf9",
        "fe8cbaed4a7b76635cc51c746d1a68ef",
        "2b82d427395a673c554a2574555b1788",
        "479646a3a3d3be45e99aaf3543add7a1",
        "e11ef497573a956756bc2e63ff11ec37",
        "2147040eebb82d971e2fcbed65865d3f",
        "a7314fa6581a87d5911d6db2b0a26135",
        "3c3a958045ca301d0bad5a867e07780f",
        "cd208bfb21b9525b31442da431966ab9",
        "5407544a49b8bf7fb08cdefa01fe62d1",
        "7587a919b0ec87287c6b1f0a51cba4f7",
        "cfcd05673c430d0087e613551c8b239f",
        "18968339d0d0d1af306acf28fadab372",
        "d032548f4fd9c909786181f36212021e",
        "d0620ae80dd8dbf2217cb2c886222c5a",
        "614abf56da67987e4c5851bdf2efb270",
        "7ab94ed87deeaacc8ec2e0c8f9963573",
        "8def0e649108793bcca76daa2e9715a0",
        "88c899f73a0210ed7a52f6e3c129d910",
        "3644ed81ad7acf375467db23ef135372",
        "9fe9ca2b25b3b09b1e4d4cfac998dbdb",
        "570686a41686623a158778ce031d4c6b",
        "150b60d60b17d82cb19f01be33ee34db",
        "39744a3f91ab15089ebd9a9d87882a1a",
        "cab15bfd0b989c7d3f92f4e2c3715cca",
        "0677216d8db010c7b2f98eef64093bb9",
        "9dfcb9c50ed108c88a9bba5c530b6fd8",
        "e7b8110cdc111d5d1311289fdfdfde23",
        "9da4b015509cb17bcc1120eb7ed79ba6",
        "9a773b06f35666ed8b48d5dbf7a6394d",
        "d29888c23c9b9ba031ff09d53f42f859",
        "ad8e11e470328cd327958d240b736b7c",
        "d5bc0d568d764a5d5b58d0031c6cef3a",
        "f76854a8bae0580ad199d8335429057e",
        "4919b280fb5318177912059a44290dee",
        "967f855c4742f30331d39bc95baa2c84",
        "81f8fe1d6700d48f407863e3fe360a39",
        "3c36f9e72dad40230177c31c1084bff0",
        "23f61e2e9afdef2abfd64345d4908895",
        "39963701dbd5d8bf29361ac55816d782",
        "88f35f3667b9bb72f9e872a47e0bfd7a",
        "ab8521290140f25e09fde8bf94aa933b",
        "43d503ed73b506872cb4881ace317a22",
        "26c3baba39111a0d5f8f3714c4aedc87",
        "97defd9cde06889e445ab56ada1fde61",
        "6f67a1e35f33e87ca3904f2e5aea8fc4",
        "87894f1cd732eaf79e51a22895861ac3",
        "7ba9be3f2049b205cc7e3e161ee95bf2",
        "d557a1c5fe0d1aae94c7c3f6b1ec5c40",
        "322485a8d4351b93138ddf723c785247",
        "2a00c7753e3ffd57183525a4e3a21e8c",
        "68c9981c6be9799e2e0f85adfa6a956d",
        "5ad9dfe60e4b5fef64682e44b56432c5",
        "97a286a3388960d8adbd7c271e120185",
        "b4f4342f74f32a26b2e84a0407c9feea",
        "11b419c6967bfd36c8c0d7f14850e831",
        "0d394b56b41d09a6a5c1bb1680308abc",
        "63eee8712a9e881489528503f6ed8c47",
        "e12fc621adb9e905cc694772aac5d0a2",
        "cda1e0c088cbf0e99ba7e3ca54d63773",
        "ee7e21d6dc4ad44e394f9d812923720d",
        "0a5518b43ac9c43ddb1b021602764656",
        "173b08bf0b91d1abf4e180e408b7ba84",
        "11f3574e9e4d792f45256fb87ce7ba47",
        "c5f21e22575155e858dbfddbc88828d8",
        "00992474545aa9e39ca749f6ebbaaedf",
        "35b6e3f9412b6d4b7e1d6e6ab22ad57c",
        "40dc8eabeee6b33b293c99be4258d623",
        "99350aae44eb5a9734e4dae593992faf",
        "cf6cf785159b7febd34f6d90544ae84e",
        "5b1dcae168d906678a55893982378c99",
        "c254ed49461592247d5f561dd9c29c85",
        "b0726ddfa58450fb8b5d5ffd0f324109",
        "49dae4a556ebe214ec5191279e2186db",
        "0e071ce469264adbaf1e515ab2c4af9e",
        "fd2fd128d6c6ef25e5f957838e32ec89",
        "95af351fa98403b131656abe8781a267",
        "4aff9dc0e07ac95e9c0418a5d8e4664f",
        "4a681fa0b72bfbf3eceec8fefb7650dc",
        "cd7951bd51c1efe25cad2a26b2861da0",
        "3fe2e00b7d07d5f16a1b85bd6457a640",
        "77669a2bfd4a7fc53ef2e47dc19db757",
        "230000d176f79b24c67b81c257d665b8",
        "db31b2a314a70ed5797451105469027d",
        "920dc5622dfa7743efb3e2ca2194a730",
        "be9b02898536185abc9a16b69493c770",
        "5e798961ce8a01ae2b37a5f60b9f333b",
        "e7774aaca51e19640a9ea39642c3c049",
        "078b9ed01106663e4e6b95e8cde96fde",
        "0b1ce5c85148f50941d6878264f662c9",
        "087cf145118ec21cd048934a6bd09f88",
        "a95ab30a68cf9a6c3bd5705db15fec29",
        "69aa5a52660805bc4a670cbe80d7f988",
        "0c13325d4f7a451c4783696956ca6bee",
        "11c6b28c88d116e1eae0300e39c54165",
        "4b9fc8bf456bd04cab409b04170955ec",
        "d3568018f11635c162d78cb6d098503e",
        "6d8f27a8f2e99ba0a351cd8ec051f878",
        "868cb196318e33de424d2f754c89fdea",
        "01b03555349c49810a0bbcb6f70cf683",
        "e3459b3e466df8f467f7fbac6b6a36c5",
        "39196a370b0c4175ce8ed8303070449f",
        "9d68f241ea941c77deff5e4855a1f509",
        "83998e10070c2e92d8f55d4a3b895888",
        "163eefc53f1673ab881d3c906eab0660",
        "dd383ec1dc4277227fea25bee3483778",
        "aaa9b6cb9613beda3c8972c21a411fdb",
        "9fc38fbf63c9cf1a3b62cfa85c97b175",
        "66e97fe8de96b7e7c55c54a1b43c0ac9",
        "2d72bed35e6b9abf42b8aa02dfdff8d7",
        "72bbcbb48ddbf2bbebabb5bb675ee5ea",
        "acfbffbda5e8c04b2ec72aaab2b2f5d9",
        "7b4770e3cb8eb950e580ce15111054cd",
        "71d641a3c7cf75109c6fd105eeef8349",
        "a8c36385150c01ef64a9eb0f052e4e82",
        "4d11981dce18328df5ea1924ee5a16ae",
        "e2148c2510f0b336bbd729e71c34bec0",
        "8ab843bb6b5a220e841e7056283b5421",
        "aaad6ea58d10d314b093a7674e07d828",
        "244eb74918955178466db438cb6203da",
        "ed7571c76be988d4a1de39ce182c2393",
        "b34b91688368c1944edcfb7543996b7e",
        "b2787912a429bf4ba38e3166a7b439ca",
        "b81ddea3a858688f79c56671f601f06e",
        "3ee9b7926b82a6dd02f42090abf9cff8",
        "1fac4ec508e16636b7fba39705493ecd",
        "7af62c6ed752f5029b8387e765ff304a",
        "f575013f98d188d34c76b46ec7c0ebd4",
        "9815bc0a19a7aaa0f15f2edc39e0439e",
        "adadbab938d1b55784708d21e94f81e8",
        "42e08562a7e6da02eb258601d3344467",
        "58f6de29e33b67d1388fc9dfd916700a",
        "92a1e246a23c1553691f834f1558013e",
        "0ab18426ef97aa784356b5e77466036f",
        "6b61c9eccc1645d4a04dce30fd65d52f",
        "4bd8bd7e5a6fcdba1c1685eab0bbfd58",
        "b320132eada7353267d54bc319478bbe",
        "03239cf78b756ff6c72a00384233935e",
        "8121c9079d6634be0e8f0b9d073d4d56",
        "cf9be7602a593cd2b4601895b62fa0bc",
        "71fbc13f06966fd22df1ec430e2b7f1c",
        "c658b9d9ba062fd92471a818592e3b61",
        "fa201e377ca07a8fd1cd2804d4ecdb1a",
        "4d843fcf12098d7e7b518cebf91b3577",
        "59b92f786594f8dc0986d8681243a3f9",
        "0af34709943b966ef935f9cabfa6382f",
        "fa468192881b364272aa7d7fdb9efb77",
        "53e757c2c289d48b779dc94a43fd48ca",
        "97668eb4e2bd4f27899a116b663d54f1",
        "4a656b4e19723a90e1e5862eeaaf6cf3",
        "1d1df3060a9beccfdb49a600bf078001",
        "b14af2774c06cf7fd045bf7896ba8ba1",
        "a01ba156d745d298dc75a432faf3b982",
        "0bcf0bac9653f1913a891e2d733d48ad",
        "ade26bde0b1d703e5babdf55c00a55e1",
        "d9e27368301d9a74912c7e9c8e4c6e23",
        "15774be39c3704055d418df9749d5aa5",
        "0a810ec2984817b7eb149972be347654",
        "b93403ee157b419f169ab97ffa5df146",
        "dafc2823eefc9989ae390fc6f1639c56",
        "50171b1a81ee0ce8479eb165e1766e83",
        "fea74250ef3fca716cba908e8e54b655",
        "a979eed220fd37f3e717e60bc2acca9b",
        "8f753447e5026b3de090c3f5d5b25109",
        "0533ad6a99cadb67ef8ba0c6913732ea",
        "29583d4719fad19435ada31571f68d17",
        "718d6ad44037758b61b69081998eb2b6",
        "e831279632d6cdf43a66e594e492e387",
        "3d0c8bf34a069564970678c378dc9a3e",
        "29c6f174763783d6159be109857d48dd",
        "b24555af6abae9e1351153b8948ccdc2",
        "53fb9873faa94e7fd3410faf2ea574d5",
        "690e32121339c64d54a8cceed3b8fd1b",
        "b263c5a04db73be10c1a9c30fc593e44",
        "e80b5755c29df9218394c4fa795377df",
        "f94da34d0698aaa0d8d2e8d501caf4ce",
        "0983f4d12cdf15d93f2238c0a34e36ae",
        "531dfd6bc78037df373d1346c7248e88",
        "ce0937233f5b97e437cd26c6f2395e14",
        "14c3615f5c2927ae23d8c128e4e5b5cd",
        "02acc89e28c169a90c08ce681a949f4d",
        "33813ef0a9d9714ebbec78c8d78cb463",
        "20feb40421afefa0d53dff3f902be7dc",
        "acf7844c386ed66ea791345dff22a510",
        "e6e295deb04a6b206ad251996074e3fc",
        "16bee30587a300bd80cd50aeb6365bc7",
        "7946647e4e7a472cf9ec9eb7d7ceb8ae",
        "f985a2a778c04950977eaa3f483fc230",
        "967b43d671604bdfd526b14b3c9c82f8",
        "1f0d333aa2de23d3d9f49e88a30cbf49",
        "298d8494d4180bf36567ddeafa97bb2a",
        "cd2846f32d26904e8fb344e7e819c965",
        "1886c7551b20bea82c6fa76474d0d085",
        "3d5f65099670939f31af2a665e07beb7",
        "d20700e354c2a61375264813a6b09eba",
        "d74e5df010709a0503ee2641c889b472",
        "679c5c4b4e3d4096278001d56b12412d",
        "e866ff9957e63b988951fc98268cccbe",
        "cc9676333e7995723f6f691d749bc2dd",
        "de06e09caac17842a9adbe0f3e4edca6",
        "1dc65b1d18bd9a9bad1be462a184fed1",
        "ef6248b20936813a67a19d7eb3042880",
        "f5545d4a2dbbc4975e4b5394a21004ee",
        "54bf181f0fcd9b1e815b4dc50e9f53e8",
        "79e8bef92b633f90de6ef01dccf2c204",
        "077e031f1bc22d21e8acc3e1c9ab8a90",
        "42e630605e979f2f07835e6bb26f4f72",
        "4ddcfc195aa8878ff164f0e165ad17b0",
        "8a5fce2ccbb3511ac19e3f6960580a49",
        "86600e8068e146c37dbb122ef774c6e7",
        "0f73686e24abd542fc341ecdd17d44c9",
        "05a0a502d7bdd2f1a8dd50c882c7fa53",
        "1475a5aa9f349318a68ba64ed8d0d370",
        "e4d5ebc799b8cee31a83feefd2db5851",
        "a64c6681ab03db9dba8f7ce602f3bd9a",
        "ef0b7d16405847590648a3bdbb7175fd",
        "38def21954a9c23b746de95f647cbec4",
        "b90441e947301a3230358206e83bec18",
        "6f4f79c3b6f132152fd2abc5130b0265",
        "32bd0499c1f2b526308759c7a34fc642",
        "391a05ccbbb67987bd885037bdb89952",
        "c1232773e381c27ec8ce4c277eff33a6",
        "300a3c4efe210b21b2687d40a8a33903",
        "e30bf2edd1e75be154146e1f20ac0ab5",
        "9836d776ae21314ef8a197abfaa2c9bc",
        "a74add9486b81c5a225a03528f9716f5",
        "890cb33d98ef357c8074b743f6478e1d",
        "a1bca00cb63c73ab1702786969d276de",
        "a2790248585e37fc60ec294b1cbd0db1",
        "f8039ece9af1c037cd84a29b68e0a920",
        "dbc583428cc93d386de4b79e1f050dc9",
        "67a4fd6e819ce818928bb7f7c11b16d2",
        "4416b532b5c165f0f65aa569bff5f811",
        "3e21741ca155344fed4af1be3ad3adcc",
        "edb9f325703c5d040c83ce9bbf76360d",
        "ffcccca9e4341459c176816d04f94b52",
        "9766e9647a28e6da94cd6f38394e2cdc",
        "fea6a0d6a83b92007427b2590502a035",
        "74dc6306efa0c87006d86e3bdea2b7ee",
        "c92259854c93f31bd1bdcc135f370c91",
        "a839cd0be233ec5c074ab2f62f07c6a2",
        "18d35ba1d5179f228f00a04801d5daa8",
        "bfd4c41bae0aef1c9b742a4fc1e083c6",
        "57fbb565f9c8728f12c871bfd8ec2c30",
        "5c4aec0999a3814c7b3baae2a7e0bcf3",
        "5803e4df8e335e246f522c6ba91e2fb3",
        "89d45a7704b7f8b59e528119eddd5e12",
        "5aab74b3dd4fcf91eaae91f9e8d525d6",
        "c6cfb77b07a66f5252c040c3651910ed",
        "29c220f07a6ae653f3ae7f95b4144af6",
        "3d0ac52800da7159d78fa3c2b0e36ce9",
        "f86cab2dd8b06531ce0c8a796d72ef5d",
        "408cbe73fee4777c69985b42ffe1757c",
        "d2ccb97b4a2b0f72bc76320b82d0bd7b",
        "74f58d935e59210b23dda32282dc95c0",
        "de7669967f896e37a145e1623e260ae7",
        "f57c5633c242ee57f2be34754eb60e43",
        "60e4f158e2e1a9c07941c4dfadb1d071",
        "06466148de2c2fd06932005944ce32f2",
        "4db21ed821bdad1850323fc3e7a5b73c",
        "34a95ffbbd77f53eca85ff3d55a458d6",
        "7986eb7147b789414218a5e1a75bf59b",
        "aef2376fd0955139dc9182d62c2f5eb2",
        "47a4475cacd9aafa5ed29f947836e811",
        "e27d40498d1983555d1b9346456cc1a8",
        "391b86da9e646ff7103f49a6deb9253a",
        "e5c0c9e3e38ae50e1c33ef5d3004ecb2",
        "33fa91805ce34ee8367593ff236a4e44",
        "f7394254e9fbc61e42f74d48b3aee69d",
        "a243246dec1ba0d710a522055ce331b9",
        "5db84f9f0cc5c6aca7c86131fe6c1435",
        "767ee618531806222c31a43e2e66f036",
        "281addc9c402df4fdc63d3acf02d3c9e",
        "7cb45031550d3ddb28ee8387a60da2f0",
        "5612e7421a4d8a7d3191ba7ccd1cdc5a",
        "0113f60c0c133a845bd050c909862e64",
        "c0f3700264afa803d14d80e1aa929d41",
        "d21dc8263127eb68963bf0fc156caa64",
        "6d1a4ec7fd9e294be06c3fe9ad5a6f18",
        "b4c09b49858d660e0a2a19cf0d06187c",
        "02edb7368f5920281a977502ac0b3cff",
        "08b595c071be736ac9741e9e5349053c",
        "af51456605a608d1a9528f8b6cf00503",
        "d066b79b395af4df5329128975a6d650",
        "b72fe26074a148fab7b80da5d38fabbc",
        "d86aa5f2716c6beb9a93e143889a71d6",
        "1152848d12227009f8dd11001c9b3583",
        "e61c4fbd7dabbdc784302208ce3def38",
        "f50ab36adc8f0cf593cdcb92460022a0",
        "f25adb191b1f5e8fab922c0ac48342d4",
        "609e3e1302d9122979393ea791ba123f",
        "83b65b48db7c56696fe48d458eee9544",
        "fe191181ec682dcc46249199b9e76bad",
        "d6c303b0a5135edebd640369dfc3a5d8",
        "b12c79cb112e968630b7f0c62f7ad121",
        "649133d17cf556520d9b4fbdc78cf882",
        "0dda3c617ae3bcce54437a10a3a6308a",
        "1bed891b4ea7221ac03d79a9275b43ad",
        "74a682dc0dbc2cc67ef4936919f2add0",
        "0ccbf17a1c885c2637412061b8c4c7af",
        "8e1f047808589e405c818c1037acf346",
        "5db03a31d730baef9b09cc7e8516b709",
        "0c44014de8f09e8185f1898bb2635b47",
        "c71a3543e15abb8d7051c29a721b1f58",
        "3090b5fbc7db5eeecd7520dd25e59e9a",
        "039e9fd1b37f73b4805e61371bd5e63e",
        "465ef7590649124e1de2add1b08baa7a",
        "6d00492003a846c85a60c4fd87473a73",
        "e2ac7e523696c2f5d160acda0417eb35",
        "c6bb980a95192cb194697bd2c060ea9e",
        "2bde9957ee44db8e6d2484b3e91db7d4",
        "6d6adff5cf225683154ae52b6b720bd5",
        "8cafdfe308f17c3c353d2b43cebad8b8",
        "97d1586a25009a02b9a1e23fc3070866",
        "d81b378a4562966b1270ebf06ff46f71",
        "583c5c79bee302ae7d585d0f900276ad",
        "b88611f55a6e060c07c9fc940bcd00b1",
        "8cd92d8a7b897698e8cf6597d8da3ed5",
        "8478029a53cbc6e62922ca7606bf15e8",
        "3dab31df2e5040eab0ed8ae861a45a7a",
        "473bf195001add409f480df42f2ba3ed",
        "4d1a671c871f6fcee47bae286982bde8",
        "67dc951903968c873bb8ad6b97230adb",
        "5a118f9383857176181e8c27ed1bdc79",
        "e1009bd0b9cef841f467b0fc37ee31f4",
        "f6328f5e9ea00023ad2030d96eaebfc0",
        "f6ee76294b242f5b26088ef90a55763f",
        "a343be23923ed4a3128bde6141fd5a36",
        "3bb998986b2365824274e2da512ba003",
        "328e620e0cbdffa03d9eb32326d45cc2",
        "565d58347b67c893573d0e924c27715a",
        "548beb8bd552847a68de115542567e01",
        "66f77bce0aa8da4c009127fa4d7eba0a",
        "8541c154723043da0fc18e00d68583e9",
        "7a3a748ca2e095bcbcd8b4332b949a2e",
        "4036954ab198d20a508a1ce58df90fdf",
        "dc91f054f958f2a95ba60cd01f764f46",
        "382ea761e15db12da42e7b4f84ed2279",
        "0db5741ec37b8ebcf0849e2e5757edab",
        "5b0c7b3ff50d1a0a4930b1a1c88cc5e9",
        "d70dc5f558a44d69da0db455b142ac02",
        "f412daf47bdda085a3725a355f475d95",
        "0d1481de5aa34076e77b2606d23fb7c9",
        "e7112601b9b920f5165c771fadac810e",
        "41845072de7c6ca8c8a1fd37f1df9eb5",
        "c7e918b0919db6353bae898e4aef671d",
        "b98d35fb573d38a2b0a44d6e60c6caea",
        "737650af385c56d4a5efb749f3fa0018",
        "99556317513cfd3207ca8a86035608dc",
        "c7c200187b52267551e00ee9c3836cff",
        "7a52405693ad10b3fee905bca42e4c57",
        "0bb8140c68414660f5a130b455e41ccd",
        "b8e703d9b13305139f1f1f320e57c075",
        "abc4b68b2f73e1e9f6f9ee7f4f727f6b",
        "c36dc582af05289e79cb119022b8de34",
        "d84f1881a238330260d12d64fce8dca8",
        "b64da888416114cc067d0253c0bcf2ba",
        "444b944363977dc5e26ed289a3d8ce05",
        "abb7ba106b650607f2898f98b80a4158",
        "ec822b2aac398c66d0628721112b74b5",
        "fc5f77ce8d14394e1015717fe333edca",
        "a998f182189e0dd3ed04597a9bb0440f",
        "a2ec9ba62da4318f44ea51004ca59aee",
        "03d6d655c532794ddb662a2ffabe0afa",
        "8fe0a8cc7b05d21f74d3ec9c4aea5043",
        "164ca2669025e10174562ac2b5c48a33",
        "9ac7cf9f3e65d9f49405e2264643215f",
        "ebccf8dd01882bbcb2d81ada7760a58e",
        "536942f52d1a90fd655dd1aef75a0626",
        "5ac97646c7c5cf63ef7a7a46c5eb3b55",
        "814913204dfb20671c95e17f4ea181a4",
        "ff04c712f7567e2ebff2efbd3f21a68c",
        "0d72931ec67149a63d26ae4043f573f4",
        "757fbe31eebc705014d26da1b9bd2833",
        "e5964ce46be4fcab7588cef4eaf2a955"
      ]
    },
    "D": {
      "count": 42,
      "ids": [
        "920ed48a2e6919d0302d27cfea7d4439",
        "dbbb1cc15f2ba41a7fe246214caa5a83",
        "d06a3b1bbda695afb16a09240c4fb6c1",
        "36b7da3495940325e7bc8ff5a401c1e9",
        "ffef5eb1b1c8a1942c2c21d85aef9c1d",
        "e4e43a127c56d584bafc752c54170932",
        "25e9d6b974ccf630a27fd7c31168ec59",
        "7e03fd4216c27fb8e80046c513426133",
        "a99334f3f152d07df59391d25204899c",
        "24ae7d44751bda78f0720202f6e07fd8",
        "5c116f1967207edf9d2ea1129f424fe3",
        "4ee2e6481e222aab0c4ac505b83a2a9a",
        "e25644b1643c64d756451ad491f79f25",
        "9398c3d806bcfb9be465ca7e8bdfd0bd",
        "1fc610bb3ac586c24b19e53bac353faa",
        "f25f951b9b234fa286ea99ddae9845a2",
        "d3e459c9ddb898600e3fef406cad9fc7",
        "acd6029ca8d0d05ed6487eea02bc1521",
        "eea465a53b3303ad51d8deca3cdfd324",
        "69370f2d7e19b5697985e459bd3c384c",
        "f21202deae896a9ff5f55f15123c8567",
        "d01abc5ab7529f46bacfe74296030d85",
        "ec17f54f37994f5e56e3afee03ccca70",
        "b672e9083f449f3f05f2771b44da9039",
        "78a0abf6d07fa1a5533ae373765ffc98",
        "4a18d2b5d31cf4f6ef95891fc4a17af3",
        "a12410273e2bd2ccb17e3e5ae3cf3268",
        "2fb155a5f291037359e1035d47738cc5",
        "a4778d178c7ad0787b7be20b4ae8b4e8",
        "a868ff09622fb67e1dab65382980bd2d",
        "9c4de83d6658cc1ef0b4a5a7c55f1f8b",
        "d4e73502d25de6fd69c0d0da2502acf7",
        "4b0dff98bfe8032377b68f741de6d3d8",
        "83415c84d7f82f40c13a742cb05cd369",
        "11d646d4ca11334a109bde33473d4714",
        "af3bc696094ab596aae8ead085e189f4",
        "804c3e6a5de78990c31b9be0cdc33db3",
        "1c29fda91c1d59d7378577a023bd1405",
        "54b32eafe768b0255420f8ee3b24135d",
        "86bc7c68561ac26c613739b1858dbe8a",
        "b639fcc1a67ecaab577f80bdcf6a25f2",
        "92b209fe72c0859e3fd9ac8e4a6002e6"
      ]
    }
  }
}